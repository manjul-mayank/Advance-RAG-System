[{"source": "1907.11692v1.pdf", "text": "arXiv:1907.11692v1  [cs.CL]  26 Jul 2019RoBERTa: A Robustly Optimized BERT Pretraining Approach\nYinhan Liu\u2217\u00a7Myle Ott\u2217\u00a7Naman Goyal\u2217\u00a7Jingfei Du\u2217\u00a7Mandar Joshi\u2020\nDanqi Chen\u00a7Omer Levy\u00a7Mike Lewis\u00a7Luke Zettlemoyer\u2020\u00a7Veselin Stoyanov\u00a7\n\u2020Paul G. Allen School of Computer Science & Engineering,\nUniversity of Washington, Seattle, WA\n{mandar90,lsz }@cs.washington.edu\n\u00a7Facebook AI"}, {"source": "1907.11692v1.pdf", "text": "\u00a7Facebook AI\n{yinhanliu,myleott,naman,jingfeidu,\ndanqi,omerlevy,mikelewis,lsz,ves }@fb.com\nAbstract\nLanguage model pretraining has led to sig-\nni\ufb01cant performance gains but careful com-\nparison between different approaches is chal-\nlenging. Training is computationally expen-\nsive, often done on private datasets of different\nsizes, and, as we will show, hyperparameter"}, {"source": "1907.11692v1.pdf", "text": "choices have signi\ufb01cant impact on the \ufb01nal re-\nsults. We present a replication study of BERT\npretraining ( Devlin et al. ,2019 ) that carefully\nmeasures the impact of many key hyperparam-\neters and training data size. We \ufb01nd that BERT\nwas signi\ufb01cantly undertrained, and can match\nor exceed the performance of every model\npublished after it. Our best model achieves"}, {"source": "1907.11692v1.pdf", "text": "state-of-the-art results on GLUE, RACE and\nSQuAD. These results highlight the impor-\ntance of previously overlooked design choices,\nand raise questions about the source of re-\ncently reported improvements. We release our\nmodels and code.1\n1 Introduction\nSelf-training methods such as ELMo ( Peters et al. ,\n2018 ), GPT ( Radford et al. ,2018 ), BERT"}, {"source": "1907.11692v1.pdf", "text": "(Devlin et al. ,2019 ), XLM ( Lample and Conneau ,\n2019 ), and XLNet ( Yang et al. ,2019 ) have\nbrought signi\ufb01cant performance gains, but it can\nbe challenging to determine which aspects of\nthe methods contribute the most. Training is\ncomputationally expensive, limiting the amount\nof tuning that can be done, and is often done with\nprivate training data of varying sizes, limiting"}, {"source": "1907.11692v1.pdf", "text": "our ability to measure the effects of the modeling\nadvances.\n\u2217Equal contribution.\n1Our models and code are available at:\nhttps://github.com/pytorch/fairseqWe present a replication study of BERT pre-\ntraining ( Devlin et al. ,2019 ), which includes a\ncareful evaluation of the effects of hyperparmeter\ntuning and training set size. We \ufb01nd that BERT\nwas signi\ufb01cantly undertrained and propose an im-"}, {"source": "1907.11692v1.pdf", "text": "proved recipe for training BERT models, which\nwe call RoBERTa, that can match or exceed the\nperformance of all of the post-BERT methods.\nOur modi\ufb01cations are simple, they include: (1)\ntraining the model longer, with bigger batches,\nover more data; (2) removing the next sentence\nprediction objective; (3) training on longer se-\nquences; and (4) dynamically changing the mask-"}, {"source": "1907.11692v1.pdf", "text": "ing pattern applied to the training data. We also\ncollect a large new dataset (CC-N EWS) of compa-\nrable size to other privately used datasets, to better\ncontrol for training set size effects.\nWhen controlling for training data, our im-\nproved training procedure improves upon the pub-\nlished BERT results on both GLUE and SQuAD.\nWhen trained for longer over additional data, our"}, {"source": "1907.11692v1.pdf", "text": "model achieves a score of 88.5 on the public\nGLUE leaderboard, matching the 88.4 reported\nbyYang et al. (2019 ). Our model establishes a\nnew state-of-the-art on 4/9 of the GLUE tasks:\nMNLI, QNLI, RTE and STS-B. We also match\nstate-of-the-art results on SQuAD and RACE.\nOverall, we re-establish that BERT\u2019s masked lan-\nguage model training objective is competitive"}, {"source": "1907.11692v1.pdf", "text": "with other recently proposed training objectives\nsuch as perturbed autoregressive language model-\ning (Yang et al. ,2019 ).2\nIn summary, the contributions of this paper\nare: (1) We present a set of important BERT de-\nsign choices and training strategies and introduce\n2It is possible that these other methods could also improve"}, {"source": "1907.11692v1.pdf", "text": "with more tuning. We leave this exploration to future work.alternatives that lead to better downstream task\nperformance; (2) We use a novel dataset, CC-\nNEWS, and con\ufb01rm that using more data for pre-\ntraining further improves performance on down-\nstream tasks; (3) Our training improvements show\nthat masked language model pretraining, under\nthe right design choices, is competitive with all"}, {"source": "1907.11692v1.pdf", "text": "other recently published methods. We release our\nmodel, pretraining and \ufb01ne-tuning code imple-\nmented in PyTorch ( Paszke et al. ,2017 ).\n2 Background\nIn this section, we give a brief overview of the\nBERT ( Devlin et al. ,2019 ) pretraining approach\nand some of the training choices that we will ex-\namine experimentally in the following section.\n2.1 Setup\nBERT takes as input a concatenation of two"}, {"source": "1907.11692v1.pdf", "text": "segments (sequences of tokens), x1,...,x N\nandy1,...,yM. Segments usually consist of\nmore than one natural sentence. The two seg-\nments are presented as a single input sequence\nto BERT with special tokens delimiting them:\n[CLS],x1,...,x N,[SEP],y1,...,yM,[EOS].\nMandNare constrained such that M+N < T ,\nwhereTis a parameter that controls the maximum\nsequence length during training."}, {"source": "1907.11692v1.pdf", "text": "sequence length during training.\nThe model is \ufb01rst pretrained on a large unla-\nbeled text corpus and subsequently \ufb01netuned us-\ning end-task labeled data.\n2.2 Architecture\nBERT uses the now ubiquitous transformer archi-\ntecture ( Vaswani et al. ,2017 ), which we will not\nreview in detail. We use a transformer architecture\nwithLlayers. Each block uses Aself-attention\nheads and hidden dimension H."}, {"source": "1907.11692v1.pdf", "text": "heads and hidden dimension H.\n2.3 Training Objectives\nDuring pretraining, BERT uses two objectives:\nmasked language modeling and next sentence pre-\ndiction.\nMasked Language Model (MLM) A random\nsample of the tokens in the input sequence is\nselected and replaced with the special token\n[MASK]. The MLM objective is a cross-entropy\nloss on predicting the masked tokens. BERT uni-"}, {"source": "1907.11692v1.pdf", "text": "formly selects 15% of the input tokens for possi-\nble replacement. Of the selected tokens, 80% are\nreplaced with [MASK], 10% are left unchanged,and 10% are replaced by a randomly selected vo-\ncabulary token.\nIn the original implementation, random mask-\ning and replacement is performed once in the be-\nginning and saved for the duration of training, al-"}, {"source": "1907.11692v1.pdf", "text": "though in practice, data is duplicated so the mask\nis not always the same for every training sentence\n(see Section 4.1).\nNext Sentence Prediction (NSP) NSP is a bi-\nnary classi\ufb01cation loss for predicting whether two\nsegments follow each other in the original text.\nPositive examples are created by taking consecu-\ntive sentences from the text corpus. Negative ex-"}, {"source": "1907.11692v1.pdf", "text": "amples are created by pairing segments from dif-\nferent documents. Positive and negative examples\nare sampled with equal probability.\nThe NSP objective was designed to improve\nperformance on downstream tasks, such as Natural\nLanguage Inference ( Bowman et al. ,2015 ), which\nrequire reasoning about the relationships between\npairs of sentences.\n2.4 Optimization"}, {"source": "1907.11692v1.pdf", "text": "pairs of sentences.\n2.4 Optimization\nBERT is optimized with Adam ( Kingma and Ba ,\n2015 ) using the following parameters: \u03b21= 0.9,\n\u03b22= 0.999,\u01eb=1e-6 and L2weight de-\ncay of0.01. The learning rate is warmed up\nover the \ufb01rst 10,000 steps to a peak value of\n1e-4, and then linearly decayed. BERT trains\nwith a dropout of 0.1 on all layers and at-\ntention weights, and a GELU activation func-"}, {"source": "1907.11692v1.pdf", "text": "tion ( Hendrycks and Gimpel ,2016 ). Models are\npretrained for S=1,000,000 updates, with mini-\nbatches containing B=256 sequences of maxi-\nmum length T=512 tokens.\n2.5 Data\nBERT is trained on a combination of B OOK COR-\nPUS (Zhu et al. ,2015 ) plus English W IKIPEDIA ,\nwhich totals 16GB of uncompressed text.3\n3 Experimental Setup\nIn this section, we describe the experimental setup"}, {"source": "1907.11692v1.pdf", "text": "for our replication study of BERT.\n3.1 Implementation\nWe reimplement BERT in FAIRSEQ (Ott et al. ,\n2019 ). We primarily follow the original BERT\n3Yang et al. (2019 ) use the same dataset but report having\nonly 13GB of text after data cleaning. This is most likely due\nto subtle differences in cleaning of the Wikipedia data.optimization hyperparameters, given in Section 2,"}, {"source": "1907.11692v1.pdf", "text": "except for the peak learning rate and number of\nwarmup steps, which are tuned separately for each\nsetting. We additionally found training to be very\nsensitive to the Adam epsilon term, and in some\ncases we obtained better performance or improved\nstability after tuning it. Similarly, we found setting\n\u03b22= 0.98to improve stability when training with\nlarge batch sizes."}, {"source": "1907.11692v1.pdf", "text": "large batch sizes.\nWe pretrain with sequences of at most T= 512\ntokens. Unlike Devlin et al. (2019 ), we do not ran-\ndomly inject short sequences, and we do not train\nwith a reduced sequence length for the \ufb01rst 90% of\nupdates. We train only with full-length sequences.\nWe train with mixed precision \ufb02oating point\narithmetic on DGX-1 machines, each with 8 \u00d7"}, {"source": "1907.11692v1.pdf", "text": "32GB Nvidia V100 GPUs interconnected by In-\n\ufb01niband ( Micikevicius et al. ,2018 ).\n3.2 Data\nBERT-style pretraining crucially relies on large\nquantities of text. Baevski et al. (2019 ) demon-\nstrate that increasing data size can result in im-\nproved end-task performance. Several efforts\nhave trained on datasets larger and more diverse\nthan the original BERT ( Radford et al. ,2019 ;"}, {"source": "1907.11692v1.pdf", "text": "Yang et al. ,2019 ;Zellers et al. ,2019 ). Unfortu-\nnately, not all of the additional datasets can be\npublicly released. For our study, we focus on gath-\nering as much data as possible for experimenta-\ntion, allowing us to match the overall quality and\nquantity of data as appropriate for each compari-\nson.\nWe consider \ufb01ve English-language corpora of\nvarying sizes and domains, totaling over 160GB"}, {"source": "1907.11692v1.pdf", "text": "of uncompressed text. We use the following text\ncorpora:\n\u2022BOOK CORPUS (Zhu et al. ,2015 ) plus English\nWIKIPEDIA . This is the original data used to\ntrain BERT. (16GB).\n\u2022CC-N EWS, which we collected from the En-\nglish portion of the CommonCrawl News\ndataset ( Nagel ,2016 ). The data contains 63\nmillion English news articles crawled between\nSeptember 2016 and February 2019. (76GB af-"}, {"source": "1907.11692v1.pdf", "text": "ter \ufb01ltering).4\n\u2022OPENWEBTEXT (Gokaslan and Cohen ,2019 ),\nan open-source recreation of the WebText cor-\n4We usenews-please (Hamborg et al. ,2017 ) to col-\nlect and extract CC-N EWS. CC-N EWS is similar to the R E-\nALNEWS dataset described in Zellers et al. (2019 ).pus described in Radford et al. (2019 ). The text\nis web content extracted from URLs shared on"}, {"source": "1907.11692v1.pdf", "text": "Reddit with at least three upvotes. (38GB).5\n\u2022STORIES , a dataset introduced in Trinh and Le\n(2018 ) containing a subset of CommonCrawl\ndata \ufb01ltered to match the story-like style of\nWinograd schemas. (31GB).\n3.3 Evaluation\nFollowing previous work, we evaluate our pre-\ntrained models on downstream tasks using the fol-\nlowing three benchmarks.\nGLUE The General Language Understand-"}, {"source": "1907.11692v1.pdf", "text": "GLUE The General Language Understand-\ning Evaluation (GLUE) benchmark ( Wang et al. ,\n2019b ) is a collection of 9 datasets for evaluating\nnatural language understanding systems.6Tasks\nare framed as either single-sentence classi\ufb01cation\nor sentence-pair classi\ufb01cation tasks. The GLUE\norganizers provide training and development data\nsplits as well as a submission server and leader-"}, {"source": "1907.11692v1.pdf", "text": "board that allows participants to evaluate and com-\npare their systems on private held-out test data.\nFor the replication study in Section 4, we report\nresults on the development sets after \ufb01netuning\nthe pretrained models on the corresponding single-\ntask training data (i.e., without multi-task training\nor ensembling). Our \ufb01netuning procedure follows"}, {"source": "1907.11692v1.pdf", "text": "the original BERT paper ( Devlin et al. ,2019 ).\nIn Section 5we additionally report test set re-\nsults obtained from the public leaderboard. These\nresults depend on a several task-speci\ufb01c modi\ufb01ca-\ntions, which we describe in Section 5.1.\nSQuAD The Stanford Question Answering\nDataset (SQuAD) provides a paragraph of context\nand a question. The task is to answer the question"}, {"source": "1907.11692v1.pdf", "text": "by extracting the relevant span from the context.\nWe evaluate on two versions of SQuAD: V1.1\nand V2.0 ( Rajpurkar et al. ,2016 ,2018 ). In V1.1\nthe context always contains an answer, whereas in\n5The authors and their af\ufb01liated institutions are not in any\nway af\ufb01liated with the creation of the OpenWebText dataset.\n6The datasets are: CoLA ( Warstadt et al. ,2018 ),"}, {"source": "1907.11692v1.pdf", "text": "Stanford Sentiment Treebank (SST) ( Socher et al. ,\n2013 ), Microsoft Research Paragraph Corpus\n(MRPC) ( Dolan and Brockett ,2005 ), Semantic Tex-\ntual Similarity Benchmark (STS) ( Agirre et al. ,2007 ),\nQuora Question Pairs (QQP) ( Iyer et al. ,2016 ), Multi-\nGenre NLI (MNLI) ( Williams et al. ,2018 ), Question NLI\n(QNLI) ( Rajpurkar et al. ,2016 ), Recognizing Textual"}, {"source": "1907.11692v1.pdf", "text": "Entailment (RTE) ( Dagan et al. ,2006 ;Bar-Haim et al. ,\n2006 ;Giampiccolo et al. ,2007 ;Bentivogli et al. ,2009 ) and\nWinograd NLI (WNLI) ( Levesque et al. ,2011 ).V2.0 some questions are not answered in the pro-\nvided context, making the task more challenging.\nFor SQuAD V1.1 we adopt the same span pre-\ndiction method as BERT ( Devlin et al. ,2019 ). For"}, {"source": "1907.11692v1.pdf", "text": "SQuAD V2.0, we add an additional binary classi-\n\ufb01er to predict whether the question is answerable,\nwhich we train jointly by summing the classi\ufb01ca-\ntion and span loss terms. During evaluation, we\nonly predict span indices on pairs that are classi-\n\ufb01ed as answerable.\nRACE The ReAding Comprehension from Ex-\naminations (RACE) ( Lai et al. ,2017 ) task is a"}, {"source": "1907.11692v1.pdf", "text": "large-scale reading comprehension dataset with\nmore than 28,000 passages and nearly 100,000\nquestions. The dataset is collected from English\nexaminations in China, which are designed for\nmiddle and high school students. In RACE, each\npassage is associated with multiple questions. For\nevery question, the task is to select one correct an-\nswer from four options. RACE has signi\ufb01cantly"}, {"source": "1907.11692v1.pdf", "text": "longer context than other popular reading compre-\nhension datasets and the proportion of questions\nthat requires reasoning is very large.\n4 Training Procedure Analysis\nThis section explores and quanti\ufb01es which choices\nare important for successfully pretraining BERT\nmodels. We keep the model architecture \ufb01xed.7\nSpeci\ufb01cally, we begin by training BERT models"}, {"source": "1907.11692v1.pdf", "text": "with the same con\ufb01guration as BERT BASE (L=\n12,H= 768 ,A= 12 , 110M params).\n4.1 Static vs. Dynamic Masking\nAs discussed in Section 2, BERT relies on ran-\ndomly masking and predicting tokens. The orig-\ninal BERT implementation performed masking\nonce during data preprocessing, resulting in a sin-\nglestatic mask. To avoid using the same mask for\neach training instance in every epoch, training data"}, {"source": "1907.11692v1.pdf", "text": "was duplicated 10 times so that each sequence is\nmasked in 10 different ways over the 40 epochs of\ntraining. Thus, each training sequence was seen\nwith the same mask four times during training.\nWe compare this strategy with dynamic mask-\ningwhere we generate the masking pattern every\ntime we feed a sequence to the model. This be-\ncomes crucial when pretraining for more steps or"}, {"source": "1907.11692v1.pdf", "text": "with larger datasets.\n7Studying architectural changes, including larger archi-\ntectures, is an important area for future work.Masking SQuAD 2.0 MNLI-m SST-2\nreference 76.3 84.3 92.8\nOur reimplementation:\nstatic 78.3 84.3 92.5\ndynamic 78.7 84.0 92.9\nTable 1: Comparison between static and dynamic\nmasking for BERT BASE. We report F1 for SQuAD and\naccuracy for MNLI-m and SST-2. Reported results are"}, {"source": "1907.11692v1.pdf", "text": "medians over 5 random initializations (seeds). Refer-\nence results are from Yang et al. (2019 ).\nResults Table 1compares the published\nBERT BASE results from Devlin et al. (2019 ) to our\nreimplementation with either static or dynamic\nmasking. We \ufb01nd that our reimplementation\nwith static masking performs similar to the\noriginal BERT model, and dynamic masking is"}, {"source": "1907.11692v1.pdf", "text": "comparable or slightly better than static masking.\nGiven these results and the additional ef\ufb01ciency\nbene\ufb01ts of dynamic masking, we use dynamic\nmasking in the remainder of the experiments.\n4.2 Model Input Format and Next Sentence\nPrediction\nIn the original BERT pretraining procedure, the\nmodel observes two concatenated document seg-\nments, which are either sampled contiguously"}, {"source": "1907.11692v1.pdf", "text": "from the same document (with p= 0.5) or from\ndistinct documents. In addition to the masked lan-\nguage modeling objective, the model is trained to\npredict whether the observed document segments\ncome from the same or distinct documents via an\nauxiliary Next Sentence Prediction (NSP) loss.\nThe NSP loss was hypothesized to be an impor-\ntant factor in training the original BERT model."}, {"source": "1907.11692v1.pdf", "text": "Devlin et al. (2019 ) observe that removing NSP\nhurts performance, with signi\ufb01cant performance\ndegradation on QNLI, MNLI, and SQuAD 1.1.\nHowever, some recent work has questioned the\nnecessity of the NSP loss ( Lample and Conneau ,\n2019 ;Yang et al. ,2019 ;Joshi et al. ,2019 ).\nTo better understand this discrepancy, we com-\npare several alternative training formats:"}, {"source": "1907.11692v1.pdf", "text": "\u2022SEGMENT -PAIR +NSP: This follows the original\ninput format used in BERT ( Devlin et al. ,2019 ),\nwith the NSP loss. Each input has a pair of seg-\nments, which can each contain multiple natural\nsentences, but the total combined length must\nbe less than 512 tokens.Model SQuAD 1.1/2.0 MNLI-m SST-2 RACE\nOur reimplementation (with NSP loss):\nSEGMENT -PAIR 90.4/78.7 84.0 92.9 64.2"}, {"source": "1907.11692v1.pdf", "text": "SEGMENT -PAIR 90.4/78.7 84.0 92.9 64.2\nSENTENCE -PAIR 88.7/76.2 82.9 92.1 63.0\nOur reimplementation (without NSP loss):\nFULL -SENTENCES 90.4/79.1 84.7 92.5 64.8\nDOC-SENTENCES 90.6/79.7 84.7 92.7 65.6\nBERT BASE 88.5/76.3 84.3 92.8 64.3\nXLNet BASE (K = 7) \u2013/81.3 85.8 92.7 66.1\nXLNet BASE (K = 6) \u2013/81.0 85.6 93.4 66.7"}, {"source": "1907.11692v1.pdf", "text": "Table 2: Development set results for base models pretrained over B OOK CORPUS and W IKIPEDIA . All models are\ntrained for 1M steps with a batch size of 256 sequences. We rep ort F1 for SQuAD and accuracy for MNLI-m,\nSST-2 and RACE. Reported results are medians over \ufb01ve random initializations (seeds). Results for BERT BASEand\nXLNet BASEare from Yang et al. (2019 )."}, {"source": "1907.11692v1.pdf", "text": "XLNet BASEare from Yang et al. (2019 ).\n\u2022SENTENCE -PAIR +NSP: Each input contains a\npair of natural sentences , either sampled from\na contiguous portion of one document or from\nseparate documents. Since these inputs are sig-\nni\ufb01cantly shorter than 512 tokens, we increase\nthe batch size so that the total number of tokens\nremains similar to SEGMENT -PAIR +NSP. We re-\ntain the NSP loss."}, {"source": "1907.11692v1.pdf", "text": "tain the NSP loss.\n\u2022FULL -SENTENCES : Each input is packed with\nfull sentences sampled contiguously from one\nor more documents, such that the total length is\nat most 512 tokens. Inputs may cross document\nboundaries. When we reach the end of one doc-\nument, we begin sampling sentences from the\nnext document and add an extra separator token\nbetween documents. We remove the NSP loss."}, {"source": "1907.11692v1.pdf", "text": "\u2022DOC-SENTENCES : Inputs are constructed sim-\nilarly to FULL -SENTENCES , except that they\nmay not cross document boundaries. Inputs\nsampled near the end of a document may be\nshorter than 512 tokens, so we dynamically in-\ncrease the batch size in these cases to achieve\na similar number of total tokens as FULL -\nSENTENCES . We remove the NSP loss.\nResults Table 2shows results for the four dif-"}, {"source": "1907.11692v1.pdf", "text": "ferent settings. We \ufb01rst compare the original\nSEGMENT -PAIR input format from Devlin et al.\n(2019 ) to the SENTENCE -PAIR format; both for-\nmats retain the NSP loss, but the latter uses sin-\ngle sentences. We \ufb01nd that using individual\nsentences hurts performance on downstream\ntasks , which we hypothesize is because the model"}, {"source": "1907.11692v1.pdf", "text": "is not able to learn long-range dependencies.We next compare training without the NSP\nloss and training with blocks of text from a sin-\ngle document ( DOC-SENTENCES ). We \ufb01nd that\nthis setting outperforms the originally published\nBERT BASEresults and that removing the NSP loss\nmatches or slightly improves downstream task\nperformance , in contrast to Devlin et al. (2019 )."}, {"source": "1907.11692v1.pdf", "text": "It is possible that the original BERT implementa-\ntion may only have removed the loss term while\nstill retaining the SEGMENT -PAIR input format.\nFinally we \ufb01nd that restricting sequences to\ncome from a single document ( DOC-SENTENCES )\nperforms slightly better than packing sequences\nfrom multiple documents ( FULL -SENTENCES ).\nHowever, because the DOC-SENTENCES format"}, {"source": "1907.11692v1.pdf", "text": "results in variable batch sizes, we use FULL -\nSENTENCES in the remainder of our experiments\nfor easier comparison with related work.\n4.3 Training with large batches\nPast work in Neural Machine Translation has\nshown that training with very large mini-batches\ncan both improve optimization speed and end-task\nperformance when the learning rate is increased"}, {"source": "1907.11692v1.pdf", "text": "appropriately ( Ott et al. ,2018 ). Recent work has\nshown that BERT is also amenable to large batch\ntraining ( You et al. ,2019 ).\nDevlin et al. (2019 ) originally trained\nBERT BASE for 1M steps with a batch size of\n256 sequences. This is equivalent in computa-\ntional cost, via gradient accumulation, to training\nfor 125K steps with a batch size of 2K sequences,"}, {"source": "1907.11692v1.pdf", "text": "or for 31K steps with a batch size of 8K.\nIn Table 3we compare perplexity and end-bsz steps lr ppl MNLI-m SST-2\n256 1M 1e-4 3.99 84.7 92.7\n2K 125K 7e-4 3.68 85.2 92.9\n8K 31K 1e-3 3.77 84.6 92.8\nTable 3: Perplexity on held-out training data ( ppl) and\ndevelopment set accuracy for base models trained over\nBOOK CORPUS and W IKIPEDIA with varying batch"}, {"source": "1907.11692v1.pdf", "text": "sizes ( bsz). We tune the learning rate ( lr) for each set-\nting. Models make the same number of passes over the\ndata (epochs) and have the same computational cost.\ntask performance of BERT BASE as we increase the\nbatch size, controlling for the number of passes\nthrough the training data. We observe that train-\ning with large batches improves perplexity for the"}, {"source": "1907.11692v1.pdf", "text": "masked language modeling objective, as well as\nend-task accuracy. Large batches are also easier to\nparallelize via distributed data parallel training,8\nand in later experiments we train with batches of\n8K sequences.\nNotably You et al. (2019 ) train BERT with even\nlarger batche sizes, up to 32K sequences. We leave\nfurther exploration of the limits of large batch\ntraining to future work."}, {"source": "1907.11692v1.pdf", "text": "training to future work.\n4.4 Text Encoding\nByte-Pair Encoding (BPE) ( Sennrich et al. ,2016 )\nis a hybrid between character- and word-level rep-\nresentations that allows handling the large vocab-\nularies common in natural language corpora. In-\nstead of full words, BPE relies on subwords units,\nwhich are extracted by performing statistical anal-\nysis of the training corpus."}, {"source": "1907.11692v1.pdf", "text": "ysis of the training corpus.\nBPE vocabulary sizes typically range from\n10K-100K subword units. However, unicode char-\nacters can account for a sizeable portion of this\nvocabulary when modeling large and diverse cor-\npora, such as the ones considered in this work.\nRadford et al. (2019 ) introduce a clever imple-\nmentation of BPE that uses bytes instead of uni-"}, {"source": "1907.11692v1.pdf", "text": "code characters as the base subword units. Using\nbytes makes it possible to learn a subword vocab-\nulary of a modest size (50K units) that can still en-\ncode any input text without introducing any \u201cun-\nknown\u201d tokens.\n8Large batch training can improve training ef\ufb01ciency even\nwithout large scale parallel hardware through gradient ac-\ncumulation , whereby gradients from multiple mini-batches"}, {"source": "1907.11692v1.pdf", "text": "are accumulated locally before each optimization step. Thi s\nfunctionality is supported natively in FAIRSEQ (Ott et al. ,\n2019 ).The original BERT implementa-\ntion ( Devlin et al. ,2019 ) uses a character-level\nBPE vocabulary of size 30K, which is learned\nafter preprocessing the input with heuristic tok-\nenization rules. Following Radford et al. (2019 ),"}, {"source": "1907.11692v1.pdf", "text": "we instead consider training BERT with a larger\nbyte-level BPE vocabulary containing 50K sub-\nword units, without any additional preprocessing\nor tokenization of the input. This adds approxi-\nmately 15M and 20M additional parameters for\nBERT BASEand BERT LARGE , respectively.\nEarly experiments revealed only slight dif-\nferences between these encodings, with the"}, {"source": "1907.11692v1.pdf", "text": "Radford et al. (2019 ) BPE achieving slightly\nworse end-task performance on some tasks. Nev-\nertheless, we believe the advantages of a univer-\nsal encoding scheme outweighs the minor degre-\ndation in performance and use this encoding in\nthe remainder of our experiments. A more de-\ntailed comparison of these encodings is left to fu-\nture work.\n5 RoBERTa"}, {"source": "1907.11692v1.pdf", "text": "ture work.\n5 RoBERTa\nIn the previous section we propose modi\ufb01cations\nto the BERT pretraining procedure that improve\nend-task performance. We now aggregate these\nimprovements and evaluate their combined im-\npact. We call this con\ufb01guration RoBERTa for\nRobustly optimized BERT approach. Speci\ufb01-\ncally, RoBERTa is trained with dynamic mask-\ning (Section 4.1),FULL -SENTENCES without NSP"}, {"source": "1907.11692v1.pdf", "text": "loss (Section 4.2), large mini-batches (Section 4.3)\nand a larger byte-level BPE (Section 4.4).\nAdditionally, we investigate two other impor-\ntant factors that have been under-emphasized in\nprevious work: (1) the data used for pretraining,\nand (2) the number of training passes through the\ndata. For example, the recently proposed XLNet\narchitecture ( Yang et al. ,2019 ) is pretrained us-"}, {"source": "1907.11692v1.pdf", "text": "ing nearly 10 times more data than the original\nBERT ( Devlin et al. ,2019 ). It is also trained with\na batch size eight times larger for half as many op-\ntimization steps, thus seeing four times as many\nsequences in pretraining compared to BERT.\nTo help disentangle the importance of these fac-\ntors from other modeling choices (e.g., the pre-\ntraining objective), we begin by training RoBERTa"}, {"source": "1907.11692v1.pdf", "text": "following the BERT LARGE architecture ( L= 24 ,\nH= 1024 ,A= 16 , 355M parameters). We\npretrain for 100K steps over a comparable B OOK -\nCORPUS plus W IKIPEDIA dataset as was used inModel data bsz stepsSQuADMNLI-m SST-2(v1.1/2.0)\nRoBERTa\nwith B OOKS + W IKI 16GB 8K 100K 93.6/87.3 89.0 95.3\n+ additional data ( \u00a73.2) 160GB 8K 100K 94.0/87.7 89.3 95.6"}, {"source": "1907.11692v1.pdf", "text": "+ pretrain longer 160GB 8K 300K 94.4/88.7 90.0 96.1\n+ pretrain even longer 160GB 8K 500K 94.6/89.4 90.2 96.4\nBERT LARGE\nwith B OOKS + W IKI 13GB 256 1M 90.9/81.8 86.6 93.7\nXLNet LARGE\nwith B OOKS + W IKI 13GB 256 1M 94.0/87.8 88.4 94.4\n+ additional data 126GB 2K 500K 94.5/88.8 89.8 95.6\nTable 4: Development set results for RoBERTa as we pretrain o ver more data (16GB \u2192160GB of text) and pretrain"}, {"source": "1907.11692v1.pdf", "text": "for longer (100K \u2192300K\u2192500K steps). Each row accumulates improvements from the row s above. RoBERTa\nmatches the architecture and training objective of BERT LARGE . Results for BERT LARGE and XLNet LARGE are from\nDevlin et al. (2019 ) and Yang et al. (2019 ), respectively. Complete results on all GLUE tasks can be fo und in the\nAppendix.\nDevlin et al. (2019 ). We pretrain our model using"}, {"source": "1907.11692v1.pdf", "text": "1024 V100 GPUs for approximately one day.\nResults We present our results in Table 4. When\ncontrolling for training data, we observe that\nRoBERTa provides a large improvement over the\noriginally reported BERT LARGE results, reaf\ufb01rming\nthe importance of the design choices we explored\nin Section 4.\nNext, we combine this data with the three ad-\nditional datasets described in Section 3.2. We"}, {"source": "1907.11692v1.pdf", "text": "train RoBERTa over the combined data with the\nsame number of training steps as before (100K).\nIn total, we pretrain over 160GB of text. We ob-\nserve further improvements in performance across\nall downstream tasks, validating the importance of\ndata size and diversity in pretraining.9\nFinally, we pretrain RoBERTa for signi\ufb01cantly\nlonger, increasing the number of pretraining steps"}, {"source": "1907.11692v1.pdf", "text": "from 100K to 300K, and then further to 500K. We\nagain observe signi\ufb01cant gains in downstream task\nperformance, and the 300K and 500K step mod-\nels outperform XLNet LARGE across most tasks. We\nnote that even our longest-trained model does not\nappear to over\ufb01t our data and would likely bene\ufb01t\nfrom additional training.\nIn the rest of the paper, we evaluate our best"}, {"source": "1907.11692v1.pdf", "text": "RoBERTa model on the three different bench-\nmarks: GLUE, SQuaD and RACE. Speci\ufb01cally\n9Our experiments con\ufb02ate increases in data size and di-\nversity. We leave a more careful analysis of these two dimen-\nsions to future work.we consider RoBERTa trained for 500K steps over\nall \ufb01ve of the datasets introduced in Section 3.2.\n5.1 GLUE Results\nFor GLUE we consider two \ufb01netuning settings."}, {"source": "1907.11692v1.pdf", "text": "In the \ufb01rst setting ( single-task, dev ) we \ufb01netune\nRoBERTa separately for each of the GLUE tasks,\nusing only the training data for the correspond-\ning task. We consider a limited hyperparameter\nsweep for each task, with batch sizes \u2208 {16,32}\nand learning rates \u2208 {1e\u22125,2e\u22125,3e\u22125}, with a\nlinear warmup for the \ufb01rst 6% of steps followed by\na linear decay to 0. We \ufb01netune for 10 epochs and"}, {"source": "1907.11692v1.pdf", "text": "perform early stopping based on each task\u2019s eval-\nuation metric on the dev set. The rest of the hyper-\nparameters remain the same as during pretraining.\nIn this setting, we report the median development\nset results for each task over \ufb01ve random initial-\nizations, without model ensembling.\nIn the second setting ( ensembles, test ), we com-\npare RoBERTa to other approaches on the test set"}, {"source": "1907.11692v1.pdf", "text": "via the GLUE leaderboard. While many submis-\nsions to the GLUE leaderboard depend on multi-\ntask \ufb01netuning, our submission depends only on\nsingle-task \ufb01netuning . For RTE, STS and MRPC\nwe found it helpful to \ufb01netune starting from the\nMNLI single-task model, rather than the baseline\npretrained RoBERTa. We explore a slightly wider\nhyperparameter space, described in the Appendix,"}, {"source": "1907.11692v1.pdf", "text": "and ensemble between 5 and 7 models per task.MNLI QNLI QQP RTE SST MRPC CoLA STS WNLI Avg\nSingle-task single models on dev\nBERT LARGE 86.6/- 92.3 91.3 70.4 93.2 88.0 60.6 90.0 - -\nXLNet LARGE 89.8/- 93.9 91.8 83.8 95.6 89.2 63.6 91.8 - -\nRoBERTa 90.2/90.2 94.7 92.2 86.6 96.4 90.9 68.0 92.4 91.3 -\nEnsembles on test (from leaderboard as of July 25, 2019)"}, {"source": "1907.11692v1.pdf", "text": "ALICE 88.2/87.9 95.7 90.7 83.5 95.2 92.6 68.6 91.1 80.8 86.3\nMT-DNN 87.9/87.4 96.0 89.9 86.3 96.5 92.7 68.4 91.1 89.0 87.6\nXLNet 90.2/89.8 98.6 90.3 86.3 96.8 93.0 67.8 91.6 90.4 88.4\nRoBERTa 90.8/90.2 98.9 90.2 88.2 96.7 92.3 67.8 92.2 89.0 88.5\nTable 5: Results on GLUE. All results are based on a 24-layer a rchitecture. BERT LARGE and XLNet LARGE results"}, {"source": "1907.11692v1.pdf", "text": "are from Devlin et al. (2019 ) and Yang et al. (2019 ), respectively. RoBERTa results on the development set are a\nmedian over \ufb01ve runs. RoBERTa results on the test set are ense mbles of single-task models. For RTE, STS and\nMRPC we \ufb01netune starting from the MNLI model instead of the ba seline pretrained model. Averages are obtained\nfrom the GLUE leaderboard."}, {"source": "1907.11692v1.pdf", "text": "from the GLUE leaderboard.\nTask-speci\ufb01c modi\ufb01cations Two of the GLUE\ntasks require task-speci\ufb01c \ufb01netuning approaches\nto achieve competitive leaderboard results.\nQNLI : Recent submissions on the GLUE\nleaderboard adopt a pairwise ranking formulation\nfor the QNLI task, in which candidate answers\nare mined from the training set and compared to\none another, and a single (question, candidate)"}, {"source": "1907.11692v1.pdf", "text": "pair is classi\ufb01ed as positive ( Liu et al. ,2019b ,a;\nYang et al. ,2019 ). This formulation signi\ufb01cantly\nsimpli\ufb01es the task, but is not directly comparable\nto BERT ( Devlin et al. ,2019 ). Following recent\nwork, we adopt the ranking approach for our test\nsubmission, but for direct comparison with BERT\nwe report development set results based on a pure\nclassi\ufb01cation approach."}, {"source": "1907.11692v1.pdf", "text": "classi\ufb01cation approach.\nWNLI : We found the provided NLI-format\ndata to be challenging to work with. Instead\nwe use the reformatted WNLI data from Super-\nGLUE ( Wang et al. ,2019a ), which indicates the\nspan of the query pronoun and referent. We \ufb01ne-\ntune RoBERTa using the margin ranking loss from\nKocijan et al. (2019 ). For a given input sentence,\nwe use spaCy ( Honnibal and Montani ,2017 ) to"}, {"source": "1907.11692v1.pdf", "text": "extract additional candidate noun phrases from the\nsentence and \ufb01netune our model so that it assigns\nhigher scores to positive referent phrases than for\nany of the generated negative candidate phrases.\nOne unfortunate consequence of this formulation\nis that we can only make use of the positive train-\ning examples, which excludes over half of the pro-\nvided training examples.10"}, {"source": "1907.11692v1.pdf", "text": "vided training examples.10\n10While we only use the provided WNLI training data, ourResults We present our results in Table 5. In the\n\ufb01rst setting ( single-task, dev ), RoBERTa achieves\nstate-of-the-art results on all 9 of the GLUE\ntask development sets. Crucially, RoBERTa uses\nthe same masked language modeling pretrain-\ning objective and architecture as BERT LARGE , yet"}, {"source": "1907.11692v1.pdf", "text": "consistently outperforms both BERT LARGE and\nXLNet LARGE . This raises questions about the rel-\native importance of model architecture and pre-\ntraining objective, compared to more mundane de-\ntails like dataset size and training time that we ex-\nplore in this work.\nIn the second setting ( ensembles, test ), we\nsubmit RoBERTa to the GLUE leaderboard and"}, {"source": "1907.11692v1.pdf", "text": "achieve state-of-the-art results on 4 out of 9 tasks\nand the highest average score to date. This is espe-\ncially exciting because RoBERTa does not depend\non multi-task \ufb01netuning, unlike most of the other\ntop submissions. We expect future work may fur-\nther improve these results by incorporating more\nsophisticated multi-task \ufb01netuning procedures.\n5.2 SQuAD Results"}, {"source": "1907.11692v1.pdf", "text": "5.2 SQuAD Results\nWe adopt a much simpler approach for SQuAD\ncompared to past work. In particular, while\nboth BERT ( Devlin et al. ,2019 ) and XL-\nNet ( Yang et al. ,2019 ) augment their training data\nwith additional QA datasets, we only \ufb01netune\nRoBERTa using the provided SQuAD training\ndata .Yang et al. (2019 ) also employed a custom\nlayer-wise learning rate schedule to \ufb01netune"}, {"source": "1907.11692v1.pdf", "text": "results could potentially be improved by augmenting this wi th\nadditional pronoun disambiguation datasets.ModelSQuAD 1.1 SQuAD 2.0\nEM F1 EM F1\nSingle models on dev, w/o data augmentation\nBERT LARGE 84.1 90.9 79.0 81.8\nXLNet LARGE 89.0 94.5 86.1 88.8\nRoBERTa 88.9 94.6 86.5 89.4\nSingle models on test (as of July 25, 2019)\nXLNet LARGE 86.3\u202089.1\u2020\nRoBERTa 86.8 89.8\nXLNet + SG-Net Veri\ufb01er 87.0\u202089.9\u2020"}, {"source": "1907.11692v1.pdf", "text": "XLNet + SG-Net Veri\ufb01er 87.0\u202089.9\u2020\nTable 6: Results on SQuAD. \u2020indicates results that de-\npend on additional external training data. RoBERTa\nuses only the provided SQuAD data in both dev and\ntest settings. BERT LARGE and XLNet LARGE results are\nfrom Devlin et al. (2019 ) and Yang et al. (2019 ), re-\nspectively.\nXLNet, while we use the same learning rate for\nall layers."}, {"source": "1907.11692v1.pdf", "text": "all layers.\nFor SQuAD v1.1 we follow the same \ufb01netun-\ning procedure as Devlin et al. (2019 ). For SQuAD\nv2.0, we additionally classify whether a given\nquestion is answerable; we train this classi\ufb01er\njointly with the span predictor by summing the\nclassi\ufb01cation and span loss terms.\nResults We present our results in Table 6. On\nthe SQuAD v1.1 development set, RoBERTa"}, {"source": "1907.11692v1.pdf", "text": "the SQuAD v1.1 development set, RoBERTa\nmatches the state-of-the-art set by XLNet. On the\nSQuAD v2.0 development set, RoBERTa sets a\nnew state-of-the-art, improving over XLNet by 0.4\npoints (EM) and 0.6 points (F1).\nWe also submit RoBERTa to the public SQuAD\n2.0 leaderboard and evaluate its performance rel-\native to other systems. Most of the top systems"}, {"source": "1907.11692v1.pdf", "text": "build upon either BERT ( Devlin et al. ,2019 ) or\nXLNet ( Yang et al. ,2019 ), both of which rely on\nadditional external training data. In contrast, our\nsubmission does not use any additional data.\nOur single RoBERTa model outperforms all but\none of the single model submissions, and is the\ntop scoring system among those that do not rely\non data augmentation.\n5.3 RACE Results"}, {"source": "1907.11692v1.pdf", "text": "on data augmentation.\n5.3 RACE Results\nIn RACE, systems are provided with a passage of\ntext, an associated question, and four candidate an-\nswers. Systems are required to classify which of\nthe four candidate answers is correct.\nWe modify RoBERTa for this task by concate-Model Accuracy Middle High\nSingle models on test (as of July 25, 2019)\nBERT LARGE 72.0 76.6 70.1\nXLNet LARGE 81.7 85.4 80.2"}, {"source": "1907.11692v1.pdf", "text": "XLNet LARGE 81.7 85.4 80.2\nRoBERTa 83.2 86.5 81.3\nTable 7: Results on the RACE test set. BERT LARGE and\nXLNet LARGE results are from Yang et al. (2019 ).\nnating each candidate answer with the correspond-\ning question and passage. We then encode each of\nthese four sequences and pass the resulting [CLS]\nrepresentations through a fully-connected layer,\nwhich is used to predict the correct answer. We"}, {"source": "1907.11692v1.pdf", "text": "truncate question-answer pairs that are longer than\n128 tokens and, if needed, the passage so that the\ntotal length is at most 512 tokens.\nResults on the RACE test sets are presented in\nTable 7. RoBERTa achieves state-of-the-art results\non both middle-school and high-school settings.\n6 Related Work\nPretraining methods have been designed\nwith different training objectives, includ-"}, {"source": "1907.11692v1.pdf", "text": "ing language modeling ( Dai and Le ,2015 ;\nPeters et al. ,2018 ;Howard and Ruder ,2018 ),\nmachine translation ( McCann et al. ,2017 ), and\nmasked language modeling ( Devlin et al. ,2019 ;\nLample and Conneau ,2019 ). Many recent\npapers have used a basic recipe of \ufb01netuning\nmodels for each end task ( Howard and Ruder ,\n2018 ;Radford et al. ,2018 ), and pretraining"}, {"source": "1907.11692v1.pdf", "text": "with some variant of a masked language model\nobjective. However, newer methods have\nimproved performance by multi-task \ufb01ne tun-\ning ( Dong et al. ,2019 ), incorporating entity\nembeddings ( Sun et al. ,2019 ), span predic-\ntion ( Joshi et al. ,2019 ), and multiple variants\nof autoregressive pretraining ( Song et al. ,2019 ;\nChan et al. ,2019 ;Yang et al. ,2019 ). Perfor-"}, {"source": "1907.11692v1.pdf", "text": "mance is also typically improved by training\nbigger models on more data ( Devlin et al. ,\n2019 ;Baevski et al. ,2019 ;Yang et al. ,2019 ;\nRadford et al. ,2019 ). Our goal was to replicate,\nsimplify, and better tune the training of BERT,\nas a reference point for better understanding the\nrelative performance of all of these methods.7 Conclusion\nWe carefully evaluate a number of design de-"}, {"source": "1907.11692v1.pdf", "text": "cisions when pretraining BERT models. We\n\ufb01nd that performance can be substantially im-\nproved by training the model longer, with bigger\nbatches over more data; removing the next sen-\ntence prediction objective; training on longer se-\nquences; and dynamically changing the masking\npattern applied to the training data. Our improved\npretraining procedure, which we call RoBERTa,"}, {"source": "1907.11692v1.pdf", "text": "achieves state-of-the-art results on GLUE, RACE\nand SQuAD, without multi-task \ufb01netuning for\nGLUE or additional data for SQuAD. These re-\nsults illustrate the importance of these previ-\nously overlooked design decisions and suggest\nthat BERT\u2019s pretraining objective remains com-\npetitive with recently proposed alternatives.\nWe additionally use a novel dataset,\nCC-N EWS, and release our models and"}, {"source": "1907.11692v1.pdf", "text": "CC-N EWS, and release our models and\ncode for pretraining and \ufb01netuning at:\nhttps://github.com/pytorch/fairseq .\nReferences\nEneko Agirre, Llu\u2019is M\u2018arquez, and Richard Wicen-\ntowski, editors. 2007. Proceedings of the Fourth\nInternational Workshop on Semantic Evaluations\n(SemEval-2007) .\nAlexei Baevski, Sergey Edunov, Yinhan Liu, Luke\nZettlemoyer, and Michael Auli. 2019. Cloze-"}, {"source": "1907.11692v1.pdf", "text": "driven pretraining of self-attention networks. arXiv\npreprint arXiv:1903.07785 .\nRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,\nDanilo Giampiccolo, Bernardo Magnini, and Idan\nSzpektor. 2006. The second PASCAL recognising\ntextual entailment challenge. In Proceedings of the\nsecond PASCAL challenges workshop on recognis-\ning textual entailment .\nLuisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo"}, {"source": "1907.11692v1.pdf", "text": "Giampiccolo, and Bernardo Magnini. 2009. The\n\ufb01fth PASCAL recognizing textual entailment chal-\nlenge.\nSamuel R Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nInEmpirical Methods in Natural Language Process-\ning (EMNLP) .\nWilliam Chan, Nikita Kitaev, Kelvin Guu, Mitchell"}, {"source": "1907.11692v1.pdf", "text": "Stern, and Jakob Uszkoreit. 2019. KERMIT: Gener-\native insertion-based modeling for sequences. arXiv\npreprint arXiv:1906.01604 .Ido Dagan, Oren Glickman, and Bernardo Magnini.\n2006. The PASCAL recognising textual entailment\nchallenge. In Machine learning challenges. evalu-\nating predictive uncertainty, visual object classi\ufb01ca-\ntion, and recognising tectual entailment ."}, {"source": "1907.11692v1.pdf", "text": "Andrew M Dai and Quoc V Le. 2015. Semi-supervised\nsequence learning. In Advances in Neural Informa-\ntion Processing Systems (NIPS) .\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In North American Association for Com-\nputational Linguistics (NAACL) ."}, {"source": "1907.11692v1.pdf", "text": "putational Linguistics (NAACL) .\nWilliam B Dolan and Chris Brockett. 2005. Auto-\nmatically constructing a corpus of sentential para-\nphrases. In Proceedings of the International Work-\nshop on Paraphrasing .\nLi Dong, Nan Yang, Wenhui Wang, Furu Wei,\nXiaodong Liu, Yu Wang, Jianfeng Gao, Ming\nZhou, and Hsiao-Wuen Hon. 2019. Uni\ufb01ed\nlanguage model pre-training for natural language"}, {"source": "1907.11692v1.pdf", "text": "understanding and generation. arXiv preprint\narXiv:1905.03197 .\nDanilo Giampiccolo, Bernardo Magnini, Ido Dagan,\nand Bill Dolan. 2007. The third PASCAL recog-\nnizing textual entailment challenge. In Proceedings\nof the ACL-PASCAL workshop on textual entailment\nand paraphrasing .\nAaron Gokaslan and Vanya Cohen. 2019. Openweb-\ntext corpus. http://web.archive.org/\nsave/http://Skylion007.github.io/"}, {"source": "1907.11692v1.pdf", "text": "save/http://Skylion007.github.io/\nOpenWebTextCorpus .\nFelix Hamborg, Norman Meuschke, Corinna Bre-\nitinger, and Bela Gipp. 2017. news-please: A\ngeneric news crawler and extractor. In Proceedings\nof the 15th International Symposium of Information\nScience .\nDan Hendrycks and Kevin Gimpel. 2016. Gaus-\nsian error linear units (gelus). arXiv preprint\narXiv:1606.08415 ."}, {"source": "1907.11692v1.pdf", "text": "arXiv:1606.08415 .\nMatthew Honnibal and Ines Montani. 2017. spaCy 2:\nNatural language understanding with Bloom embed-\ndings, convolutional neural networks and incremen-\ntal parsing. To appear.\nJeremy Howard and Sebastian Ruder. 2018. Universal\nlanguage model \ufb01ne-tuning for text classi\ufb01cation.\narXiv preprint arXiv:1801.06146 .\nShankar Iyer, Nikhil Dandekar, and Kornl Cser-"}, {"source": "1907.11692v1.pdf", "text": "nai. 2016. First quora dataset release: Question\npairs.https://data.quora.com/First-\nQuora-Dataset-Release-Question-\nPairs .Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S.\nWeld, Luke Zettlemoyer, and Omer Levy. 2019.\nSpanBERT: Improving pre-training by repre-\nsenting and predicting spans. arXiv preprint\narXiv:1907.10529 .\nDiederik Kingma and Jimmy Ba. 2015. Adam: A"}, {"source": "1907.11692v1.pdf", "text": "method for stochastic optimization. In International\nConference on Learning Representations (ICLR) .\nVid Kocijan, Ana-Maria Cretu, Oana-Maria Camburu,\nYordan Yordanov, and Thomas Lukasiewicz. 2019.\nA surprisingly robust trick for winograd schema\nchallenge. arXiv preprint arXiv:1905.06290 .\nGuokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang,\nand Eduard Hovy. 2017. Race: Large-scale reading"}, {"source": "1907.11692v1.pdf", "text": "comprehension dataset from examinations. arXiv\npreprint arXiv:1704.04683 .\nGuillaume Lample and Alexis Conneau. 2019. Cross-\nlingual language model pretraining. arXiv preprint\narXiv:1901.07291 .\nHector J Levesque, Ernest Davis, and Leora Morgen-\nstern. 2011. The Winograd schema challenge. In\nAAAI Spring Symposium: Logical Formalizations of\nCommonsense Reasoning ."}, {"source": "1907.11692v1.pdf", "text": "Commonsense Reasoning .\nXiaodong Liu, Pengcheng He, Weizhu Chen, and\nJianfeng Gao. 2019a. Improving multi-task deep\nneural networks via knowledge distillation for\nnatural language understanding. arXiv preprint\narXiv:1904.09482 .\nXiaodong Liu, Pengcheng He, Weizhu Chen, and Jian-\nfeng Gao. 2019b. Multi-task deep neural networks\nfor natural language understanding. arXiv preprint\narXiv:1901.11504 ."}, {"source": "1907.11692v1.pdf", "text": "arXiv:1901.11504 .\nBryan McCann, James Bradbury, Caiming Xiong, and\nRichard Socher. 2017. Learned in translation: Con-\ntextualized word vectors. In Advances in Neural In-\nformation Processing Systems (NIPS) , pages 6297\u2013\n6308.\nPaulius Micikevicius, Sharan Narang, Jonah Alben,\nGregory Diamos, Erich Elsen, David Garcia, Boris\nGinsburg, Michael Houston, Oleksii Kuchaiev,"}, {"source": "1907.11692v1.pdf", "text": "Ganesh Venkatesh, and Hao Wu. 2018. Mixed preci-\nsion training. In International Conference on Learn-\ning Representations .\nSebastian Nagel. 2016. Cc-news. http:\n//web.archive.org/save/http:\n//commoncrawl.org/2016/10/news-\ndataset-available .\nMyle Ott, Sergey Edunov, Alexei Baevski, Angela\nFan, Sam Gross, Nathan Ng, David Grangier, and\nMichael Auli. 2019. FAIRSEQ : A fast, exten-"}, {"source": "1907.11692v1.pdf", "text": "sible toolkit for sequence modeling. In North\nAmerican Association for Computational Linguis-\ntics (NAACL): System Demonstrations .Myle Ott, Sergey Edunov, David Grangier, and\nMichael Auli. 2018. Scaling neural machine trans-\nlation. In Proceedings of the Third Conference on\nMachine Translation (WMT) .\nAdam Paszke, Sam Gross, Soumith Chintala, Gre-\ngory Chanan, Edward Yang, Zachary DeVito, Zem-"}, {"source": "1907.11692v1.pdf", "text": "ing Lin, Alban Desmaison, Luca Antiga, and Adam\nLerer. 2017. Automatic differentiation in PyTorch.\nInNIPS Autodiff Workshop .\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word repre-\nsentations. In North American Association for Com-\nputational Linguistics (NAACL) ."}, {"source": "1907.11692v1.pdf", "text": "putational Linguistics (NAACL) .\nAlec Radford, Karthik Narasimhan, Time Salimans,\nand Ilya Sutskever. 2018. Improving language un-\nderstanding with unsupervised learning. Technical\nreport, OpenAI.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. Techni-\ncal report, OpenAI."}, {"source": "1907.11692v1.pdf", "text": "cal report, OpenAI.\nPranav Rajpurkar, Robin Jia, and Percy Liang. 2018.\nKnow what you don\u2019t know: Unanswerable ques-\ntions for squad. In Association for Computational\nLinguistics (ACL) .\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. SQuAD: 100,000+ questions for\nmachine comprehension of text. In Empirical Meth-\nods in Natural Language Processing (EMNLP) ."}, {"source": "1907.11692v1.pdf", "text": "Rico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Neural machine translation of rare words with\nsubword units. In Association for Computational\nLinguistics (ACL) , pages 1715\u20131725.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models\nfor semantic compositionality over a sentiment tree-"}, {"source": "1907.11692v1.pdf", "text": "bank. In Empirical Methods in Natural Language\nProcessing (EMNLP) .\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and\nTie-Yan Liu. 2019. MASS: Masked sequence\nto sequence pre-training for language generation.\nInInternational Conference on Machine Learning\n(ICML) .\nYu Stephanie Sun, Shuohuan Wang, Yukun Li, Shikun\nFeng, Xuyi Chen, Han Zhang, Xinlun Tian, Danxi-"}, {"source": "1907.11692v1.pdf", "text": "ang Zhu, Hao Tian, and Hua Wu. 2019. ERNIE: En-\nhanced representation through knowledge integra-\ntion. arXiv preprint arXiv:1904.09223 .\nTrieu H Trinh and Quoc V Le. 2018. A simple\nmethod for commonsense reasoning. arXiv preprint\narXiv:1806.02847 .Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all"}, {"source": "1907.11692v1.pdf", "text": "you need. In Advances in neural information pro-\ncessing systems .\nAlex Wang, Yada Pruksachatkun, Nikita Nangia,\nAmanpreet Singh, Julian Michael, Felix Hill, Omer\nLevy, and Samuel R. Bowman. 2019a. SuperGLUE:\nA stickier benchmark for general-purpose language\nunderstanding systems. arXiv preprint 1905.00537 .\nAlex Wang, Amanpreet Singh, Julian Michael, Felix"}, {"source": "1907.11692v1.pdf", "text": "Hill, Omer Levy, and Samuel R. Bowman. 2019b.\nGLUE: A multi-task benchmark and analysis plat-\nform for natural language understanding. In Inter-\nnational Conference on Learning Representations\n(ICLR) .\nAlex Warstadt, Amanpreet Singh, and Samuel R. Bow-\nman. 2018. Neural network acceptability judg-\nments. arXiv preprint 1805.12471 .\nAdina Williams, Nikita Nangia, and Samuel Bowman."}, {"source": "1907.11692v1.pdf", "text": "2018. A broad-coverage challenge corpus for sen-\ntence understanding through inference. In North\nAmerican Association for Computational Linguis-\ntics (NAACL) .\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Ruslan Salakhutdinov, and Quoc V Le.\n2019. Xlnet: Generalized autoregressive pretrain-\ning for language understanding. arXiv preprint\narXiv:1906.08237 ."}, {"source": "1907.11692v1.pdf", "text": "arXiv:1906.08237 .\nYang You, Jing Li, Jonathan Hseu, Xiaodan Song,\nJames Demmel, and Cho-Jui Hsieh. 2019. Reduc-\ning bert pre-training time from 3 days to 76 minutes.\narXiv preprint arXiv:1904.00962 .\nRowan Zellers, Ari Holtzman, Hannah Rashkin,\nYonatan Bisk, Ali Farhadi, Franziska Roesner, and\nYejin Choi. 2019. Defending against neural fake\nnews. arXiv preprint arXiv:1905.12616 ."}, {"source": "1907.11692v1.pdf", "text": "news. arXiv preprint arXiv:1905.12616 .\nYukun Zhu, Ryan Kiros, Richard Zemel, Ruslan\nSalakhutdinov, Raquel Urtasun, Antonio Torralba,\nand Sanja Fidler. 2015. Aligning books and movies:\nTowards story-like visual explanations by watch-\ning movies and reading books. In arXiv preprint\narXiv:1506.06724 .\nAppendix for \u201cRoBERTa: A Robustly\nOptimized BERT Pretraining Approach\u201d\nA Full results on GLUE"}, {"source": "1907.11692v1.pdf", "text": "A Full results on GLUE\nIn Table 8we present the full set of development\nset results for RoBERTa. We present results for\naLARGE con\ufb01guration that follows BERT LARGE ,\nas well as a BASE con\ufb01guration that follows\nBERT BASE.B Pretraining Hyperparameters\nTable 9describes the hyperparameters for pre-\ntraining of RoBERTa LARGE and RoBERTa BASE\nC Finetuning Hyperparameters"}, {"source": "1907.11692v1.pdf", "text": "C Finetuning Hyperparameters\nFinetuning hyperparameters for RACE, SQuAD\nand GLUE are given in Table 10. We select the\nbest hyperparameter values based on the median\nof 5 random seeds for each task.MNLI QNLI QQP RTE SST MRPC CoLA STS\nRoBERTa BASE\n+ all data + 500k steps 87.6 92.8 91.9 78.7 94.8 90.2 63.6 91.2\nRoBERTa LARGE\nwith B OOKS + W IKI 89.0 93.9 91.9 84.5 95.3 90.2 66.3 91.6"}, {"source": "1907.11692v1.pdf", "text": "+ additional data ( \u00a73.2) 89.3 94.0 92.0 82.7 95.6 91.4 66.1 92.2\n+ pretrain longer 300k 90.0 94.5 92.2 83.3 96.1 91.1 67.4 92.3\n+ pretrain longer 500k 90.2 94.7 92.2 86.6 96.4 90.9 68.0 92.4\nTable 8: Development set results on GLUE tasks for various co n\ufb01gurations of RoBERTa.\nHyperparam RoBERTa LARGE RoBERTa BASE\nNumber of Layers 24 12\nHidden size 1024 768\nFFN inner hidden size 4096 3072"}, {"source": "1907.11692v1.pdf", "text": "FFN inner hidden size 4096 3072\nAttention heads 16 12\nAttention head size 64 64\nDropout 0.1 0.1\nAttention Dropout 0.1 0.1\nWarmup Steps 30k 24k\nPeak Learning Rate 4e-4 6e-4\nBatch Size 8k 8k\nWeight Decay 0.01 0.01\nMax Steps 500k 500k\nLearning Rate Decay Linear Linear\nAdam\u01eb 1e-6 1e-6\nAdam\u03b21 0.9 0.9\nAdam\u03b22 0.98 0.98\nGradient Clipping 0.0 0.0"}, {"source": "1907.11692v1.pdf", "text": "Gradient Clipping 0.0 0.0\nTable 9: Hyperparameters for pretraining RoBERTa LARGE and RoBERTa BASE.\nHyperparam RACE SQuAD GLUE\nLearning Rate 1e-5 1.5e-5 {1e-5, 2e-5, 3e-5 }\nBatch Size 16 48 {16, 32}\nWeight Decay 0.1 0.01 0.1\nMax Epochs 4 2 10\nLearning Rate Decay Linear Linear Linear\nWarmup ratio 0.06 0.06 0.06\nTable 10: Hyperparameters for \ufb01netuning RoBERTa LARGE on RACE, SQuAD and GLUE."}, {"source": "2023.semeval-1.193.pdf", "text": "Proceedings of the The 17th International Workshop on Semantic Evaluation (SemEval-2023) , pages 1395\u20131400\nJuly 13-14, 2023 \u00a92023 Association for Computational Linguistics\nKb at SemEval-2023 Task 3: On Multitask Hierarchical BERT Base\nNeural Network for Multi-label Persuasion Techniques Detection\nKatarzyna Baraniak and Marcin Sydow\nPolish-Japanese Academy of Information Technology"}, {"source": "2023.semeval-1.193.pdf", "text": "kbaraniak@pjwstk.edu.pl\nmsyd@pjwstk.edu.pl\nAbstract\nThis paper presents a solution for Semeval\n2023 subtask3 of task3: persuasion techniques\nin paragraphs detection. The aim of this task\nis to identify all persuasion techniques in each\nparagraph of given news articles. We use hier-\narchical multitask neural networks combined\nwith transformers. Span detection is an aux-"}, {"source": "2023.semeval-1.193.pdf", "text": "iliary task that helps in the main task: iden-\ntify propaganda techniques. Our experiments\nshow that if we change the index of BERT em-\nbedding from the \ufb01rst token of the whole input\nto the \ufb01rst token of the identi\ufb01ed span it can\nimprove the performance. Span and label de-\ntection can be performed using one network so\nwe save data and, when data is limited, we can\nuse more of it for training."}, {"source": "2023.semeval-1.193.pdf", "text": "use more of it for training.\n1 Introduction\nNews articles are expected to present reliable infor-\nmation, however quite often contain some kind of\nmanipulation. Unconscious reader can be unable\nto spot all kind of persuasion that he is exposed to.\nReading such news can in\ufb02uence a reader\u2019s point\nof view especially if the reader has a low level of\npolitical knowledge (Eberl et al., 2017). Automatic"}, {"source": "2023.semeval-1.193.pdf", "text": "tools for detection of persuasion can help in media\nanalysis and creating more objective news.\nThe task prepared by the organisers (Piskorski\net al., 2023) covers three topics, as follows: cate-\ngory of news article identi\ufb01cation, framing classi\ufb01-\ncation and paragraph-level persuasion techniques\nrecognition. Our team focused on the third topic\nand created solution tested on all languages that"}, {"source": "2023.semeval-1.193.pdf", "text": "have training data available: English, French, Ger-\nman, Italian, Polish and Russian and for additional\nlanguages with only test data: Spanish, Greek and\nGeorgian.\nOur system combines multitask learning and hi-\nerarchical neural networks. The system identi\ufb01es\nspan where the persuasion techniques appear and"}, {"source": "2023.semeval-1.193.pdf", "text": "then passes this information to the next module thatclassi\ufb01es it to one or more categories of persuasion\ntechniques. We used pre-trained and \ufb01ne-tuned\nBert embedding as the shared input layer.\nWe discover that adding an auxiliary task such\nas span identi\ufb01cation as the \ufb01rst step of training\nneural network may give better results than simply\nclassifying the whole paragraph. Moreover, using"}, {"source": "2023.semeval-1.193.pdf", "text": "one neural network for that approach makes solving\nthe task possible even for limited data.\nThe code of our solution is available\nat https://github.com/Katarzynaa/\npersuasion_detection\n2 Background\nThe persuasion technique identi\ufb01cation problem\nhas been addressed before as a problem of span\nand technique classi\ufb01cation. There exist several\nworks on solving the persuasion techniques detec-"}, {"source": "2023.semeval-1.193.pdf", "text": "tion problem, for example: as a problem of multi-\nmodal image and text input (Dimitrov et al., 2021)\nor as problem of span and technique classi\ufb01cation\n(Da San Martino et al., 2020). In our case it is the\nmulti-label classi\ufb01cation task, the authors of the\ntask are expected to classify all persuasion tech-\nniques that appear in every paragraph of a news"}, {"source": "2023.semeval-1.193.pdf", "text": "article. The input data is a single paragraph, the\noutput is a list of detected techniques. The data\nis provided in three folders: \u201ctrain\u201d, \u201cdev\u201d and\n\u201ctest\u201d. Each folder contains \ufb01les with articles. Each\narticle is divided into paragraphs separated by an\nadditional empty line. For each paragraph of each\narticle in \u201ctrain\u201d and \u201cdev\u201d sets organisers provide"}, {"source": "2023.semeval-1.193.pdf", "text": "the lists of labels of persuasion techniques in sep-\narate \ufb01les. Labels of test data are unknown. As\nan additional information authors provide for each\nparagraph the list of spans, start and end character\nindex, and its class.\nThere are 23 classes with a distribution that is not\nbalanced (far from the uniform one). These classes\nare presented in table 1 One can \ufb01nd a detailed"}, {"source": "2023.semeval-1.193.pdf", "text": "description in the task description paper.1395Technique N. test N. train\nDoubt 187 518\nWhataboutism 2 16\nAppeal to Hypocr. 8 40\nCausal Oversimp. 24 213\nAppeal to Author. 28 154\nGuilt by Associat. 4 59\nSlogans 28 153\nFlag Waving 96 287\nLoaded Lang. 483 1809\nRed Herring 19 44\nFalse Dil.-NoCh. 63 122\nApp. to Popular. 34 15\nConvers. Killer 25 91\nName Call.-Lab. 250 979\nA.to Fear-Prejud. 137 310"}, {"source": "2023.semeval-1.193.pdf", "text": "A.to Fear-Prejud. 137 310\nExaggerat.-Mini. 115 466\nRepetition 141 544\nStraw Man 9 15\nObf.-Vag.-Conf. 13 8\nTable 1: Number of labels in English dataset\n2.1 Multitaskand and hierarchical Networks\nfor persuasion techniques identi\ufb01cation\nOur solution is based on multitask networks. This\nkind of network shares the same part or full archi-\ntecture to solve several tasks being trained at once."}, {"source": "2023.semeval-1.193.pdf", "text": "Much research evidence demonstrates that proper\nchoosing of auxiliary task may help to get better\nresults at the main one (e.g. (Bjerva, 2017)).\nMulti-task learning is mostly used for emotion\nand sentiment analysis (Zhang et al., 2022), aspect\nbased sentiment analysis (He et al., 2019) or named\nentity recognition, etc.\nHierarchical networks are formed as an acyclic"}, {"source": "2023.semeval-1.193.pdf", "text": "graph, which means that the tasks are learned by the\nnetworks\u2019 modules in some order. The results of\nprevious modules in\ufb02uence the next modules. Hi-\nerarchical multitask approach has many forms and\napplications in NLP, for example: embedding learn-\ning (Sanh et al., 2019) or aspect-based sentiment\nanalysis (Wang et al., 2021), etc. In our solution we"}, {"source": "2023.semeval-1.193.pdf", "text": "created a network that solves two tasks: span iden-\nti\ufb01cation and persuasion techniques identi\ufb01cation.\nBoth share the same input of Bert embedding but\nhave separate layers for the classi\ufb01cation part. The\nsecond one uses the results of the \ufb01rst one. Span\nidenti\ufb01cation can be treated as sequence tag classi-\n\ufb01cation. We predict the span where the persuasion"}, {"source": "2023.semeval-1.193.pdf", "text": "technique is present. For the second task we used\nthe predicted span to identify the technique used in\nthat span. If more than one span is identi\ufb01ed we\npredicted techniques based on the \ufb01rst index. One\nspan can represent many persuasion techniques.\nIn contrast to the network presented in (Ju-rkiewicz et al., 2020) our main aim is only per-\nsuasion technique detection, we do not use special"}, {"source": "2023.semeval-1.193.pdf", "text": "tokens and we use one multitask network.\nWe also experimented with other modi\ufb01cations\nor variants of network architectures. For exam-\nple, we tried to add auxiliary task of POS tagging,\nadding general sentiment based on \u201cVader\u201d ap-\nproach (Hutto and Gilbert, 2014), add entity-level\nsentiment trained on the SEN benchmark dataset\n(Baraniak and Sydow, 2021) however no improve-"}, {"source": "2023.semeval-1.193.pdf", "text": "ment was observed so details are not included.\nIn our preliminary approach we tried to translate\narticles between languages to get more data but no\nimprovement was observed. That can be caused\nby the fact that speci\ufb01c persuasion techniques for\na given language are not easy to translate to other\nlanguage or the fact that a basic translator omits per-"}, {"source": "2023.semeval-1.193.pdf", "text": "suasion techniques and translates it in more neutral\nwords.\n3 System overview\nOur system proceeds in the following general steps:\n1. Use pre-trained model to continue pre-\ntraining using masked language model task on pro-\nvided news articles data from all subtasks\n2. Train the multitask hierarchical model on\nspeci\ufb01c tasks: span detection and multilabel classi-\n\ufb01cation"}, {"source": "2023.semeval-1.193.pdf", "text": "\ufb01cation\n3. Evaluate model on the devset\n4. Train model on joint trainset and devset\nFor the step 1 we used standard code provided\nby huggingface1. Step 2 uses our implementation\nof a multitask hierarchical BERT based network\nthat is described in the next subsection.\nOne approach is used for all languages that con-\ntain train and dev set but models are trained sepa-\nrately."}, {"source": "2023.semeval-1.193.pdf", "text": "rately.\nFor languages that do not have train and dev set\nwe translate the articles from Polish to the required\nlanguage. For these languages we use simple BERT\nmodel for sequence classi\ufb01cation. We do not use\nour model as we believe it is hard to \ufb01nd exact\nspans after translation.\n3.1 Model architecture\nGeneral schema of the model architecture is pre-\nsented in Figure 1."}, {"source": "2023.semeval-1.193.pdf", "text": "sented in Figure 1.\nThe \ufb01rst layer of a model is a BERT layer. It\ntakes tokenized input paragraph and calculates em-\nbeddings. Next we add dropout layer. Then it is\n1https://huggingface.co/1396Figure 1: Proposed model architecture. Bert embed-\nding layer is shared between two linear layers. First\nlinear layer identi\ufb01es the \ufb01rst token index (dark blue"}, {"source": "2023.semeval-1.193.pdf", "text": "arrow) of persuasion text span. Then its embedding of\nthe \ufb01rst token of persuasion span is passed to the sec-\nond linear layer that performs multilabel classi\ufb01cation.\nThe index of span embedding even for the same sample\nmay change during training.\nfollowed by the \ufb01rst linear layer responsible for tag\nclassi\ufb01cation for span identi\ufb01cation. We use soft-"}, {"source": "2023.semeval-1.193.pdf", "text": "max as activation function of this layer. It classi\ufb01es\neach token as IorO.\nWe take the index of the \ufb01rst token of a span and\nwe use it to \ufb01nd the BERT embedding from this\ntoken from the previous layer. Then this embedding\nis passed to the second linear layer. If no span is\nidenti\ufb01ed the layer takes the \ufb01rst token of BERT\nembedding. The second linear layer is followed"}, {"source": "2023.semeval-1.193.pdf", "text": "by sigmoidal activation function. It has as many\noutputs as the number of classes and determines\nwhether the sample belongs to each class or not (it\ncan activate for any class).\nLoss function for our model is a sum of two:\nLoss = 0.5\u2217Loss 1+Loss 2 (1)\nTheLoss 1is cross entropy that calculates the loss\nfor span identi\ufb01cation and is used without any mod-\ni\ufb01cation."}, {"source": "2023.semeval-1.193.pdf", "text": "i\ufb01cation.\nLoss1n=\u2212[ynlogx n+ (1\u2212yn)\u2217log(1\u2212xn)]\n(2)\nwhere ynis the correct answer and xnis the pre-\ndiction for the nth batch. The Loss 2is used for\na multi-label classi\ufb01cation and is binary cross en-\ntropy calculated for each label with added weight\npc:\nLoss2n,c=\u2212[pcynlogx n+(1\u2212yn)\u2217log(1\u2212xn)]\n(3)\nWe add weight pcbecause of unbalanced num-"}, {"source": "2023.semeval-1.193.pdf", "text": "ber of classes. Weight of a class cis a proportionof samples from other classes to the number of\nsamples from class ccalculated as follows:\npc=nall\u2212nc\nnc(4)\nwhere nallis the number of all samples in the\ndataset and ncof the current class.\n4 Experimental Setup\nFor \ufb01nal evaluation we use train \ufb01le for training\nand test \ufb01le for evaluation. After choosing the"}, {"source": "2023.semeval-1.193.pdf", "text": "right parameters we train the whole model on both\ndatasets.\nWe used random search for hyper-parameter tun-\ning. For \ufb01nal model we used hyper-parameters as\nfollows. Maximum length of a sequence is 256, as\nit speeds up the computation and we did not see\nmuch improvement when using longer sequences.\nTrain batch size is 8 as it is mostly limited by the\nmachines that were available. Maximum number"}, {"source": "2023.semeval-1.193.pdf", "text": "of epochs is 30 and we saved the best model on dev\nset according to the micro-f1 metric. Learning rate\nwas set to 1e-05 and max gradient norm was set to\n10. Dropout before both linear layers is set to 0.1.\nThe network is trained using AdamW optimization\nalgorithm with weight decay equal to 0.01.\n4.1 Data preprocessing\nSpans are provided as a list of starting and ending"}, {"source": "2023.semeval-1.193.pdf", "text": "indexes of characters. We converted them to list\nofIandOtags where each tag corresponds to one\nword. Tag Omeans that the word does not contain\npersuasion and Imeans that word belongs to a\npersuasion span. First we identify which parts are\nbetween start and end index and then we split into\nwords using the \u201cspacy\u201d library2.\nWhen preparing the input data to the BERT"}, {"source": "2023.semeval-1.193.pdf", "text": "model, transformers have their own tokenizer and\nit may split the words into smaller tokens. In such\ncase each token has the same tag as the original\nword.\nAll labels were provided as a list. We convert\nthem to multi-hot encoding vectors. Pre-trained\nmodels from table 2 are used in our retraining . All\nof them come from the huggingface3. We use all"}, {"source": "2023.semeval-1.193.pdf", "text": "sets from all the three tasks to continue pre-training\nour BERT model for a particular language. We use\nmasked language model for that.\nModels were evaluated by micro \u2212F1in a \ufb01rst\nplace and then macro \u2212F1.\n2https://spacy.io/\n3https://huggingface.co/1397Language model name\nEnglish bert-base-cased\nPolish dkleczek/bert-base-polish-uncased-v1\nFrench dbmdz/bert-base-french-europeana-cased"}, {"source": "2023.semeval-1.193.pdf", "text": "Italian dbmdz/bert-base-italian-uncased\nRussian DeepPavlov/bert-base-bg-cs-pl-ru-cased\nGerman dbmdz/bert-base-german-uncased\nSpanish dccuchile/bert-base-spanish-wwm-uncased\nGreek nlpaueb/bert-base-greek-uncased-v1\nGeorgian bert-base-multilingual-cased\nTable 2: Transformer models used for continuing pre-\ntraining.\n5 Results\nThe results on the of\ufb01cial test set are presented in"}, {"source": "2023.semeval-1.193.pdf", "text": "table 4. Our system for all languages performs\nbetter than the baseline. Interestingly, models that\nhave no train and dev set such as Spanish, Greek\nor Georgian still perform better than baseline but\nmuch worse than other languages. That means we\ncan achieve better performance using translation\nbut it is never good enough. The reason could be\nthat translation tries to preserve the meaning but"}, {"source": "2023.semeval-1.193.pdf", "text": "may skip or change the type of persuasion. Also\nthe techniques for different languages may vary.\nAll models on the dev set perform much better\nthan the baseline (Figure 3). According to micro-f1,\nthe results for 3 random runs of model are stable,\nthe standard deviation is rather low. According to\nmacro-f1, the standard deviation is slightly higher,\nthat means one can observe differences between"}, {"source": "2023.semeval-1.193.pdf", "text": "dev set results and test set results. The reason may\nbe that the data for test set may come from different\ntopics and time. The system learns the techniques\nthat are more speci\ufb01c for train and dev set.\n5.1 Error analysis\nWe analysed which classes in the English devset are\nthe easiest/hardest to be recognized (Table 5). The\nmost frequent class (\"loaded language\") gets a high"}, {"source": "2023.semeval-1.193.pdf", "text": "f-measure value, but the highest one is achieved by\nthe \u201cGuilt by Association\u201d class which has only 4\nand 59 observations in the test and train sets, re-\nspectively, which means it is probably the easiest\nclass to detect. Classes \"Loaded Language\" and\n\"Name-Calling Labeling\" get high recall but lower\nprecision, which means they are often wrongly\ndetected. \"False Dillema-No Choice\" gets much"}, {"source": "2023.semeval-1.193.pdf", "text": "higher precision than recall which means it is pre-\ncisely recognized. There are a few classes that are\nnot recognized at all and most of them have the low\nnumber of samples.Our model baseline\nLanguage r/t f-micro f-micro\nPolish 11/20 0.31427 0.17928\nFrench 11/20 0.36246 0.24014\nItalian 15/20 0.39874 0.39719\nRussian 12/19 0.25289 0.20722\nGerman 12/20 0.37264 0.31667\nEnglish 23/23 0.06022 0.19517"}, {"source": "2023.semeval-1.193.pdf", "text": "English 23/23 0.06022 0.19517\n12* 0.30113*\nSpanish 13/17 0.24490 0.24843\nGreek 12/16 0.15021 0.08831\nGeorgian 13/16 0.15017 0.13793\nTable 3: Results on the \ufb01nal test sets. For English lan-\nguage we present post-evaluation result marked as \u2217,\nas the reason of the lower score on of\ufb01cial evaluation is\na wrong \ufb01le uploaded. The rank with * is calculated"}, {"source": "2023.semeval-1.193.pdf", "text": "based on of\ufb01cial leader board. r/t-rank/total number\nof participants, baseline - of\ufb01cial baseline, svm model\nwith unigrams and bigrams as input\nSome classes may require another approach, like\nadding broader context. For example \"Red Her-\nring\" is when someone introduces irrelevant infor-\nmation, what may be hard to detect based on a\nsingle sentence like He died there. what was classi-"}, {"source": "2023.semeval-1.193.pdf", "text": "\ufb01ed wrongly as \"Repetition\" or \"Melania paired the\nmid-length half price frock with Christian Loubotin\nheels\" what was classi\ufb01ed as \"Loaded language\"\nand \"Name-Calling-Labelling\". Both cases are\nhard to be recognized without the context. For\nexample, the second is suited to an article about\nfashion but not about politics.\nThe system was wrong also about the \"Conver-"}, {"source": "2023.semeval-1.193.pdf", "text": "sation Killer\" technique which is often a short and\nrather obvious statement: \"Everybody knows it.\" or\nhidden in some long paragraph \"How about sorting\nthat stuff out instead of politicizing something that\nshould be fun for everyone? How many times does\nit have to be said\".\nWe noticed that sometimes a broader context not\nonly from the article but also from the world of pol-"}, {"source": "2023.semeval-1.193.pdf", "text": "itics is necessary to correctly recognise a technique.\nFor example, the paragraph containing \"Appeal to\nHypocrisy\" But he didn\u2019t mention Mueller for the\nrest of the day. andOf course, Sir Kim would have\nhad plenty of targets had he decided to pass judge-\nment on the present incumbent of the White House.\nare not easy to be classi\ufb01ed based only on what is\ngiven in the sentence."}, {"source": "2023.semeval-1.193.pdf", "text": "given in the sentence.\nOnly 129 paragraphs were predicted correctly1398Our model BERT baseline\nLanguage f-micro f-macro f-micro f-macro f-micro f-macro\nEnglish 0.4080 \u00b10.001 0.1604 \u00b10.030 0.3811 \u00b10.012 0.1454 \u00b10.003 0.16125 0.21735\nPolish 0.3672 \u00b10.006 0.2113 \u00b10.023 0.3624 \u00b10.002 0.2181 \u00b10.008 0.12524 0.05673\nFrench 0.4157 \u00b10.009 0.2825 \u00b10.014 0.3859 \u00b10.005 0.2849 \u00b10.006 0.29285 0.13484"}, {"source": "2023.semeval-1.193.pdf", "text": "Italian 0.4351 \u00b10.020 0.2207 \u00b10.005 0.4022 \u00b10.028 0.2051 \u00b10.006 0.38918 0.10385\nRussian 0.4460 \u00b10.004 0.1598 \u00b10.020 0.3997 \u00b10.02 0.1469 \u00b10.02 0.25316 0.04284\nGerman 0.4120 \u00b10.001 0.2373 \u00b10.016 0.3964 \u00b10.001 0.2359 \u00b10.01 0.33116 0.10016\nTable 4: Mean scores achieved on the dev set for all language. Our model for each language was run 3 times. For\nbaseline we get the results from the leader board"}, {"source": "2023.semeval-1.193.pdf", "text": "Technique precision recall f1\nDoubt 0.29 0.25 0.27\nWhataboutism 0.00 0.00 0.00\nAppeal to Hypocr. 0.00 0.00 0.00\nCausal Oversimp. 0.06 0.08 0.07\nAppeal to Author. 0.10 0.04 0.05\nGuilt by Associat. 0.60 0.75 0.67\nSlogans 0.26 0.25 0.25\nFlag Waving 0.46 0.50 0.48\nLoaded Lang. 0.49 0.89 0.63\nRed Herring 0.00 0.00 0.00\nFalse Dil.-NoCh. 0.30 0.05 0.08\nApp. to Popular. 0.00 0.00 0.00"}, {"source": "2023.semeval-1.193.pdf", "text": "App. to Popular. 0.00 0.00 0.00\nConvers. Killer 0.00 0.00 0.00\nName Call.-Lab. 0.39 0.70 0.50\nA.to Fear-Prejud. 0.26 0.15 0.19\nExaggerat.-Mini. 0.19 0.38 0.26\nRepetition 0.19 0.04 0.06\nStraw Man 0.00 0.00 0.00\nObf.-Vag.-Conf. 0.00 0.00 0.00\nTable 5: Scores for each class achieved by our model\non English devset . Prec, rec, f1 are precision recall and\nf1-measure respectively."}, {"source": "2023.semeval-1.193.pdf", "text": "f1-measure respectively.\nfrom the English devset (all true labels are correctly\nrecognised and no other labels). Most of them have\none or two labels.\n6 Conclusion\nWe discovered that simple change of the index in\nBert embedding may help to improve the persua-\nsion classi\ufb01cation. Moreover, we are able to iden-\ntify spans and perform classi\ufb01cation on limited data"}, {"source": "2023.semeval-1.193.pdf", "text": "using the described networks. Our system works\nbetter than classic BERT for sequence classi\ufb01cation\nbut still needs some improvements.\nThe next step would be to check another lan-\nguage models, that may be more powerful for this\ntask. One could improve so that all the detected\nspans are included in classi\ufb01cation. If more data\nis available, we can use separate network for spans"}, {"source": "2023.semeval-1.193.pdf", "text": "and for classi\ufb01cation. As a future work we should\nalso extend the error analysis and \ufb01nd an approachfor \ufb01nding classes that are poorly recognized.\nWe believe that persuasion techniques are\nstrongly diverse and hard to be detected by one\nmodel. We think that trying ensemble models could\nimprove the results.\nReferences\nKatarzyna Baraniak and Marcin Sydow. 2021. A"}, {"source": "2023.semeval-1.193.pdf", "text": "dataset for sentiment analysis of entities in news\nheadlines (sen). Procedia Computer Science ,\n192:3627\u20133636. Knowledge-Based and Intelligent\nInformation and Engineering Systems: Proceedings\nof the 25th International Conference KES2021.\nJohannes Bjerva. 2017. Will my auxiliary tagging\ntask help? estimating auxiliary tasks effectivity in\nmulti-task learning. In Proceedings of the 21st"}, {"source": "2023.semeval-1.193.pdf", "text": "Nordic Conference on Computational Linguistics ,\npages 216\u2013220.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\nNakov. 2020. Semeval-2020 task 11: Detection of\npropaganda techniques in news articles. In Proceed-\nings of the Fourteenth Workshop on Semantic Evalu-\nation , pages 1377\u20131414.\nDimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj"}, {"source": "2023.semeval-1.193.pdf", "text": "Alam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021.\nSemEval-2021 task 6: Detection of persuasion tech-\nniques in texts and images. In Proceedings of the\n15th International Workshop on Semantic Evalua-\ntion (SemEval-2021) , pages 70\u201398, Online. Associa-\ntion for Computational Linguistics.\nJakob-Moritz Eberl, Hajo G Boomgaarden, and"}, {"source": "2023.semeval-1.193.pdf", "text": "Markus Wagner. 2017. One bias \ufb01ts all? three types\nof media bias and their effects on party preferences.\nCommunication Research , 44(8):1125\u20131148.\nRuidan He, Wee Sun Lee, Hwee Tou Ng, and Daniel\nDahlmeier. 2019. An interactive multi-task learn-\ning network for end-to-end aspect-based sentiment\nanalysis. In Proceedings of the 57th Annual Meet-"}, {"source": "2023.semeval-1.193.pdf", "text": "ing of the Association for Computational Linguis-1399tics, pages 504\u2013515, Florence, Italy. Association for\nComputational Linguistics.\nClayton Hutto and Eric Gilbert. 2014. Vader: A par-\nsimonious rule-based model for sentiment analysis\nof social media text. In Proceedings of the inter-\nnational AAAI conference on web and social media ,\nvolume 8, pages 216\u2013225."}, {"source": "2023.semeval-1.193.pdf", "text": "volume 8, pages 216\u2013225.\nDawid Jurkiewicz, \u0141ukasz Borchmann, Izabela Kos-\nmala, and Filip Grali \u00b4nski. 2020. ApplicaAI at\nSemEval-2020 task 11: On RoBERTa-CRF, span\nCLS and whether self-training helps them. In Pro-\nceedings of the Fourteenth Workshop on Semantic\nEvaluation , pages 1415\u20131424, Barcelona (online).\nInternational Committee for Computational Linguis-\ntics."}, {"source": "2023.semeval-1.193.pdf", "text": "tics.\nJakub Piskorski, Nicolas Stefanovitch, Giovanni\nDa San Martino, and Preslav Nakov. 2023. Semeval-\n2023 task 3: Detecting the category, the framing,\nand the persuasion techniques in online news in a\nmulti-lingual setup. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , Se-\nmEval 2023, Toronto, Canada.\nVictor Sanh, Thomas Wolf, and Sebastian Ruder. 2019."}, {"source": "2023.semeval-1.193.pdf", "text": "A hierarchical multi-task approach for learning em-\nbeddings from semantic tasks. In Proceedings of\nthe AAAI Conference on Arti\ufb01cial Intelligence , vol-\nume 33, pages 6949\u20136956.\nXinyi Wang, Guangluan Xu, Zequn Zhang, Li Jin, and\nXian Sun. 2021. End-to-end aspect-based sentiment\nanalysis with hierarchical multi-task learning. Neu-\nrocomputing , 455:178\u2013188."}, {"source": "2023.semeval-1.193.pdf", "text": "rocomputing , 455:178\u2013188.\nT Zhang, X Gong, and CLP Chen. 2022. Bmt-\nnet: Broad multitask transformer network for sen-\ntiment analysis. IEEE Transactions on Cybernetics ,\n52(7):6232\u20136243.1400"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Proceedings of the The 17th International Workshop on Semantic Evaluation (SemEval-2023) , pages 382\u2013388\nJuly 13-14, 2023 \u00a92023 Association for Computational Linguistics\nAPatt at SemEval-2023 Task 3: The Sapienza NLP System for\nEnsemble-based Multilingual Propaganda Detection\nAntonio Purificato and Roberto Navigli\nDepartment of Computer, Control and Management Engineering"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Sapienza University of Rome\npurificato.2019135@studenti.uniroma1.it ,navigli@diag.uniroma1.it\nAbstract\nIn this paper, we present our approach to the\ntask of identification of persuasion techniques\nin text, which is a subtask of the SemEval-\n2023 Task 3 on the multilingual detection of\ngenre, framing, and persuasion techniques in\nonline news. The subtask is multi-label at the"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "paragraph level and the inventory considered\nby the organizers covers 23 persuasion tech-\nniques. Our solution is based on an ensem-\nble of a variety of pre-trained language models\n(PLMs) fine-tuned on the propaganda dataset.\nWe first describe our system, the different ex-\nperimental setups we considered, and then pro-\nvide the results on the dev and test sets re-"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "leased by the organizers. The official evalua-\ntion shows our solution ranks 1stin English and\nattains high scores in all the other languages,\ni.e. French, German, Italian, Polish, and Rus-\nsian. We also perform an extensive analysis of\nthe data and the annotations to investigate how\nthey can influence the quality of our systems.\nWe release our code at https://github.com/"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "antoniopurificato/apatt_at_semeval .\n1 Introduction\nDue to its diffusion on social media platforms,\ninformation is being shared in real-time in the\nmodern digital world, in particular following the\nCOVID-19 pandemic. The detection of propaganda\nhas emerged as an important research topic with\nthe recent interest in fake news (Da San Martino\net al., 2020). In today\u2019s information age, anyone"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "can take advantage of the diffusion potential of\nInternet to spread propaganda surreptitiously, and\nthis is in fact done by activist groups, businesses,\nreligious institutions, the media, and even ordinary\npeople, reaching vast audiences. Many different\nstrategies are used to \u201chide\u201d propaganda messages\ninside standard text, ranging from appealing to the"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "audience\u2019s emotions to utilizing logical fallacies.\nSemEval-2023 Task 3 (Piskorski et al., 2023)\nSubtask 3 offers a different way to investigate thisproblem: given a news article selected from a me-\ndia source that could potentially spread disinforma-\ntion, the system is tasked to identify the persuasion\ntechniques adopted in each paragraph. This is a"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "multi-label task at the paragraph level and also\nmultilingual, with news articles in 6 different lan-\nguages: English, Italian, Polish, German, French\nand Russian.\nIn our approach, we adopt transfer learning and,\ninstead of using one single pre-trained language\nmodel, we create an ensemble of multiple state-of-\nthe-art architectures. To output the final prediction"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "two different approaches are used. For all the lan-\nguages except English it is possible to use a maxi-\nmum of two models, so for every ensemble we take\nthe probabilities of these models and average them\nto make the final prediction.\nIn English, instead, where it is possible to use\nmore than two models for the ensemble, we do not\naverage but weight the predictions of each model."}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "We notice that some models have better results on\na subset of classes, so we assign them a higher\nweight on the corresponding classes in the final\noutput. Our contribution is summarized as follows:\n\u2022We employ transfer learning by fine-tuning\nTransformer-based language models on the\npropaganda dataset.\n\u2022We improve the classification results of the\nensemble by weighting the predictions of each"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "model.\nThe remainder of this paper is organized as fol-\nlows: In Section 2 we review some recent work\nin the current literature. In Section 3 we provide\nthe details of our method, while in Section 4 we\ndescribe the experimental setup. In Section 5 we\ndemonstrate the effectiveness of the proposed ap-\nproach by showing and discussing its results. We"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "provide conclusions in Section 6.3822 Related Work\nPropaganda detection is a crucial topic for research\nin the field of Natural Language Processing be-\ncause it may be useful for additional applications\nlike spotting fake news on social media. Jiang et al.\n(2016) used the representation power of graphs\nto detect strange behaviours of groups of people."}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "They noticed that propaganda techniques are ap-\nplied when there are strange patterns on the ad-\njacency matrix and in the spectral subspaces of\nthe corresponding graph. Garimella et al. (2018)\ntried to capture the main style of propaganda with\na graph-based three-stage pipeline: they first built\na conversation graph about a topic, then they parti-"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "tioned the graph to identify potential controversies\nand finally they measured the amount of contro-\nversy from features of the graph.\nBarr\u00f3n-Cede\u00f1o et al. (2019) developed a tech-\nnique to determine the \u201cdegree\u201d of propaganda in\na piece of writing and integrated their model into a\nwebsite that groups recent articles about the same\nevent based on their propagandistic content. With"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "a similar approach V orakitphan et al. (2022) im-\nplemented a system, called PROTECT, to automat-\nically detect propagandist messages and classify\nthem along with the propaganda techniques em-\nployed. PROTECT allows users to input text and\nretrieve the propagandist spans in the message as\noutput. They used the RoBERTa PLM and then\nperformed a post-processing step to automatically"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "join tokens labelled with the same propaganda tech-\nnique into the same textual span. Da San Mar-\ntino et al. (2019) focused on more in-depth anal-\nysis, putting forward a more theoretical paradigm\nfor identifying and categorizing propaganda cam-\npaigns. They first created a corpus of manually\nannotated news articles at the fragment level and\nthen they proposed a suitable evaluation measure"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "for this task.\nA major limit of all the above cited previous\nwork is their focus on the English language. With\nthis work we aim to study propaganda techniques\nin a multilingual setup by employing ensemble\nmethods.\n3 Method\n3.1 Pre-trained Language Models (PLMs)\nWe worked with six types of Transformer-based\n(Vaswani et al., 2017) PLMs, with the goal of cre-"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "ating an ensemble of them whenever this was pos-sible. In fact, in some languages, we were not able\nto find more than one PLM, therefore the predic-\ntions were made using the only available one. In all\ncases, we used the pre-trained models with a layer\non top to perform classification. In the following\nwe provide a brief description of the models we\nused in our proposed solution:"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "used in our proposed solution:\n\u2022BERT (Devlin et al., 2019) is a popular\nTransformer-based PLM, which enables bidi-\nrectional training using a \u201cmasked language\nmodel\u201d (MLM) pre-training objective. It also\nuses next-sentence prediction (NSP) objective\nduring pre-training in order to understand re-\nlationships between sentences.\n\u2022RoBERTa (Liu et al., 2019) is an architecture"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "based on BERT, but improved using dynamic\nmasking and a different byte-level Byte-Pair\nEncoding.\n\u2022alBERT (Lan et al., 2020) replaces the next\nsentence prediction (NSP) loss with a sen-\ntence order prediction (SOP) one to better\nmodel inter-sentence coherence. In order to\nreduce memory consumption and computa-\ntional time it introduces two parameter reduc-\ntion techniques."}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "tion techniques.\n\u2022XLNet (Yang et al., 2019) is based mainly on\npre-training and a different parametrization\nfrom that of the other models but it also in-\ntroduces concepts from Transformer-XL (Dai\net al., 2019), such as the segment recurrence\nmechanism and the relative encoding scheme.\n\u2022distilBERT (Sanh et al., 2019) is a simpler\nTransformer model trained by distilling BERT"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "base. It has 40% fewer parameters than BERT\nand runs much faster, while in many cases\nkeeping performance in the same ballpark.\n\u2022HerBERT (Mroczkowski et al., 2021) is a\nTransformer-based model that was trained for\nthe Polish language, and outperformed multi-\nlingual BERT on average on a set of tests.\n3.2 Ensemble\nEach PLM is fed with the input_ids that are the"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "indices of the input sequence tokens in the vocabu-\nlary. They also take as input the attention_masks ,\nused to prevent the model from looking at padding\ntokens, and which also result from the tokenization383Figure 1: Our ensemble for this task. For English we select the value of the weights as described in Section 4. For\nthe other languages, we use a simple average and we set the weights to 1."}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "step that is responsible for preprocessing text into\nthe corresponding array of indices.\nAs we can see from Figure 1, after we train each\nPLM we create a list containing their predictions.\nOnce all the predictions are available we apply a\nweighted average. Our APatt architecture works in\nthe following way:\nx=/summationdisplay\npwp\u03c3p (1)\nwhere \u03c3pis the output of the p-th PLM, wpis the"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "weight given to the corresponding prediction and x\nis the final result. For all the languages other than\nEnglish wp= 1, while for the English language\nthe value of the weights is described in Section 4.\n3.3 Training\nAt training time, we minimize the binary cross-\nentropy (BCE) objective Las follows:\nL(xc, yc) =\u2212yclogx c\u2212(1\u2212yc)log(1\u2212xc)\nwhere ycis the label of class candxcis the pre-"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "dicted value for class c.\nAt test time, to predict the labels we classify\neach class based on the following formula:\n\u02dcyc=\u03c7(xc> \u03c4)\nwhere \u03c4is a probability threshold and \u03c7is an indi-\ncator function.\n4 Experimental setup\n4.1 Ensemble setup\nFor Russian, Polish and Italian we decided to avoid\nensembling and use only the output of the PLM,\nfor one or other of the following reasons:Model Micro-F1"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "alBERT 0.293\nRoBERTa 0.322\nBERT 0.343\nDeBERTa 0.345\nXLNet 0.365\nTable 1: Comparison of the performance of the different\nmodels for the English subtask on the dev set.\n\u2022It was not possible to find more than one PLM\nfor the specific language, or\n\u2022The creation of the ensemble did not improve\nthe performance.\nFor all the other languages we decided to use\nan ensemble. For English the PLMs used were"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "BERT, RoBERTa, DeBERTa, alBERT, XLNet. For\nFrench, we used BERT and RoBERTa. For German\nwe used BERT and distilBERT.\nTo select the values of the weights for the En-\nglish language we performed an ablation study for\neach PLM on the dev set, as shown in Table 1.\nXLNet achieves the best results. For this reason,\nthe predictions of XLNet are the most weighted"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "in the ensemble. alBERT has the worst results\nbut is not penalized too much in the final ensemble\nbecause in some classes it also attains very high val-\nues of micro-F1. In the final ensemble, we used the\nnormalized F1 scores as weights of the correspond-\ning PLMs: BERT 0.15, alBERT 0.17, RoBERTa\n0.19, DeBERTa 0.22 and XLNet 0.27.\n4.2 Hardware and Hyperparameters"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "4.2 Hardware and Hyperparameters\nAll the experiments were performed on an NVIDIA\nRTX 3090 with 10752 CUDA cores. We selected384Team Micro-F1 Macro-F1\nAPatt (weighted)10.39823 0.29660\nNLUBot101 0.39737 0.29273\nAPatt (not weighted) 0.36895 0.26413\nNL4IA 0.37937 0.32936\nPersuasionNLP4SG 0.37790 0.26514\nBaseline 0.16125 0.21735\nTable 2: Results on the dev set for the subtask 3 for"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "the English language. Our solution ranks 1stover 18\nteams1.\nthebase version of the PLMs to reduce the compu-\ntational time. We decided to use the cased models\nbecause casing might convey expressions of emo-\ntion: for example, if we write one or more words\nin capital letters it might be because we want to\nexpress anger. We tried different learning rates, but"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "the best results were obtained with 3\u00d710\u22125. We\nselected a batch size equal to 16 and we trained our\nsystems for 10 epochs using the AdamW optimizer\n(Loshchilov and Hutter, 2019). We selected a value\n\u03c4= 0.2as classification threshold because, after\nmultiple experiments with the dev set, we obtained\nthe best results with this value. The hyperparame-\nters were equal for all the languages.\n4.3 Data"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "4.3 Data\nThe input for all tasks was news and Web articles\nin plain text format. Articles were given in six lan-\nguages (English, French, German, Italian, Polish,\nand Russian) and were collected from 2020 to 2022.\nThey were gathered from various sources and cover\na variety of popular subjects, such as COVID-19\nor the Russo-Ukrainian War, as well as abortion"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "and migration. They were chosen primarily from\nthe mainstream media, but also from websites that\nmedia credibility experts have flagged as possibly\ndisseminating false information.\n4.4 Evaluation metrics\nThis subtask is a multi-label classification task. The\nofficial evaluation measure for this task is micro-F1.\nWe also report macro-F1.\n5 Results"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "We also report macro-F1.\n5 Results\nWe first report results on the English language. The\nintroduction of weighting the predictions improved\nour results. As we can see from Table 2, we ranked\n2ndon the dev set when using a standard aver-\nage, while we achieved the 1stplace by applying aTeam Micro-F1 Macro-F1\nAPatt (ours) 0.37562 0.12919\nSheffieldVeraAI 0.36802 0.17194"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "SheffieldVeraAI 0.36802 0.17194\nAppeal for attention 0.36299 0.16621\nKInITVeraAI 0.36157 0.13324\nBaseline 0.19517 0.06925\nTable 3: Official results on the test set for the subtask 3\nfor the English language. Our solution ranks 1stover 22\nteams.\nLanguage Micro-F1 Macro-F1 Ranking\nGerman 0.48375 0.17692 4/20\nPolish 0.36570 0.14969 6/20\nRussian 0.30602 0.11666 7/19\nFrench 0.38414 0.19125 8/20"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "French 0.38414 0.19125 8/20\nItalian 0.44094 0.16626 9/20\nTable 4: The results of our APatt for the other languages.\nweighted average.1\nTurning to the test set, according to the official\nresults, shown in Table 3, our weighted average\nsystem ranked 1st.\nFor the other languages we obtained good results\nin German and Polish, as we can see from the per-\nformance and the corresponding ranking shown in"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Table 4.\n5.1 Output\nFrom an analysis of the output of our system it can\nimmediately be seen how the results are affected\nby the distribution of the samples in the dataset.\nThis is shown clearly in Table 5. If we sort the\nclass distribution in the dev set from the least fre-\nquent (1) to the most frequent (23), we can see that\nresults are heavily biased towards more frequent"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "classes. Interestingly, however, we notice that we\nobtain a high F1-Score for Appeal To Time without\ntraining samples for this class. On the other hand,\ntheFalse Dilemma-No Choice class is in position\n16 of the ranking but has an F1-Score of only 0.128.\nMore in general, it is clear that, for a number of\nclasses, there are insufficient training samples to fit\nthe network parameters satisfactorily."}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "the network parameters satisfactorily.\n5.2 Data analysis\nThe training set for the English language is com-\nposed of 446 articles, while the dev set of 90 ar-\nticles. As we can see from the label distribution\n1This latter result with weighted average was obtained after\nthe competition was closed.385Class Ranking F1-Score\nRed Herring 10 0.295\nAppeal To Time 4 0.462\nRepetition 20 0.570"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Repetition 20 0.570\nLoaded Language 23 0.574\nTable 5: Comparison between the distribution of sam-\nples and the performance of the model on some classes.\nFigure 2: Data distribution of the labels in the English\ntrain set.\nin Figure 2, 54% of the paragraphs have no la-\nbels, 13% contain the Loaded Language propa-\nganda technique and 7% contain the Name calling"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "labelling propaganda technique. We noticed that\nfor the English language, there are techniques that\nare not in the training set, such as Appeal to time\nandAppeal to values .\nObviously, the distribution of the data depends\non the language under consideration. As also\ndiscussed in other works (Wu et al., 2019), the\ndataset imbalance is a problem that needs to be"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "addressed in this task. However, there is also\na more serious problem: while the labels for\nthe propaganda techniques were assigned using\nannotation guidelines, there are multiple cases\nwhere there is an ambiguity as to which label to\nchoose, also for a human. Here below we show\nand discuss two examples in English:\nHe vowed that London would remain the"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "He vowed that London would remain the\nsame after March 29 2019, and said the fireworks\ndisplay was about \u201cshowing the world, whilethey\u2019re watching us, that we\u2019re going to carry on\nbeing open-minded, outward looking, pluralistic\u201d.\nThe prediction of our system is Repetition while\nthe labels are Repetition, Name Calling Labelling .\nFrom the annotation guidelines, we have the"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "following definition of Name Calling Labelling :\n\u201ca form of argument in which loaded labels are\ndirected at an individual or group, typically in an\ninsulting or demeaning way\u201d. The reason why this\npropaganda technique is assigned to this paragraph\nis not clear. In fact, it contains no words that recall\nany type of insult or accusation. Another example\nis the following:"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "is the following:\nThere is a chance; as unfortunately there\nare many MPs who don\u2019t respect the vote and may\njust turn on it, but short of that I don\u2019t see any\nway the Conservatives would vote for it, and the\nmajority is slender as it is, as the DUP is bitterly\nagainst it, and I can\u2019t see the Lib Dems voting for\nit, so it will only be if there are enough, what I can"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "describe as remoaner MPs, that the deal won\u2019t be\ndead in the water.\nThe prediction of our system is Doubt, Loaded\nLanguage, Name Calling-Labeling while the labels\nareFalse Dilemma-No Choice, Loaded Language,\nName Calling-Labeling . Reading this sentence,\nfrom the point of view of a human, it is really diffi-\ncult to understand why Doubt is not the right label."}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "In fact, there are some sentences that express doubt,\nsuch as, for example, if there are enough orthere\nis a chance . These types of ambiguous annota-\ntions can influence the performance of propaganda\ndetection systems.\n6 Conclusion\nIn this paper, we examined the ability of\nTransformer-based language models, and in partic-\nular weighting the predictions of multiple models,"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "to carry out the task of detecting propaganda tech-\nniques in different languages. We showed how the\nclass imbalance of a dataset can influence the per-\nformance of a model on this task. Future work in-\ncludes examining more effective methods for solv-\ning the previous issue and also optimizing the value\nof the weights on the dev set to improve the perfor-\nmance.386Acknowledgments"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "mance.386Acknowledgments\nThe authors gratefully acknowledge\nthe support of the ERC Consolida-\ntor Grant MOUSSE No. 726487 un-\nder the European Union\u2019s Horizon\n2020 research and innovation pro-\ngramme.\nThis work was also supported in part by the PNRR\nMUR project PE0000013-FAIR.\nReferences\nJulien Abadji, Pedro Ortiz Suarez, Laurent Romary, and\nBeno\u00eet Sagot. 2022. Towards a Cleaner Document-"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Oriented Multilingual Crawled Corpus. arXiv e-\nprints , page arXiv:2201.06642.\nAlberto Barr\u00f3n-Cede\u00f1o, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Inf. Process. Manage. , 56(5):1849\u20131864.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nHenning Wachsmuth, Rostislav Petrov, and Preslav"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Nakov. 2020. SemEval-2020 task 11: Detection of\npropaganda techniques in news articles. In Proceed-\nings of the Fourteenth Workshop on Semantic Evalu-\nation , pages 1377\u20131414, Barcelona (online). Interna-\ntional Committee for Computational Linguistics.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarr\u00f3n-Cede\u00f1o, Rostislav Petrov, and Preslav Nakov."}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "2019. Fine-grained analysis of propaganda in news\narticle. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) , pages\n5636\u20135646, Hong Kong, China. Association for Com-\nputational Linguistics.\nZihang Dai, Zhilin Yang, Yiming Yang, Jaime Car-"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "bonell, Quoc Le, and Ruslan Salakhutdinov. 2019.\nTransformer-XL: Attentive language models beyond\na fixed-length context. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics , pages 2978\u20132988, Florence, Italy. Asso-\nciation for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "deep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n4171\u20134186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nKiran Garimella, Gianmarco De Francisci Morales,"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Aristides Gionis, and Michael Mathioudakis. 2018.\nQuantifying controversy on social media. Trans. Soc.\nComput. , 1(1).Meng Jiang, Peng Cui, Alex Beutel, Christos Falout-\nsos, and Shiqiang Yang. 2016. Inferring lockstep\nbehavior from connectivity pattern in large graphs.\nKnowledge and Information Systems , 48:399\u2013428.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Kevin Gimpel, Piyush Sharma, and Radu Soricut.\n2020. ALBERT: A lite BERT for self-supervised\nlearning of language representations. In 8th Inter-\nnational Conference on Learning Representations,\nICLR 2020, Addis Ababa, Ethiopia, April 26-30,\n2020 . OpenReview.net.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Luke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In 7th International\nConference on Learning Representations, ICLR 2019,\nNew Orleans, LA, USA, May 6-9, 2019 . OpenRe-\nview.net.\nVerena Lyding, Egon Stemle, Claudia Borghetti, Marco"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Brunello, Sara Castagnoli, Felice Dell\u2019Orletta, Hen-\nrik Dittmann, Alessandro Lenci, and Vito Pirrelli.\n2014. The PAIS\u00c0 corpus of Italian web texts. In Pro-\nceedings of the 9th Web as Corpus Workshop (WaC-\n9), pages 36\u201343, Gothenburg, Sweden. Association\nfor Computational Linguistics.\nRobert Mroczkowski, Piotr Rybak, Alina Wr\u00f3blewska,\nand Ireneusz Gawlik. 2021. HerBERT: Efficiently"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "pretrained transformer-based language model for Pol-\nish. In Proceedings of the 8th Workshop on Balto-\nSlavic Natural Language Processing , pages 1\u201310,\nKiyv, Ukraine. Association for Computational Lin-\nguistics.\nJakub Piskorski, Nicolas Stefanovitch, Giovanni\nDa San Martino, and Preslav Nakov. 2023. Semeval-\n2023 task 3: Detecting the category, the framing,"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "and the persuasion techniques in online news in a\nmulti-lingual setup. In Proceedings of the 17th Inter-\nnational Workshop on Semantic Evaluation , SemEval\n2023, Toronto, Canada.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Thomas Wolf. 2019. Distilbert, a distilled version of\nbert: smaller, faster, cheaper and lighter.\nJ\u00f6rg Tiedemann. 2012. Parallel data, tools and inter-\nfaces in opus. In Proceedings of the Eight Inter-\nnational Conference on Language Resources and\nEvaluation (LREC\u201912) , Istanbul, Turkey. European\nLanguage Resources Association (ELRA).\nTrieu H. Trinh and Quoc V . Le. 2019. A simple method"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "for commonsense reasoning.387Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, \u0141 ukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems , volume 30. Curran Associates, Inc.\nV orakit V orakitphan, Elena Cabrio, and Serena Villata.\n2022. PROTECT: A Pipeline for Propaganda Detec-"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "tion and Classification. In CLiC-it 2021- Italian Con-\nference on Computational Linguistics , Milan, Italy.\nZhenghao Wu, Hao Zheng, Jianming Wang, Weifeng Su,\nand Jefferson Fong. 2019. BNU-HKBU UIC NLP\nteam 2 at SemEval-2019 task 6: Detecting offensive\nlanguage using BERT model. In Proceedings of the\n13th International Workshop on Semantic Evalua-\ntion, pages 551\u2013555, Minneapolis, Minnesota, USA."}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "Association for Computational Linguistics.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for lan-\nguage understanding. In Advances in Neural Infor-\nmation Processing Systems , volume 32. Curran Asso-\nciates, Inc.\nAdrian Zbiciak and Tymon Markiewicz. 2023. A new"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "extraordinary means of appeal in the polish criminal\nprocedure: the basic principles of a fair trial and a\ncomplaint against a cassatory judgment. Access to\nJustice in Eastern Europe , 6(2):1\u201318.\nYukun Zhu, Ryan Kiros, Richard Zemel, Ruslan\nSalakhutdinov, Raquel Urtasun, Antonio Torralba,\nand Sanja Fidler. 2015. Aligning books and movies:\nTowards story-like visual explanations by watch-"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "ing movies and reading books. In arXiv preprint\narXiv:1506.06724 .\nA Pre-trained Language Models\nAll the selected PLMs were available on hugging-\nface2.\nFor the English language BERT was pretrained\non the BookCorpus (Zhu et al., 2015) and the En-\nglish Wikipedia, like alBERT. RoBERTa on Book-\nCorpus (Zhu et al., 2015), CC-News, OpenWeb-\nText (Radford et al., 2019), Stories (Trinh and Le,"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "2019) and English Wikipedia. XLNet was pre-\ntrained on BookCorpus (Zhu et al., 2015), English\nWikipedia, Giga5 (Zbiciak and Markiewicz, 2023),\nCC-News and ClueWeb. DeBERTa was pretrained\non English Wikipedia, BookCorpus (Zhu et al.,\n2015), OpenWebText and Stories (Trinh and Le,\n2019).\nFor the Italian Language BERT was pretrained\non OPUS (Tiedemann, 2012) and OSCAR (Abadji"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "et al., 2022), while DistilBERT on PAIS\u00c1 (Lyding\net al., 2014) and ItWaC corpora.\n2https://huggingface.coFor the Russian language both RoBERTa and\nBERT were pretrained on the Taiga corpus.\nFor the Polish language BERT was pretrained on\nPolish Wikipedia, a Polish Parliamentary corpus,\nOPUS (Tiedemann, 2012) and OSCAR (Abadji\net al., 2022).\nFor the French language BERT was pretrained"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "on the French Wikipedia corpus. RoBERTa was\npretrained on the French Wikipedia corpus and on\nCC-News.\nFinally for the German language BERT was pre-\ntrained on the German Wikipedia and OpenLegal-\nData corpora, as DistilBERT.\nB Ensemble\nAs shown in the paper the introduction of the en-\nsemble improved our results in all the languages.\nWhile we showed the improvements only for the"}, {"source": "Ensemble-based Multilingual Propaganda Detection.pdf", "text": "English language, we achieved better results also\nin French and German, as we can see from Table 6.\nLanguage No Ensemble Ensemble\nFrench 0.40881 0.43783\nGerman 0.40900 0.43288\nTable 6: Official results on the dev set for Subtask 3\nfor the French and German languages with and without\nensemble. No Ensemble and Ensemble are the values\nof Micro-F1 without and with ensemble respectively.388"}, {"source": "2020.semeval-1.187.pdf", "text": "Proceedings of the 14th International Workshop on Semantic Evaluation , pages 1415\u20131424\nBarcelona, Spain (Online), December 12, 2020.1415ApplicaAI at SemEval-2020 Task 11:\nOn RoBERTa-CRF, Span CLS and Whether Self-Training Helps Them\nDawid Jurkiewicz\u0003\u0141ukasz Borchmann\u0003Izabela Kosmala Filip Grali \u00b4nski\nApplica.ai Zaj\u02db ecza 15, 00-351 Warsaw, Poland\nfirstname.lastname@applica.ai\nAbstract"}, {"source": "2020.semeval-1.187.pdf", "text": "firstname.lastname@applica.ai\nAbstract\nThis paper presents the winning system for the propaganda Technique Classi\ufb01cation (TC) task\nand the second-placed system for the propaganda Span Identi\ufb01cation (SI) task. The purpose of\nthe TC task was to identify an applied propaganda technique given propaganda text fragment."}, {"source": "2020.semeval-1.187.pdf", "text": "The goal of SI task was to \ufb01nd speci\ufb01c text fragments which contain at least one propaganda\ntechnique. Both of the developed solutions used semi-supervised learning technique of self-\ntraining. Interestingly, although CRF is barely used with transformer-based language models,\nthe SI task was approached with RoBERTa-CRF architecture. An ensemble of RoBERTa-based"}, {"source": "2020.semeval-1.187.pdf", "text": "models was proposed for the TC task, with one of them making use of Span CLS layers we\nintroduce in the present paper. In addition to describing the submitted systems, an impact of\narchitectural decisions and training schemes is investigated along with remarks regarding training\nmodels of the same or better quality with lower computational budget. Finally, the results of error"}, {"source": "2020.semeval-1.187.pdf", "text": "analysis are presented.\n1 Introduction\nThe idea of \ufb01ne-grained propaganda detection was introduced by Da San Martino et al. (2019), whose\nintention was to facilitate research on this topic by publishing a corpus with detailed annotations of high\nreliability. There was a chance to propose NLP systems solving this task automatically as a part of this"}, {"source": "2020.semeval-1.187.pdf", "text": "year\u2019s SemEval series. It was expected to detect all fragments of news articles that contain propaganda\ntechniques, and to identify the exact type of used technique (Da San Martino et al., 2020).\nThe authors decided to evaluate Technique Classi\ufb01cation (TC) and Span Identi\ufb01cation (SI) tasks sepa-"}, {"source": "2020.semeval-1.187.pdf", "text": "rately. The purpose of the TC task was to identify an applied propaganda technique given the propaganda\ntext fragment. In contrast, the goal of the SI task was to \ufb01nd speci\ufb01c text fragments that contain at least\none propaganda technique. This paper presents the winning system for the propaganda Technique Clas-\nsi\ufb01cation task and the second-placed system for the propaganda Span Identi\ufb01cation task."}, {"source": "2020.semeval-1.187.pdf", "text": "2 Systems Description\nSystems proposed for both SI and TC tasks were based on RoBERTa model (Liu et al., 2019) with\ntask-speci\ufb01c modi\ufb01cations and training schemes applied.\nThe central motif behind our submissions is a commonly used semi-supervised learning technique\nof self-training (Yarowsky, 1995; Liao and Veeramachaneni, 2009; Liu et al., 2011; Wang et al.,"}, {"source": "2020.semeval-1.187.pdf", "text": "2020), sometimes referred to as incremental semi-supervised training (Rosenberg et al., 2005) or self-\nlearning (Lin et al., 2010). In general, these terms stand for a process of training an initial model on a\nmanually annotated dataset \ufb01rst and using it to further extend the train set by automatically annotating"}, {"source": "2020.semeval-1.187.pdf", "text": "other dataset. Usually, only a selected subset of auto-annotated data is used, however neither selection\nof high-con\ufb01dence examples nor loss correction for noisy annotations is performed in our case. This is\nwhy it can be considered a simpli\ufb01cation of mainstream approaches\u2014the na\u00efve self-training."}, {"source": "2020.semeval-1.187.pdf", "text": "This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://creative\ncommons.org/licenses/by/4.0/ .\n\u0003Equal contribution. Author order determined by a coin \ufb02ip.1416\nGold\ntrainingUnannotated\ndata\nRoBER Ta (1)\ninference\nSilver\nRoBER Ta (2)Figure 1: Self-training stands for a process of training an ini-"}, {"source": "2020.semeval-1.187.pdf", "text": "tial model on manually annotated dataset \ufb01rst and using it to\nfurther extend train by means of annotating other dataset auto-\nmatically.Hparam SI TC\nDropout .1\nAttention dropout .1\nMax sequence length 256 256\nBatch size 8 16\nLearning rate 5e-4 2e-5\nNumber of steps 60k 20k\nLearning rate decay \u2013\nWeight decay \u2013 .01\nMomentum .9 \u2013\nOptimizer SGD AdamW\nLoss Viterbi BCE"}, {"source": "2020.semeval-1.187.pdf", "text": "Optimizer SGD AdamW\nLoss Viterbi BCE\nTable 1: Optimizers and hyperparameters used for both \ufb01ne-\ntuning RoBERTa and training additional parameters.\nHparam SI TC\nDropout .0\nAttention dropout .0\nBatch size 16 16\nTable 2: Hyperparameter overwrites for self-training.\n2.1 Span Identi\ufb01cation\nThe problem of span identi\ufb01cation was treated as a sequence labeling task, which in the case of"}, {"source": "2020.semeval-1.187.pdf", "text": "Transformer-based language models is often solved by means of classifying selected sub-tokens (e.g.,\n\ufb01rst BPE of each word considered) with or without applying LSTM before the classi\ufb01cation layer (De-\nvlin et al., 2019).\nAlthough pre-Transformer sequence labeling solutions exploited CRF layer in the output (Huang et"}, {"source": "2020.semeval-1.187.pdf", "text": "al., 2015; Lample et al., 2016), this practice was abandoned by the authors of BERT (Devlin et al., 2019)\nand subsequent researchers developing the idea of bidirectional Transformers, with rare exceptions, such\nas Souza et al. (2019) who used BERT-CRF for Portuguese NER. Contrary to the above, we approached\nSpan Identi\ufb01cation task with RoBERTa-CRF architecture."}, {"source": "2020.semeval-1.187.pdf", "text": "The impact of this decision will be discussed in Section 3 along with remarks regarding training models\nof the same or better quality with a lower computational budget in an orderly fashion. In contrast, the\nfollowing narrative aims at a faithful re\ufb02ection of the actual way the model which we used was trained."}, {"source": "2020.semeval-1.187.pdf", "text": "Recipe Take one pretrained RoBERTa LARGE model, add CRF layer and train on original (gold) dataset\nuntil progress is no longer achieved with Viterbi loss, SGD optimizer, and hyperparameters de\ufb01ned in Ta-\nble 1. Use the best-performing model to annotate random 500k OpenWebText1sentences automatically."}, {"source": "2020.semeval-1.187.pdf", "text": "Train the second model on both original (gold) dataset and autotagged (silver) one with hyperparameters\nde\ufb01ned in Table 1. Repeat the procedure two more times with the best model from the previous step,\nhyperparameters from Table 2, and other OpenWebText sentences.\nNote that hyperparameters were indeed not overwritten during the \ufb01rst self-training iteration. Scores"}, {"source": "2020.semeval-1.187.pdf", "text": "achieved by the best-performing models were respectively 50:91(without self-training) and 50:98,51:45,\n52:24in consecutive self-training iterations.\nMany questions may arise regarding this procedure and the role of purely random factors. It is not a\nproblem when rather the best score than its explanation is desired. In a leaderboard-driven exploration,"}, {"source": "2020.semeval-1.187.pdf", "text": "one can simply conduct a broad set of experiments and choose the best-performing model without re-\n\ufb02ection, whether it is a byproduct of training instability. What actually happened here was investigated\nafterward and will be discussed in Section 3.\n1See:https://github.com/jcpeterson/openwebtext OpenWebText is a project aimed at the reconstruction\nof OpenAI\u2019s unreleased WebText dataset.1417"}, {"source": "2020.semeval-1.187.pdf", "text": "RoBER T a RoBER T a\n[BOS] T ok\t1 T ok\tN [BOP] T ok\t1' T ok\tM [EOP] T ok\t1\" T ok\tL ... ... ...... ... ... E [BOS] E 1 E M E [BOP] E 1 ' E 1 \" E L... ... ... T [BOS] T 1 T M T [BOP] T 1 ' T 1 \" T L\nE [EOP]T [EOP]\nE NT NSpan\tlabel"}, {"source": "2020.semeval-1.187.pdf", "text": "E [EOP]T [EOP]\nE NT NSpan\tlabel\nLeft\tcontext Right\tcontext Span\tto\tclassify[BOS] T ok\t1 T ok\tN T ok\t1' T ok\tM T ok\t1\" T ok\tL ... ... ...... ... ... E [BOS] E 1 E M E 1 ' E 1 \" E L... ... ... T [BOS] T 1 T M T 1 ' T 1 \" T L\nE NT NSpan\tlabel"}, {"source": "2020.semeval-1.187.pdf", "text": "E NT NSpan\tlabel\nLeft\tcontext Right\tcontext Span\tto\tclassify... T M T 1 ' E [BOS] '... T M\u2605 T 1\u2605 T [BOS]\u2605Figure 2: Comparison of span classi\ufb01cation by means of special tokens (left) and in Span CLS approach (right). On the left,\nspecial [BOP] and[EOP] tokens are introduced, and the span is further classi\ufb01ed as in the usual Transformer-based sentence"}, {"source": "2020.semeval-1.187.pdf", "text": "classi\ufb01cation task. On the right, an additional, small Transformer is stacked only over the selected tokens. It has no own\nembeddings apart from one for the [BOS] token, but uses representations provided by the host model instead.\n2.2 Technique Classi\ufb01cation\nTransformer-based language models used in the sentence classi\ufb01cation setting assume that representa-"}, {"source": "2020.semeval-1.187.pdf", "text": "tions of special tokens (such as [CLS] or[BOS] ) are passed to the classi\ufb01cation layer. Since TC task\nis aimed at the classi\ufb01cation of spans, it might be bene\ufb01cial to introduce information about the text\nfragment to be classi\ufb01ed. We experimented with two approaches addressing this requirement.\nThe \ufb01rst assumes an injection of special tokens indicating the beginning and the end of the text marked"}, {"source": "2020.semeval-1.187.pdf", "text": "as propaganda, such as a sample sentence before BPE applied appears as:\n[BOS] Democrats acted like [BOP] babies [EOP] at the SOTU [EOS]\nIn this approach we continue with representation of [BOS] , as in the usual sentence classi\ufb01cation task.\nThe second approach is to stack a small Transformer only on the selected tokens.2This one has no"}, {"source": "2020.semeval-1.187.pdf", "text": "own embeddings apart from the ones for [BOS] but uses the host model\u2019s representations instead. This\ntechnique is roughly equivalent to adding consecutive layers and masking attention outside the selected\nspan and will be referred to as Span CLS. Figure 2 summarizes differences between Span CLS and\nclassi\ufb01cation using special [BOP] and[EOP] tokens."}, {"source": "2020.semeval-1.187.pdf", "text": "The initial experiments have shown that underrepresented classes achieve lower scores. To overcome\nthis problem, we experimented with class-dependent rescaling applied to binary cross-entropy. In this\nsetting (further referred to as re-weighting ) factor for each class was determined as its inverse frequency\nmultiplied by the frequency of the most popular class. The modi\ufb01ed loss is equal to:"}, {"source": "2020.semeval-1.187.pdf", "text": "`(x;y) =\u00001\nNdNX\nn=1dX\nk=1\u0002\npkyk\nnlogxk\nn+ (1\u0000yk\nn) log(1 \u0000xk\nn)\u0003\npk=1\nfkmax( f)\nwhereNis the batch size, nindex denotes nth batch element, dis the number of classes, fstands for\na vector of class absolute frequencies calculated on the train set, xis the output vector from the last\nsigmoid layer and yis a vector of multi-hot encoded ground truth labels. Note that the only difference"}, {"source": "2020.semeval-1.187.pdf", "text": "from the original binary cross entropy for multi-label classi\ufb01cation is the addition of the pkclass weights.\nIn addition to the above, a part of the tested models took the use of the self-training approach. In\nthe case of TC task one had to identify spans \ufb01rst and then predict their classes to generate silver train"}, {"source": "2020.semeval-1.187.pdf", "text": "2The Transformer we used in our experiment had 3hidden layers, 4attention heads and an intermediate layer of size 512.\nNote that hidden size depends on host model, since we are using external embeddings.1418\n0.420.440.460.480.50\nBatch = 8\nRoBERTa-CRF \nRoBERTa\n25 50 100 200 500 1000 2000\nPercentage of train set used0.420.440.460.480.50"}, {"source": "2020.semeval-1.187.pdf", "text": "Batch = 16Figure 3: Performance of RoBERTa with and without CRF\nas a function of percentage of train set available. Values above\n100% indicate self-training was performed. Mean FLC-F1 and\nstandard deviation across 5 runs for each percentage.CRF Self-train FLC-F1 (std, max)\n\u0000 \u0000 45:2\u00060:3 45:6\n+\u0000 47:4\u00060:8 48:2\n\u0000 + 48:9\u00060:5 50:2\n+ + 49 :1\u00063:0 51:7\n+ + (2) 49 :7\u00062:0 51:6\n+ + (3) 50 :0\u00061:8 51:8"}, {"source": "2020.semeval-1.187.pdf", "text": "+ + (3) 50 :0\u00061:8 51:8\nTable 3: Best scores on the dev set achieved with RoBERTa\nlarge model on SI task. Mean, standard deviation and maxi-\nmum across 10 runs with different random seeds. Numbers in\nbrackets indicate how many self-training iterations were used.\nBatch Dropouts Self-train CRF \u0001FLC-F1\n16!8:0!:1\n+\u0000 \u0000 1:1\n+\u00001:6\n:0\u0000 \u0000 0:4\n+\u00001:1\n8!16:1!:0\n\u0000\u0000 \u0000 3:9\n+\u00007:0\n:1\u0000 \u0000 0:7\n+\u00001:3"}, {"source": "2020.semeval-1.187.pdf", "text": "\u0000\u0000 \u0000 3:9\n+\u00007:0\n:1\u0000 \u0000 0:7\n+\u00001:3\nTable 4: Impact of hypothetical lowering batch size during self\ntraining or enlarging batch size during initial training, as well\nas of enabling or disabling both hidden and attention dropouts.\nChange between means across 10 runs with different random\nseeds.\nset (Figure 1). We reused our best-performing model from SI task to identify spans, and the TC model"}, {"source": "2020.semeval-1.187.pdf", "text": "trained on ground truth to automatically annotate these spans.\nRegardless of the approach taken, context as broad as possible within the 256 subword units limit was\nprovided on both sides of the span to be classi\ufb01ed. Note that it was a maximum equal extension of the\nspan text in both directions, and we did not limit the extension to the sentence boundaries."}, {"source": "2020.semeval-1.187.pdf", "text": "The winning TC model (described in the recipe below) was an ensemble of three models. Each of\nthem used a different mix of previously described approaches with hyperparameters de\ufb01ned in Table 1\nfor \ufb01rst and second model, and those from Table 2 in case of the third model.\nRecipe Add classi\ufb01cation layer (described in Figure 2 on the left) to the pretrained RoBERTa LARGE"}, {"source": "2020.semeval-1.187.pdf", "text": "model in order to obtain the \ufb01rst model and train until no score gain is observed on development set.\nTrain the second model in the same manner, but this time using the re-weighting . Combine re-weighting ,\nSpan CLS and self-training approaches to get the third model, and again train until no score improvement"}, {"source": "2020.semeval-1.187.pdf", "text": "on development set is observed. Finally, ensemble all three models by averaging class probabilities from\ntheir \ufb01nal layers.\nAs shown later, the approach we took and reported above turned out to be sub-optimal. An in-depth\nanalysis of this system and a better one is proposed in Section 3.2.\n3 Ablation Studies"}, {"source": "2020.semeval-1.187.pdf", "text": "3 Ablation Studies\nSince different random initialization or data order can result in considerably higher scores,3models with\ndifferent random seeds were trained for the purposes of ablation studies. In the case of the SI task, results\nwere evaluated on the original development set. In contrast, in the case of TC, where fewer data points"}, {"source": "2020.semeval-1.187.pdf", "text": "are available, we decided to use cross-validation instead.1419# Re-weight Span CLS Self-train Micro-F1 (std)\n(1)\u0000 \u0000 \u0000 71:9\u00061:5\n(2)\u0000 \u0000 + 71 :4\u00061:4\n(3)\u0000 +\u0000 72:2\u00061:3\n(4)\u0000 + + 71 :8\u00061:7\n(5) +\u0000 \u0000 71:8\u00061:6\n(6) +\u0000 + 70 :9\u00061:7\n(7) + + \u0000 72:4\u00061:5\n(8) + + + 71 :3\u00061:5\nTable 5: Average of 6-fold cross-validation score on TC task\nwith micro-averaged F1 metric.Ensemble Micro-F1 (std)\n(1) (6) 72:3\u00061:7"}, {"source": "2020.semeval-1.187.pdf", "text": "(1) (6) 72:3\u00061:7\n(1) (2) 72:9\u00061:8\n(3) (5) 73:6\u00061:5\n(1) (5) (8) 74:1\u00061:7\n(2) (4) (7) 74:4\u00061:5\n(1) (4) (7) 74:6\u00061:4\n(1) (4) (7) (8) 74:9\u00061:2\n(1) (2) (4) (5) (7) 75:1\u00061:5\nTable 6: Average scores achieved with ensembles of individual\nmodels described in Table 5. Micro-averaged F1 metric.\n3.1 Span Identi\ufb01cation"}, {"source": "2020.semeval-1.187.pdf", "text": "3.1 Span Identi\ufb01cation\nModels with different random seeds were trained for 60K steps with an evaluation performed every 2K\nsteps. This is equivalent to approximately 30 epochs, and per-epoch validation in a scenario without data\ngenerated during the self-training procedure. Table 3 summarizes the best scores achieved across 10 runs\nfor each con\ufb01guration."}, {"source": "2020.semeval-1.187.pdf", "text": "for each con\ufb01guration.\nCRF has a noticeable positive impact on FLC-F1 (Da San Martino et al., 2020) scores achieved without\nself-training in the setting we consider. The presence of the CRF layer is correlated positively with the\nscore (\u001a= 0:27,p<0:001). The difference is signi\ufb01cant ( p<0:001), according to the Kruskal\u2013Wallis"}, {"source": "2020.semeval-1.187.pdf", "text": "test (Kruskal and Wallis, 1952) . Unless said otherwise, all further statistical statements within this\nsection were con\ufb01rmed with statistically signi\ufb01cant positive Spearman rank correlation and Kruskal-\nWallis test results. Differences in variance were con\ufb01rmed using Bartlett\u2019s test (Snedecor and Cochran,\n1989). The 0:05signi\ufb01cance level was assumed."}, {"source": "2020.semeval-1.187.pdf", "text": "The statistically signi\ufb01cant in\ufb02uence of CRF disappears when the self-training is investigated. In the\ncase of \ufb01rst self-training, regardless of whether or not CRF was used, a considerable increase in median\nscore can be observed. Self-trained models with and without the CRF layer, however, are indistinguish-\nable."}, {"source": "2020.semeval-1.187.pdf", "text": "able.\nImprovement offered by further self-training iterations is not so evident but is statistically signi\ufb01cant.\nIn particular, they slightly improve mean scores and decrease variance (see Table 3). As it comes to the\nlatter, CRF-extended models generally have higher variance and scores achieved across the runs."}, {"source": "2020.semeval-1.187.pdf", "text": "Table 4 analyzes the importance of using different hyperparameters. Whereas use of a smaller batch\nsize and dropout is bene\ufb01cial for the initial training without noisy data, it negatively impacts the self-\ntraining phase. The most substantial negative impact is observed when dropout is disabled during training\non the small amount of manually annotated data."}, {"source": "2020.semeval-1.187.pdf", "text": "Figure 3 illustrates scores achieved by models trained for the same number of steps on subsets or\nsupersets of manually annotated data. CRF layer has a positive impact regardless of the percentage of\ntrain set available. Once again, a large variance in scores of CRF-equipped models can be observed,"}, {"source": "2020.semeval-1.187.pdf", "text": "however, it is substantially reduced with the increase of a batch size. Interestingly, \ufb01gures suggest the\nproportion of automatically annotated data we used might be suboptimal since it was an equivalent of\naround 3000% in line with the chart\u2019s convention. One may hypothesize better scores would be achieved\nby models trained with 1 : 4 gold to silver proportion.\n3.2 Technique Classi\ufb01cation"}, {"source": "2020.semeval-1.187.pdf", "text": "3.2 Technique Classi\ufb01cation\n6-fold cross-validation was conducted. The results are presented in Table 5. Folds were created by\nmixing training and development datasets, then shuf\ufb02ing them and splitting into even folds. Parameters\nwere set according to Table 1 and Table 2, whereas experiments were carried out as follows. Each"}, {"source": "2020.semeval-1.187.pdf", "text": "approach from Table 5 was separately evaluated on each fold using the micro-averaged F1 metric. Then,\nfor each approach, the average score and the standard deviation were obtained using six scores from\nevery fold.\n3See e.g., Junczys-Dowmunt et al. (2018) or recent analysis of Dodge et al. (2020).1420\n(1) (2) (3) (4) (5) (6) (7) (8)\nModel73.073.574.074.575.0Score\nYes"}, {"source": "2020.semeval-1.187.pdf", "text": "Model73.073.574.074.575.0Score\nYes\nNoFigure 4: Impact of adding a particular model to the ensem-\nble has on mean scores from different folds. Comparison of\nresults with and without it present in tested combination.Model (1) (2) (3) (4) (5) (6) (7) (8)\n\u001a:28:30:20:41:32:05\u0003:50:36\nTable 7: Spearman\u2019s \u001abetween presence of ensemble com-\nponent (models from Table 5) and score achieved by ensem-"}, {"source": "2020.semeval-1.187.pdf", "text": "ble.\u0003indicate results were not signi\ufb01cant, assuming 0:05\nsigni\ufb01cance level.\nMoreover, all the 247 possible ensembles4were evaluated in the same fashion as in experiments from\nTable 5. Table 6 shows the performance achieved by selected combinations when simple averaging of\nthe probabilities returned by individual models was used as the \ufb01nal prediction."}, {"source": "2020.semeval-1.187.pdf", "text": "Due to a large number of available results, it is bene\ufb01cial to conduct a statistical analysis to formulate\nremarks regarding the general observed trends. Each component model of the ensemble was treated as a\ncategorical variable with respect to the ensemble score. Spearman rank correlation between the presence"}, {"source": "2020.semeval-1.187.pdf", "text": "of an ensemble component (approaches from Table 5) and achieved scores shows that adding model to\nthe ensemble correlates with a signi\ufb01cant increase in score, except for (6) model (see Table 7). Boxplots\nfrom Figure 4 lead to the same conclusions.5\nRe-weighting seems to be bene\ufb01cial only when ensembled with other models. An interesting \ufb01nding"}, {"source": "2020.semeval-1.187.pdf", "text": "is that Span CLS offers a small but consistent increase of performance both in models from Table 5 and\nwhen used in ensembles. Bear in mind, we outperformed the second-placed team by \", so an improve-\nment of a point or half is not negligible.\nWhat is most conspicuous, however, is that self-training based solutions from Table 5 seem to be"}, {"source": "2020.semeval-1.187.pdf", "text": "detrimental in the case of TC task. This damaging effect can be potentially attributed to the fact that\nautomatically generated data accumulate errors from both Span Identi\ufb01cation and Classi\ufb01cation. Another\npossible explanation is that much fewer data points are available for span classi\ufb01cation task than for span"}, {"source": "2020.semeval-1.187.pdf", "text": "identi\ufb01cation attempted as a sequence labeling task. The latter would be somehow consistent with what\nwas found in the \ufb01eld of Neural Machine Translation, where the use of the back-translation technique in\nlow-resource setting was determined to be harmful (Edunov et al., 2018).\nOn the other hand, self-training has a positive, statistically signi\ufb01cant impact on the score when used in"}, {"source": "2020.semeval-1.187.pdf", "text": "ensembles (see Figure 4 and Table 7). It is not surprising as the bene\ufb01cial impact of combining individual\nestimates was observed in many disciplines and is known since the times of Laplace (Clemen, 1989).\n4 Error analysis\nIn addition to providing an overview of problematic classes, the question of which shallow features"}, {"source": "2020.semeval-1.187.pdf", "text": "in\ufb02uence score and worsen the results was addressed. This problem was analyzed in a no-box manner,\nas proposed by Grali \u00b4nski et al. (2019). The main idea is to create two dataset subsets for each feature\nconsidered (one for data points with the feature present and one for data points without the feature),"}, {"source": "2020.semeval-1.187.pdf", "text": "rank subsets by per-item scores, and use Mann-Whitney rank U(Mann and Whitney, 1947) to determine\nwhether there is a non-accidental difference between subsets. A low p-value indicates that feature reduces\nthe evaluation score of the model.\n4It is the number of all subsets with cardinality greater than one, drawn from an 8-element set."}, {"source": "2020.semeval-1.187.pdf", "text": "5Kruskal-Wallis test and Boruta algorithm (Kursa et al., 2010) were used in addition to support these \ufb01ndings too.1421\nAuthority\nFear\nBandwagon\nB&W\nSimpli\ufb01cation\nDoubt\nMinimization\nFlag-Waving\nLoaded\nLabeling\nRepetition\nSlogans\nClich\u00e9s\nStrawmanOverall\nIdenti\ufb01ed subsequence 57 56 20 36 50 42 48 40 44 45 26 62 41 41 43\nFully identi\ufb01ed % 7 18 0 18 5 6 11 50 25 21 33 7 23 10 23"}, {"source": "2020.semeval-1.187.pdf", "text": "Not identi\ufb01ed 35 25 80 45 44 51 39 9 29 33 40 30 35 48 33\nNumber of instances 14 44 5 22 18 66 68 87 325 183 145 40 17 29 1063\nTable 8: Proportion of partially and fully identi\ufb01ed spans (SI task) depending on the propaganda technique used. All the\nexperiments conducted on the original development set.\n4.1 Span Identi\ufb01cation"}, {"source": "2020.semeval-1.187.pdf", "text": "4.1 Span Identi\ufb01cation\nSince the FLC-F1 metric used in the SI task gives non-zero scores for partial matches; it is interesting to\nanalyze what was the proportion of entirely missed (partially identi\ufb01ed) spans. Table 8 investigates this\nquestion broken down by the propaganda technique used.\nOur system was unable to identify one-third of expected spans, whereas a majority of those correctly"}, {"source": "2020.semeval-1.187.pdf", "text": "identi\ufb01ed were the partial matches. The spans the easiest to identify in the text represented Flag-Waving ,\nAppeal to fear/prejudice , and Slogans techniques. In contrast, Bandwagon ,Doubt , and the group of\n{Whataboutism ,Strawman ,Red Herring } turned out to be the hardest. The highest proportion of fully"}, {"source": "2020.semeval-1.187.pdf", "text": "identi\ufb01ed spans was achieved for Flag-Waving ,Repetition , and Loaded Language . Unfortunately, it is\nnot possible to investigate precision in this manner, without training separate models for each label or\nestimating one-to-one alignments between output and expected spans.\nFurther investigation of problematic cases in a paradigm of no-box debugging with the GEval"}, {"source": "2020.semeval-1.187.pdf", "text": "tool (Grali \u00b4nski et al., 2019) revealed the most worsening features, that are features whose presence im-\npacts span identi\ufb01cation evaluation metrics negatively (Table 9). It seems that our system tends to return\nranges without adjacent punctuation. This is the case of sentences such as The new CIA Director Haspel,"}, {"source": "2020.semeval-1.187.pdf", "text": "who \u2018tortured some folks, \u2019 probably can\u2019t travel to the EU , where only the quoted text was returned,\nwhereas annotation assumes it should be returned with apostrophes and commas. This remark can be\nused to improve overall results with simple post-processing slightly. Returned andconjunction refers to"}, {"source": "2020.semeval-1.187.pdf", "text": "the cases where it connects two propaganda spans. The system frequently returns them as a single span,\ncontrary to what is expected in the gold standard.\n4.2 Technique Classi\ufb01cation\nFigure 5 presents the normalized confusion matrix of the submitted system predictions. Interestingly,\nthere are a few commonly confused pairs. Loaded Language andBlack-and-white Fallacy were fre-"}, {"source": "2020.semeval-1.187.pdf", "text": "quently misclassi\ufb01ed as Appeal to fear/prejudice . Similarly, Causal Oversimpli\ufb01cation was often pre-\ndicted as Doubt andClich\u00e9s asLoaded Language .\nThe most worsening features are presented in Table 10. One of the frequent predictors of low accuracy\nis a comma character present within the span to be classi\ufb01ed. It can probably be attributed to the fact that"}, {"source": "2020.semeval-1.187.pdf", "text": "its presence is a good indicator of span linguistic complexity. Another determinant of inef\ufb01ciency turned\nout to be a negation\u2014around half of the sentences containing word notwere misclassi\ufb01ed by the system.\nSuggested features of a quotation mark before the span and the digram according to after the span are"}, {"source": "2020.semeval-1.187.pdf", "text": "related to reported or indirect speech. The explanation of the worsening effect of other features is not as\nevident as in the case mentioned above. Moreover, it seems there is no obvious way of improving the\n\ufb01nal results with our \ufb01ndings, and a more detailed analysis might be required.\n5 Discussion and Summary"}, {"source": "2020.semeval-1.187.pdf", "text": "5 Discussion and Summary\nThe winning system for the propaganda Technique Classi\ufb01cation (TC) task and the second-placed system\nfor the propaganda Span Identi\ufb01cation (SI) task has been described. Both of the developed solutions used\na semi-supervised learning technique of self-training. Although CRF is barely used with Transformer-"}, {"source": "2020.semeval-1.187.pdf", "text": "based language models, the SI task was approached with RoBERTa-CRF architecture. An ensemble of1422\nAuthority\nFear\nBandwagon\nB&W\nSimplification\nDoubt\nMinimisation\nFlag-Waving\nLoaded\nLabeling\nRepetition\nSlogans\nClich\u00e9s\nStrawmanAuthority\nFear\nBandwagon\nB&W\nSimplification\nDoubt\nMinimisation\nFlag-Waving\nLoaded\nLabeling\nRepetition\nSlogans\nClich\u00e9s\nStrawman.43.07 .14.07 .07.07.07 .07"}, {"source": "2020.semeval-1.187.pdf", "text": "Strawman.43.07 .14.07 .07.07.07 .07\n.02.52 .02 .02.07.02.23.07.02\n.8 .2\n.05.32 .14 .05.18.05.14 .09\n.06.06 .44.22.06 .06.11\n.02.08 .03.62.08 .08.03.05.02 .02\n.06.04 .01.66 .1.06.03.01 .01\n.02 .01.06 .79.02.02.01.06\n.03 .01.04 .81.03.04.02\n.01 .02.01.15.74.05 .02\n.01 .02.13.14.66\n.03 .12.03.05.12.62.03\n.06 .06.12.12.24 .06.29.06"}, {"source": "2020.semeval-1.187.pdf", "text": ".06 .06.12.12.24 .06.29.06\n.03 .03.07.17.07.03.07.1.07 .34Figure 5: Confusion matrix of the submitted system predic-\ntions normalized over the number of correct labels. Rows\nrepresent the correct labels and columns \u2013 the predicted ones\n(TC).Feature Count P-value\nquestion expected 21 0:036\ndot 36 0:037\nquotation 58 0:050\nexclamation 15 0:064\nand output 14 0:070"}, {"source": "2020.semeval-1.187.pdf", "text": "and output 14 0:070\nTable 9: Selected shallow features one may hypothesize im-\npact evaluation scores negatively (SI).\nFeature Count P-value\ncomma inside 119<0:001\nwe 15 0:002\nthis 28 0:007\nwill 40 0:008\nnot 62 0:013\nexclamation 16 0:014\nCIA before 25<0:001\naccording to after 8<0:001\nquotation before 65 0:004\nTable 10: Selected shallow features one may hypothesize im-"}, {"source": "2020.semeval-1.187.pdf", "text": "pact evaluation scores negatively (TC).\nRoBERTa-based models has been proposed for the TC task, with one of them making use of Span CLS\nlayers we introduce in the present paper.\nAnalysis conducted afterward can be applied in a rather straightforward manner to further improve\nthe scores for both SI and TC tasks. It is because some of the decisions we have made given lack of"}, {"source": "2020.semeval-1.187.pdf", "text": "or uncertain information, during the post-hoc inquiry turned out to be sub-optimal. These include the\nproportion of data from self-training in the SI task, and the possibility of providing a better ensemble in\nthe case of TC.\nThe ablation studies conducted, however, have some limitations. The same subset of OpenWebText"}, {"source": "2020.semeval-1.187.pdf", "text": "was used in experiments conducted within one self-training iteration. This means a random seed did\nnot impact which sentences were used during the \ufb01rst, second, and third self-training phase, and in\neach, we were manipulating only the data order. Moreover, an analysis we reported was limited to few\nhyperparameter combinations and no extensive hyperparameter space search was performed. Finally,"}, {"source": "2020.semeval-1.187.pdf", "text": "only one and a rather simple method of cost-sensitive re-weighting was tested, and there is a great chance\nit was sub-optimal. It would be interesting to investigate other schemes, such as the one proposed by Cui\net al. (2019).\nThe error analysis revealed propaganda techniques commonly confused in TC task, and the techniques"}, {"source": "2020.semeval-1.187.pdf", "text": "we were unable to detect effectively within the SI input articles. In addition to providing an overview of\nproblematic classes, the question of which shallow features in\ufb02uence score and worsen the results was\naddressed. A few of these were identi\ufb01ed and our remarks can be used to slightly improve results on SI"}, {"source": "2020.semeval-1.187.pdf", "text": "task with simple post-processing. This is not the case for TC task, where one is unable to propose how\nto improve the \ufb01nal results with our \ufb01ndings.\nAn interesting future research direction seems to be the application of the CRF layer and Span CLS\nto Transformer-based language models when dealing with other tasks outside the propaganda detection"}, {"source": "2020.semeval-1.187.pdf", "text": "problem. These may include Named Entity Recognition in the case of RoBERTa-CRF, and an aspect-\nbased sentiment analysis that can be viewed through the lens of span classi\ufb01cation with Span CLS we\nproposed.14236 Outro\nDeveloped systems were used to identify and classify spans in the present paper to detect fragments one"}, {"source": "2020.semeval-1.187.pdf", "text": "may suspect to represent one or more propaganda techniques. Unfortunately for the entertaining value\nof this work, none of such were identi\ufb01ed by our SI model.\nReferences\nRobert T. Clemen. 1989. Combining forecasts: A review and annotated bibliography. International Journal of\nForecasting , 5(4):559 \u2013 583."}, {"source": "2020.semeval-1.187.pdf", "text": "Forecasting , 5(4):559 \u2013 583.\nYin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge J. Belongie. 2019. Class-balanced loss based on ef-\nfective number of samples. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) ,\npages 9260\u20139269.\nGiovanni Da San Martino, Seunghak Yu, Alberto Barr\u2019on-Cede no, Rostislav Petrov, and Preslav Nakov. 2019."}, {"source": "2020.semeval-1.187.pdf", "text": "Fine-grained analysis of propaganda in news articles. In Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th International Joint Conference on Natural Language\nProcessing, EMNLP-IJCNLP 2019 , EMNLP-IJCNLP 2019, Hong Kong, China, November.\nGiovanni Da San Martino, Alberto Barr\u2019on-Cede no, Henning Wachsmuth, Rostislav Petrov, and Preslav Nakov."}, {"source": "2020.semeval-1.187.pdf", "text": "2020. SemEval-2020 task 11: Detection of propaganda techniques in news articles. In Proceedings of the 14th\nInternational Workshop on Semantic Evaluation , SemEval 2020, Barcelona, Spain, September.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirec-\ntional transformers for language understanding. In NAACL-HLT ."}, {"source": "2020.semeval-1.187.pdf", "text": "Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh Hajishirzi, and Noah Smith. 2020. Fine-\ntuning pretrained language models: Weight initializations, data orders, and early stopping.\nSergey Edunov, Myle Ott, Michael Auli, and David Grangier. 2018. Understanding back-translation at scale. In\nEMNLP ."}, {"source": "2020.semeval-1.187.pdf", "text": "EMNLP .\nFilip Grali \u00b4nski, Anna Wr\u00f3blewska, Tomasz Stanis\u0142awek, Kamil Grabowski, and Tomasz G\u00f3recki. 2019. GEval:\nTool for debugging NLP datasets and models. In Proceedings of the 2019 ACL Workshop BlackboxNLP: An-\nalyzing and Interpreting Neural Networks for NLP , pages 254\u2013262, Florence, Italy, August. Association for\nComputational Linguistics."}, {"source": "2020.semeval-1.187.pdf", "text": "Computational Linguistics.\nZhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. CoRR ,\nabs/1508.01991.\nMarcin Junczys-Dowmunt, Roman Grundkiewicz, Shubha Guha, and Kenneth Hea\ufb01eld. 2018. Approaching\nneural grammatical error correction as a low-resource machine translation task. In Proceedings of the 2018"}, {"source": "2020.semeval-1.187.pdf", "text": "Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long Papers) , pages 595\u2013606, New Orleans, Louisiana, June. Association for\nComputational Linguistics.\nWilliam H Kruskal and W Allen Wallis. 1952. Use of ranks in one-criterion variance analysis. Journal of the\nAmerican statistical Association , 47(260):583\u2013621."}, {"source": "2020.semeval-1.187.pdf", "text": "Miron B Kursa, Aleksander Jankowski, and Witold R Rudnicki. 2010. Boruta\u2013a system for feature selection.\nFundamenta Informaticae , 101(4):271\u2013285.\nGuillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer. 2016. Neural\narchitectures for named entity recognition. CoRR , abs/1603.01360."}, {"source": "2020.semeval-1.187.pdf", "text": "Wenhui Liao and Sriharsha Veeramachaneni. 2009. A simple semi-supervised algorithm for named entity recog-\nnition. In Proceedings of the NAACL HLT 2009 Workshop on Semi-supervised Learning for Natural Language\nProcessing , pages 58\u201365, Boulder, Colorado, June. Association for Computational Linguistics."}, {"source": "2020.semeval-1.187.pdf", "text": "Yao Lin, Chengjie Sun, Wang Xiaolong, and Wang Xuan. 2010. Combining self learning and active learning for\nchinese named entity recognition. Journal of Software , 5, 05.\nXiaohua Liu, Shaodian Zhang, Furu Wei, and Ming Zhou. 2011. Recognizing named entities in tweets. In\nProceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language"}, {"source": "2020.semeval-1.187.pdf", "text": "Technologies , pages 359\u2013367, Portland, Oregon, USA, June. Association for Computational Linguistics.1424Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke\nZettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. ArXiv ,\nabs/1907.11692."}, {"source": "2020.semeval-1.187.pdf", "text": "abs/1907.11692.\nHenry B Mann and Donald R Whitney. 1947. On a test of whether one of two random variables is stochastically\nlarger than the other. The annals of mathematical statistics , pages 50\u201360.\nChuck Rosenberg, Martial Hebert, and Henry Schneiderman. 2005. Semi-supervised self-training of object detec-\ntion models. In WACV/MOTION , pages 29\u201336."}, {"source": "2020.semeval-1.187.pdf", "text": "George W. Snedecor and William G. Cochran. 1989. Statistical Methods . Iowa State University Press, eighth\nedition.\nF\u00e1bio Souza, Rodrigo Frassetto Nogueira, and Roberto de Alencar Lotufo. 2019. Portuguese named entity recog-\nnition using BERT-CRF. CoRR , abs/1909.10649.\nLei Wang, Qing Qian, Qiang Zhang, Jishuai Wang, Wenbo Cheng, and Wei Yan. 2020. Classi\ufb01cation Model on"}, {"source": "2020.semeval-1.187.pdf", "text": "Big Data in Medical Diagnosis Based on Semi-Supervised Learning. The Computer Journal , 03. bxaa006.\nDavid Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In 33rd Annual\nMeeting of the Association for Computational Linguistics , pages 189\u2013196, Cambridge, Massachusetts, USA,\nJune. Association for Computational Linguistics."}, {"source": "2023.semeval-1.86.pdf", "text": "Proceedings of the The 17th International Workshop on Semantic Evaluation (SemEval-2023) , pages 629\u2013637\nJuly 13-14, 2023 \u00a92023 Association for Computational Linguistics\nKInITVeraAI at SemEval-2023 Task 3: Simple yet Powerful Multilingual\nFine-Tuning for Persuasion Techniques Detection\nTimo Hromadka1and Timotej Smolen1and Tomas Remis1and\nBranislav Pecher2,1and Ivan Srba1"}, {"source": "2023.semeval-1.86.pdf", "text": "Branislav Pecher2,1and Ivan Srba1\n1Kempelen Institute of Intelligent Technologies, Bratislava, Slovakia\n2Brno University of Technology, Brno, Czechia\n{timo.hromadka,timotej.smolen,tomas.remis}@intern.kinit.sk\n{branislav.pecher,ivan.srba}@kinit.sk\nAbstract\nThis paper presents the best-performing solu-\ntion to the SemEval 2023 Task 3 on the sub-\ntask 3 dedicated to persuasion techniques de-"}, {"source": "2023.semeval-1.86.pdf", "text": "tection. Due to a high multilingual character\nof the input data and a large number of 23 pre-\ndicted labels (causing a lack of labelled data\nfor some language-label combinations), we\nopted for fine-tuning pre-trained transformer-\nbased language models. Conducting multi-\nple experiments, we find the best configura-\ntion, which consists of large multilingual model"}, {"source": "2023.semeval-1.86.pdf", "text": "(XLM-RoBERTa large) trained jointly on all\ninput data, with carefully calibrated confidence\nthresholds for seen and surprise languages sep-\narately. Our final system performed the best\non 6 out of 9 languages (including two surprise\nlanguages) and achieved highly competitive re-\nsults on the remaining three languages.\n1 Introduction\nThe subtask 3 of the SemEval 2023 Task 3 aims"}, {"source": "2023.semeval-1.86.pdf", "text": "at identifying persuasion techniques. The task is a\nmulti-label one, where a model is required to iden-\ntify which of the 23 persuasion techniques (e.g.,\nan appeal to authority) are present in a given para-\ngraph. The paragraphs are obtained from articles\nin 6 languages (English, French, German, Italian,\nPolish, and Russian) collected between 2020 and"}, {"source": "2023.semeval-1.86.pdf", "text": "mid 2022, revolving around widely discussed top-\nics such as COVID-19, climate change, abortion,\nmigration etc. Media sources are both mainstream\nand alternative news and web portals. Furthermore,\nthe model is tested on 3 surprise languages (Greek,\nGeorgian, and Spanish), for which labeled training\ndata were not available. The importance of the task\nis eminent \u2014 automatically detected persuasion"}, {"source": "2023.semeval-1.86.pdf", "text": "techniques can be utilized as credibility signals to\nassess content credibility and thus also to improve\ndisinformation detection. The detailed description\nof the task is available in (Piskorski et al., 2023).\nIn this paper, we propose a multilingual system,\nconsisting of a single model tackling all languages.Our main strategy is to fine-tune a large pre-trained"}, {"source": "2023.semeval-1.86.pdf", "text": "transformer-based language model. To find the best\nperforming system, we experimented with differ-\nent language models (and finally opted for XLM-\nRoBERTa large due to its performance), hyper-\nparameter tuning as well as confidence threshold\ncalibration by changing the threshold for prediction\nin the multi-label classification. We also simulated"}, {"source": "2023.semeval-1.86.pdf", "text": "the zero-shot setting on the training data to adjust\nthe confidence threshold and better estimate the per-\nformance of our model on the surprise languages.\nFurthermore, we experiment with additional con-\nfigurations, such as translating the data to a single\nlanguage (English) and using it to fine-tune a mono-\nlingual model, applying various text pre-processing"}, {"source": "2023.semeval-1.86.pdf", "text": "strategies, or layer freezing. However, these config-\nurations did not lead to improvements.\nAlthough our system is based on a rather sim-\nple concept, it still achieved exceptional results.\nWe ranked 1st for 6 languages (Italian, Russian,\nGerman, Polish, Greek and Georgian), 2nd for the\nSpanish, 3rd for the French and 4th for the English\nlanguage. In the zero-shot setting introduced by"}, {"source": "2023.semeval-1.86.pdf", "text": "unseen languages, our system also performs excep-\ntionally, achieving the best performance on two\nlanguages (Greek and Georgian) and second on the\nremaining unseen language (Spanish).\nBased on our experiments and official ranking\non the test set, we make the following observations:\n1.Combination of a high number of predicted\nclasses and multiple languages (including sur-"}, {"source": "2023.semeval-1.86.pdf", "text": "prise ones) results in a lack of labeled data,\nwhich significantly limits the potential of\ntraining multiple monolingual models. Fur-\nthermore, even though monolingual models\ntrained on all data translated into English lan-\nguage often achieve state-of-the-art or compa-\nrable performance on other multilingual tasks,\nin this case they are outperformed by the sin-"}, {"source": "2023.semeval-1.86.pdf", "text": "gle multilingual models trained on all data.6292.Since detecting the presence of persuasion\ntechniques is a complex task (even for hu-\nmans), the larger models perform significantly\nbetter. We also recognized the importance\nof calibrating the confidence thresholds (for\nseen and unseen languages separately). At the\nsame time, interestingly, many model config-"}, {"source": "2023.semeval-1.86.pdf", "text": "urations (pre-processing, layer freezing, etc.)\ndid not improve model performance.\n3.Even though F1 micro score is the decisive\nmetric in the subtask, we can see a significant\ndifference between F1 micro and macro scores\nin some of the languages. Similar trend is fol-\nlowed throughout the results of other teams as\nwell. This difference indicates, that our sys-"}, {"source": "2023.semeval-1.86.pdf", "text": "tem focuses on the majority classes and strug-\ngles with classifying some of the more scarce\npersuasion techniques within the dataset.\nTogether with the system description, we also\nrelease its source code1, as well as the fine-tuned\nmodel used for submitting the final results2.\n2 Background\nThe train and dev sets provided by the organizers\nconsisted of 26 663 samples in 6 languages. Each"}, {"source": "2023.semeval-1.86.pdf", "text": "sample consist of a paragraph of news article and\nzero, one or multiple persuasion techniques (out\nof 23 possible classes) present in such a paragraph\n(with the exact span identified). By performing\nexploratory data analysis of the provided dataset,\nwe observed a high data imbalance in both classes\n(persuasion techniques) as well as languages (some\ncombinations of classes and languages contain no"}, {"source": "2023.semeval-1.86.pdf", "text": "samples at all) - see Appendix A.\nThe research on the computational propa-\nganda/persuasion techniques detection is still in\nits early stages, despite its potential importance\nand utilization for credibility evaluation or disinfor-\nmation detection (Martino et al., 2020). Many ex-\nisting works closely relate to the SemEval tasks in\n2020 (Da San Martino et al., 2020a) and 2021 (Dim-"}, {"source": "2023.semeval-1.86.pdf", "text": "itrov et al., 2021), which preceded the current Se-\nmEval 2023 Task 3. The approaches evolved from\na simple binary classification of propaganda being\npresent in a document (Barr\u00f3n-Cede\u00f1o et al., 2019),\nthrough a fine-grained detection of 18 propaganda\n1https://github.com/kinit-sk/\nsemeval2023-task3-persuasion-techniques\n2https://huggingface.co/kinit/"}, {"source": "2023.semeval-1.86.pdf", "text": "2https://huggingface.co/kinit/\nsemeval2023-task3-persuasion-techniquestechniques (Da San Martino et al., 2019, 2020b) to\ndetection of 23 persuasion techniques introduced\nin this task. Moreover, while the methods proposed\nso far are trained solely on monolingual data, the\nintroduced multilingual data allows to research true\nmultilingual approaches.\n3 System Overview"}, {"source": "2023.semeval-1.86.pdf", "text": "3 System Overview\nThe main principle used for development of our\nsystem is fine-tuning of a large language model\nusing the data provided within the SemEval task.\nIn similar fashion to other fine-tuning approaches,\nwe add a classification layer at the end of the pre-\ntrained model, while also including a dropout layer\nto prevent overfitting. As input, the language model"}, {"source": "2023.semeval-1.86.pdf", "text": "takes the paragraph, potentially truncated if its\nlength is higher than the maximum input size. No\nother processing of input is performed (i.e., we are\nworking on paragraph level only). As the task is a\nmulti-class multi-label problem, the predicted out-\nput label is not determined based on the maximum\nprobability, but instead by specifying a confidence"}, {"source": "2023.semeval-1.86.pdf", "text": "threshold. All classes that have their probability\nhigher than this confidence threshold are predicted\nas output label.\nTo develop the best configuration of the language\nmodel fine-tuning solution, we performed multiple\nexperiments that can be organized into following\nfive steps (which are summarized in Figure 1):\n1.Candidate Model Selection , where we explore"}, {"source": "2023.semeval-1.86.pdf", "text": "the behaviour of both monolingual and multi-\nlingual language models on the task, selecting\nthe best performing ones;\n2.Exploration of Multilinguality Strategies ,\nwhere we compare the best monolingual and\nmultilingual model, and their ensemble;\n3.Confidence Threshold Calibration , where we\ndetermine the best confidence threshold for\nboth seen languages and surprise languages;"}, {"source": "2023.semeval-1.86.pdf", "text": "4.Selection of Preprocessing Strategies , where\nwe investigate the benefits data preprocessing;\n5.Layer Freezing , where we try different fine-\ntuning strategies based on what portion of the\nmodel is frozen.\nThe final solution utilizes a single multilingual\nmodel fine-tuned on all languages at once, with\nslightly lowered confidence threshold, with no pre-"}, {"source": "2023.semeval-1.86.pdf", "text": "processing and no layer freezing.630Monolingual Model \nOnlyMultilinguality \nStrategies\nSection 3.2Preprocessing \nStrategies\nSection 3.4Layer \nFreezing\nSection 3.5\nEnsemble ApproachData Cleaning and \nNormalization\nNo PreprocessingPretrained Model \nFreezing\nMultilingual Model \nOnlyMultilingual Model \nOnlyNo FreezingCandidate Model\nSelection\nSection 3.1Confidence Threshold \nCalibration\nSection 3.3"}, {"source": "2023.semeval-1.86.pdf", "text": "Calibration\nSection 3.3\nFor Seen Languages\nFor Surprise Languages\n(zero -shot setting)BERT (base)\nRoBERTa (base)\nRoBERTa (large)\nmBERT (base)\nXLM -RoBERTa (base)\nXLM -RoBERTa (large)Monolingual Models\n+ Translated DataMultilingual \nModelsMonolingual Models\n+ Translated DataMultilingual"}, {"source": "2023.semeval-1.86.pdf", "text": "+ Translated DataMultilingual \nModelsFigure 1: We perform multiple experiments to determine the best configuration for our solution. The performance-\nimproving approaches (denoted in bold ) are used in the final solution.\n3.1 Candidate Model Selection\nIn the first step, we select the best performing fine-\ntuned language models separately for monolingual\nand multilingual models."}, {"source": "2023.semeval-1.86.pdf", "text": "and multilingual models.\nAt first, the use of monolingual language model\nhas previously shown an exceptional performance\neven in multilingual setting, where data from non-\nEnglish languages were translated to English lan-\nguage (Pikuliak et al., 2023). Naturally, machine\ntranslation, as a specific transfer paradigm for cross-\nlingual learning (Pikuliak et al., 2021), may intro-"}, {"source": "2023.semeval-1.86.pdf", "text": "duce some level of noise and thus break the re-\nquired correspondence between the original and\ntranslated sample (which plays an important role\nin persuasion techniques detection, since it is espe-\ncially sensitive to the used wording). At the same\ntime, such approach may potentially better deal\nwith the limited labeled data available for some lan-"}, {"source": "2023.semeval-1.86.pdf", "text": "guages, and even with the zero-shot setting intro-\nduced by the surprise languages. Therefore, despite\nsome potential noise introduced by the translation,\nwe decide to explore the behaviour of monolin-\ngual models for this task by translating all avail-\nable data (using Google Translate API) to a single\nhigh-resource language (English) and training a\nmonolingual model on such translated data. The"}, {"source": "2023.semeval-1.86.pdf", "text": "monolingual models we experiment with are BERT\n(base) (Devlin et al., 2019) and RoBERTa (base\nand large) (Liu et al., 2019).\nOn the other hand, the multilingual models pro-\nvide us with an option to train a single model for all\nthe languages, increasing the amount of available\ntraining data. However, multilingual models may\nlack language-specific understanding required for"}, {"source": "2023.semeval-1.86.pdf", "text": "the complex persuasion technique detection and\nthus they may not potentially perform as good as\nthe monolingual models. The multilingual modelswe experiment with are mBERT (base) and XLM-\nRoBERTa (base and large) (Conneau et al., 2019).\n3.2 Multilinguality Strategies\nIn this step, the monolingual, multilingual and en-\nsemble strategy are compared to determine which"}, {"source": "2023.semeval-1.86.pdf", "text": "one is better for persuasion technique detection.\nNamely, we compare the best performing monolin-\ngual model (RoBERTa large), the best performing\nmultilingual model (XLM-RoBERTa large) and\ntheir ensemble. The assumption is that the ensem-\nble may exploit the strengths of the combination\nof translation and monolingual models to deal with\nthe zero-shot setting; and the flexibility of the mul-"}, {"source": "2023.semeval-1.86.pdf", "text": "tilingual model to work with all languages at the\nsame time without a loss of information due to\ntranslation. In the ensemble, the predicted output\nlabels from both models are merged together (con-\ncatenated) to provide a final prediction.\n3.3 Confidence Threshold Calibration\nIn the third step, we perform experiments to deter-\nmine the best confidence threshold for predicting"}, {"source": "2023.semeval-1.86.pdf", "text": "output classes \u2014 the probability threshold after\nwhich the specific class is considered to be the out-\nput label for the specific sample. For example, if\nthe threshold is set to 0.2, all classes with predicted\nprobability of at least 0.2 are assigned as predicted\nlabels. To determine the optimal threshold, we\nuse the fine-tuned best-performing monolingual,"}, {"source": "2023.semeval-1.86.pdf", "text": "multilingual model, as well as their ensemble and\nevaluate their performance on different threshold\nvalues. In addition, to determine how our solution\nwill perform on the surprise (unseen) languages, we\nsimulate the zero-shot setting. We randomly select\ntwo languages from the training ones as surprise,\ntrain all three models on the remaining languages"}, {"source": "2023.semeval-1.86.pdf", "text": "only and use the data from the selected languages631only for evaluation. In this way, we are able to bet-\nter estimate the confidence threshold when working\nin zero-shot setting on the test set.\nAnother possibility for the calibration would be\nto calibrate the confidence threshold for each in-\ndividual language and class. Although this would\nimprove the performance of the evaluated models"}, {"source": "2023.semeval-1.86.pdf", "text": "on the available data, we believe it would lead to se-\nvere overfitting to the distribution of classes on the\nindividual languages and negatively affect the gen-\neralizability of our models. Therefore, we opted\nto pursue the calibration strategy as described in\nthe previous paragraph (single overall calibration\nfor all classes and languages at the same time, with\nsimulated zero-shot setting)."}, {"source": "2023.semeval-1.86.pdf", "text": "simulated zero-shot setting).\nThe comparison of all three models for the anal-\nysed spectrum of confidence thresholds, also allow\nus to select the final best-performing model, which\nis used in the next experiments.\n3.4 Preprocessing Strategies\nIn this step, we explore whether preprocessing the\ndata, by removing any potential noise in it, is help-\nful. To determine the impact of preprocessing, we"}, {"source": "2023.semeval-1.86.pdf", "text": "compare the best-performing model with the al-\nready calibrated confidence threshold on the pre-\nprocessed data and compare its performance on\ndata without preprocessing. The preprocessing\nstrategies we use are: 1) normalizing white space\nand punctuation (e.g., reducing multiple punctu-\nation characters to one); and 2) replacing emails,\nURLs, emojis and hashtags with a placeholder text"}, {"source": "2023.semeval-1.86.pdf", "text": "indicating the specific object (e.g., replacing a spe-\ncific URL with a generic placeholder \u201c{url}\u201d). We\ndo not evaluate the preprocessing separately, but\ninstead evaluate the model trained on data prepro-\ncessed using all strategies at the same time.\n3.5 Layer Freezing\nIn the final step, we explore the different layer freez-\ning strategies that can be used during fine-tuning of"}, {"source": "2023.semeval-1.86.pdf", "text": "language models. We compare the best-performing\nmodel on following two strategies: 1) no freezing -\ndefault setting, where all the layers are fine-tuned\n(represents the highest level of specialization in the\nmodel, as also the layers responsible for generating\nrepresentations are fine-tuned, but may be more\nsensitive to overfitting); 2) pretrained layers freez-"}, {"source": "2023.semeval-1.86.pdf", "text": "ing - in this setting, we freeze 80% of the pretrained\nlayers and only fine-tune the rest, along with the\nclassification layer (represents a lower level of spe-\ncialization, mainly in the feature representation).4 Experimental Setup\nThe only data we use for our system is the official\ndataset provided for the task (Piskorski et al., 2023).\nWe also use the default training-development split"}, {"source": "2023.semeval-1.86.pdf", "text": "provided for the task. During the development of\nour solution, we use the development set only for\nevaluating the different steps and experimental con-\nfigurations. For the final submission, the language\nmodel is fine-tuned on both sets of data. For evalu-\nation purposes we use the F1 micro score, which is\nthe default for this subtask, even though it empha-"}, {"source": "2023.semeval-1.86.pdf", "text": "sizes the majority classes over the minority ones.\nThe different pretrained language models used\nin our system are chosen from the ones available\nat Hugging Face. We use the PyTorch deep learn-\ning library, version 1.13.1. We have also created a\ncustom pipeline for efficient combining paragraphs\nand their labels from all articles into a single object,"}, {"source": "2023.semeval-1.86.pdf", "text": "for running all the preprocessing and data transla-\ntion, and the training of the models.\nFor each language model, we add a dropout layer\nwith dropout rate of 0.3, followed by a classifica-\ntion layer with output size of 23(one per persuasion\ntechnique). Before all the experiments, we perform\na hyperparameter optimisation for each language\nmodel, mainly focusing on the number of epochs,"}, {"source": "2023.semeval-1.86.pdf", "text": "batch size and learning rate. As starting point for\nthe hyperparameters, we use the values that were\ndetermined to perform well in related work (e.g.,\n(Zhang et al., 2021; Mosbach et al., 2021)) and\nthen searched close to these values. The best hy-\nperparameters used for all the language models are:\nbatch size of 16, ADAM optimizer with 1e\u221205\nlearning rate and fine-tuning for 5epochs with early"}, {"source": "2023.semeval-1.86.pdf", "text": "stopping using cross-entropy loss.\n5 Results\nThe results from the different configurations of\nour solution are presented in Table 1. We can ob-\nserve that the larger language models achieve sig-\nnificantly better performance on the task, both in\nmonolingual setting with translated data (RoBERTa\nbase achieving 26.77% F1 micro compared with\nRoBERTa large achieving 40.38%) and in mul-"}, {"source": "2023.semeval-1.86.pdf", "text": "tilingual setting (XLM-RoBERTa base achiev-\ning34.45% and XLM-RoBERTa large achieving\n45.09%). In addition, the multilingual setting out-\nperforms the monolingual with translated data.\nBoth of these results can be explained by the com-\nplexity of the task, which needs more complex rep-"}, {"source": "2023.semeval-1.86.pdf", "text": "resentation provided by the large architectures. At632Table 1: Results of different experimental configurations, grouped by the experiment steps (as illustrated in Figure\n1). The comparison between monolingual models that utilize translation is provided in the first step (denoted\nasMonolingual Model Selection ). The comparison between multilingual models is presented in the second step"}, {"source": "2023.semeval-1.86.pdf", "text": "(denoted as Multilingual Model Selection ). The best performing models from the first two steps are ensembled and\nthe comparison of this ensemble with the original models is presented in the step 3 (denoted as Multilinguality\nStrategies ). The performance of these 3 models on their individual best confidence threshold (which is same for all"}, {"source": "2023.semeval-1.86.pdf", "text": "models) is presented in the step 4 (denoted as Confidence Threshold Calibration ). For the best performing model\nfrom the step 4 (XLM-RoBERTa large with threshold set as 0.29), we report the impact of applying preprocessing\nstrategies ( Preprocessing ) and freezing of 80% of the pretrained layers ( Layer Freezing ).\nExperiment step Configuration F1 micro (%) F1 macro (%)"}, {"source": "2023.semeval-1.86.pdf", "text": "Monolingual Model BERT (base) 20.21 7.24\nSelection RoBERTa (base) 26.77 5.98\nSection 3.1 RoBERTa (large) 40.38 15.86\nMultilingual Model mBERT (base) 22.06 5.02\nSelection XLM-RoBERTa (base) 34.45 13.64\nSection 3.1 XLM-RoBERTa (large) 45.09 22.36\nMultilinguality Strategies\nSection 3.2Ensemble (RoBERTa large + XLM-RoBERTa large) 47.66 23.99"}, {"source": "2023.semeval-1.86.pdf", "text": "Confidence Threshold RoBERTa (confidence threshold 0.29) 45.77 21.88\nCalibration XLM-RoBERTa (confidence threshold 0.29) 48.65 27.46\nSection 3.3 Ensemble (confidence threshold 0.29) 48.15 27.31\nPreprocessing\nSection 3.4XLM-RoBERTa, threshold 0.29, 2 preprocessing strategies 48.31 25.83\nLayer Freezing\nSection 3.5XLM-RoBERTa, threshold 0.29, 80% freeze 36.44 10.57"}, {"source": "2023.semeval-1.86.pdf", "text": "the same time, the nuances needed to correctly de-\ntect the persuasion techniques may be lost in trans-\nlation. However, we can see that both monolingual\nand multilingual models have their own strengths\nand weakness, as their ensemble produces the best\nresults overall.\nWe can also observe significant impact of the\nconfidence threshold calibration. Although the en-"}, {"source": "2023.semeval-1.86.pdf", "text": "semble of monolingual and multilingual models\nperforms best without the calibration, the multi-\nlingual model quickly outperforms the ensemble\nwhen the best confidence threshold is used for all\nmodels (confidence threshold of 0.29).\nFinally, we observe that impact of preprocess-\ning has negligible impact on the overall perfor-\nmance, achieving similar, although slightly lower"}, {"source": "2023.semeval-1.86.pdf", "text": "F1 score. On the other hand, the different layer\nfreezing strategies have significant negative effects\non the model, lowering the performance by \u223c12%.\n5.1 Confidence Threshold Calibration\nThe results of the confidence threshold calibration\nfor the XLM-RoBERTa large model in both the\ndefault setting (where all languages are seen during\ntraining) and zero-shot setting (where some lan-"}, {"source": "2023.semeval-1.86.pdf", "text": "guages are unseen during training) are presented in\nFigure 2. The detailed results for specific languagesand for other models are included in Appendix B.\nWe observe a significant effect of the calibration,\nwith the performance being significantly higher\nwhen lowering the threshold. However, this in-\ncrease can be observed only to a certain point, after"}, {"source": "2023.semeval-1.86.pdf", "text": "which the performance starts to go down again.\nThe best performing confidence threshold for all\nmodels is 0.29in the default setting. Changing\nthis threshold also has a significant impact on what\nmodel can be considered best. At higher thresholds,\nthe ensemble of monolingual and multilingual mod-\nels outperforms all others, while at lower values\nthe multilingual model becomes better."}, {"source": "2023.semeval-1.86.pdf", "text": "the multilingual model becomes better.\nFinally, the best confidence threshold for the\nzero-shot setting is lower than in the default setting.\nInstead of the 0.29, the value of 0.25appears to be\nthe best one. This change can be explained by the\nlower availability of data in this setting, making the\nmodels less confident in their predictions.\n5.2 Final Submission"}, {"source": "2023.semeval-1.86.pdf", "text": "5.2 Final Submission\nThe final submission was done using the XLM-\nRoBERTa large model, trained on the training and\ndevelopment set, using the 0.30confidence thresh-\nold for seen languages and 0.28confidence thresh-\nold for the unseen languages (due to lower confi-\ndence observed in confidence threshold calibration633Figure 2: Results (aggregated across languages) from"}, {"source": "2023.semeval-1.86.pdf", "text": "calibrating the confidence threshold for the XLM-\nRoBERTa (large) model for both the default setting\nand zero-shot setting.\nTable 2: Results of our system from final submission. \u2206\nspecifies the difference of our results to the best, or the\nsecond best (in case we places in the first place) system.\nThe last three languages (Spanish, Greek and Georgian)\nhad no training data."}, {"source": "2023.semeval-1.86.pdf", "text": "had no training data.\nLanguage F1 micro (%) Rank \u2206\nEnglish 36.157 4 -1.405\nItalian 55.019 1 +1.140\nRussian 38.682 1 +0.901\nFrench 43.217 3 -3.652\nGerman 51.304 1 +0.351\nPolish 43.037 1 +0.857\nSpanish 38.035 2 -0.071\nGreek 26.733 1 +0.252\nGeorgian 45.714 1 +4.361\nexperiments). Both thresholds are purposefully\nslightly higher than the best ones found in the ex-"}, {"source": "2023.semeval-1.86.pdf", "text": "periments, as we expect that training the model on\nboth available data sets will make it also slightly\nmore confident. The official results from the test\nset are presented in Table 2. Based on the achieved\nresults, our system ranked 1st for 6 languages (Ital-\nian, Russian, German, Polish, Greek and Georgian),\n2 of which are languages without any training data"}, {"source": "2023.semeval-1.86.pdf", "text": "(Greek and Georgian), 2nd for the Spanish, which\nis the final unseen language, 3rd for the French and\n4th for the English language.\n6 Conclusion\nIn this paper, we have presented the implementa-\ntion of the solution proposed by KInITVeraAI team\nfor the subtask 3 within the SemEval 2023 Task\n3. Our rather simple, yet powerful, solution uti-"}, {"source": "2023.semeval-1.86.pdf", "text": "lizes fine-tuning of multilingual language model.In a challenging multi-label task with 23 classes, it\nachieves very promising performance (F1 micro) of\n36-55% for languages seen during the training, and\n26-45% for unseen languages (zero-shot setting).\nIn future, we plan to investigate the potential of\nprompting and in-context learning on the top of"}, {"source": "2023.semeval-1.86.pdf", "text": "large pre-trained language models (like GTP-3 or\nChatGPT). Our hypothesis is that the large size of\nthese models may allow even deeper understanding\nof the input text. Nevertheless, it will be critical to\ndesign appropriate prompts as a part of prompt en-\ngineering process, address a potential bias towards\nmajority classes, and also overcome well-known\nissues with instability of these approaches."}, {"source": "2023.semeval-1.86.pdf", "text": "Acknowledgements\nThis research was partially supported by vera.ai\nproject funded by the European Union under the\nHorizon Europe, GA No. 101070093; and by VIG-\nILANT, a project funded by the European Union\nunder the Horizon Europe, GA No. 101073921.\nReferences\nAlberto Barr\u00f3n-Cede\u00f1o, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:"}, {"source": "2023.semeval-1.86.pdf", "text": "Organizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2019. Unsupervised\ncross-lingual representation learning at scale."}, {"source": "2023.semeval-1.86.pdf", "text": "Giovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\nNakov. 2020a. SemEval-2020 Task 11: Detection\nof Propaganda Techniques in News Articles. In Pro-\nceedings of the Fourteenth Workshop on Semantic\nEvaluation , pages 1377\u20131414, Barcelona (online).\nInternational Committee for Computational Linguis-\ntics."}, {"source": "2023.semeval-1.86.pdf", "text": "tics.\nGiovanni Da San Martino, Shaden Shaar, Yifan Zhang,\nSeunghak Yu, Alberto Barr\u00f3n-Cede\u00f1o, and Preslav\nNakov. 2020b. Prta: A System to Support the\nAnalysis of Propaganda Techniques in the News.\narXiv:2005.05854 [cs] .\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarr\u00f3n-Cede\u00f1o, Rostislav Petrov, and Preslav Nakov.\n2019. Fine-Grained Analysis of Propaganda in News"}, {"source": "2023.semeval-1.86.pdf", "text": "Article. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) , pages6345636\u20135646, Hong Kong, China. Association for Com-\nputational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of"}, {"source": "2023.semeval-1.86.pdf", "text": "deep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n4171\u20134186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nDimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj"}, {"source": "2023.semeval-1.86.pdf", "text": "Alam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021.\nSemEval-2021 Task 6: Detection of Persuasion Tech-\nniques in Texts and Images. In Proceedings of the\n15th International Workshop on Semantic Evaluation\n(SemEval-2021) , pages 70\u201398, Online. Association\nfor Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-"}, {"source": "2023.semeval-1.86.pdf", "text": "dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692 .\nGiovanni Da San Martino, Stefano Cresci, Alberto\nBarr\u00f3n-Cede\u00f1o, Seunghak Yu, Roberto Di Pietro,\nand Preslav Nakov. 2020. A Survey on Computa-\ntional Propaganda Detection. In Proceedings of the"}, {"source": "2023.semeval-1.86.pdf", "text": "Twenty-Ninth International Joint Conference on Ar-\ntificial Intelligence , pages 4826\u20134832, Yokohama,\nJapan. International Joint Conferences on Artificial\nIntelligence Organization.\nMarius Mosbach, Maksym Andriushchenko, and Diet-\nrich Klakow. 2021. On the Stability of Fine-tuning\nBERT: Misconceptions, Explanations, and Strong\nBaselines.\nMat\u00fa\u0161 Pikuliak, Ivan Srba, Robert Moro, Timo Hro-"}, {"source": "2023.semeval-1.86.pdf", "text": "madka, Timotej Smolen, Martin Melisek, Ivan\nVykopal, Jakub Simko, Juraj Podrouzek, and Maria\nBielikova. 2023. Multilingual Previously Fact-\nChecked Claim Retrieval.\nMat\u00fa\u0161 Pikuliak, Mari\u00e1n \u0160imko, and M\u00e1ria Bielikov\u00e1.\n2021. Cross-lingual learning for text process-\ning: A survey. Expert Systems with Applications ,\n165:113765.\nJakub Piskorski, Nicolas Stefanovitch, Giovanni"}, {"source": "2023.semeval-1.86.pdf", "text": "Da San Martino, and Preslav Nakov. 2023. Semeval-\n2023 task 3: Detecting the category, the framing,\nand the persuasion techniques in online news in a\nmulti-lingual setup. In Proceedings of the 17th Inter-\nnational Workshop on Semantic Evaluation , SemEval\n2023, Toronto, Canada.\nTianyi Zhang, Felix Wu, Arzoo Katiyar, Kilian Q. Wein-\nberger, and Yoav Artzi. 2021. Revisiting Few-sample"}, {"source": "2023.semeval-1.86.pdf", "text": "BERT Fine-tuning.A Exploratory Analysis: Data Imbalance\nThe dataset for persuasion technique detection con-\ntains a significant data imbalance, as illustrated in\nthe Figure 3. The data imbalance is present in both\nthe classes, as well as the languages. Although\nthe dataset is working with 23 different persuasion\ntechniques, the technique \u201cLoaded Language\u201d is"}, {"source": "2023.semeval-1.86.pdf", "text": "the most frequent one, even representing majority\nof the labels for some languages. On the other\nhand, some of the remaining persuasion techniques\ncan even have zero representative samples for some\nlanguages, such as \u201cAppeal to Values\u201d in English.\nThis imbalance complicates the evaluation of the\nperformance for different models, which is even\nmore augmented by the use of the F1 micro metric"}, {"source": "2023.semeval-1.86.pdf", "text": "that prefers the majority classes.\nIn addition, the data imbalance is also present\nin the languages. The number of samples for the\nEnglish language represent a large portion of the\navailable data. As the task is multilingual, the large\nrepresentation of the English samples (which also\nget majority focus in the overall NLP techniques),\nmay have negative impact on the training of a single"}, {"source": "2023.semeval-1.86.pdf", "text": "multilingual model as it may start to prefer English\nover other languages. Finally, this can also skew\nthe evaluation to prefer models that perform good\non the single language, but poorer on the smaller\nmultilingual ones.\nB Detailed Confidence Threshold\nCalibration\nFigure 4 depicts a more detailed confidence thresh-\nold calibration over different languages and the"}, {"source": "2023.semeval-1.86.pdf", "text": "best performing models in two settings \u2014 when\nusing all languages for training and when working\nin zero-shot setting with some hold-out languages.\nWe can observe similar behaviour of the best\nperforming models on the different languages. All\nmodels perform the best on the Italian language\nand the French. For the other languages, we can\nobserve that the RoBERTa models that uses trans-"}, {"source": "2023.semeval-1.86.pdf", "text": "lation performs poorer than the multilingual XLM-\nRoBERTa. This may be due to the specifics of the\nother languages, where the translation of the sam-\nples obscures some of the details required for the\ndetection of persuasion techniques.\nThe same behaviour can also be observed on the\nthreshold. The best threshold determined in aggre-\ngate was 0.29. Looking at individual languages, all"}, {"source": "2023.semeval-1.86.pdf", "text": "of them, except for the French and English, achieve"}, {"source": "2023.semeval-1.86.pdf", "text": "highest performance with this threshold. In case"}, {"source": "2023.semeval-1.86.pdf", "text": "of635/uni00000024/uni00000053/uni00000053/uni00000048/uni00000044/uni0000004f/uni00000003/uni00000057/uni00000052/uni00000003/uni00000024/uni00000058/uni00000057/uni0000004b/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000024/uni00000053/uni00000053/uni00000048/uni00000044/uni0000004f/uni00000003/uni00000057/uni00000052/uni00000003/uni00000033/uni00000052/uni00000053/uni000000"}, {"source": "2023.semeval-1.86.pdf", "text": "000033/uni00000052/uni00000053/uni00000058/uni0000004f/uni00000044/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000024/uni00000053/uni00000053/uni00000048/uni00000044/uni0000004f/uni00000003/uni00000057/uni00000052/uni00000003/uni00000039/uni00000044/uni0000004f/uni00000058/uni00000048/uni00000056"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000024/uni00000053/uni00000053/uni00000048/uni00000044/uni0000004f/uni00000003/uni00000057/uni00000052/uni00000003/uni00000029/uni00000048/uni00000044/uni00000055/uni00000010/uni00000033/uni00000055/uni00000048/uni0000004d/uni00000058/uni00000047/uni0000004c/uni00000046/uni00000048/uni00000029/uni0000004f/uni00000044/uni0000004a/uni00000003/uni0000003a/uni00000044/uni00000059/uni0000004c/un"}, {"source": "2023.semeval-1.86.pdf", "text": "a/uni00000044/uni00000059/uni0000004c/uni00000051/uni0000004a"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000026/uni00000044/uni00000058/uni00000056/uni00000044/uni0000004f/uni00000003/uni00000032/uni00000059/uni00000048/uni00000055/uni00000056/uni0000004c/uni00000050/uni00000053/uni0000004f/uni0000004c/uni00000049/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000029/uni00000044/uni0000004f/uni00000056/uni00000048/uni00000003/uni00000027/uni0000004c/uni0000004f/uni00000048/uni00000050/uni00000050/uni00000044/uni00000010/uni00000031/uni00000052/uni00000003/uni00000026/uni0000004b/uni00000052/uni0000004c/uni00000046/uni00000048"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000026/uni00000052/uni00000051/uni00000056/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000057/uni0000004c/uni00000044/uni0000004f/uni00000003/uni00000032/uni00000059/uni00000048/uni00000055/uni00000056/uni0000004c/uni00000050/uni00000053/uni0000004f/uni0000004c/uni00000049/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000036/un"}, {"source": "2023.semeval-1.86.pdf", "text": "c/uni00000052/uni00000051/uni00000036/uni00000057/uni00000055/uni00000044/uni0000005a/uni00000003/uni00000030/uni00000044/uni00000051/uni00000035/uni00000048/uni00000047/uni00000003/uni0000002b/uni00000048/uni00000055/uni00000055/uni0000004c/uni00000051/uni0000004a/uni0000003a/uni0000004b/uni00000044/uni00000057/uni00000044/uni00000045/uni00000052/uni00000058/uni00000057/uni0000004c/uni00000056/un"}, {"source": "2023.semeval-1.86.pdf", "text": "8/uni00000057/uni0000004c/uni00000056/uni00000050/uni00000036/uni0000004f/uni00000052/uni0000004a/uni00000044/uni00000051/uni00000056"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000024/uni00000053/uni00000053/uni00000048/uni00000044/uni0000004f/uni00000003/uni00000057/uni00000052/uni00000003/uni00000037/uni0000004c/uni00000050/uni00000048"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000026/uni00000052/uni00000051/uni00000059/uni00000048/uni00000055/uni00000056/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni0000002e/uni0000004c/uni0000004f/uni0000004f/uni00000048/uni00000055"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni0000002f/uni00000052/uni00000044/uni00000047/uni00000048/uni00000047/uni00000003/uni0000002f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048/uni00000035/uni00000048/uni00000053/uni00000048/uni00000057/uni0000004c/uni00000057/uni0000004c/uni00000052/uni00000051"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000028/uni0000005b/uni00000044/uni0000004a/uni0000004a/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000010/uni00000030/uni0000004c/uni00000051/uni0000004c/uni00000050/uni0000004c/uni00000056/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000032/uni00000045/uni00000049/uni00000058/uni00000056/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000010/uni00000039/uni00000044/uni0000004a/uni00000058/uni00000048/uni00000051/uni00000048/uni00000056/uni00000056/uni00000010/uni00000026/uni00000052/uni00000051/uni00000049/uni00000058/uni00000056/uni0000004c/uni00000052/uni00000051/uni00000031/uni00000044/un"}, {"source": "2023.semeval-1.86.pdf", "text": "2/uni00000051/uni00000031/uni00000044/uni00000050/uni00000048/uni00000003/uni00000026/uni00000044/uni0000004f/uni0000004f/uni0000004c/uni00000051/uni0000004a/uni00000010/uni0000002f/uni00000044/uni00000045/uni00000048/uni0000004f/uni0000004c/uni00000051/uni0000004a/uni00000027/uni00000052/uni00000058/uni00000045/uni00000057"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni0000002a/uni00000058/uni0000004c/uni0000004f/uni00000057/uni00000003/uni00000045/uni0000005c/uni00000003/uni00000024/uni00000056/uni00000056/uni00000052/uni00000046/uni0000004c/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000024/uni00000053/uni00000053/uni00000048/uni00000044/uni0000004f/uni00000003/uni00000057/uni00000052/uni00000003/uni0000002b/uni0000005c/uni00000053/uni00000052/uni00000046/uni00000055/uni0000004c/uni00000056/uni0000005c"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000057/uni0000004b/uni00000048/uni00000003/uni00000035/uni00000048/uni00000053/uni00000058/uni00000057/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000048/uni00000051\n/uni00000049/uni00000055\n/uni0000004a/uni00000048"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni0000004a/uni00000048\n/uni0000004c/uni00000057\n/uni00000053/uni00000052"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000055/uni00000058/uni00000014/uni0000001b/uni00000015 /uni00000017/uni0000001c /uni00000013 /uni00000017/uni00000017/uni0000001a /uni00000016/uni0000001b/uni00000016 /uni00000015/uni00000016/uni0000001a /uni00000014/uni0000001b/uni00000018 /uni00000013 /uni00000015/uni00000017 /uni00000019/uni00000016 /uni00000014/uni0000001b /uni00000014/uni0000001b/uni00000014 /uni00000013"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000013 /uni00000014/uni00000014/uni00000019 /uni00000015/uni00000015/uni0000001c/uni00000015 /uni00000019/uni0000001b/uni00000018 /uni00000018/uni0000001b/uni00000014 /uni00000016/uni00000014 /uni00000014/uni00000015/uni00000015/uni0000001c /uni0000001a/uni00000013/uni00000018 /uni00000019/uni00000016 /uni00000017/uni0000001b /uni00000013"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000014/uni00000014/uni00000019 /uni0000001c/uni0000001c /uni00000014/uni00000017/uni00000017 /uni00000015/uni0000001a/uni00000015 /uni00000017/uni0000001a /uni00000014/uni00000019/uni0000001c /uni00000014/uni00000013/uni00000015 /uni00000014/uni00000019/uni00000018 /uni00000014/uni00000018/uni0000001b /uni00000019/uni00000017 /uni0000001a/uni00000017 /uni00000014/uni0000001a/uni00000019"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000014/uni0000001a/uni00000019 /uni00000018/uni00000018 /uni00000015/uni00000015/uni00000015 /uni00000014/uni00000014/uni0000001c/uni00000017 /uni00000014/uni00000014/uni00000016 /uni00000016/uni00000016/uni00000015 /uni00000014/uni00000017/uni0000001c /uni00000018/uni00000017/uni00000017 /uni00000017/uni00000015/uni00000015 /uni00000014/uni00000018/uni0000001c"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000014/uni00000018/uni0000001c /uni00000014/uni0000001a/uni00000014 /uni00000017/uni00000016/uni00000018"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000015/uni00000019/uni00000014 /uni0000001b/uni00000013 /uni00000014/uni00000013/uni0000001c /uni00000015/uni00000015/uni0000001a /uni0000001b/uni00000016 /uni00000018/uni00000016 /uni00000017/uni00000019 /uni00000017/uni0000001a /uni00000014/uni0000001a /uni00000016/uni00000017 /uni00000015/uni00000019 /uni00000014/uni00000015/uni00000019 /uni00000014/uni0000001a"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000014/uni0000001a /uni00000014/uni00000018/uni00000015 /uni00000016/uni00000014/uni0000001c /uni00000014/uni00000015 /uni00000015/uni00000013/uni00000013 /uni0000001b/uni00000017 /uni0000001c/uni0000001a/uni00000017 /uni00000016/uni0000001b/uni00000014 /uni00000014/uni00000017/uni00000018 /uni00000014/uni0000001c/uni00000015 /uni00000016/uni0000001c/uni00000013"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni0000001c/uni00000017 /uni00000018/uni00000018 /uni00000014/uni0000001b/uni00000019 /uni00000016/uni0000001a/uni00000014 /uni00000017/uni0000001a /uni00000019/uni00000015 /uni0000001a/uni0000001a /uni00000016/uni0000001b /uni00000019/uni00000019 /uni00000015/uni0000001a /uni0000001c /uni0000001a/uni00000017 /uni00000017/uni00000016 /uni00000015/uni00000017/uni0000001a"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000015/uni00000017/uni0000001a /uni00000014/uni00000014/uni0000001c/uni0000001c /uni00000016/uni0000001a /uni00000014/uni0000001c/uni00000014 /uni00000015/uni00000018 /uni0000001a/uni00000017/uni0000001a /uni00000014/uni00000014/uni00000019/uni0000001c /uni0000001a/uni00000018 /uni00000014/uni00000013/uni0000001c /uni00000018/uni00000013/uni00000018"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni0000001b/uni00000014 /uni00000018/uni00000015 /uni00000014/uni00000018/uni00000014 /uni00000014/uni00000017/uni00000017 /uni0000001c/uni00000019 /uni00000014/uni0000001a /uni00000015/uni00000013 /uni00000016/uni00000015 /uni00000014/uni0000001b /uni00000014/uni0000001c /uni00000014/uni00000014 /uni00000017/uni00000016 /uni00000014/uni0000001c /uni0000001c/uni00000013"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni0000001c/uni00000013 /uni00000017/uni00000013/uni00000016 /uni00000015/uni00000016 /uni00000014/uni00000018/uni00000014 /uni00000017/uni0000001a /uni00000018/uni0000001b/uni00000019 /uni00000016/uni0000001c/uni00000014 /uni00000014/uni00000015/uni00000017 /uni00000015/uni00000016/uni0000001b /uni00000015/uni00000015/uni00000014"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni00000014/uni00000015 /uni00000014/uni00000013 /uni00000018/uni00000019 /uni00000019/uni0000001a /uni00000018/uni00000015 /uni00000017/uni00000018 /uni00000016/uni0000001c /uni0000001b/uni00000016 /uni00000016/uni00000013 /uni00000016 /uni00000014/uni00000014 /uni0000001b/uni00000016 /uni00000015/uni0000001c /uni00000014/uni00000014/uni00000015 /uni0000001a/uni0000001c/uni00000014"}, {"source": "2023.semeval-1.86.pdf", "text": "/uni0000001a/uni0000001c/uni00000014 /uni0000001b/uni0000001c /uni00000014/uni00000018/uni0000001b /uni00000015/uni0000001c /uni00000015/uni0000001c/uni00000019 /uni00000019/uni00000014/uni00000019 /uni00000016/uni00000014 /uni00000014/uni00000015/uni00000013 /uni00000016/uni0000001c/uni0000001aFigure 3: Distribution of labels in the available data sets per language and persuasion technique."}, {"source": "2023.semeval-1.86.pdf", "text": "French, the performance start to drop significantly\nafter confidence threshold value of 0.3. In case of\nEnglish, the performance further increases even af-\nter the threshold 0.29and even achieves the highest\nperformance on the confidence threshold value of\n0.225. This slightly different behaviour on the con-\nfidence threshold value may also explain the poorer"}, {"source": "2023.semeval-1.86.pdf", "text": "behaviour of our final model on the French (where\nwe placed 3rd) and English (where we placed 4th).\nIn addition, we can see a more significant im-\npact of the threshold for the monolingual RoBERTa\nmodel than in other models. Reducing the thresh-\nold increases the performance more than in other\nmodels. However, the performance never overtakes\nthat of the multilingual model or the ensemble of"}, {"source": "2023.semeval-1.86.pdf", "text": "monolingual and multilingual models.\nOn the zero-shot setting, where we work with\nlower number of samples for training, the models\nbehave slightly different on the confidence thresh-\nolds. For many of the languages seen during train-\ning, the best confidence threshold moves more to\nthe left, i.e., lower threshold value provides better\nperformance. We utilize this finding when prepar-"}, {"source": "2023.semeval-1.86.pdf", "text": "ing the final solution. As we train the final system\non both training and dev datasets, we have more\nsamples for training and therefore slightly increase\nthe confidence threshold.\nWe can also observe different impact of the zero-\nshot setting for different models. The monolingual\nmodel that translates the data into English suffer\nlower decrease of performance than the multilin-"}, {"source": "2023.semeval-1.86.pdf", "text": "gual model that trains on all the training data in\nthe original languages. However, this behaviour\ncan be expected, as in the monolingual model theunseen languages are still translated and so their\nsamples do not have such importance. However,\nwe still see a significant drop in performance for\nthem. This may point to the fact that the persua-\nsion techniques look slightly different in different"}, {"source": "2023.semeval-1.86.pdf", "text": "languages and this also manifests in translations.\nOn the other hand, the monolingual model suffers\nmore significant overall drop in performance than\nthe multilingual model (where the seen languages\nstill behave with similar performance). This may\nbe due to the lower number of training samples the\nmonolingual model can use, while the drop in num-"}, {"source": "2023.semeval-1.86.pdf", "text": "ber of samples in multilingual model is only in the\nunseen languages (although it is more significant\ndecrease in number of samples there).\nFinally, the behaviour on the unseen languages\nis also different. We can observe a significant de-\ncrease in the performance (as is expected). In ad-\ndition, the best confidence threshold value is also\nlower. Instead of the value 0.29, the best perform-"}, {"source": "2023.semeval-1.86.pdf", "text": "ing one for the unseen languages is 0.25on all\nthe models. As the models do not work with any\ntraining samples for the specific languages, their\nconfidence is lower, which also lowers the best per-\nforming confidence threshold. We also use this\nfinding when preparing the final solution. For the\nprediction of unseen languages, we use a lower\nthreshold, of value 0.26\u2013 the slightly higher value"}, {"source": "2023.semeval-1.86.pdf", "text": "than the best performing one from the experiments\nis due to the increase in number of training samples,\nwhich should also increase the confidence slightly.6360.300.350.400.450.500.55Micro-f1 scoreRoBERT a-large\n0.300.350.400.450.500.55RoBERT a-large hold-out\n0.300.350.400.450.500.55Micro-f1 scoreXLM-RoBERT a-large\n0.300.350.400.450.500.55XLM-RoBERT a-large hold-out"}, {"source": "2023.semeval-1.86.pdf", "text": "0.2250.2500.2600.2700.2800.2900.3000.310 0.350 0.500\nConfidence Threshold0.300.350.400.450.500.55Micro-f1 scoreEnsemble\n0.2250.2500.2600.2700.2800.2900.3000.310 0.350 0.500\nConfidence Threshold0.300.350.400.450.500.55Ensemble - hold outen\nfr\nge\npo\nru\nitFigure 4: Detailed confidence threshold calibration over different languages and the best performing models"}, {"source": "2023.semeval-1.86.pdf", "text": "(RoBERTa large as monolingual model which uses translation, XLM-RoBERTa model as single multilingual model,\nand their ensemble). The figure also depicts a comparison between the thresholds when using all languages for\ntraining and when working in zero-shot setting with some hold-out languages.637"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Proceedings of the The 17th International Workshop on Semantic Evaluation (SemEval-2023) , pages 2343\u20132361\nJuly 13-14, 2023 \u00a92023 Association for Computational Linguistics\nSemEval-2023 Task 3: Detecting the Category, the Framing,\nand the Persuasion Techniques in Online News in a Multi-lingual Setup\nJakub Piskorski1, Nicolas Stefanovitch2, Giovanni Da San Martino3, Preslav Nakov4"}, {"source": "2023.semeval-1.317v1.pdf", "text": "1Institute of Computer Science, Polish Academy of Science, Poland jpiskorski@gmail.com\n2European Commission Joint Research Centre, Italy nicolas.stefanovitch@ec.europa.eu\n3Department of Mathematics, University of Padova, Italy dasan@math.unipd.it\n4Mohamed bin Zayed University of Artificial Intelligence, UAE preslav.nakov@mbzuai.ac.ae\nAbstract\nWe describe SemEval-2023 task 3 on Detect-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ing the Category, the Framing, and the Per-\nsuasion Techniques in Online News in a Multi-\nlingual Setup : the dataset, the task organization\nprocess, the evaluation setup, the results, and\nthe participating systems. The task focused on\nnews articles in nine languages (six known to\nthe participants upfront: English ,French ,Ger-\nman,Italian ,Polish , and Russian ), and three ad-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ditional ones revealed to the participants at the\ntesting phase: Spanish ,Greek , and Georgian ).\nThe task featured three subtasks: (1) determin-\ning the genre of the article (opinion, reporting,\nor satire), (2) identifying one or more frames\nused in an article from a pool of 14 generic\nframes, and (3) identify the persuasion tech-\nniques used in each paragraph of the article,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "using a taxonomy of 23 persuasion techniques.\nThis was a very popular task: a total of 181\nteams registered to participate, and 41 even-\ntually made an official submission on the test\nset.\n1 Introduction\nThe widespread use of Internet and the advances in\nInternet-related technologies paved the way to eas-\nily create direct communication channels between"}, {"source": "2023.semeval-1.317v1.pdf", "text": "information producers and consumers, potentially\nleaving the latter exposed to manipulative, propa-\ngandistic, and deceptive content. Given the poten-\ntially huge audience that can be reached through\nonline channels, major public events and debates re-\nvolving around relevant topics could be influenced\nas a result. Therefore, there is an ever-growing"}, {"source": "2023.semeval-1.317v1.pdf", "text": "need to develop automated tools supporting experts\nin analysing the news ecosystem and identifying\nlarge-scale manipulation attempts, and facilitating\nthe study of how different events, global topics,\nand policies are being embraced by media in var-\nious countries, in order to carry out cross-country\nanalysis and to gather knowledge on the ways how"}, {"source": "2023.semeval-1.317v1.pdf", "text": "media informs public opinion, i.e., what aspectsare being highlighted and linked to a topic, what\npros and cons are mentioned, the way opinions are\nconveyed, and what rhetorical devices, i.e., logical\nfallacies and appeal to emotions, are used to sup-\nport flawed argumentation, potentially leading to\nmanipulation.\nTo foster research in this direction, there have"}, {"source": "2023.semeval-1.317v1.pdf", "text": "been several shared tasks asking to detect the use of\nspecific propaganda techniques in text, as well as\nthe specific span of each instance. This includes the\nNLP4IF-2019 shared task on Fine-Grained Propa-\nganda Detection (Da San Martino et al., 2019),\nSemEval-2020 task 11 on Detection of Persua-\nsion Techniques in News Articles (Da San Martino\net al., 2020a), SemEval-2021 task 6 on Detection of"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Persuasion Techniques in Texts and Images (Dim-\nitrov et al., 2021b), and WANLP-2022 Shared Task\non Propaganda Detection in Arabic (Alam et al.,\n2022).\nOur task is an extension of the above ones and\nintroduces several novelties. First, it is multilin-\ngual, covering nine languages. Second, it adds ad-\nditional dimensions for better news understanding,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "i.e., framing and news genre detection. Finally, our\ntaxonomy of persuasion techniques is an extension\ncompared to previous inventories, and it contains\n23 techniques organised in a two-tier hierarchy.\n2 The Tasks\nThe shared task comprises three subtasks:\nSubtask 1 (ST1): News Genre Categorization.\nGiven a news article, determine whether: (a) it\nis an opinion piece, (b) aims at objective news"}, {"source": "2023.semeval-1.317v1.pdf", "text": "reporting , or (c) is satirical .1This is a multi-class\nclassification task at the article level.\nSubtask 2 (ST2): Framing Detection. Given a\nnews article, identify one or more frames used in\n1A satirical piece is a factually incorrect article, with the\nintent not to deceive, but rather to call out, ridicule, or expose\nbehaviours considered \u2018bad\u2019. It deliberately exposes real-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "world individuals, organisations and events to ridicule.2343the article from a pool of 14 generic framing dimen-\nsions (introduced in Card et al. (2015)): Economic ,\nCapacity and resources ,Morality ,Fairness and\nequality ,Legality, constitutionality and jurispru-\ndence ,Policy prescription and evaluation ,Crime\nand punishment ,Security and defense ,Health and"}, {"source": "2023.semeval-1.317v1.pdf", "text": "safety ,Quality of life ,Cultural identity ,Public\nopinion ,Political ,External regulation and reputa-\ntion. This is a multi-class multi-label classification\ntask at the article level.\nSubtask 3 (ST3): Persuasion Techniques Detec-\ntion. Given a news article, identify the persuasion\ntechniques used in each paragraph of the article.\nThe pool of persuasion techniques consists of 23"}, {"source": "2023.semeval-1.317v1.pdf", "text": "techniques, and is an extension of the taxonomy\nintroduced in Da San Martino et al. (2019); Dim-\nitrov et al. (2021b)2. This is a multi-class multi-\nlabel classification task at the paragraph level. The\npersuasion techniques are grouped into six main\ncategories:\nAttack on reputation: The argument does not\naddress the topic, but rather targets the participant"}, {"source": "2023.semeval-1.317v1.pdf", "text": "(personality, experience, deeds) in order to question\nand/or to undermine their credibility. The object of\nthe argumentation can also refer to a group of indi-\nviduals, an organization, an object, or an activity.\nJustification: The argument is made of two parts,\na statement and an explanation or an appeal, where\nthe latter is used to justify and/or to support the\nstatement."}, {"source": "2023.semeval-1.317v1.pdf", "text": "statement.\nSimplification: The argument excessively simpli-\nfies a problem, usually regarding the cause, the\nconsequence or the existence of choices.\nDistraction: The argument takes the focus away\nfrom the main topic or argument to distract the\nreader.\nCall: The text is not an argument, but an encour-\nagement to act or to think in a particular way."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Manipulative wording: the text is not an argument\nper se, but uses specific language, which contains\nwords or phrases that are either non-neutral, confus-\ning, exaggerating, loaded, etc., in order to impact\nthe reader emotionally.\nFigure 1 gives an overview of the two-tier per-\nsuasion techniques taxonomy.\n3 Related Work\nThis section discusses prior work related to each of"}, {"source": "2023.semeval-1.317v1.pdf", "text": "the subtasks of the shared task.\n2the second paper has five additional techniques with re-\nspect to the previous oneATTACK ON REPUTATION\nName Calling or Labelling [AR:NCL]: a form of argument in which\nloaded labels are directed at an individual, group, object or activity,\ntypically in an insulting or demeaning way, but also using labels the target\naudience finds desirable."}, {"source": "2023.semeval-1.317v1.pdf", "text": "audience finds desirable.\nGuilt by Association [AR:GA]: attacking the opponent or an activity by\nassociating it with another group, activity, or concept that has sharp\nnegative connotations for the target audience.\nCasting Doubt [AR:D]: questioning the character or the personal\nattributes of someone or something in order to question their general\ncredibility or quality."}, {"source": "2023.semeval-1.317v1.pdf", "text": "credibility or quality.\nAppeal to Hypocrisy [AR:AH]: the target of the technique is attacked\nbased on their reputation by charging them with hypocrisy/inconsistency.\nQuestioning the Reputation [AR:QR]: the target is attacked by making\nstrong negative claims about it, focusing specially on undermining its\ncharacter and moral stature rather than relying on an argument about the\ntopic.\nJUSTIFICATION"}, {"source": "2023.semeval-1.317v1.pdf", "text": "topic.\nJUSTIFICATION\nFlag Waiving [J:FW]: justifying an idea by exhaling the pride of a group\nor highlighting the benefits for that specific group.\nAppeal to Authority [J:AA]: a weight is given to an argument, an idea or\ninformation by simply stating that a particular entity considered as an\nauthority is the source of the information."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Appeal to Popularity [J:AP]: a weight is given to an argument or idea by\njustifying it on the basis that allegedly \u201ceverybody\u201d (or the large majority)\nagrees with it or \u201cnobody\u201d disagrees with it.\nAppeal to Values [J:A V]: a weight is given to an idea by linking it to\nvalues seen by the target audience as positive.\nAppeal to Fear, Prejudice [J:AF]: promotes or rejects an idea through the"}, {"source": "2023.semeval-1.317v1.pdf", "text": "repulsion or fear of the audience towards this idea.\nDISTRACTION\nStrawman [D:SM]: consists in making an impression of refuting an\nargument of the opponent\u2019s proposition, whereas the real subject of the\nargument was not addressed or refuted, but instead was replaced with a\nfalse one.\nRed Herring [D:RH]: consists in diverting the attention of the audience"}, {"source": "2023.semeval-1.317v1.pdf", "text": "from the main topic being discussed, by introducing another topic, which\nis irrelevant.\nWhataboutism [D:W]: a technique that attempts to discredit an\nopponent\u2019s position by charging them with hypocrisy without directly\ndisproving their argument.\nSIMPLIFICATION\nCausal Oversimplification [S:CaO]: assuming a single cause or reason\nwhen there are actually multiple causes for an issue."}, {"source": "2023.semeval-1.317v1.pdf", "text": "False Dilemma or No Choice [S:FDNC]: a logical fallacy that presents\nonly two options or sides when there are many options or sides. In\nextreme, the author tells the audience exactly what actions to take,\neliminating any other possible choices.\nConsequential Oversimplification [S:CoO]: is an assertion one is\nmaking of some \u201cfirst\u201d event/action leading to a domino-like chain of"}, {"source": "2023.semeval-1.317v1.pdf", "text": "events that have some significant negative (positive) effects and\nconsequences that appear to be ludicrous or unwarranted or with each step\nin the chain more and more improbable.\nCALL\nSlogans [C:S]: a brief and striking phrase, often acting like an emotional\nappeal, that may include labeling and stereotyping.\nConversation Killer [A:CK]: words or phrases that discourage critical"}, {"source": "2023.semeval-1.317v1.pdf", "text": "thought and meaningful discussion about a given topic.\nAppeal to Time [C:AT]: the argument is centred around the idea that time\nhas come for a particular action.\nMANIPULATIVE WORDING\nLoaded Language [MW:LL]: use of specific words and phrases with\nstrong emotional implications (either positive or negative) to influence and\nconvince the audience that an argument is valid."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Obfuscation, Intentional Vagueness, Confusion [MW:OVC]: use of\nwords that are deliberately not clear, vague, or ambiguous so that the\naudience may have its own interpretations.\nExaggeration or Minimisation [MW:EM]: consists of either\nrepresenting something in an excessive manner or making something seem\nless important or smaller than it really is."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Repetition [MW:R]: the speaker uses the same phrase repeatedly with the\nhope that the repetition will lead to persuade the audience.\nFigure 1: Persuasion techniques taxonomy. The six\ncoarse-grained techniques are subdivided into 23 fine-\ngrained ones. An acronym for each technique is given\nin squared brackets.23443.1 News Genre Categorization\nRashkin et al. (2017) developed a corpus with"}, {"source": "2023.semeval-1.317v1.pdf", "text": "document-level annotations into four classes\n(trusted ,satire ,hoax , and propaganda ), annotated\nusing distant supervision. Horne and Adali (2017)\nstudied the relationship between fake news, real\nnews, and satire with focus on style. They found\nthat fake news is more similar to satire than to real\nnews. Golbeck et al. (2018) developed a dataset\nof fake news and satire stories and analyzed and"}, {"source": "2023.semeval-1.317v1.pdf", "text": "compared their thematic content. Satire was also\none of the categories in the NELA-GT-2018 dataset\n(N\u00f8rregaard et al., 2019), as well as in its extended\nversion NELA-GT-2019 (Gruppi et al., 2020).\nThe set up of our shared task is different, and\nfocusing on distinguishing between objective news\nreporting vs. opinion piece vs. satire.\n3.2 Framing Detection"}, {"source": "2023.semeval-1.317v1.pdf", "text": "3.2 Framing Detection\nFraming is a strategic device and a central con-\ncept in political communication for representing\ndifferent salient aspects and perspectives for the\npurpose of conveying the latent meaning about an\nissue (Entman, 1993). It is important for news\nmedia as the same topics can be discussed from\ndifferent perspectives. There has been work on"}, {"source": "2023.semeval-1.317v1.pdf", "text": "automatically identifying media frames, including\nannotation schemes and datasets such as the Media\nFrames Corpus (Card et al., 2015), systems to au-\ntomatically detect media frames (Liu et al., 2019;\nZhang et al., 2019), large-scale automatic analysis\nof New York Times Articles (Kwak et al., 2020),\nand a semi-supervised approach to detecting frames\nin online news sources (Cheeks et al., 2020)."}, {"source": "2023.semeval-1.317v1.pdf", "text": "In our shared task, we adopt the frame inventory\nof the Media Frames Corpus.\n3.3 Persuasion Techniques Detection\nWork on persuasion detection overlaps to a large\nextent with work on propaganda detection, as there\nare many commonalities between the two.\nEarly work on propaganda detection focused on\ndocument-level analysis. Rashkin et al. (2017) pre-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "dicted four classes ( trusted ,satire ,hoax , and propa-\nganda ), labeled using distant supervision. Barr\u00f3n-\nCedeno et al. (2019) developed a corpus with two\nlabels (i.e., propaganda vs.non-propaganda ) and\nfurther investigated writing style and readability\nlevel. Their findings confirmed that using distant\nsupervision, in conjunction with rich representa-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "tions, might encourage the model to predict thesource of the article, rather than to discriminate\npropaganda from non-propaganda.\nAn alternative line of research focused on de-\ntecting the use of specific propaganda techniques\nin text, e.g., Habernal et al. (2017, 2018) devel-\noped a corpus with 1.3k arguments annotated with\nfive fallacies that directly relate to propaganda tech-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "niques. A more fine-grained analysis was done by\nDa San Martino et al. (2019), who developed a cor-\npus of news articles annotated for 18 propaganda\ntechniques, considering separately the task of tech-\nnique spans detection and classification. They fur-\nther tackled a sentence-level propaganda detection\ntask, and proposed a multi-granular gated deep"}, {"source": "2023.semeval-1.317v1.pdf", "text": "neural network. Subsequently, the Prta system was\nreleased (Da San Martino et al., 2020c), and im-\nproved models were proposed addressing the limi-\ntations of transformers (Chernyavskiy et al., 2021),\nor looking into interpretable propaganda detection\n(Yu et al., 2021). Finally, there is work addressing\nthe detection of use of propaganda techniques in"}, {"source": "2023.semeval-1.317v1.pdf", "text": "memes (Dimitrov et al., 2021a), the relationship\nbetween propaganda and coordination (Hristakieva\net al., 2022), and work studying COVID-19 related\npropaganda in social media (Nakov et al., 2021a,b).\nSee (Da San Martino et al., 2020b) for a survey on\ncomputational propaganda detection.\nSeveral shared tasks on propaganda detecting in\ntext were also organized. SemEval-2020 task 11"}, {"source": "2023.semeval-1.317v1.pdf", "text": "on Detection of Persuasion Techniques in News Ar-\nticles (Da San Martino et al., 2020a) focused on\nnews articles, and asked to detect the text spans\nwhere propaganda techniques are used, and to pre-\ndict their type (14 techniques). Closely related to\nthat is the NLP4IF-2019 task on Fine-Grained Pro-\npaganda Detection (Da San Martino et al., 2019),"}, {"source": "2023.semeval-1.317v1.pdf", "text": "which asked to detect the spans of use in news ar-\nticles of each of 18 propaganda techniques. The\nSemEval-2021 task 6 on Detection of Persuasion\nTechniques in Texts and Images focused on 22\npropaganda techniques in memes (Dimitrov et al.,\n2021b), while WANLP\u20192022 shared task asked to\ndetect the use of 20 propaganda techniques in Ara-\nbic tweets (Alam et al., 2022). Here, we extend"}, {"source": "2023.semeval-1.317v1.pdf", "text": "and redesign the above annotation schemes.\n4 The Dataset\nThis section provides a brief description of the\ndataset, whereas detailed guidelines, definitions\nand examples are provided in a separate technical\nreport (Piskorski et al., 2023).2345We collected articles in nine languages: En-\nglish, French, German, Georgian, Greek, Italian,\nPolish, Russian, and Spanish published in the pe-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "riod between 2020 and mid-2022, and revolving\naround various globally discussed topics, including\nthe COVID-19 pandemic, abortion-related legisla-\ntion, migration, Russo-Ukrainian war, some local\nevents such as parliamentary elections, etc. We con-\nsidered both mainstream media and \u201calternative\u201d\nmedia sources that could potentially spread mis-\n/disinformation. For the former, we used various"}, {"source": "2023.semeval-1.317v1.pdf", "text": "news aggregation engines, e.g., Google News3and\nEurope Media Monitor4, etc., which cover sources\nwith different political orientation, whereas for the\nlatter, we used online services such as MediaBias-\nFactCheck5and NewsGuard.6We extracted the ar-\nticle texts either using Trafilatura (Barbaresi, 2021)\nor, in few cases, ad hoc procedures.\nWe annotated each text for genre, framing, and"}, {"source": "2023.semeval-1.317v1.pdf", "text": "persuasion techniques using the taxonomy de-\nscribed in Section 2. While genre and framing\nwere annotated at the document level, we anno-\ntated the persuasion techniques at the span level.\nWe had about 40 annotators, who were either media\nanalysts, disinformation specialists or NLP experts,\nmost of which had prior experience in performing\nlinguistic annotations. All annotators were either"}, {"source": "2023.semeval-1.317v1.pdf", "text": "native or near-native speakers of the language they\nannotated for. We used the INCEpTION (Klie et al.,\n2018) platform for carrying out the annotations.\nThe annotation interface for an example document\nusing INCEpTION is shown in Figure 2.\nFigure 2: Example of a multi-label annotation using In-\nception: news genre is annotated as document metadata"}, {"source": "2023.semeval-1.317v1.pdf", "text": "(left), while the persuasion techniques and the framings\nare highlighted in blue and green, respectively.\nAs regards English, we exploited the texts from\nDa San Martino et al. (2019), but the annotations\n3https://news.google.com\n4https://emm.newsbrief.eu\n5https://mediabiasfactcheck.com\n6https://www.newsguardtech.comfor persuasion techniques have been slightly modi-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "fied in order to match the extended taxonomy, most\nnotably Whataboutism included two meanings: dis-\ntracting from the main argument and calling the\nhypocrisy of the speaker; the latter meaning is\nnow covered by the technique Appeal to Hypocrisy .\nMoreover, we added annotations for framing and\nnews genre.\ntrain\nlang #docs #chars #spans #ne-par #avg-fr #avg-pt\nEnglish 446 2,431K 7201 9498 3.7 16.1"}, {"source": "2023.semeval-1.317v1.pdf", "text": "English 446 2,431K 7201 9498 3.7 16.1\nFrench 158 737K 5,595 2196 3.0 35.4\nGerman 132 581K 4,501 1484 4.3 34.1\nItalian 227 927K 6,027 2552 3.8 26.6\nPolish 145 765K 2,839 2294 5.0 19.6\nRussian 143 590K 3,399 1876 2.5 23.8\ndevelopment\nlang #docs #chars #spans #ne-par #avg-fr #avg-pt\nEnglish 90 403K 1,801 3,127 5.1 20.0\nFrench 53 222K 1,586 610 3.0 29.9\nGerman 45 171K 1,236 522 4.6 27.5"}, {"source": "2023.semeval-1.317v1.pdf", "text": "German 45 171K 1,236 522 4.6 27.5\nItalian 76 287K 1,934 882 3.9 25.4\nPolish 49 264K 985 800 4.9 20.1\nRussian 48 163K 739 515 2.3 15.4\ntest\nlang #docs #chars #spans #ne-par #avg-fr #avg-pt\nEnglish 54 228K 1,775 910 4.7 32.9\nFrench 50 181K 1,681 510 3.1 33.6\nGerman 50 259K 1,904 790 5.7 38.1\nItalian 61 245K 2,351 593 3.8 38.5\nPolish 47 349K 1,491 1006 5.9 31.7\nRussian 72 161K 944 601 1.2 13.1"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Russian 72 161K 944 601 1.2 13.1\nGeorgian 29 46K 218 161 1.7 7.5\nGreek 64 248K 691 947 2.9 10.8\nSpanish 30 109K 546 330 2.3 18.2\nTable 1: Statistics about the training , the development ,\nand the testdatasets: total number of documents (#docs),\ntotal number of characters (#chars), total number of text\nspans annotated (#spans), total number of non-empty"}, {"source": "2023.semeval-1.317v1.pdf", "text": "paragraphs (#ne-par), average number of frames per\ndocument (#avg-fr), and average number of persuasion\ntechniques per document (#avg-pt).\ntrain dev test\nlang op rep sat op rep satire op rep sat\nEnglish 382 41 10 20 54 9 32 17 5\nFrench 103 43 11 35 15 4 37 7 6\nGerman 86 27 19 29 9 7 33 12 5\nItalian 174 44 8 59 15 3 41 13 7\nPolish 104 25 15 35 9 6 35 10 2\nRussian 93 41 8 32 14 3 45 18 9"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Russian 93 41 8 32 14 3 45 18 9\nGeorgian - - - - - - 19 10 0\nGreek - - - - - - 39 22 3\nSpanish - - - - - - 14 9 7\nall 942 221 71 210 116 32 295 118 44\nTable 2: Number of documents from each genre across\nthe languages: opinion (op), reporting (rep), satire (sat).\nEach document was annotated by at least two\nannotators. Once the individual annotations for a"}, {"source": "2023.semeval-1.317v1.pdf", "text": "document have been accomplished, a curator (an\nexperienced annotator) with the help of annotators2346consolidated the final annotation. The consolida-\ntion consisted of: (a) merging complementary an-\nnotations (tagged only by one annotator), (b) decid-\ning whether overlapping annotations are to be kept\nas they are (multi-labels) or joined into a single-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "labeled annotation, and (c) carrying out global con-\nsistency analysis. The detailed description of the\nannotation and the consolidation process are de-\nscribed in a detailed technical report (Piskorski\net al., 2023). In order to assess the annotation qual-\nity, we computed the Inter-Annotator Agreement\n(IAA) using Krippendorf\u2019s \u03b1: the value was 0.342,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "which is lower than the recommended threshold\nof 0.667, but we should note that this value repre-\nsents the agreement before the consolidation, and\nas such, it is more representative of the consoli-\ndation difficulty rather than of the quality of the\nfinal consolidated annotations. Actually, we used\nIAA to allocate consolidation roles and to eliminate\nlow-performing annotators."}, {"source": "2023.semeval-1.317v1.pdf", "text": "low-performing annotators.\nWe further studied the IAA by ranking the an-\nnotators by their performance with respect to the\nground truth on the subset of documents they anno-\ntated. We then split them into two groups, topand\nlow, based on the median micro- F1scores. Their\nrespective \u03b1scores were 0.415 and 0.250. Finally,\nwe considered the value of \u03b1of the group of anno-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "tators, based on Italian, the only language with two\ncurators, achieving 0.588, which is lower but close\nto the recommended value.\nThe annotated data, consisting of 2,049 docu-\nments in total, were divided into train ,dev, and test\ndatasets, whose high-level statistics are provided in\nTable 1. Georgian, Greek, and Spanish-annotated\ndata was used only for testing (surprise languages)."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Table 2 shows the distribution of articles per lan-\nguage in terms of genre. Detailed statistics about\nthe fine-grained persuasion techniques are shown\nin Table 17 in Annex A.\n5 Evaluation Framework\n5.1 Evaluation Measures\nSubtask 1 is a multi-class classification problem.\nWe used macro F 1as the official evaluation mea-\nsure, but we also computed micro F 1."}, {"source": "2023.semeval-1.317v1.pdf", "text": "sure, but we also computed micro F 1.\nSubtask 2 is a multi-label multi-class classification\nproblem. We used micro F 1as the official evalua-\ntion measure, but we also computed macro F 1.\nSubtask 3 is a multi-label multi-class classification\nproblem. We used micro F 1as the official eval-\nuation measure. The official score was computedusing the 23 fine-grained persuasion technique la-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "bels. We also computed macro F 1.\n5.2 Task Organization\nThe shared task was run in two phases:\nDevelopment Phase: initially, only training and\ndevelopment data were made available to the par-\nticipants, and no gold labels were provided for the\nlatter. The participants competed against each other\nto achieve the best performance on the develop-\nment set. They could make an unlimited number"}, {"source": "2023.semeval-1.317v1.pdf", "text": "of submissions, and the best score for each team,\nregardless of the submission time, was shown in\nreal time on a public leaderboard.\nTest Phase: in the second phase, the gold labels\nfor the development and the testsets were released,\nand the participants were given a week to submit\ntheir final predictions on the testset. It is impor-\ntant to note that the test data contained news in"}, {"source": "2023.semeval-1.317v1.pdf", "text": "three additional languages, i.e., Georgian, Greek,\nand Spanish, which were not known upfront to the\nparticipants (surprise languages). The participants\ncould again submit multiple runs, but they would\nnot get any feedback on their performance. Only\nthe latest submission of each team was considered\nas official and was used for the final team ranking."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Overall, 41 teams made official submissions to all\nthe tasks, where 27, 22, and 22 teams submitted\nresults for ST1, ST2, ST3, respectively. Moreover,\n13, 14, and 14 teams submitted results for all lan-\nguages for ST1, ST2, ST3, respectively.\nThe results for the development and the test\nphases are available on the leaderboard7page. Af-\nter the competition was over, we left the submission"}, {"source": "2023.semeval-1.317v1.pdf", "text": "system open for the test dataset for post-shared task\nevaluations and to monitor the state of the art for\nthe different subtasks across the languages.\n6 Participants and Results\n6.1 Subtask 1: News Genre Categorization\nThe full results for Subtask 1 are shown in Tables 3\nand 4 (surprise languages). We used a linear SVM8\nwith class balancing, trained on 5-char n-grams as a"}, {"source": "2023.semeval-1.317v1.pdf", "text": "baseline (highlighted in blue in the tables). Table 5\nshows an overview of the approaches. Almost all\nparticipants used transformers. The scarcity of the\nannotated data was dealt with either by combining\nthe datasets for all languages, e.g., via multilingual\n7https://propaganda.math.unipd.it/\nsemeval2023task3/leaderboard.php"}, {"source": "2023.semeval-1.317v1.pdf", "text": "semeval2023task3/leaderboard.php\n8https://scikit-learn.org2347English Italian Russian French German Polish\nTEAM mac mic TEAM mac mic TEAM mac mic TEAM mac mic TEAM mac mic TEAM mac mic\nMELODI .784 .815 Hitachi .768 .852 Hitachi .755 .750 UMUTeam .835 .880 UMUTeam .820 .820 FTD .786 .936"}, {"source": "2023.semeval-1.317v1.pdf", "text": "MLModeler5 .616 .630 QUST .767 .836 SheffieldVeraAI .729 .722 QCRI .767 .800 SheffieldVeraAI .820 .820 Hitachi .779 .872\nSheffieldVeraAI .613 .704 DSHacker .720 .836 FTD .668 .694 Hitachi .744 .780 DSHacker .813 .820 SheffieldVeraAI .765 .851\nHHU .594 .611 SheffieldVeraAI .720 .836 UMUTeam .645 .681 DSHacker .710 .720 SinaAI .782 .760 MELODI .709 .851"}, {"source": "2023.semeval-1.317v1.pdf", "text": "DSHacker .591 .630 MELODI .587 .754 MELODI .586 .625 SheffieldVeraAI .682 .740 MELODI .779 .780 UMUTeam .664 .809\nUnisa .586 .611 UnedMediaBias .584 .623 QCRI .567 .653 FTD .671 .780 Hitachi .777 .760 SinaAI .663 .809\nHitachi .553 .593 UMUTeam .553 .754 DSHacker .559 .597 MELODI .656 .740 FTD .713 .720 DSHacker .661 .809"}, {"source": "2023.semeval-1.317v1.pdf", "text": "UnedMediaBias .524 .574 QCRI .541 .787 Spoke .490 .653 SinaAI .638 .680 QCRI .667 .660 kb .653 .809\nSinaAI .506 .667 FTD .517 .754 QUST .472 .514 QUST .621 .700 SATLab .644 .700 SATLab .571 .830\nQUST .506 .630 SinaAI .502 .738 SinaAI .443 .472 Baseline .568 .740 Baseline .630 .760 QCRI .571 .830\nUMUTeam .413 .593 HHU .455 .639 HHU .426 .472 UnedMediaBias .465 .480 QUST .626 .660 QUST .528 .596"}, {"source": "2023.semeval-1.317v1.pdf", "text": "UM6P .394 .519 Riga .436 .574 Baseline .398 .653 SATLab .447 .640 HHU .611 .740 UnedMediaBias .507 .553\nRiga .349 .537 Baseline .389 .672 UnedMediaBias .365 .444 Riga .356 .580 FramingFreaks .569 .700 Baseline .490 .830\nFTD .329 .463 FramingFreaks .360 .656 Riga .271 .389 JUSTR00 .347 .660 Riga .412 .480 Riga .433 .468"}, {"source": "2023.semeval-1.317v1.pdf", "text": "kb .299 .574 SATLab .319 .623 MaChAmp .256 .625 FramingFreaks .341 .660 UnedMediaBias .362 .420 MaChAmp .285 .745\nBaseline .288 .611 JUSTR00 .317 .574 FramingFreaks .236 .319 MaChAmp .284 .740 JUSTR00 .265 .660 FramingFreaks .282 .702\nQCRI .281 .593 MaChAmp .268 .672 E8IJS .175 .306 E8IJS .080 .120 MaChAmp .265 .660 E8IJS .063 .085\nSpoke .265 .444 E8IJS .121 .164 E8IJS .118 .180\nJUSTR00 .257 .370"}, {"source": "2023.semeval-1.317v1.pdf", "text": "JUSTR00 .257 .370\nFramingFreaks .248 .593\nMaChAmp .248 .593\nssnNlp .248 .593\nSATLab .243 .574\nUTB-NLP .243 .574\nE8IJS .075 .093\nTable 3: Results for Subtask 1 for the six main languages: macro F 1(mac), micro F 1(mic), ordered by the former,\nwhich is the official score.\nlanguage models or by automatic translation, or\nby looking for similar datasets in the literature;"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ensemble methods have also been very popular.\nSpanish Greek Georgian\nTEAM mac mic TEAM mac mic TEAM mac mic\nDSHacker .563 .567 SinaAI .806 .813 Riga 1,000 1,000\nQUST .552 .633 UMUTeam .767 .797 SheffieldVeraAI .963 .966\nQCRI .489 .567 HHU .750 .750 FTD .888 .897\nSheffieldVeraAI .443 .500 QCRI .708 .813 QCRI .622 .897\nMELODI .443 .600 FTD .698 .766 DSHacker .597 .862"}, {"source": "2023.semeval-1.317v1.pdf", "text": "UMUTeam .438 .500 SheffieldVeraAI .687 .734 UMUTeam .582 .862\nFTD .400 .433 MELODI .637 .703 QUST .537 .690\nRiga .385 .500 DSHacker .593 .641 SATLab .519 .724\nUnedMediaBias .336 .367 UnedMediaBias .521 .563 MELODI .490 .724\nHHU .327 .433 QUST .492 .609 UnedMediaBias .486 .690\nSinaAI .323 .433 Riga .412 .578 SinaAI .468 .690\nFramingFreaks .317 .467 SATLab .254 .406 MaChAmp .396 .655"}, {"source": "2023.semeval-1.317v1.pdf", "text": "SATLab .282 .433 MaChAmp .252 .609 Baseline .256 .345\nE8IJS .235 .300 FramingFreaks .234 .344 FramingFreaks .255 .621\nMaChAmp .212 .467 Baseline .171 .344 E8IJS .000 .000\nBaseline .154 .300 E8IJS .057 .063\nTable 4: Results for Subtask 1 for the three surprise\nlanguages: macro F 1(mac), micro F 1(mic), ordered\nby the former, which is the official score."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Below, we give a short description of the sys-\ntem papers that were top-ranked for at least one\nlanguage.\nSinaAI (EL) used multilingual languages mod-\nels, XLM, mBERT and LABSE, and ensembles\nthereof. They further used data augmentation by\nselecting 30% of the sentences of each document\nto create new synthetic examples.\nDSHacker (ES) created synthetic texts for each"}, {"source": "2023.semeval-1.317v1.pdf", "text": "class using the OpenAI GPT-3 Davinci language\nmodel. Each language was augmented by approxi-\nmately 500 articles per genre, producing roughly\n13,500 artificially generated articles. Then, they\nfine-tuned a single XLM-RoBERTalarge on theTeam Name\ntransformers\nother representations\nadditional data\ndata augmentation\nensembles\npreprocessing\ntrained on all languages\nknowledge base\nchunk processing"}, {"source": "2023.semeval-1.317v1.pdf", "text": "knowledge base\nchunk processing\ndata translation\nDSHacker \u2713 \u2713 \u2713 \u2713\nFTD \u2713 \u2713 \u2713 \u2713 \u2713\nHHU \u2713 \u2713 \u2713 \u2713 \u2713\nHitachi \u2713 \u2713 \u2713 \u2713\nMELODI \u2713 \u2713 \u2713\nMLModeler5 \u2713 \u2713 \u2713 \u2713\nMaChAmp \u2713 \u2713 \u2713\nNLUBot101\nQCRI \u2713 \u2713 \u2713\nQUST \u2713 \u2713 \u2713 \u2713 \u2713\nRiga \u2713 \u2713 \u2713 \u2713\nSheffieldVeraAI \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nUM6P \u2713 \u2713 \u2713\nUMUTeam \u2713 \u2713 \u2713 \u2713\nUTB-NLP \u2713 \u2713 \u2713 \u2713\nUnedMediaBiasTeam \u2713 \u2713 \u2713\nUnisa \u2713 \u2713 \u2713 \u2713\nkb \u2713\nTable 5: ST1: Overview of the approaches and the"}, {"source": "2023.semeval-1.317v1.pdf", "text": "features used by the participating systems. The systems\nhighlighted in bold ranked first for at least one language.\noriginal and the augmented data.\nFTD (PL): They experimented with monolin-\ngual and multilingual models, ensembles, addi-\ntional data, and uncertainty estimation. For Russian\nand English, they fine-tuned models pretrained on\nthe FTD dataset for genre classification. For En-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "glish, they added 1,000 reporting texts from Giga-\nword. For Polish and German, their best results\nwere achieved by fine-tuning a monolingual Polish\nBERT and a monolingual German Electra, respec-2348English Italian Russian French German Polish\nTEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac"}, {"source": "2023.semeval-1.317v1.pdf", "text": "SheffieldVeraAI .579 .539 MarsEclipse .617 .545 MarsEclipse .450 .303 MarsEclipse .553 .537 MarsEclipse .711 .660 MarsEclipse .673 .638\nTeamAmpa .567 .510 QCRI .599 .479 SheffieldVeraAI .441 .356 BERTastic .537 .520 QCRI .660 .606 SheffieldVeraAI .645 .603\nMarsEclipse .562 .490 Hitachi .598 .515 QCRI .434 .364 SheffieldVeraAI .534 .520 SheffieldVeraAI .653 .601 QCRI .642 .599"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Hitachi .543 .472 TeamAmpa .597 .483 TeamAmpa .409 .294 Hitachi .514 .488 TeamAmpa .632 .573 UMUTeam .642 .593\nmCPT .535 .482 mCPT .584 .469 mCPT .409 .367 TeamAmpa .506 .479 Hitachi .629 .567 Hitachi .634 .584\nQUST .513 .462 UMUTeam .576 .447 BERTastic .393 .265 TheSyllogist .486 .462 mCPT .622 .564 SATLab .620 .570"}, {"source": "2023.semeval-1.317v1.pdf", "text": "QCRI .513 .419 SheffieldVeraAI .571 .491 TheSyllogist .385 .290 QCRI .480 .430 QUST .616 .545 TeamAmpa .614 .555\nBERTastic .512 .446 TheSyllogist .554 .444 UMUTeam .385 .288 UMUTeam .477 .438 UMUTeam .614 .565 MaChAmp .597 .582\nUMUTeam .508 .415 BERTastic .545 .469 Hitachi .370 .326 mCPT .469 .429 BERTastic .603 .562 mCPT .597 .555"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ACCEPT .507 .502 QUST .502 .465 Riga .315 .222 ACCEPT .456 .443 MaChAmp .582 .564 Baseline .594 .532\nMaChAmp .506 .493 Riga .499 .321 ACCEPT .254 .249 QUST .447 .438 SATLab .572 .519 QUST .591 .533\nTheSyllogist .487 .409 ACCEPT .495 .439 QUST .250 .213 Riga .376 .287 FTD .555 .299 FTD .588 .516"}, {"source": "2023.semeval-1.317v1.pdf", "text": "MLModeler5 .477 .427 Baseline .486 .372 Baseline .230 .218 SATLab .375 .352 FramingFreaks .545 .496 BERTastic .587 .535\nFTD .453 .362 SATLab .474 .416 FramingFreaks .219 .159 MaChAmp .359 .355 TheSyllogist .537 .465 FramingFreaks .560 .460\nJUSTR00 .443 .363 FTD .459 .227 FTD .198 .117 Baseline .329 .276 Riga .509 .375 TheSyllogist .553 .501"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Riga .420 .313 FramingFreaks .452 .355 MaChAmp .161 .151 FramingFreaks .327 .300 ACCEPT .496 .460 Riga .542 .412\nSATLab .378 .317 MaChAmp .424 .403 SinaAI .113 .128 FTD .255 .105 Baseline .487 .418 ACCEPT .510 .490\nBaseline .350 .274 SinaAI .251 .200 DigDemLab .070 .055 DigDemLab .220 .192 DigDemLab .335 .279 SinaAI .475 .446"}, {"source": "2023.semeval-1.317v1.pdf", "text": "UTB-NLP .341 .309 DigDemLab .237 .173 SinaAI .187 .157 SinaAI .302 .265 DigDemLab .392 .348\nIA2022Grupa1 .326 .265\nSinaAI .266 .226\nDigDemLab .207 .172\nFramingFreaks .196 .142\nTable 6: Results for Subtask 2 for the six main languages: micro F 1(mic), macro F 1(mac), ordered by the former,\nwhich is the official score.\nSpanish Greek Georgian\nTEAM mic mac TEAM mic mac TEAM mic mac"}, {"source": "2023.semeval-1.317v1.pdf", "text": "TEAM mic mac TEAM mic mac TEAM mic mac\nmCPT .571 .455 SheffieldVeraAI .546 .454 SheffieldVeraAI .654 .679\nUMUTeam .558 .465 TeamAmpa .544 .444 MarsEclipse .645 .639\nSheffieldVeraAI .508 .432 UMUTeam .534 .404 TheSyllogist .561 .493\nTeamAmpa .506 .387 TheSyllogist .530 .440 BERTastic .552 .408\nRiga .489 .426 BERTastic .526 .444 UMUTeam .529 .411\nQCRI .488 .390 QCRI .519 .400 QCRI .517 .457"}, {"source": "2023.semeval-1.317v1.pdf", "text": "MarsEclipse .477 .404 mCPT .516 .410 TeamAmpa .517 .379\nBERTastic .477 .428 MarsEclipse .498 .402 Riga .424 .381\nTheSyllogist .473 .387 QUST .414 .392 mCPT .400 .291\nACCEPT .388 .387 FramingFreaks .380 .154 FramingFreaks .352 .344\nMaChAmp .385 .269 Riga .377 .195 MaChAmp .313 .225\nSATLab .383 .293 ACCEPT .355 .370 QUST .311 .260\nQUST .374 .353 Baseline .345 .057 Baseline .260 .251"}, {"source": "2023.semeval-1.317v1.pdf", "text": "FTD .265 .201 MaChAmp .293 .206 ACCEPT .220 .290\nFramingFreaks .215 .211 SinaAI .140 .123 SinaAI .133 .205\nSinaAI .181 .163 SATLab .068 .037 SATLab .053 .184\nBaseline .120 .095\nTable 7: Results for Subtask 2 for the three surprise\nlanguages: micro F 1(mic), macro F 1(mac), ordered\nby the former, which is the official score.\ntively. For the other languages, their best systems"}, {"source": "2023.semeval-1.317v1.pdf", "text": "used multilingual BERT, XLM-RoBERTa, or en-\nsembles thereof. In all cases, they truncated the\ninput to the first 510 tokens. They further upsam-\npled the data to balance the distribution between\nthe classes (the results without upsampling were\nlow).\nHitachi (IT, RU) augmented the dataset for sub-\ntask 1 by collecting labelled examples from simi-\nlar datasets. They pretrained (XLM-)RoBERTa in"}, {"source": "2023.semeval-1.317v1.pdf", "text": "multi-task (one language, subtasks 1 and 2), multi-\nlingual (one subtask, all languages), and multilin-\ngual multi-task (subtasks 1 and 2 in all languages)\nsettings. Besides using the single models, they re-\nport experiments with ensembles of base models\nand different hyper-parameter values.\nMELODI (EN) fine-tuned the domain-specificlanguage model trained on English data, POLI-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "TICS, on the English input articles and on the\narticles in all other languages, which were auto-\nmatically translated. In addition, in order to use\nwhole articles as input, they used a sliding win-\ndow and aggregated each window representation\nusing mean-pooling. They also tested other multi-\nlingual approaches, such as XLM-RoBERTa, and\nwere able to process long documents (Longformer),"}, {"source": "2023.semeval-1.317v1.pdf", "text": "which were generally less effective.\nUMUTeam (FR, DE) used a multilingual model\nbased on XML-RoBERTa, which was fine-tuned\non all languages at once and a sentence transformer\nmodel to extract the most important chunk of text.\nThe input data was truncated to 200 tokens with 50\noverlaps using the sentence-transformer model to\nobtain the subset of text most related to the article\u2019s\ntitle."}, {"source": "2023.semeval-1.317v1.pdf", "text": "title.\nSheffieldVeraAI (DE) deployed an ensemble of\nthree fine-tuned mBERT models and one mBERT\nmodel with a bottleneck adapter. All used bert-\nbase-multilingual-cased. The pool of training data\nwas also extended by integration additional \u201csatire\u201d\nresources for English. The final predictions were\ndrawn as a majority-voting predicted class.\n6.2 Subtask 2: Framing"}, {"source": "2023.semeval-1.317v1.pdf", "text": "6.2 Subtask 2: Framing\nThe full results for subtask 2 on framing classifi-\ncation are provided in Table 6 and 7 (surprise lan-\nguages). We used linear SVM trained using word\nunigrams and bigrams as a baseline (highlighted in\nblue in the tables). Table 8 shows an overview\nof the approaches. Since the models were all2349transformer-based, what differentiated the partici-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "pating systems were once again the pre-processing\nand the data augmentation techniques. The vast\nmajority of teams trained their systems on all lan-\nguages and used ensembles.\nTeam Name\ntransformers\nother representations\nadditional data\ndata augmentation\nensembles\npreprocessing\ntrained on all languages\nknowledge base\nchunk processing\ndata translation\nACCEPT \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nBERTastic \u2713 \u2713 \u2713 \u2713 \u2713\nFTD \u2713"}, {"source": "2023.semeval-1.317v1.pdf", "text": "BERTastic \u2713 \u2713 \u2713 \u2713 \u2713\nFTD \u2713\nHitachi \u2713 \u2713 \u2713\nMLModeler5 \u2713 \u2713 \u2713 \u2713\nMaChAmp \u2713\nMarsEclipse \u2713 \u2713 \u2713\nQCRI \u2713 \u2713 \u2713\nQUST \u2713 \u2713 \u2713 \u2713 \u2713\nRiga \u2713 \u2713 \u2713 \u2713\nSheffieldVeraAI \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nTheSyllogist \u2713 \u2713 \u2713\nUMUTeam \u2713 \u2713 \u2713\nUTB-NLP \u2713 \u2713 \u2713 \u2713\nmCPT \u2713 \u2713\nTable 8: ST2: Overview of the approaches and the\nfeatures used by the participating systems. The systems\nhighlighted in bold ranked first for at least one language."}, {"source": "2023.semeval-1.317v1.pdf", "text": "MarsEclipse (IT, RU, FR, DE, PL): This team\nused a multi-label contrastive loss for fine-tuning\nXLM-RoBERTa using SimCLR and SimCSE and\nadapting the loss function to a multilabel setup.\nmCPT (ES): This team used a two-phase train-\ning procedure of a transformer model, first by pre-\ntraining jointly on all the languages and then by\nfine-tuning for each language. In both phases, a"}, {"source": "2023.semeval-1.317v1.pdf", "text": "multi-label contrastive loss was used.\nSheffieldVeraAI (EN, EL, KA): The team\nachieved the best average rank score over all the\nlanguages. They used two different ensembles of\nMUPPET large and of XLM-RoBERTa large with\nadapters and task-adaptive MLM pretraining on the\ntrain+dev+test data. Their data was preprocessed\nand truncated. The models were trained both with\nand without class weighting."}, {"source": "2023.semeval-1.317v1.pdf", "text": "and without class weighting.\n6.3 Subtask 3: Persuasion Techniques\nDetection\nThe full results for subtask 3 on persuasion tech-\nniques detection are given in Tables 9 and 10 (sur-\nprise languages). We used linear SVM trained\nusing word uni-grams and bigrams as a baseline\n(highlighted in blue in the tables). Table 11 shows"}, {"source": "2023.semeval-1.317v1.pdf", "text": "an overview of the approaches used by the partic-ipating systems. The big picture is very similar\nto the previous subtasks: multilingual transformer\nmodels were used by all participants, and what\ndifferentiated the approaches was again the pre-\nprocessing and data augmentation strategies, for\nexample, a few teams made use of the span-level\nannotations."}, {"source": "2023.semeval-1.317v1.pdf", "text": "annotations.\nAPatt (EN): The team combined different fine-\ntuned transformer models (XLNet, RoBERTa,\nBERT, ALBERT, and DeBERTa) through a\nweighted average. For English, they weighted the\npredictions of the models to give higher importance\nto certain models.\nKInITVeraAI (IT, RU, DE, PL, EL, KA): This\nteam performed overall the best, using a fine-tuned\nXLM-RoBERTa-large transformer model trained"}, {"source": "2023.semeval-1.317v1.pdf", "text": "on all the input data. They carefully adjusted the\nprediction threshold for each language using a prin-\ncipled approach. They truncated the input, and also\nfound that preprocessing did not impact the quality\nmuch.\nNAP (FR): The team presented an approach\ncombining predictions of several models in an en-\nsemble, which differ in three main aspects: a)"}, {"source": "2023.semeval-1.317v1.pdf", "text": "training data, b) model architecture, and c) in-\nput format to the model. They leveraged trans-\nlation as data augmentation strategies using avail-\nable MarianMT models. Model architectures in-\ncluded XLM-RoBERTa models, Adapters, SetFit,\nand linguistically-informed heuristics for under-\nrepresented techniques which were fine-tuned on\ndifferent combinations of original and augmented"}, {"source": "2023.semeval-1.317v1.pdf", "text": "data. They fine-tuned models on both paragraph-\nand span-level information.\nTeamAmpa (ES): The team used different over-\nsampling strategies, data truncation, and monolin-\ngual and multilingually trained models, combined\nin an ensemble for the English Task 3 data. The\nsurprise languages were handled using the mul-\ntilingual model only, which where trained using"}, {"source": "2023.semeval-1.317v1.pdf", "text": "XLM-R on all languages with oversampling, for\none of these languages the team ranked first.\n6.4 Aggregated results\nTables 12-14 report the average micro F 1scores of\nthe teams who, for each subtask, submitted solu-\ntions for multiple languages: the 6 for which we\nprovided training data (6L), the 3 surprise ones\n(3L), all of them (9L). Results are ranked by de-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "creasing value on all.2350English Italian Russian French German Polish\nTEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac\nAPatt .376 .129 KInITVeraAI .550 .214 KInITVeraAI .387 .189 NAP .469 .322 KInITVeraAI .513 .233 KInITVeraAI .430 .179\nSheffieldVeraAI .368 .172 NAP .539 .266 TeamAmpa .378 .227 TeamAmpa .434 .305 NAP .510 .272 NAP .422 .246"}, {"source": "2023.semeval-1.317v1.pdf", "text": "AppealForAtt .363 .166 SheffieldVeraAI .525 .282 QCRI .361 .182 KInITVeraAI .432 .214 QCRI .498 .231 DSHacker .390 .170\nKInITVeraAI .362 .133 TeamAmpa .521 .264 NLUBot101 .323 .201 SheffieldVeraAI .414 .324 APatt .484 .177 TeamAmpa .389 .236\nNLUBot101 .361 .197 FTD .516 .176 SheffieldVeraAI .318 .205 QCRI .401 .226 TeamAmpa .476 .266 QCRI .378 .156"}, {"source": "2023.semeval-1.317v1.pdf", "text": "FTD .346 .088 QCRI .513 .209 AppealForAtt .312 .173 NLUBot101 .396 .254 SheffieldVeraAI .447 .237 APatt .366 .150\nTeamAmpa .325 .158 DSHacker .496 .153 APatt .306 .117 DSHacker .388 .201 NLUBot101 .420 .179 SheffieldVeraAI .347 .191\nQCRI .320 .133 ReDASPersuasion .448 .106 NAP .305 .193 APatt .384 .191 AppealForAtt .418 .218 AppealForAtt .344 .201"}, {"source": "2023.semeval-1.317v1.pdf", "text": "DSHacker .320 .140 APatt .441 .166 MaChAmp .271 .148 AppealForAtt .374 .203 DSHacker .408 .154 FTD .327 .122\nCLaC .309 .071 Riga .436 .092 DSHacker .257 .083 kb .362 .266 MaChAmp .405 .178 NLUBot101 .320 .169\nNL4IA .308 .142 NLUBot101 .435 .164 kb .253 .117 MaChAmp .345 .207 ReDASPersuasion .384 .078 kb .314 .179"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Unisa .298 .109 SATLab .433 .183 Riga .252 .064 SATLab .338 .241 kb .373 .201 MaChAmp .307 .170\nMaChAmp .295 .149 AppealForAtt .431 .211 FTD .235 .058 Riga .306 .078 Riga .373 .060 SATLab .300 .143\nRiga .280 .062 MaChAmp .422 .166 ReDASPersuasion .219 .050 ReDASPersuasion .301 .115 FTD .363 .110 ReDASPersuasion .238 .112"}, {"source": "2023.semeval-1.317v1.pdf", "text": "NAP .263 .082 kb .399 .201 Baseline .207 .086 FTD .298 .126 SATLab .355 .163 UnedMediaBias .237 .103\nSATLab .259 .103 Baseline .397 .122 CLaC .193 .057 Baseline .240 .099 UnedMediaBias .318 .106 Riga .228 .038\nReDASPersuasion .251 .045 UnedMediaBias .317 .111 UnedMediaBias .183 .100 CLaC .239 .066 Baseline .317 .083 CLaC .190 .050"}, {"source": "2023.semeval-1.317v1.pdf", "text": "UnedMediaBias .241 .078 CLaC .313 .063 SinaAI .139 .057 UnedMediaBias .236 .121 CLaC .248 .055 Baseline .179 .059\nBaseline .195 .069 QUST .213 .155 QUST .100 .080 QUST .209 .164 QUST .153 .112 QUST .097 .074\nIA2022Grupa1 .193 .072 SinaAI .203 .064 SinaAI .195 .063 SinaAI .042 .034 SinaAI .064 .025\nSinaAI .141 .022\nQUST .135 .103\nkb .060 .031"}, {"source": "2023.semeval-1.317v1.pdf", "text": "QUST .135 .103\nkb .060 .031\nTable 9: Results for subtask 3 for the six main languages: micro F 1(mic), macro F 1(mac), ordered by the former,\nwhich is the official score.\nSpanish Greek Georgian\nTEAM mic mac TEAM mic mac TEAM mic mac\nTeamAmpa .381 .244 KInITVeraAI .267 .126 KInITVeraAI .457 .328\nKInITVeraAI .380 .155 QCRI .265 .129 QCRI .414 .339\nNAP .370 .181 NAP .258 .164 NAP .413 .306"}, {"source": "2023.semeval-1.317v1.pdf", "text": "QCRI .350 .157 TeamAmpa .238 .171 TeamAmpa .408 .259\nAppealForAtt .317 .139 MaChAmp .215 .129 Riga .362 .209\nNLUBot101 .305 .151 AppealForAtt .206 .119 MaChAmp .301 .221\nFTD .281 .074 SheffieldVeraAI .174 .110 AppealForAtt .280 .261\nMaChAmp .276 .139 Riga .164 .036 CLaC .271 .199\nSheffieldVeraAI .275 .130 CLaC .156 .055 NLUBot101 .254 .172"}, {"source": "2023.semeval-1.317v1.pdf", "text": "CLaC .267 .048 NLUBot101 .150 .097 SheffieldVeraAI .249 .296\nBaseline .248 .020 kb .150 .121 UnedMediaBias .180 .221\nkb .245 .143 SinaAI .114 .029 kb .150 .100\nUnedMediaBias .227 .078 UnedMediaBias .106 .026 SinaAI .139 .040\nRiga .199 .045 Baseline .088 .006 Baseline .138 .141\nSATLab .193 .057 QUST .057 .047 QUST .091 .115\nSinaAI .178 .028 SATLab .000 .000 SATLab .076 .158\nQUST .126 .099"}, {"source": "2023.semeval-1.317v1.pdf", "text": "QUST .126 .099\nTable 10: Results for Subtask 3 for the three surprise\nlanguages: micro F 1(mic), macro F 1(mac), ordered\nby the former, which is the official score.\n7 Conclusions and Future Work\nWe presented SemEval-2023 Task 3 on Detecting\nthe Category, the Framing, and the Persuasion\nTechniques in Online News in a Multi-lingual Setup .\nThe task attracted a lot of attention: 181 teams reg-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "istered for the task, 41 teams eventually madevan\nofficial submission on the test set, and 32 teams\nalso submitted a task description paper.\nIn future work, we plan to further increase the\ndata size, cover additional languages, and explore\ndifferent ways of evaluation of the persuasion\ntechnique detection, e.g., by changing the focus\n(sentence- and text span-level evaluation).\n8 Limitations"}, {"source": "2023.semeval-1.317v1.pdf", "text": "8 Limitations\nDataset Representativeness Our dataset covers\na range of topics of public interest (COVID-19,Team Name\ntransformers\nother representations\nadditional data\ndata augmentation\nensembles\npreprocessing\ntrained on all languages\nknowledge base\nchunk processing\ndata translation\nAPatt \u2713 \u2713\nAppealForAtt \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nDSHacker \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nFTD \u2713\nKInITVeraAI \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nNAP \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nNL4IA \u2713 \u2713"}, {"source": "2023.semeval-1.317v1.pdf", "text": "NAP \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nNL4IA \u2713 \u2713\nNLUBot101 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nQCRI \u2713 \u2713 \u2713\nQUST \u2713 \u2713 \u2713 \u2713 \u2713\nReDASPersuasion \u2713 \u2713\nRiga \u2713 \u2713 \u2713\nSheffieldVeraAI \u2713 \u2713 \u2713\nUnedMediaBiasTeam \u2713 \u2713 \u2713\nUnisa \u2713 \u2713 \u2713\nkb \u2713 \u2713\nTable 11: ST3: Overview of the approaches and the\nfeatures used by the participating systems. The systems\nhighlighted in bold ranked first for at least one language.\nclimate change, abortion, migration, the Russo-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Ukrainian war, and local elections) as well as media\nfrom all sides of the political spectrum. However,\nit should not be seen as representative of the media\nin any country, nor should it be seen as perfectly\nbalanced in any specific way.\nBiases Human data annotation involves some de-\ngree of subjectivity. To mitigate this, we created\na comprehensive 60-page guidelines document,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "which we updated from time to time to clarify\nnewly arising important cases during the annota-\ntion process. We further had quality control steps2351team 6L 3L 9L\nSheffieldVeraAI 0.779 0.733 0.764\nHitachi 0.768 - -\nMELODI 0.761 0.676 0.732\nUMUTeam 0.756 0.720 0.744\nDSHacker 0.735 0.690 0.720\nFTD 0.725 0.699 0.716\nQCRI 0.720 0.759 0.733\nBaseline 0.711 0.330 0.584\nSinaAI 0.688 0.645 0.673"}, {"source": "2023.semeval-1.317v1.pdf", "text": "SinaAI 0.688 0.645 0.673\nMaChAmp 0.672 0.577 0.641\nQUST 0.656 0.644 0.652\nFramingFreaks 0.605 0.477 0.562\nUnedMediaBiasTeam 0.516 0.540 0.524\nRiga 0.505 0.693 0.567\nE8IJS 0.158 0.121 0.146\nTable 12: Average macro score across language for the\nteams participating in all \u2018provided\u2019 six languages (6L),\nthe three surprise languages (3L), all nine languages\n(9L) for subtask 1.\nteam 6L 3L 9L"}, {"source": "2023.semeval-1.317v1.pdf", "text": "(9L) for subtask 1.\nteam 6L 3L 9L\nMarsEclipse 0.594 0.540 0.576\nSheffieldVeraAI 0.571 0.570 0.570\nQCRI 0.555 0.508 0.539\nTeamAmpa 0.554 0.522 0.543\nHitachi 0.548 - -\nmCPT 0.536 0.496 0.523\nUMUTeam 0.534 0.541 0.536\nBERTastic 0.530 0.518 0.526\nTheSyllogist 0.500 0.521 0.507\nQUST 0.486 0.366 0.446\nACCEPT 0.453 0.321 0.409\nRiga 0.444 0.430 0.439\nMaChAmp 0.438 0.330 0.402\nFTD 0.418 - -"}, {"source": "2023.semeval-1.317v1.pdf", "text": "MaChAmp 0.438 0.330 0.402\nFTD 0.418 - -\nBaseline 0.412 0.242 0.356\nFramingFreaks 0.383 0.316 0.361\nSinaAI 0.266 0.151 0.227\nDigDemLab 0.244 - -\nTable 13: Average micro score across language for the\nteams participating in all \u2018provided\u2019 six languages (6L),\nthe three surprise languages (3L), all nine languages\n(9L) for subtask 2.\nin the data annotation process, and we have been"}, {"source": "2023.semeval-1.317v1.pdf", "text": "excluding low-performing annotators. Despite all\nthis, we are aware that some degree of intrinsic\nsubjectivity will inevitably be present in the dataset\nand will eventually be learned by models trained\non it.\nAcknowledgments\nWe are greatly indebted to all the annotators from\ndifferent organisations, including, i.a., the Euro-\npean Commission, the European Parliament, the"}, {"source": "2023.semeval-1.317v1.pdf", "text": "University of Padua, and the Qatar Computing Re-\nsearch Institute, HBKU, who took part in the anno-team 6L 3L 9L\nKInITVeraAI 0.446 0.368 0.420\nTeamAmpa 0.420 0.343 0.395\nNAP 0.418 0.347 0.394\nQCRI 0.412 0.343 0.389\nSheffieldVeraAI 0.403 0.233 0.346\nAPatt 0.393 - -\nDSHacker 0.376 - -\nNLUBot101 0.376 0.236 0.329\nAPatt 0.374 0.268 0.338\nFTD 0.347 - -\nMaChAmp 0.341 0.264 0.315\nRiga 0.312 0.242 0.289"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Riga 0.312 0.242 0.289\nReDASPersuasion 0.307 - -\nkb 0.294 0.182 0.256\nBaseline 0.256 0.158 0.223\nUnedMediaBias 0.255 0.171 0.227\nCLaC 0.249 0.231 0.243\nQUST 0.151 0.091 0.131\nSinaAI 0.131 0.144 0.135\nTable 14: Average micro score across language for the\nteams participating in all \u2018provided\u2019 six languages (6L),\nthe three surprise languages (3L), all nine languages\n(9L) for subtask 3."}, {"source": "2023.semeval-1.317v1.pdf", "text": "(9L) for subtask 3.\ntations, and notably to the language curators whose\npatience and diligence have been fundamental for\nthe quality of the dataset. We are also thankful\nto Nikolaidis Nikolaos for the preparation of the\nbaseline models and for sharing various ideas.\nPart of this work was supported by IDKT Fund\nTDF 03-1209-210013: Tanbih: Get to Know What\nYou Are Reading .\nReferences"}, {"source": "2023.semeval-1.317v1.pdf", "text": "You Are Reading .\nReferences\nAhmed Al-Qarqaz and Malak Abdullah. 2023. Team\njustr00 at semeval-2023 task 3: Transformers for\nnews articles classification. In Proceedings of the\n17th International Workshop on Semantic Evaluation ,\npages 1213\u20131216, Toronto, Canada. Association for\nComputational Linguistics.\nFiroj Alam, Hamdy Mubarak, Wajdi Zaghouani, Gio-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "vanni Da San Martino, and Preslav Nakov. 2022.\nOverview of the WANLP 2022 shared task on pro-\npaganda detection in Arabic. In Proceedings of the\nSeventh Arabic Natural Language Processing Work-\nshop , Abu Dhabi, UAE.\nHamza Alami, Abdessamad Benlahbib, Abdelkader\nEl Mahdaouy, and Ismail Berrada. 2023. Um6p at\nsemeval-2023 task 3: News genre classification based"}, {"source": "2023.semeval-1.317v1.pdf", "text": "on transformers, graph convolution networks and\nnumber of sentences. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n856\u2013861, Toronto, Canada. Association for Compu-\ntational Linguistics.\nSergiu Amihaesei, Laura Cornei, and George Stoica.\n2023. Appeal for attention at semeval-2023 task 3:2352Data augmentation extension strategies for detection"}, {"source": "2023.semeval-1.317v1.pdf", "text": "of online news persuasion techniques. In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 616\u2013623, Toronto, Canada. Asso-\nciation for Computational Linguistics.\nMicaela Bangerter, Giuseppe Fenza, Mariacristina\nGallo, Vincenzo Loia, Alberto V olpe, Carmen De\nMaio, and Claudio Stanzione. 2023. Unisa at\nsemeval-2023 task 3: A shap-based method for pro-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "paganda detection. In Proceedings of the 17th Inter-\nnational Workshop on Semantic Evaluation , pages\n885\u2013891, Toronto, Canada. Association for Compu-\ntational Linguistics.\nKatarzyna Baraniak and M Sydow. 2023. Kb at semeval-\n2023 task 3: On multitask hierarchical bert base neu-\nral network for multi-label persuasion techniques de-\ntection. In Proceedings of the 17th International"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Workshop on Semantic Evaluation , pages 1395\u20131400,\nToronto, Canada. Association for Computational Lin-\nguistics.\nAdrien Barbaresi. 2021. Trafilatura: A Web Scrap-\ning Library and Command-Line Tool for Text Dis-\ncovery and Extraction. In Proceedings of the Joint\nConference of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th"}, {"source": "2023.semeval-1.317v1.pdf", "text": "International Joint Conference on Natural Language\nProcessing: System Demonstrations , pages 122\u2013131.\nAssociation for Computational Linguistics.\nAlberto Barr\u00f3n-Cedeno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864."}, {"source": "2023.semeval-1.317v1.pdf", "text": "56(5):1849\u20131864.\nRosina Baumann and Sabrina Deisenhofer. 2023. Fram-\ningfreaks at semeval-2023 task 3: Detecting the cate-\ngory and the framing of texts as subword units with\ntraditional machine learning. In Proceedings of the\n17th International Workshop on Semantic Evalua-\ntion, pages 922\u2013926, Toronto, Canada. Association\nfor Computational Linguistics."}, {"source": "2023.semeval-1.317v1.pdf", "text": "for Computational Linguistics.\nFabian Billert and Stefan Conrad. 2023. Hhu at semeval-\n2023 task 3: An adapter-based approach for news\ngenre classification. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n1166\u20131171, Toronto, Canada. Association for Com-\nputational Linguistics.\nDallas Card, Amber E. Boydstun, Justin H. Gross,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Philip Resnik, and Noah A. Smith. 2015. The Media\nFrames Corpus: Annotations of frames across issues.\nInProceedings of the 53rd Annual Meeting of the\nAssociation for Computational Linguistics and the\n7th International Joint Conference on Natural Lan-\nguage Processing , ACL-IJCNLP \u201915, pages 438\u2013444,\nBeijing, China.\nLoretta H Cheeks, Tracy L Stepien, Dara M Wald, and"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Ashraf Gaffar. 2020. Discovering news frames: An\napproach for exploring text, content, and concepts inonline news sources. In Cognitive Analytics: Con-\ncepts, Methodologies, Tools, and Applications , pages\n702\u2013721. IGI Global.\nAnton Chernyavskiy, Dmitry Ilvovsky, and Preslav\nNakov. 2021. Transformers: \u201cThe end of history\u201d\nfor NLP? In Proceedings of the European Confer-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ence on Machine Learning and Principles and Prac-\ntice of Knowledge Discovery in Databases , ECML-\nPKDD\u201921.\nJuan Cuadrado, Elizabeth Martinez, Anderson Morillo,\nDaniel Pe\u00f1a, Kevin Sossa, Juan Carlos Martinez-\nSantos, and Edwin Puertas. 2023. Utb-nlp at semeval-\n2023 task 3: Weirdness, lexical features for detecting\ncategorical framings, and persuasion in online news."}, {"source": "2023.semeval-1.317v1.pdf", "text": "InProceedings of the 17th International Workshop\non Semantic Evaluation , pages 1551\u20131557, Toronto,\nCanada. Association for Computational Linguistics.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\nNakov. 2020a. SemEval-2020 task 11: Detection\nof propaganda techniques in news articles. In Pro-\nceedings of the International Workshop on Semantic"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Evaluation , SemEval \u201920, Barcelona, Spain.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o, and\nPreslav Nakov. 2019. Findings of the NLP4IF-2019\nshared task on fine-grained propaganda detection. In\nProceedings of the Second Workshop on Natural Lan-\nguage Processing for Internet Freedom: Censorship,\nDisinformation, and Propaganda , NLP4IF \u201919, pages\n162\u2013170, Hong Kong, China."}, {"source": "2023.semeval-1.317v1.pdf", "text": "162\u2013170, Hong Kong, China.\nGiovanni Da San Martino, Stefano Cresci, Alberto\nBarr\u00f3n-Cede\u00f1o, Seunghak Yu, Roberto Di Pietro,\nand Preslav Nakov. 2020b. A survey on computa-\ntional propaganda detection. In Proceedings of the\nInternational Joint Conference on Artificial Intelli-\ngence , IJCAI-PRICAI \u201920, pages 4826\u20134832.\nGiovanni Da San Martino, Shaden Shaar, Yifan Zhang,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Seunghak Yu, Alberto Barr\u00f3n-Cedeno, and Preslav\nNakov. 2020c. Prta: A system to support the analysis\nof propaganda techniques in the news. In Proceed-\nings of the 58th Annual Meeting of the Association for\nComputational Linguistics: System Demonstrations,\nACL 2020, Online, July 5-10, 2020 , pages 287\u2013293.\nAssociation for Computational Linguistics.\nGiovanni Da San Martino, Seunghak Yu, Alberto"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Barron-Cedeno, Rostislav Petrov, and Preslav Nakov.\n2019. Fine-grained analysis of propaganda in news\narticles. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing ,\nEMNLP \u201919, pages 5636\u20135646, Hong Kong, China.\nNicolas Devatine, Philippe Muller, and Chlo\u00e9 Braud.\n2023. Melodi at semeval-2023 task 3: In-domain"}, {"source": "2023.semeval-1.317v1.pdf", "text": "pre-training for low-resource classification of news\narticles. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 108\u2013113,\nToronto, Canada. Association for Computational Lin-\nguistics.2353Dimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021a. De-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "tecting propaganda techniques in memes. In Pro-\nceedings of the Joint Conference of the 59th Annual\nMeeting of the Association for Computational Lin-\nguistics and the 11th International Joint Conference\non Natural Language Processing , ACL-IJCNLP \u201921,\npages 6603\u20136617.\nDimiter Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Nakov, and Giovanni Da San Martino. 2021b. Task\n6 at SemEval-2021: Detection of persuasion tech-\nniques in texts and images. In Proceedings of the\n15th International Workshop on Semantic Evalua-\ntion, SemEval \u201921, Bangkok, Thailand.\nRobert M Entman. 1993. Framing: Towards clarifica-\ntion of a fractured paradigm. McQuail\u2019s reader in\nmass communication theory , pages 390\u2013397."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Neele Falk, Annerose Eichel, and Prisca Piccirilli. 2023.\nNap at semeval-2023 task 3: Is less really more?\n(back-)translation as data augmentation strategies for\ndetecting persuasion techniques. In Proceedings of\nthe 17th International Workshop on Semantic Evalua-\ntion, pages 1433\u20131446, Toronto, Canada. Association\nfor Computational Linguistics.\nJennifer Golbeck, Matthew Mauriello, Brooke Aux-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ier, Keval H. Bhanushali, Christopher Bonk, Mo-\nhamed Amine Bouzaghrane, Cody Buntain, Riya\nChanduka, Paul Cheakalos, Jennine B. Everett,\nWaleed Falak, Carl Gieringer, Jack Graney, Kelly M.\nHoffman, Lindsay Huth, Zhenya Ma, Mayanka Jha,\nMisbah Khan, Varsha Kori, Elo Lewis, George Mi-\nrano, William T. Mohn IV , Sean Mussenden, Tam-\nmie M. Nelson, Sean Mcwillie, Akshat Pant, Priya"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Shetye, Rusha Shrestha, Alexandra Steinheimer,\nAditya Subramanian, and Gina Visnansky. 2018.\nFake news vs satire: A dataset and analysis. In Pro-\nceedings of the 10th ACM Conference on Web Sci-\nence, WebSci \u201918, page 17\u201321, Amsterdam, Nether-\nlands. Association for Computing Machinery.\nMaur\u00edcio Gruppi, Benjamin D. Horne, and Sibel Adali.\n2020. NELA-GT-2019: A large multi-labelled news"}, {"source": "2023.semeval-1.317v1.pdf", "text": "dataset for the study of misinformation in news arti-\ncles. arXiv , 2003.08444.\nIvan Habernal, Raffael Hannemann, Christian Pol-\nlak, Christopher Klamm, Patrick Pauli, and Iryna\nGurevych. 2017. Argotario: Computational argu-\nmentation meets serious games. In Proceedings of\nthe 2017 Conference on Empirical Methods in Nat-\nural Language Processing: System Demonstrations ,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "EMNLP \u201917, pages 7\u201312, Copenhagen, Denmark.\nIvan Habernal, Patrick Pauli, and Iryna Gurevych. 2018.\nAdapting serious game for fallacious argumentation\nto German: Pitfalls, insights, and best practices. In\nLREC . European Language Resources Association\n(ELRA).Maram Hasanain, Ahmed Oumar El-Shangiti, Ra-\nbindra Nath Nandi, Preslav Nakov, and Firoj Alam."}, {"source": "2023.semeval-1.317v1.pdf", "text": "2023. Qcri at semeval-2023 task 3: News genre,\nframing and persuasion techniques detection using\nmultilingual models. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n1237\u20131244, Toronto, Canada. Association for Com-\nputational Linguistics.\nPhilipp Heinisch, Moritz Plenz, Anette Frank, and\nPhilipp Cimiano. 2023. Accept at semeval-2023"}, {"source": "2023.semeval-1.317v1.pdf", "text": "task 3: An ensemble-based approach to multilingual\nframing detection. In Proceedings of the 17th Inter-\nnational Workshop on Semantic Evaluation , pages\n1347\u20131358, Toronto, Canada. Association for Com-\nputational Linguistics.\nBenjamin Horne and Sibel Adali. 2017. This just in:\nFake news packs a lot in title, uses simpler, repetitive\ncontent in text body, more similar to satire than real"}, {"source": "2023.semeval-1.317v1.pdf", "text": "news. arXiv , 1703.09398.\nKristina Hristakieva, Stefano Cresci, Giovanni\nDa San Martino, Mauro Conti, and Preslav Nakov.\n2022. The spread of propaganda by coordinated\ncommunities on social media. In Proceedings of the\n14th ACM Web Science Conference , WebSci \u201922,\npages 191\u2013201, Barcelona, Spain.\nTimo Hromadka, Timotej Smolen, Tomas Remis,\nBranislav Pecher, and Ivan Srba. 2023. Kinitveraai at"}, {"source": "2023.semeval-1.317v1.pdf", "text": "semeval-2023 task 3: Simple yet powerful multilin-\ngual fine-tuning for persuasion techniques detection.\nInProceedings of the 17th International Workshop\non Semantic Evaluation , pages 629\u2013637, Toronto,\nCanada. Association for Computational Linguistics.\nYe Jiang. 2023. Team qust at semeval-2023 task 3:\nA comprehensive study of monolingual and multi-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "lingual approaches for detecting online news genre,\nframing and persuasion techniques. In Proceedings\nof the 17th International Workshop on Semantic Eval-\nuation , pages 300\u2013306, Toronto, Canada. Association\nfor Computational Linguistics.\nArjun Khanchandani, Nitansh Jain, and Jatin Bedi. 2023.\nMlmodeler5 at semeval-2023 task 3: Detecting the\ncategory and the framing techniques in online news in"}, {"source": "2023.semeval-1.317v1.pdf", "text": "a multi-lingual setup. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n1096\u20131101, Toronto, Canada. Association for Com-\nputational Linguistics.\nJan-Christoph Klie, Michael Bugert, Beto Boullosa,\nRichard Eckart de Castilho, and Iryna Gurevych.\n2018. The inception platform: Machine-assisted and\nknowledge-oriented interactive annotation. In Pro-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ceedings of the 27th International Conference on\nComputational Linguistics: System Demonstrations ,\npages 5\u20139. Association for Computational Linguis-\ntics. Event Title: The 27th International Conference\non Computational Linguistics (COLING 2018).\nYuta Koreeda, Ken-ichi Yokote, Hiroaki Ozaki, Atsuki"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Yamaguchi, Masaya Tsunokake, and Yasuhiro So-2354gawa. 2023. Hitachi at semeval-2023 task 3: Explor-\ning cross-lingual multi-task strategies for genre and\nframing detection in online news. In Proceedings of\nthe 17th International Workshop on Semantic Evalua-\ntion, pages 1702\u20131711, Toronto, Canada. Association\nfor Computational Linguistics.\nHaewoon Kwak, Jisun An, and Yong-Yeol Ahn. 2020."}, {"source": "2023.semeval-1.317v1.pdf", "text": "A systematic media frame analysis of 1.5 million\nNew York Times articles from 2000 to 2017. In\nProceedings of the 12th ACM Conference on Web\nScience , WebSci \u201920, pages 305\u2013314, Southampton,\nUnited Kingdom.\nMikhail Lepekhin and Serge Sharoff. 2023. Ftd at\nsemeval-2023 task 3: News genre and propaganda de-\ntection by comparing mono- and multilingual models"}, {"source": "2023.semeval-1.317v1.pdf", "text": "with fine-tuning on additional data. In Proceedings of\nthe 17th International Workshop on Semantic Evalu-\nation , pages 549\u2013555, Toronto, Canada. Association\nfor Computational Linguistics.\nQisheng Liao, Meiting Lai, and Preslav Nakov. 2023.\nMarseclipse at semeval-2023 task 3: Multi-lingual\nand multi-label framing detection with contrastive\nlearning. In Proceedings of the 17th International"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Workshop on Semantic Evaluation , pages 83\u201387,\nToronto, Canada. Association for Computational Lin-\nguistics.\nGenglin Liu, Yi Fung, and Heng Ji. 2023. Nlubot101 at\nsemeval-2023 task 3: An augmented multilingual nli\napproach towards online news persuasion techniques\ndetection. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 1636\u20131643,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Toronto, Canada. Association for Computational Lin-\nguistics.\nSiyi Liu, Lei Guo, Kate Mays, Margrit Betke, and\nDerry Tanti Wijaya. 2019. Detecting frames in news\nheadlines and its application to analyzing news fram-\ning trends surrounding US gun violence. In Proceed-\nings of the 23rd Conference on Computational Natu-\nral Language Learning , CoNLL \u201919, pages 504\u2013514,\nHong Kong, China."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Hong Kong, China.\nTarek Mahmoud and Preslav Nakov. 2023. Bertastic at\nsemeval-2023 task 3: Fine-tuning pretrained multilin-\ngual transformers \u2013 does order matter? In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 58\u201363, Toronto, Canada. Associa-\ntion for Computational Linguistics.\nArkadiusz Modzelewski, Witold Sosnowski, Magdalena"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Wilczynska, and Adam Wierzbicki. 2023. Dshacker\nat semeval-2023 task 3: Genres and persuasion tech-\nniques detection with multilingual data augmenta-\ntion through machine translation and text generation.\nInProceedings of the 17th International Workshop\non Semantic Evaluation , pages 1582\u20131591, Toronto,\nCanada. Association for Computational Linguistics."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Osama Mohammed Afzal and Preslav Nakov. 2023.\nTeam thesyllogist at semeval-2023 task 3: Language-\nagnostic framing detection in multi-lingual onlinenews: A zero-shot transfer approach. In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 2058\u20132061, Toronto, Canada. As-\nsociation for Computational Linguistics.\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Da San Martino, and Yifan Zhang. 2021a. COVID-\n19 in Bulgarian social media: Factuality, harmfulness,\npropaganda, and framing. In Proceedings of the Inter-\nnational Conference on Recent Advances in Natural\nLanguage Processing , RANLP \u201921.\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni\nDa San Martino, and Yifan Zhang. 2021b. A second\npandemic? Analysis of fake news about COVID-19"}, {"source": "2023.semeval-1.317v1.pdf", "text": "vaccines in Qatar. In Proceedings of the International\nConference on Recent Advances in Natural Language\nProcessing , RANLP \u201921.\nJeppe N\u00f8rregaard, Benjamin D. Horne, and Sibel Adali.\n2019. NELA-GT-2018: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. In Proceedings of the Thirteenth International\nConference on Web and Social Media , ICWSM \u201919,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "pages 630\u2013638, Munich, Germany. AAAI Press.\nRonghao Pan, Jos\u00e9 Antonio Garc\u00eda-D\u00edaz, Miguel \u00c1n-\ngel Rodr\u00edguez-Garc\u00eda, and Rafael Valencia-Garc\u00eda.\n2023. Umuteam at semeval-2023 task 3: Multilin-\ngual transformer-based model for detecting the genre,\nthe framing, and the persuasion techniques in on-\nline news. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 609\u2013615,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Toronto, Canada. Association for Computational Lin-\nguistics.\nAmalie Pauli, Rafael Pablos Sarabia, Leon Derczynski,\nand Ira Assent. 2023. Teamampa at semeval-2023\ntask 3: Exploring multilabel and multilingual roberta\nmodels for persuasion and framing detection. In Pro-\nceedings of the 17th International Workshop on Se-\nmantic Evaluation , pages 847\u2013855, Toronto, Canada."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Association for Computational Linguistics.\nJakub Piskorski, Nicolas Stefanovitch, Valerie-Anne\nBausier, Nicolo Faggiani, Jens Linge, Sopho Kharazi,\nNikolaos Nikolaidis, Giulia Teodori, Bertrand\nDe Longueville, Brian Doherty, Jason Gonin,\nCamelia Ignat, Bonka Kotseva, Eleonora Mantica,\nLorena Marcaletti, Enrico Rossi, Alessio Spadaro,\nMarco Verile, Giovanni Da San Martino, Firoj Alam,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "and Preslav Nakov. 2023. News categorization, fram-\ning and persuasion techniques: Annotation guide-\nlines. Technical Report JRC-132862, European Com-\nmission Joint Research Centre, Ispra (Italy).\nAlbert Pritzkau. 2023. Nl4ia at semeval-2023 task 3:\nA comparison of sequence classification and token\nclassification to detect persuasive techniques. In Pro-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ceedings of the 17th International Workshop on Se-\nmantic Evaluation , pages 794\u2013799, Toronto, Canada.\nAssociation for Computational Linguistics.\nAntonio Purificato and Roberto Navigli. 2023. Apatt\nat semeval-2023 task 3: The sapienza nlp system for2355ensemble-based multilingual propaganda detection.\nInProceedings of the 17th International Workshop"}, {"source": "2023.semeval-1.317v1.pdf", "text": "on Semantic Evaluation , pages 382\u2013388, Toronto,\nCanada. Association for Computational Linguistics.\nFatima Zahra Qachfar and Rakesh Verma. 2023.\nRedaspersuasion at semeval-2023 task 3: Persua-\nsion detection using multilingual transformers and\nlanguage agnostic features. In Proceedings of the\n17th International Workshop on Semantic Evaluation ,\npages 2124\u20132132, Toronto, Canada. Association for"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Computational Linguistics.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and politi-\ncal fact-checking. In Proceedings of the Conference\non Empirical Methods in Natural Language Process-\ning, EMNLP \u201917, pages 2931\u20132937, Copenhagen,\nDenmark.\nMarkus Reiter-Haas, Alexander Ertl, Kevin Innerhofer,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "and Elisabeth Lex. 2023. mcpt at semeval-2023 task\n3: Multilingual label-aware contrastive pre-training\nof transformers for few- and zero-shot framing de-\ntection. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 941\u2013949,\nToronto, Canada. Association for Computational Lin-\nguistics.\nFrancisco-Javier Rodrigo-Gin\u00e9s, Laura Plaza, and Jorge"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Carrillo-de Albornoz. 2023. Unedmediabiasteam\n@ semeval-2023 task 3: Can we detect persuasive\ntechniques transferring knowledge from media bias\ndetection? In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 787\u2013793,\nToronto, Canada. Association for Computational Lin-\nguistics.\nAryan Sadeghi, Reza Alipour, Kamyar Taeb, Parimehr"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Morassafar, Nima Salemahim, and Ehsaneddin As-\ngari. 2023. Sinaai at semeval-2023 task 3: A multilin-\ngual transformer language model-based approach for\nthe detection of news genre, framing and persuasion\ntechniques. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 2168\u20132173,\nToronto, Canada. Association for Computational Lin-\nguistics."}, {"source": "2023.semeval-1.317v1.pdf", "text": "guistics.\nHarsh Verma and Sabine Bergler. 2023. Clac at\nsemeval-2023 task 2: Comparing span-prediction and\nsequence-labeling approaches for ner. In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 1558\u20131561, Toronto, Canada. As-\nsociation for Computational Linguistics.\nBen Wu, Olesya Razuvayevskaya, Freddy Heppell,\nJo\u00e3o Leite, Carolina Scarton, Kalina Bontcheva, and"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Xingyi Song. 2023. Sheffieldveraai at semeval-2023\ntask 3: Mono and multilingual approaches for news\ngenre, topic and persuasion technique classification.\nInProceedings of the 17th International Workshop\non Semantic Evaluation , pages 1995\u20132008, Toronto,\nCanada. Association for Computational Linguistics.Seunghak Yu, Giovanni Da San Martino, Mitra Mo-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "htarami, James Glass, and Preslav Nakov. 2021. In-\nterpretable propaganda detection in news articles.\nInProceedings of the International Conference on\nRecent Advances in Natural Language Processing ,\nRANLP \u201921, pages 1597\u20131605.\nYifan Zhang, Giovanni Da San Martino, Alberto Barr\u00f3n-\nCede\u00f1o, Salvatore Romeo, Jisun An, Haewoon Kwak,\nTodor Staykovski, Israa Jaradat, Georgi Karadzhov,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Ramy Baly, Kareem Darwish, James Glass, and\nPreslav Nakov. 2019. Tanbih: Get to know what\nyou are reading. In Proceedings of the Conference\non Empirical Methods in Natural Language Process-\ning and the 9th International Joint Conference on\nNatural Language Processing: System Demonstra-\ntions , EMNLP-IJCNLP \u201919, pages 223\u2013228, Hong\nKong, China.\nA Supplementary Corpus Information\nA.1 Statistics"}, {"source": "2023.semeval-1.317v1.pdf", "text": "A.1 Statistics\nThis section contains additional statistical informa-\ntion related to the corpus.\nTable 15 provides the statistics for genre for all\nlanguages. One can observe that opinion andsatire\nare the most and least populated classes across the\nlanguages respectively.\nAnalogously, Table 16 shows the number of dif-\nferent framing dimensions per language. Political"}, {"source": "2023.semeval-1.317v1.pdf", "text": "andSecurity and Defense framings constitute the\ntwo most frequent ones across all languages. The\ndistribution of the different framings varies across\nthe languages though.\nFinally, Table 17 reports the exact count of fine-\ngrained persuasion techniques per language for\nthe entire dataset. The two most frequent tech-\nniques irrespective of the language are Loaded"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Language andName Calling-Labelling , which ac-\ncount for 18.5% and 23.7% of the dataset, trump-\ning by several order of magnitude the lower popu-\nlated classes. They are followed by Casting Doubt\n(12.5%), Questioning the Reputation (7.6%), Ap-\npeal to Fear-Prejudice (4.8%), and Exageration-\nMinimisation (4.7%). These six classes together\nrepresent 71.8% of the entire dataset."}, {"source": "2023.semeval-1.317v1.pdf", "text": "represent 71.8% of the entire dataset.\nB Participant Systems\nIn the following we list the systems of all partic-\nipants who submitted a system description paper.\nThe team name used for the submission is in bold;\nin case the team used a different name on the leader-\nboard, it is appended in parentheses; the list of sub-\ntasks the team participated in is also given in brack-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ets; in case the team was ranked first for at least2356opinion reporting satire\nEnglish 434 112 24\nFrench 175 65 21\nGerman 148 48 31\nItalian 274 72 18\nPolish 174 44 23\nRussian 170 73 20\nGeorgian 19 10 0\nGreek 39 22 3\nSpanish 14 9 7\nALL 1447 455 147\nTable 15: Statistics for the genre labels for all languages\nand the entire dataset.\na subtask-language pair, the list of all such pairs"}, {"source": "2023.semeval-1.317v1.pdf", "text": "where it is ranked first is given; a list of keywords;\nand finally, a short description of the system.\nACCEPT [ST2] (Heinisch et al., 2023) (Key-\nwords: XLM-RoBERTa, ConceptNet ) They used an\nensemble combining XLM-RoBERTa with static\nmultilingual and monolingual word embeddings;\nfor the latter, they translated the non-English-texts\nto English using Google Translate. They further"}, {"source": "2023.semeval-1.317v1.pdf", "text": "experimented with external common sense knowl-\nedge graphs, specifically ConceptNet.\nAPatt [ST3] (Purificato and Navigli, 2023) (first\nfor: ST3:EN) (Keywords: XLNet, RoBERTa, BERT,\nALBERT, DeBERTa ) They used an ensemble of\npre-trained language models fine-tuned on the pro-\npaganda dataset: BERT, RoBERTa, ALBERT, XL-\nNet, DistilBERT, and HerBERT. Whenever more"}, {"source": "2023.semeval-1.317v1.pdf", "text": "LLMs for the same language were available, their\noutput is combined through a weighted average.\nAppeal for attention (AppealForAtt) [ST3]\n(Amihaesei et al., 2023) (Keywords: XLM-\nRoBERTa-Large, WordNet, data augmentation )\nThey focused on data augmentation techniques.\nThey translated the datasets from each language\ninto all other languages using the DeepTranslator"}, {"source": "2023.semeval-1.317v1.pdf", "text": "API, and they extracted synonyms from WordNet\nto generate new sentences. Finally, they trained\nXLM-RoBERTa-large on that augmented data.\nBERTastic [ST2] (Mahmoud and Nakov, 2023)\n(Keywords: mBERT, XLM-RoBERTa ) They used\ncross-lingual transformers, mBERT and XLM-\nRoBERTa, using different orderings of the lan-\nguages when doing fine-tuning. They further used"}, {"source": "2023.semeval-1.317v1.pdf", "text": "test data augmentation via translation of both the\ntraining and the test sets. CLaC (CLAC) [ST3]\n(Verma and Bergler, 2023) (Keywords) RoBERTa\naugmented the dataset translating examples from\nother languages, focusing on articles having least\nrepresented techniques in order to balance thedataset. They used a RoBERTa-base model trained\non the English language and made predictions on"}, {"source": "2023.semeval-1.317v1.pdf", "text": "the other languages by first translating the text into\nEnglish. They report better F 1scores with such\napproach on French and German than using Large\nLanguage Models trained directly on the target lan-\nguage.\nDSHacker [ST1, ST3] (Modzelewski\net al., 2023) (first for: ST1:ES) (Keywords:\nXLMRoBERTa-large, GPT3-Davinci, sequence\nclassification, text generation, Ensemble Learning,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "XGBoost, Logistic Regression, LightGBM, BERT,\nData Augmentation, Summarization ) created,\nfor ST1, synthetic texts for each class using the\nOpenAI GPT-3 Davinci language model. Each\nlanguage was augmented by approximately 500\narticles per genre, producing roughly 13,500\nartificially generated articles. Single XLM-\nRoBERTa-large model was trained using the\noriginal and augmented data. For ST3 they"}, {"source": "2023.semeval-1.317v1.pdf", "text": "developed for Polish an ensemble consisting of\nthree one-vs-rest classifiers: eXtreme Gradient\nBoosting, Logistic Regression and Light Gradient-\nBoosting Machine with HerBERT embeddings\nand various stylometric features using StyloMetrix\nlibrary. For all other languages BERT-based\npre-trained models were deployed and they used\nsummarization applied to longer paragraphs."}, {"source": "2023.semeval-1.317v1.pdf", "text": "Furthermore, training data was augmented through\nmachine translation utilizing the DeepL API.\nFramingFreaks [ST1, ST2] (Baumann and\nDeisenhofer, 2023) (Keywords: SVM, Logistic Re-\ngression ) classified texts by splitting them into sub-\nwords and then using these tokens as input to a\nSupport Vector Machines for ST1 and to Logistic\nregression for ST2.\nFTD [ST1, ST2, ST3] (Lepekhin and Sharoff,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "2023) (first for: ST1:PL) (Keywords: SLM-\nRoBERTa, multilingual BERT, Electra, monolin-\ngual BERT-based models, fine-tuning, uncertainty\nestimation, ensembles ) focused on ST1, where they\nexperimented with monolingual and multilingual\nmodels, ensembles, additional data, and uncertainty\nestimation. For Russian and English, they fine-\ntuned models pre-trained on the FTD dataset for"}, {"source": "2023.semeval-1.317v1.pdf", "text": "genre classification. For English, they added 1,000\nreporting texts from Gigaword. For Polish and Ger-\nman, their best results were achieved by fine-tuning\na monolingual Polish BERT and a monolingual\nGerman Electra, respectively. For the other lan-\nguages, their best systems used multilingual BERT,2357Framing English French German Italian Polish Russian Georgian Greek Spanish ALL"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Capacity and resources 56 62 104 120 88 34 1 10 11 486\nCrime and punishment 274 22 44 57 57 51 3 11 4 523\nCultural identity 42 34 46 43 48 13 1 8 0 235\nEconomic 74 79 108 142 144 68 2 14 4 635\nExternal regulation and reputation 214 85 91 132 86 44 9 9 3 673\nFairness and equality 131 30 35 52 39 21 0 8 2 318\nHealth and safety 86 60 107 97 144 37 4 8 3 546"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Legality, Constitutionality, jurisprudence 281 41 65 73 56 44 0 23 7 590\nMorality 231 62 39 62 63 31 2 5 7 502\nPolicy prescription and evaluation 154 38 70 129 110 15 2 12 7 537\nPolitical 343 108 130 178 144 55 10 43 6 1017\nPublic opinion 68 34 50 58 74 22 4 10 3 323\nQuality of life 115 40 53 89 85 32 0 5 3 422\nSecurity and defense 222 89 121 155 105 90 10 19 10 821"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Table 16: Statistics for the framing labels for all languages and the entire dataset.\nPersuasion technique English French German Italian Polish Russian Georgian Greek Spanish ALL\nName Calling-Labeling 1,945 903 2,818 1,470 1,391 483 42 37 42 9,131\nGuilt by Association 84 210 216 98 234 59 4 8 12 925\nDoubt 887 679 606 2,295 574 957 40 129 37 6,204"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Appeal to Hypocrisy 82 220 307 149 329 167 1 77 14 1,346\nQuestioning the Reputation 162 662 837 819 555 598 23 35 66 3,757\nFlag Waving 434 87 100 72 176 152 3 19 6 1,049\nAppeal to Values 47 219 163 264 246 93 6 26 14 1,078\nAppeal to Popularity 76 149 119 79 86 38 0 7 11 565\nAppeal to Fear-Prejudice 554 443 339 589 245 135 1 12 41 2,359\nAppeal to Authority 207 175 377 118 133 22 2 5 6 1,045"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Causal Oversimplification 265 228 62 88 22 65 2 29 9 770\nFalse Dilemma, No Choice 241 169 55 149 28 59 2 10 22 735\nConsequential Oversimplification 21 215 50 53 47 110 8 33 7 544\nStrawman 64 242 27 111 25 46 2 13 6 536\nRed Herring 97 72 52 48 23 6 10 19 4 331\nWhataboutism 25 93 33 11 22 17 0 13 7 221\nConversation Killer 176 352 235 468 126 172 12 24 26 1,591"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Slogans 234 230 176 122 64 113 3 15 16 973\nAppeal to Time 4 71 33 53 24 41 0 3 8 237\nLoaded Language 3,467 2,533 604 2,878 654 1,347 26 88 134 11,731\nObfuscation-Vagueness-Confusion 37 185 108 42 66 62 6 34 9 549\nExaggeration-Minimisation 730 527 307 261 197 225 5 37 35 2,324\nRepetition 938 198 17 75 48 115 20 18 14 1,443"}, {"source": "2023.semeval-1.317v1.pdf", "text": "Table 17: Statistics for the fine-grained persuasion techniques for all languages and the entire dataset.\nXLM-RoBERTa, or ensembles thereof. In all cases,\nthey truncated the input to the first 510 tokens.\nThey further upsampled the data to balance the\ndistribution between the classes (the results with-\nout upsampling were low). For English they fur-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ther, experimented with uncertainty estimation, and\nshowed that replacing the model predictions that\nhave high uncertainty with the majority class on the\ntraining data was helpful on the dev set. For ST2,\nfor each language, they used the model and the\nsetup that worked best for ST1, and just retrained\nit on the ST2 data.\nHHU [ST1] (Billert and Conrad, 2023): (Key-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "words: XLM-RoBERTa, Adapters, AdapterFusion )\nused an Adapter-based configuration: Using XLM-RoBERTa as a base, they stacked first a language-\nspecific adapter and then a task-specific adapter on\ntop of it. Moreover, they augmented each dataset\nby translating the articles from the datasets in the\nother languages.\nHitachi [ST1, ST2] (Koreeda et al., 2023) (first"}, {"source": "2023.semeval-1.317v1.pdf", "text": "for: ST1:IT, ST1:RU) (Keywords: XLM-RoBERTa,\nRoBERTa ) augmented the dataset for ST1 by col-\nlecting labelled examples from similar datasets.\nThey pretrained (XLM-)RoBERTa in multi-task\n(one language, ST1 and ST2), multilingual (one\nsubtask, all languages) and multilingual multi-task\n(ST1 and ST2 in all languages) settings. Besides\nusing the single models, they report experiments"}, {"source": "2023.semeval-1.317v1.pdf", "text": "with ensemble of base models with different hyper-2358parameters.\nJUSTR00 [ST1, ST2] (Al-Qarqaz and Abdullah,\n2023): (Keywords: LongFormer, BERT, RoBERTa,\nmBERT, XLM-RoBERTa, BigBird experimented\nwith many state-of-the-art transformer-based lan-\nguage models, both monolingual and multilingual.\nTheir top performing model is based on a trans-\nformer called \u201cLongformer\u201d."}, {"source": "2023.semeval-1.317v1.pdf", "text": "former called \u201cLongformer\u201d.\nkb[ST1, ST3] (Baraniak and Sydow, 2023)\n(Keywords: BERT, Bert, hierarchical learning,\nmultitask learning ) tackled ST3 by training a BERT\nmodel to identify the start of a text fragment with a\ntechnique, then the first index of predicted span was\nused to get the BERT embedding for classification.\nKInITVeraAI (KInIT) [ST3] (Hromadka et al.,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "2023): (first for: ST3:IT, ST3:RU, ST3:DE,\nST3:PL, ST3:EL, ST3:KA) (Keywords: XLM-\nRoBERTa large and base, mBERT base, monolin-\ngual RoBERTa base and large, monolingual BERT\nbase, distilBERT, language model fine-tuning with\ndifferent layer freezing strategies ) used a fine-tuned\nXLM-RoBERTa-large transformer model trained\non all the input data. They carefully adjusted the"}, {"source": "2023.semeval-1.317v1.pdf", "text": "prediction threshold for each language using a prin-\ncipled approach. They truncated the input, and also\nfound that pre-processing did not impact the quality\nmuch.\nMarsEclipse [ST2] (Liao et al., 2023): (first for:\nST2:IT, ST2:RU, ST2:FR, ST2:DE, ST2:PL) (Key-\nwords: XLM-RoBERTa, mBERT, SimCSE, Sim-\nCLR) used a multi-label contrastive loss for fine-\ntuning pre-trained language models in a multi-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "lingual setting. They followed the general archi-\ntecture of SimCLR and SimCSE to do contrastive\nlearning, but modified the contrastive loss to make\nit fit for a multi-label setup. This yielded very com-\npetitive results for ST2, and this was the winning\nsystem for five of the languages.\nmCPT (PolarIce) [ST2] (Reiter-Haas et al.,\n2023) (first for: ST2:ES) (Keywords: paraphrase-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "multilingual-MiniLM-L12-v2, contrastive pre-\ntraining ) used a two-phase training procedure of a\ntransformer model, first by pre-training jointly on\nall the languages and then by fine-tuning for each\nlanguage. In both phases, a multi-label contrastive\nloss was used.\nMELODI [ST1] (Devatine et al., 2023): (first\nfor: ST1:EN) (Keywords: Translation + POLI-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "TICS (RoBERTa) ) fine-tuned the domain-specific\nlanguage model trained on English data, POLI-\nTICS, on the English input articles and on the arti-cles in all other languages automatically translated.\nIn addition, in order to use whole articles as input,\nthey used a sliding window approach and aggre-\ngated each window representation with mean pool-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "ing. They also tested other multilingual approaches,\nsuch as XLM-RoBERTa, and approaches able to\nprocess long documents (Longformer), which were\nin general less effective.\nMLModeler5 [ST1, ST2] (Khanchandani et al.,\n2023) (Keywords: RoBERTa, ALBERT ) provided a\nsolution for English only. For ST1 they pre-trained\nthe RoBERTa, ALBERT and other deep learning"}, {"source": "2023.semeval-1.317v1.pdf", "text": "models using the original training data in English\nand translated versions of the data in other lan-\nguages and performed NLP augmentation using\nNLPAUG library on it. For ST2 a similar-in-nature\napproach was used.\nNAP [ST3] (Falk et al., 2023) (first for: ST3:FR)\n(Keywords: XLM-RoBERTa (base and large),\nsetfit, adapters, translation and backtranslation"}, {"source": "2023.semeval-1.317v1.pdf", "text": "of paragraphs ) presented an approach combin-\ning predictions of several models in an ensem-\nble, which differ in three main aspects: a) train-\ning data, b) model architecture, and c) input\nformat to the model. They leveraged (back-\n)translation as data augmentation strategies using\navailable MarianMT models. Model architectures\nincluded XLM-RoBERTa models, Adapters, SetFit,"}, {"source": "2023.semeval-1.317v1.pdf", "text": "and linguistically-informed heuristics for under-\nrepresented techniques which were fine-tuned on\ndifferent combinations of original and augmented\ndata. They fine-tuned models on both paragraph-\nand span-level information.\nNL4IA [ST3] (Pritzkau, 2023) (Keywords:\nRoBERTa ) used RoBERTa and exploited the span\nlevel annotations framing ST3 as a token-level clas-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "sification one, but report better results when treat-\ning the subtask as a sequence classification one.\nNLUBot101 [ST1,ST3] (Liu et al., 2023) (Key-\nwords: mDeBERTa ) built, for ST3, a solution on\ntop of mDeBERTa NLI model and exploit cross-\nlingual data augmentation. The performance could\nbe improved through the exploitation of the ex-\npanded definitions of the persuasion technique"}, {"source": "2023.semeval-1.317v1.pdf", "text": "guidelines from the official annotation guidelines\nvis-a-vis the usage of single words or phrases.\nTheir system achieved the highest macro F1score\nfor the English language.\nQCRI (QCRITeam) [ST1, ST2, ST3] (Hasanain\net al., 2023) (Keywords: XLM-RoBERTa, French\nEuropeana BERT, Gottbert-base, Italian BERT,2359HerBERT ) used, for all subtasks, data augmenta-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "tion and then fine-tuned a BERT model specifically\nfor each language, in addition to fine-tuning XLM-\nRoBERTa on all languages at once.\nQUST [ST1,ST2,ST3] (Jiang, 2023): (Key-\nwords) XLM-RoBERTa Their model is build on top\nof XLM-RoBERTa, which is fine-tuned with the\npre-calculated class weights and sample weights\nto combat the imbalanced data. The class weights"}, {"source": "2023.semeval-1.317v1.pdf", "text": "are multiplied by the loss to make the model focus\nmore on the minority class. The sample weights are\ncombined with a weighted sampler to resample the\ndistribution of the training batch. In addition, two\ntypes of fine-tuning strategies, the task-agnostic\nand the task-dependent, where the latter proved\nto help the multilingual model to learn the shared"}, {"source": "2023.semeval-1.317v1.pdf", "text": "information between subtasks. The submitted sys-\ntem achieves the second best result for Italian and\nSpanish (zero-shot) in ST1.\nReDASPersuasion [ST3] (Qachfar and Verma,\n2023) (Keywords: XLM-RoBERTa ) uses XLM-\nRoBERTa as a backbone model, incorporating lan-\nguage agnostic features, computed over the articles\ntranslated using Google translation. Such features"}, {"source": "2023.semeval-1.317v1.pdf", "text": "target specific techniques, including sentiment- and\npolarity- based features targeting appeal to fear and\nslogans, indefinite pronouns indicative of exagger-\nation and minimisation, a profanity language detec-\ntion to capture loaded language. XLM-RoBERTa\nhas been proved to be a powerful multilingual pre-\ntrained language model compared against other\nmodels like Multilingual BERT (M-BERT)."}, {"source": "2023.semeval-1.317v1.pdf", "text": "models like Multilingual BERT (M-BERT).\nSheffieldVeraAI (vera) [ST1, ST2, ST3] (Wu\net al., 2023) (first for: ST1: DE, ST2:EN, ST2:EL,\nST2:KA) (Keywords: mBERT, adapters, text pre-\nprocessing, upsampling, XLM-Roberta, Pfeiffer\nAdapters, MUPPET, Task-adaptive Pre-training,\nRoBERTa, class weighting ) deployed an ensem-\nble of three fine-tuned mBERT models and one"}, {"source": "2023.semeval-1.317v1.pdf", "text": "mBERT model with a bottleneck adapter for ST1.\nAll used bert-base-multilingual-cased. For the fine-\ntuned mBERT models, they pre-processed the data\nby filtering out non-informative sentences. The\npool of training data was also extended by integra-\ntion additional \u201csatire\u201d resources for English. In\nthe cases where the length of the tokenised arti-\ncle was more than 512 tokens, an equal number of"}, {"source": "2023.semeval-1.317v1.pdf", "text": "sentences from the beginning and the end of the\narticle was selected until the size of 512 tokens in a\nconcatenated text is reached. The final predictions\nwere drawn as a majority-voting predicted classFor ST2 they used two different ensembles of\nMUPPET large, and of XLM-R with adapters\nand task-adaptive MLM pre-training on the\ntrain+dev+test data. Their data was pre-processed"}, {"source": "2023.semeval-1.317v1.pdf", "text": "and truncated. The models were trained both with\nand without class weighting.\nFor ST3 they trained a monolingual RoBERTa-\nBase model for English and a multilingual mBERT-\ncased model for the remaining languages. They\nused class weighting to account for class imbal-\nance. They also experimented with augmenting\ndata through translation, which improved the per-\nformance for the surprise languages."}, {"source": "2023.semeval-1.317v1.pdf", "text": "formance for the surprise languages.\nSinaAI (SinaaAI) [ST1, ST2, ST3] (Sadeghi\net al., 2023) (first for: ST1:EL) (Keywords: XLM,\nmBERT, LaBSE ) used multilingual languages mod-\nels such as XLM, mBERT and LaBSE, which they\ncombined in an ensemble. For ST1 and ST2, they\nfurther used data augmentation by selecting 30%\nof the sentences of each document to create new\nsynthetic examples."}, {"source": "2023.semeval-1.317v1.pdf", "text": "synthetic examples.\nTeamAmpa [ST2, ST3] (Pauli et al., 2023) (first\nfor: ST3:ES) (Keywords: RoBERTa, XML-R, en-\nsemble models) used different oversampling strate-\ngies, data truncation, and multilingual and mono-\nlingually trained models, combined in an ensem-\nble for the English data. The surprise languages\nwere handled using the multilingual model with"}, {"source": "2023.semeval-1.317v1.pdf", "text": "oversampling on English data and data from low-\nrepresented classes.\nTheSyllogist [ST2] (Mohammed Afzal and\nNakov, 2023): (Keywords: BERT ) participated\nin ST2, and experimented with zero-shot transfer:\ntranslating the data for all languages into English\n(using Google Translate), and then training and ap-\nplying an English system. They used fine-tuned\nBERT (bert-base-uncased) with mean-pooling."}, {"source": "2023.semeval-1.317v1.pdf", "text": "UM6P [ST1, ST3] (Alami et al., 2023): (Key-\nwords: Longformer, RoBERTa, GCN ) fine-tuned\nLongformer and RoBERTa transformers for both\nST1 and ST3. They further added a graph convolu-\ntion network, and a classifier based on the number\nof sentences in each document. Finally, they used\nan ensemble to combine the predictions of these\nmodels.\nUMUTeam [ST1, ST2] (Pan et al., 2023) (first"}, {"source": "2023.semeval-1.317v1.pdf", "text": "for: ST1:FR, ST1:DE) (Keywords: Sentence\ntransformers, XML-RoBERTa ) used a multilingual\nmodel based on XML-RoBERTa, which they fine-\ntuned on all languages at once and a sentence trans-\nformer to extract the most important chunk of text2360for ST1 and ST2. They further truncated the input\ndata to 200 tokens with 50 tokens of overlap using\nthe sentence-transformer model to obtain the subset"}, {"source": "2023.semeval-1.317v1.pdf", "text": "of text most related to the article title.\nUnedMediaBiasTeam [ST1, ST3] (Rodrigo-\nGin\u00e9s et al., 2023) (Keywords: XLM-RoBERTa,\nbert-base-multilingual-cased ) solutions are based\non two-stage fine-tuned multilingual models. For\nST1 they exploit the media bias detection datasets\ncalled BABE and MBIC and XLM-RoBERTa\nmodel fine-tuned in two stages: first with the BABE"}, {"source": "2023.semeval-1.317v1.pdf", "text": "and MBIC datasets, and later with the data pro-\nvided for the task. For ST3 a similar approach is\ndeployed, where instead of training a single model\nin two phases, two models are trained and the cas-\ncading inference is carried out.\nUnisa [ST1, ST3] (Bangerter et al., 2023) (Key-\nwords: DistilBert, SHAP ) built solutions on top\nof DistilBert and leverage the application of the"}, {"source": "2023.semeval-1.317v1.pdf", "text": "eXplainable Artificial Intelligence (XAI) method,\nShapley Additive Explanations (SHAP). In ST1,\ndata augmentation was exploited through transla-\ntion data to the target language (English) on top\nof which the model was trained with only the first\n512 tokens of the articles being considered as input\nto the model. SHAP was used to understand what\nwas driving the model to fail so that it could be"}, {"source": "2023.semeval-1.317v1.pdf", "text": "improved.\nIn ST3, a re-calibration of the Attention Mech-\nanism is realized by extracting critical tokens for\neach technique. XAI is exploited for countering the\noverfitting of the resulting model and attempting to\nimprove the performance when there are few train-\ning samples. First, a binary model first processes\na new incoming paragraph to predict whether it"}, {"source": "2023.semeval-1.317v1.pdf", "text": "contains any persuasion attempt. If the text is pre-\ndicted to be propaganda, it is compared with SHAP\nV ocabularies previously created, which represent\nthe most important words associated with each per-\nsuasion technique. Such comparison defines the ad-\nditional input to pass to the final multi-class model\ntrained to focus on the span that identifies the text"}, {"source": "2023.semeval-1.317v1.pdf", "text": "that characterizes the persuasion technique.\nUTB-NLP (UTBNLP) [ST1, ST2] (Cuadrado\net al., 2023) (Keywords: ) used a feature-based\nrepresentation: they extracted noun phrases and\nrepresented them as tf-idf vectors; they consid-\nered several features specific for each of the three\nclasses of ST1, such as psycholinguistic, writing\nstyle, readability, structural characteristics, concep-"}, {"source": "2023.semeval-1.317v1.pdf", "text": "tual embeddings and argumentation-based features.In addition, they used SMOTE to oversample the\nminority classes.\nST2 was tackled by collecting extra texts from\nWikipedia related to the frames, pre-processing\nthem to create a frame-related lexicon and then to\nuse it to create a bag-of-words representation for\neach input article.2361"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "HQP : A Human-Annotated Dataset for Detecting Online Propaganda\nAbdurahman Maarouf*Dominik B\u00e4r*Dominique Geissler*Stefan Feuerriegel*\n*Munich Center for Machine Learning (MCML) & LMU Munich\n{a.maarouf,baer,d.geissler,feuerriegel}@lmu.de\nAbstract\nOnline propaganda poses a severe threat to\nthe integrity of societies. However, existing\ndatasets for detecting online propaganda have"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "a key limitation: they were annotated using\nweak labels that can be noisy and even in-\ncorrect. To address this limitation, our work\nmakes the following contributions: (1) We\npresent HQP : a novel dataset ( N= 30;000) for\ndetecting online propaganda with high-quality\nlabels. To the best of our knowledge, HQP\nis the \ufb01rst dataset for detecting online propa-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ganda that was created through human anno-\ntation. (2) We show empirically that state-of-\nthe-art language models fail in detecting on-\nline propaganda when trained with weak la-\nbels (AUC: 64.03). In contrast, state-of-the-\nart language models can accurately detect on-\nline propaganda when trained with our high-\nquality labels (AUC: 92.25), which is an im-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "provement of\u001844%. (3) To address the cost\nof labeling, we extend our work to few-shot\nlearning. Speci\ufb01cally, we show that prompt-\nbased learning using a small sample of high-\nquality labels can still achieve a reasonable per-\nformance (AUC: 80.27). Finally, we discuss\nimplications for the NLP community to bal-\nance the cost and quality of labeling. Crucially,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "our work highlights the importance of high-\nquality labels for sensitive NLP tasks such as\npropaganda detection.\nDisclaimer: Our work contains potentially offen-\nsive language and manipulative content. Reader\u2019s\ndiscretion is advised.\n1 Introduction\nPropaganda refers to communication that is pri-\nmarily used to in\ufb02uence, persuade, or manipulate\npublic opinions (Smith, 2022). Nowadays, propa-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ganda is widely used as practices of modern war-\nfare (e.g., in the ongoing Russo-Ukrainian war)\nand thus poses a signi\ufb01cant threat to the integrity\nof societies (Kowalski, 2022). In this regard, socialmedia presents especially fertile grounds for dis-\nseminating propaganda at an unprecedented scale.\nExisting NLP works for propaganda detection\ngenerally focus on different types of content. One"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "literature stream aims at detecting propaganda in\nof\ufb01cial news (e.g., Rashkin et al., 2017; Barr\u00f3n-\nCede\u00f1o et al., 2019; Da San Martino et al., 2019)\nbut fails to detect propaganda in online content\n(Wang et al., 2020). Another literature stream aims\nat detecting propaganda in online content from so-\ncial media (Wang et al., 2020; Vijayaraghavan and"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "V osoughi, 2022). Here, existing works rely upon\ndatasets that were exclusively annotated using weak\nlabels and were, therefore, notvalidated by hu-\nmans. Because of this, labels can be noisy and\neven incorrect. We later provide empirical support\nfor this claim and show that the overlap between\nweak labels and human annotations is only \u001841%.\nGiven that social media is increasingly used for"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "propaganda dissemination (Geissler et al., 2022), a\ntailored dataset is needed to tackle it. To the best\nof our knowledge, there is nodataset for detecting\nonline propaganda that was constructed through hu-\nman annotation and validation and thus comprises\nhigh-quality labels.\nTo \ufb01ll this gap, we develop HQP: a novel\ndataset with high-quality labels for detecting on-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "line propaganda. HQP consists of N= 30;000\ntweets in English from the Russo-Ukrainian war.\nWe use human annotation and validation to gen-\nerate high-quality labels. Speci\ufb01cally, we follow\nbest practices and make use of a rigorous multi-\nannotator, multi-batch procedure for annotation\n(Song et al., 2020). We then leverage state-of-\nthe-art, pre-trained language models (PLMs), i.e.,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "BERT, RoBERTa, and BERTweet, to benchmark\nthe performance in detecting online propaganda\nusing weak labels vs. our high-quality labels. We\n\ufb01nd that high-quality labels are crucial for perfor-\nmance. We further acknowledge that human an-\nnotation also incurs labeling costs, and, to addressarXiv:2304.14931v2  [cs.CL]  1 May 2023this, we extend our work to few-shot learning (i.e.,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "prompt-based learning).\nOur main contributions are as follows:1\n1.We construct HQP, a novel dataset with high-\nquality labels for online propaganda detection\nusing human-annotated labels.\n2.We show that PLMs for detecting online pro-\npaganda using high-quality labels outperform\nPLMs using weak labels by a large margin.\n3.We adapt few-short learning for online propa-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ganda detection by prompting PLMs.\n2 Related Work\nDetecting harmful content: Prior literature in\nNLP has aimed to detect a broad spectrum of harm-\nful content such as hate speech (e.g., Badjatiya\net al., 2017; Mathew et al., 2021; Pavlopoulos et al.,\n2022), rumors (e.g., Zhou et al., 2019; Bian et al.,\n2020; Xia et al., 2020; Wei et al., 2021), and fake"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "news (e.g., Zellers et al., 2019; Liu et al., 2020; Lu\nand Li, 2020; Jin et al., 2022). Further, claim detec-\ntion has been studied, for example, in the context\nof the Russo-Ukrainian war (La Gatta et al., 2023).\nOverall, literature for detecting harmful content\nmakes widespread use of datasets that were cre-\nated through human annotations (e.g., Founta et al.,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "2018; Thorne et al., 2018; Mathew et al., 2021),\nyet outside of online propaganda. We add by con-\nstructing a dataset through human annotations that\nis tailored to online propaganda.\nDetecting propaganda content: Previous\nworks for propaganda detection can be loosely\ngrouped by the underlying content, namely (1) of\ufb01-\ncial news and (2) social media. We brie\ufb02y review\nboth in the following."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "both in the following.\n(1)News . To detect propaganda in of\ufb01cial news,\nexisting works leverage datasets that originate from\npropagandistic and non-propagandistic news out-\nlets (Rashkin et al., 2017; Barr\u00f3n-Cede\u00f1o et al.,\n2019; Da San Martino et al., 2019; Solopova et al.,\n2023), yet these datasets are not tailored to on-\nline content from social media. As a case in point,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Wang et al. (2020) previously examined the capa-\nbility of machine learning to transfer propaganda\ndetection between news and online content, yet\nfound challenges in doing so.\n(2)Social media. To detect propaganda in so-\ncial media, existing works create datasets from\n1Code and data publicly available at https://github.\ncom/abdumaa/HiQualProp .online platforms such as Twitter. For example,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "TWE (Wang et al., 2020) combines a random sam-\nple of tweets (representing the non-propagandistic\nclass) with a sample of tweets from the Inter-\nnet Research Agency (representing the propagan-\ndistic class). TWEETSPIN (Vijayaraghavan and\nV osoughi, 2022) is a dataset with tweets that are\nannotated with weak labels along different types of\npropaganda techniques by mining accusations in"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "the replies and quotes to each tweet. Notably, all\nexisting datasets for detecting online propaganda\nwere created through weak annotation (see Table 1).\nTo this end, labels can oftentimes be noisy or even\nincorrect. We \ufb01ll this void by developing a human-\nannotated dataset for online propaganda detection.\nMethodologically, earlier works generally rely"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "upon feature engineering (tf-idf) (Barr\u00f3n-Cede\u00f1o\net al., 2019) and LSTMs (Rashkin et al., 2017;\nWang et al., 2020). More recently, PLMs such as\nBERT evolved as the state-of-the-art method to\ndetect propaganda (Da San Martino et al., 2019;\nVijayaraghavan and V osoughi, 2022). Later, we\nthus also adopt state-of-the-art PLMs to assess the\nrole of weak vs. high-quality labels."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "role of weak vs. high-quality labels.\nFew-shot learning in NLP: Generally, con-\nstructing large-scale datasets with high-quality la-\nbels in NLP is costly. Hence, there is a growing in-\nterest in few-shot learning. Common methods typ-\nically leverage prompting, where the downstream\ntask is reformulated to resemble the masked lan-\nguage modeling task the PLM was trained on (e.g.,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Radford et al., 2019; Brown et al., 2020; Gao et al.,\n2021; Schick and Sch\u00fctze, 2021; Liu et al., 2023).\nPrompting has been highly successful in few-shot\nlearning, e.g., for rumor detection (Lin et al., 2023)\nand humor detection (Li et al., 2023). However,\nto the best of our knowledge, no work has so far\nadapted few-shot learning to detect propaganda.\n3 Dataset Construction ( HQP )"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "3 Dataset Construction ( HQP )\nIn the following, we construct a human-annotated\ndataset of English social media content with pro-\npaganda ( HQP). For this, we construct a corpus\nof tweets with Russian propaganda from the 2022\ninvasion of Ukraine. We collect tweets from Febru-\nary 2021 until October 2022, i.e., our timeframe\nstarts one year before the invasion due to the"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "widespread opinion that the invasion was plannedDataset Domain Level Human ann. Model Few-shot\nRashkin et al. (2017) News Document 7 LSTM 7\nBarr\u00f3n-Cede\u00f1o et al. (2019) News Document 7 Maximum entropy classi\ufb01er 7\nDa San Martino et al. (2019) News Fragment 3 Multi-granularity network 7\nSolopova et al. (2023) News Document 7 BERT 7\nWang et al. (2020) (\u201cTWE\u201d) Social media Short-text 7 LSTM 7"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Vijayaraghavan and V osoughi (2022) (\u201cTWEETSPIN\u201d) Social media Short-text 7 Multi-view transformer 7\nHQP (ours) Social media Short-text 3 BERT, RoBERTa, BERTweet 3\nTable 1: Overview of existing datasets for propaganda detection aimed at (i) news and (ii) online content.\nfar in advance.2We intentionally choose the Russo-\nUkrainian war due to its signi\ufb01cance for world pol-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "itics (Kowalski, 2022) and the sheer size of the\npropaganda campaign (Geissler et al., 2022). Our\nmethodology for constructing HQP follows best\npractices for human annotation (Song et al., 2020).\nSpeci\ufb01cally, we build upon a four-step process:\n(1) data collection, (2) sampling, and (3) human\nannotation.\n3.1 Data Collection\nIn practice, social media content with propaganda"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "is rare in comparison to non-propaganda (e.g., well\nbelow 0.1%). Therefore, simply collecting a ran-\ndom subset of tweets will contain only very few\nsamples from the positive class. Instead, we fol-\nlow the methodology in Founta et al. (2018) and\nperform a strati\ufb01ed search. Thereby, we separately\ngenerate candidates for the positive class ( D+) and"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "for the negative class ( D\u0000) as shown in Figure 1.\nThe latter are context-related samples in that they\nalso discuss topics related to the Russo-Ukrainian\nwar but are likely not propaganda. Thereby, we\neventually capture a challenging setting in which\nwe can evaluate how accurately propaganda and\nnon-propaganda can be discriminated.\n(i) Candidate search for positive class ( D+):"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Analogous to Vijayaraghavan and V osoughi (2022),\nwe expect that propaganda on Twitter is often\ncalled out in replies or quotes (e.g., some users\ndebunk propaganda as such). We thus access the\nTwitter Historical API and perform a keyword-\nbased search. Speci\ufb01cally, we crawl replies and\nquotes that contain phrases (keywords) that may\naccuse the original tweet of propaganda, such"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "as (\u201c russian \u201d^\u201cpropaganda \u201d) or (\u201c war\u201d^\n\u201cpropaganda \u201d). The full list is in Table A.1 in\nthe supplements.\nWe create the list of search keywords through\n2https://www.nytimes.com/2021/04/09/world/\neurope/russia-ukraine-war-troops-intervention.\nhtml\nTwitter\nhistorical \ndataPropaganda \naccusation \nkeyword\nlistPropaganda\naccusation \nreplies & \nquotes\nCrawl GenerateUpdate\n(i)\nCandidate \nsearch for"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "(i)\nCandidate \nsearch for \npositive class\nWar-related \nTweetsWar-related \nkeyword\nlist(ii)\nCandidate \nsearch for \nnegative classCrawl Generate\nUpdateCrawl Source -\ntweets of \nreplies & \nquotes\nCandidates \nfor \nHiQualPropJoin\nJoin\n~2.5 M~2.5 M\n~5 MFigure 1: Data collection of candidate tweets for HQP .\nan iterative process: (1) In each iteration, the cur-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "rent list of keywords is used to \ufb01lter for English-\nlanguage replies and quotes from Twitter. (2) We\nthen manually scan the most frequent words (in-\ncluding bi- and tri-grams) for phrases that can po-\ntentially qualify as propaganda accusations. (3) We\nadd these to our list of keywords. We repeat the\nprocess for three iterations and use the \ufb01nal list"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "of search keywords to retrieve our set of replies\nand quotes. Afterward, we crawl the correspond-\ning source tweets, which resulted in \u00182.5 million\ncandidates for D+.\n(ii) Candidates for negative class ( D\u0000):To\ncollect candidates for the negative class, we crawl\na random sample of 2.5 million tweets that discuss\nthe Russo-Ukrainian war but that have not neces-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "sarily been identi\ufb01ed as propaganda through users.\nFor this, we use a similar iterative procedure to\ngenerate a keyword list as for the positive class.\nHowever, we now perform a keyword search only\nfor source tweets (but not for replies or quotes).\nExample keywords are (\u201c russia \u201d^\u201cwar\u201d) and\n(\u201cukraine \u201d^\u201cwar\u201d). The complete list of search\nkeywords is in Table A.2 in the supplements."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Postprocessing: We postprocess the candidatesfor both the positive class ( D+) and the nega-\ntive class ( D\u0000). Speci\ufb01cally, we \ufb01lter out dupli-\ncates, non-English tweets, and very short tweets\n(i.e., fewer than 5 words). The resulting union of\nboth postprocessed candidate sets contains jD+j+\njD\u0000j\u00183.2 million samples.\nUnlike Vijayaraghavan and V osoughi (2022), we"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "do not perform weak labeling by simply assigning\na label to a tweet depending on whether it is in\nD+orD\u0000, respectively. Instead, we generate high-\nquality labels through human annotation. This is\nmotivated by our observation that many samples in\nD+cover the Russo-Ukrainian war but do not qual-\nify as propaganda. Hence, weak labeling would\nlead to many false positives.\n3.2 Boosted Sampling"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "3.2 Boosted Sampling\nWe collect N= 30;000tweets from the postpro-\ncessed union of D+andD\u0000for human annotation.\nWe adopt boosted sampling (Founta et al., 2018) as\nwe observe that the majority of samples from the\nprevious step cover \u2018normal\u2019 content and do not\nnecessarily qualify as propaganda. Our research\nobjective requires that there is a suf\ufb01cient propor-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "tion of positive class labels in our dataset, since,\notherwise, the dataset will not be useful for the re-\nsearch community. To address the class imbalance,\nwe use weighted sampling. For this, we gener-\nate weights wifor each tweet as the inverse term\nfrequency of potential propaganda-related phrases\n(e.g., \u201c nobody talks about \u201d), that is,\nwi=niPM\nj=1nj; (1)"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "wi=niPM\nj=1nj; (1)\nwhere niis the number of unique occurences of\npropaganda-related phrases and M=jD+j+jD\u0000j.\nHere, we use the list of 189 potential propaganda\nphrases from Vijayaraghavan and V osoughi (2022).\nAs a result, our boosted sampling approach will\nincrease the likelihood that actual propaganda con-\ntent (true positives) is later annotated (rather than\nfalse positives)."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "false positives).\n3.3 Human Annotation\nTo annotate our data, we recruit human work-\ners from Proli\ufb01c ( https://www.prolific.co/ )\nto label the tweets as propagandistic or non-\npropagandistic. Workers are pre-selected according\nto strict criteria: residency in the UK/US, English\nas a \ufb01rst language; enrollment in an undergraduate,\ngraduate, or doctoral degree; a minimum approval"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "rate of 95%; and min. 500 completed submissionson Proli\ufb01c. The annotation instructions are in Ap-\npendix B of the supplement.\nWorkers are asked to annotate two labels for\neach tweet. The \ufb01rst is a binary label ( BL) to clas-\nsify propagandistic vs. non-propagandistic content.\nThe second is a propaganda-strategy label ( PSL)\naimed at capturing the context-related strategy be-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "hind propagandistic tweets. Therefore, if a tweet\nis annotated as propagandistic, the worker is asked\nto select one of four context-related propaganda\nstrategies that are used in this tweet (thus giving\nPSL). The four propaganda strategies were care-\nfully chosen after manually studying a sample of\n2,000 tweets and discussing different options with"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "an expert team of propaganda researchers. Specif-\nically, for PSL, workers have to decide whether\nthe propagandistic tweet is designed to in\ufb02uence\nopinions (1) against Western countries, (2) against\nUkraine, (3) pro-Russian government, or (4) aimed\nat other countries.\nOur annotation follows a batch procedure accord-\ning to best practices (Song et al., 2020), i.e., a pool"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "of workers annotates a subset of the data to avoid\nfatigue. We thus split the dataset ( N= 30:000)\ninto 300 batches with 100 tweets each. Each batch\nis annotated by two workers. Beforehand, we man-\nually annotate 10 tweets of each batch with respect\ntoBLto measure the quality of the annotations:\nIf (a) a worker incorrectly labeled more than 20%\nof the internally annotated tweets or (b) the inter-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "annotator agreement between both workers has a\nCohen\u2019s kappa (Cohen, 1960) \u00140:4, we discard\nthe annotation and repeat the annotation for the\nbatch. Overall, we had to discard and redo 7.5% of\nthe batch annotations. When annotators disagreed\nonBLfor individual tweets, we resolve the con-\n\ufb02icts as follows: the BLis then re-annotated by\nrandomly assigning it to one of the top 25 anno-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "tators. If there is disagreement on the PSL after\nresolving the disagreement on the BL, the \ufb01nal PSL\nis decided by the author team. The latter was the\ncase for only 2.6% of the tweets. Altogether, this\ncorroborates the reliability of our multi-annotator,\nmulti-batch procedure for annotation.\nWe further crawled additional meta information\nabout authors, which we report in Appendix F."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "3.4 Dataset Statistics\nTable 2 reports summary statistics for our HQP.\nTable 3 lists \ufb01ve example tweets and their corre-\nsponding labels, i.e., BLandPSL.Propaganda = true Propaganda = false Overall\nNum. of tweets ( N) 4,610 25,390 30,000\nAvg. tweet length (in chars) 238.71 216.90 220.25\nNum. of unique authors 3,910 20,140 23,317\nTable 2: Summary statistics for HQP .\n4 Methods"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "4 Methods\nIn our experiments, we follow state-of-the-art meth-\nods from the literature (see Sec. 2) to ensure the\ncomparability of our results. To this end, we use\na binary classi\ufb01cation task (propaganda = 1, oth-\nerwise = 0). Results are reported as the average\nperformance over \ufb01ve seperate runs. In each run,\nwe divide the dataset into train (70%), val (10%),"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "and test (20%) using a strati\ufb01ed shuf\ufb02e split. All\nexperiments are conducted on a Ubuntu 20.04 sys-\ntem, with 2.30 GHz Intel Xeon Silver 4316 CPU\nand two NVIDIA A100-PCIE-40GB GPUs.\n4.1 Fine-Tuning PLMs\n4.1.1 PLMs\nWe use the following PLMs in our experiments:\nBERT-large (Devlin et al., 2019), RoBERTa-\nlarge (Liu et al., 2019), and BERTweet-large"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "(Nguyen et al., 2020). The latter uses the pretrain-\ning procedure from RoBERTa but is tailored to\nEnglish tweets in order to better handle social me-\ndia content. We report implementation details in\nAppendix C.3\n4.1.2 Baselines\nWe compare the \ufb01ne-tuning procedure on our high-\nquality labels vs. baselines that make use of weak\nlabels. All evaluations are based on separate test"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "splits of HQP with human veri\ufb01cation.\n\u000fTWE: We \ufb01ne-tune on weak labels of the pub-\nlic TWE dataset (Wang et al., 2020).\n\u000fTWEETSPIN: The TWEETSPIN dataset\nwith weak labels (Vijayaraghavan and V osoughi,\n2022) is not public, and we thus replicate the data\ncollection procedure ( N= 3;223;867).\n\u000fHQP-weak: As an ablation study, we construct\na dataset with weak labels based on our data col-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "lection procedure from HQP. Speci\ufb01cally, we map\nfrom our classi\ufb01cation into D+andD\u0000. We gen-\nerateN=jHQPjsamples so that the size is com-\nparable to HQP. This allows us later to isolate the\neffect of the dataset size from the role of weak vs\n3We also evaluated the performance of \ufb01ne-tuning PLMs\nwith incorporated author and pinned-tweet features. Imple-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "mentation details and results are reported in Appendix F.high-quality labels.4\n4.2 Prompt-Based Learning\nFor few-shot learning, we leverage state-of-the-\nart prompt-based learning (Liu et al., 2023; Gao\net al., 2021), which requires only a small set\nof labeled samples and thus reduces annotation\ncosts. Prompt-based learning reformulates the\ndownstream classi\ufb01cation task to look more like"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "the masked-language-model task the PLM was\ntrained on. For example, for our task, each input\nsequence could be appended with a textual prompt,\ne.g., the propagandistic sequence \u201c Ukraine is\nfull of nazis. \u201d is continued with the prompt \u201c I\nstand with [MASK] \u201d (which gives the so-called\ntemplate). Given a mapping of prede\ufb01ned label\nwords to each class (via the so-called verbalizer),"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "the masked language model predicts the probabil-\nities of each label word to \ufb01ll the [MASK] token\nand thereby the probabilities of each class. For our\ntask, examples for label words could be \u201c Russia \u201d\nfor the class of propaganda and \u201c Ukraine \u201d for the\nclass of no propaganda. As a result, this introduces\nthe task of prompt engineering, i.e., \ufb01nding the"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "most suitable template and verbalizer to solve the\ndownstream task. In general, manual prompt en-\ngineering can be challenging, especially because\nthe performance in the downstream task depends\nhighly on the prompt (Gao et al., 2021). In our\nwork, we use a three-step procedure: (i) \ufb01nding the\nbest template, (ii) \ufb01nding the best verbalizer, and\n(iii) prompt-based \ufb01ne-tuning, as follows:"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "(i) Automatic template generation: Here, we\nuse the LM-BFF procedure from Gao et al. (2021).\nWe randomly sample k0positive and k0negative\nexamples for training and validation, which thus\nrequires k= 4\u0002k0samples overall. We use the\nseq2seq PLM T5 (Raffel et al., 2020) to generate\ntemplate candidates. Given the training example\nand an initial verbalizer5, T5 then generates a can-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "didate template by \ufb01lling the missing spans. We\nuse beam search to generate a set of 100 candidate\ntemplates. Afterward, we \ufb01ne-tune each template\nusing the training examples and the downstream\nPLM. Finally, the best-performing template is cho-\nsen based on the performance on the val set.\n4We also experimented with a variant of the dataset where"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "we used weak labeling for all \u00183.2 million samples but found\ncomparable results.\n5This initial verbalizer is only used to generate template\ncandidates. We discard the initial verbalizer for the automatic\nverbalizer generation in step (ii).Tweet BL PSL\n\u201cSTOP RUSSIAN AGGRESSION AGAINST #UKRAINE . @USER CLOSE THE SKY OVER UKRAINE ! EXCLUDE RUSSIA FROM THE"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "@USER SECURITY COUNCIL ! #StopPutin #StopRussia HTTPURL \u201dFalse \u2014\n\u201cThe Textile Worker microdistrict in Donetsk came under fire ! The Ukraine nazis dealt another blow to\nthe residential quarter At least four civilians were killed on the spot . #UkraineRussiaWar #UkraineNazis\n#ZelenskyWarCriminal @USER @USER HTTPURL \u201dTrue Against\nUkraine"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Ukraine\n\u201cThe denazification of Ukraine continues . In Kherson , employees of the Russian Guard detained two\naccomplices of the Nazis . During the operation , the National Guard officers detained several leaders of\nneo-Nazi formations and accomplices of the SBU . HTTPURL HTTPURL \u201dTrue Pro Russian\ngovernment"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "government\n\u201cWestern \u2018leaders\u2019 continue with their irrational drive toward WWIII . NATO is a criminal enterprise , an\ninstrument of white power threat to global humanity . Join anti-NATO protests around the world . HTTPURL \u201dTrue Against West-\nern countries\n\u201cChinese and Indian citizens must leave Ukraine because Ukraine is run by the Nazi / Zionist fascists since"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "the coup d\u2019etat of 2014 . \u201dTrue Aimed at\nother coun-\ntries\nTable 3: Example tweets in our HQP dataset. BLis a binary label whether a tweet is propaganda or not. PSL is the\npropaganda strategy.\n(ii) Automatic verbalizer generation: We use\nthe method from Gao et al. (2021) to generate\nthe verbalizer (i.e., to map predictions to our la-\nbel classes). For each class, we construct a set of"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "100 candidate tokens based on the conditional like-\nlihood of the downstream PLM to \ufb01ll the [MASK]\ntoken using the best-performing template from step\n(i). These candidates are \ufb01ne-tuned and re-ranked\nto \ufb01nd the best candidate for each class with regard\nto the performance on the val set.\n(iii) Prompt-based \ufb01ne-tuning: We use the\nbest template from step (i) and the best verbalizer"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "from step (ii) to form our prompt. We \ufb01ne-tune the\ndownstream PLM with this prompt to create the\n\ufb01nal model for propaganda detection. We refer to\nthe above model as LM-BFF .\nIn our LM-BFF implementation, we use the\nOpenPromt framework (Ding et al., 2022). For\ntemplate generation, we choose an initial verbal-\nizer with label words \u201c propaganda \u201d (propaganda)"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "and \u201c truth \u201d (no propaganda) and a cloze prompt\nformat (Liu et al., 2023). We choose RoBERTa-\nlarge (Liu et al., 2019) as the underlying PLM due\nto its overall superior performance. We freeze the\n\ufb01rst 16 layers to control for over\ufb01tting and choose\na learning rate of 4e \u00005. We train for a number of\n50 epochs and choose the best checkpoint. We set\nthe batch size depending on k0; see Table 4. For"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "all other hyper-parameters, we choose the same as\nthose presented in Gao et al. (2021).6\n6We also experimented with prompt-based learning with\n(i) automatic template generation and a manual verbalizer,\n(ii) a manual template with automatic verbalizer generation,\nand (iii) a manual template with a manual verbalizer. However,\nthe results were not better than those reported in Section 5.3."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Our explanation for this is the complexity of manually setting\nup a prompt in our task for propaganda detection.k0= 16k0= 32k0= 64k0= 128\nBatch size 4 8 16 32\nTable 4: Batch size of prompt-based learning for differ-\nent numbers of overall samples ( k= 4\u0002k0).\n4.3 Extension of LM-BFF to Auxiliary-Task\nPrompting\nWe extend the above LM-BFF procedure for in-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ductive learning and use both the BLand the PSL\nlabels during prompting. The rationale behind this\nis three-fold: (1) We use information about the\npropaganda strategy and thus richer labels, which\nmay improve performance. (2) Propaganda can be\nhighly diverse, and, through the use of more gran-\nular labels, we can better capture heterogeneity.\n(3) The overall sample size remains low with only"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "a minor increase in labeling costs. This is bene\ufb01-\ncial in practice when newly emerging propaganda\nnarratives must be detected and there are thus only\na few available samples.\nTo leverage both BLandPSL labels, we develop\na custom architecture for auxiliary-task prompting,\nwhich we refer to as LM-BFF-AT . Speci\ufb01cally, we\napply steps (i) to (iii) for our two labels BLandPSL,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "separately. This results in two different \ufb01ne-tuned\nversions of the downstream PLM with different\ntemplates and verbalizers. To classify a given input\ntext, we fuse verbalizer probabilities for each label\ninto a classi\ufb01cation head, which computes the \ufb01nal\nprediction. For the classi\ufb01cation heads, we train\nan elastic net and a feed-forward neural network"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "with one hidden layer on top of the verbalizer prob-\nabilities. The val set is used for hyper-parameter\ntuning. Hyper-parameter grids for the classi\ufb01ca-\ntion heads are reported in Appendix E. Note that"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "our LM-BFF-AT approach uses two labels but can/uni00000031/uni00000052/uni00000003/uni00000053/uni00000055/uni00000052/uni00000053/uni00000044/uni0000004a/uni00000044/uni00000051/uni00000047/uni00000044 /uni00000033/uni00000055/uni00000052/uni00000053/uni00000044/uni0000004a/uni00000044/uni00000051/uni00000047/uni00000044"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni0000002b/uni0000004c/uni0000004a/uni0000004b/uni00000010/uni00000054/uni00000058/uni00000044/uni0000004f/uni0000004c/uni00000057/uni0000005c/uni00000003/uni0000004f/uni00000044/uni00000045/uni00000048/uni0000004f/uni00000056/uni00000031/uni00000052/uni00000003/uni00000053/uni00000055/uni00000052/uni00000053/uni00000044/uni0000004a/uni00000044/uni00000051/uni00000047/uni00000044"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni00000033/uni00000055/uni00000052/uni00000053/uni00000044/uni0000004a/uni00000044/uni00000051/uni00000047/uni00000044/uni0000003a/uni00000048/uni00000044/uni0000004e/uni00000003/uni0000004f/uni00000044/uni00000045/uni00000048/uni0000004f/uni00000056/uni00000003/uni00000016/uni00000017/uni00000011/uni0000001b/uni00000016/uni00000008"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni00000015/uni00000018/uni00000011/uni00000013/uni0000001a/uni00000008"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni00000019/uni00000018/uni00000011/uni00000014/uni0000001a/uni00000008 /uni0000001a/uni00000017/uni00000011/uni0000001c/uni00000016/uni00000008Figure 2: Contingency table comparing weak vs. high-\nquality labels.\neasily be generalized to nlabels.7\n5 Experiments\n5.1 Discrepancy between Weak Labels vs.\nHigh-Quality Labels\nRQ1: What is the discrepancy between weak label-\ning vs. human annotation?"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ing vs. human annotation?\nWe \ufb01nd a substantial discrepancy between the weak\nlabels (from HQP-weak) and our high-quality la-\nbels (from human annotation). In fact, the overall\nagreement is only 41.0%. Hence, the majority of\nlabels are thus different. Figure 2 shows the contin-\ngency table comparing weak and human annotation.\nCrucially, this supports our hypotheses that weak"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "labels are noisy and thus often incorrect. This mo-\ntivates our use of high-quality labels from human\nannotation in the following.\n5.2 Propopaganda Detection when using\nWeak vs. High-Quality Labels\nRQ2: How well can state-of-the-art PLMs detect\nonline propaganda when trained with weak labels\nvs. high-quality labels?\nTable 5 compares the performance. For this, we"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "vary the choice of the underlying PLM (BERT,\nRoBERTa, BERTweet) and what data is used for\ntraining (TWE, TWEETSPIN, HQP ). We make\nthe following observations: (1) The different PLMs\nreach a similar performance, which corroborates\nthe robustness and reliability of our results. Recall\nthat we intentionally chose state-of-the-art PLMs\nto allow for comparability when benchmarking the"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "role of weak vs. high-quality labels. (2) Weak\nlabels from the TWE dataset (Wang et al., 2020)\nlead to an AUC similar to a random guess, while\n7We also evaluated the performance of LM-BFF-AT when\nadditionally incorporating author and pinned-tweet features.\nImplementation details and results are in Appendix F.weak labels from the TWEETSPIN dataset reach\nan AUC of 64.03. (3) We use HQP-weak for an"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ablation study where we use the weak labels from\nour classi\ufb01cation into D+andD\u0000for training. We\nregister an AUC of 56.79. (4) PLMs trained with\nhigh-quality labels perform best with an AUC of\n92.25 (for BERTweet). Thereby, we achieve an\nimprovement in AUC over best-performing weak\nlabels (TWEETSPIN) of \u001844%. In sum, the per-\nformance gain must be exclusively attributed to"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "the informativeness of high-quality labels (and not\nother characteristics of the dataset).8\nWe further inspect weak vs. high-quality labels\nvisually. For this, we plot the representation of\nthe[CLS] tokens from HQP using t-SNE (van der\nMaaten and Hinton, 2008). As seen in Figure 3,\nthe representations learned with high-quality la-\nbels (right plot) are more discriminatory for the"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "true labels than that learned on weak labels (here:\nTWEETSPIN; left plot).\n20\n 15\n 10\n 5\n 0 5 10 15 2010\n5\n0510High-quality label\n0\n1\nWeak label\n0\n1\n20\n 10\n 0 10 204\n3\n2\n1\n0123\nHigh-quality label\n0\n1\nWeak label\n0\n1\nFigure 3: A t-SNE visualization showing the represen-\ntations of the [CLS] tokens for BERTweet \ufb01ne-tuned\non TWEETSPIN labels (left) and high-quality labels"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "(right). Evidently, representations learned with high-\nquality labels are more discriminatory than with weak\nlabels for predictions on the test set .\n5.3 Performance of Few-Shot Learning\nRQ3: How much can few-shot learning reduce\nlabeling costs for detecting online propaganda?\nTo reduce the costs of labeling, we further use few-\nshort learning (see Figure 4). Here, we vary the"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "overall number of labeled samples ( k= 4\u0002k0). We\ncompare the performance of prompt-based learning\nwith LM-BFF (using only BL) vs. LM-BFF-AT\n(using BLandPSL).\n8Note that the recall improvement with our high-quality la-\nbels is relatively small, while we register a strong improvement\nin precision. In fact, for weak labels, the \ufb01ne-tuned models"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "tend to predict the propaganda class too often, which leads\nto a large number of false positives. In practice, this incurs\nsubstantial downstream costs during fact-checking (Naumzik\nand Feuerriegel, 2022) or may oppose free speech rights.Precision Recall F1 AUC\nTraining data BERT RoBERTa BERTweet BERT RoBERTa BERTweet BERT RoBERTa BERTweet BERT RoBERTa BERTweet\nTWE (Wang et al., 2020) 14.86"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "TWE (Wang et al., 2020) 14.86\n(0.65)14.67\n(0.51)14.75\n(0.20)46.04\n(3.01)45.71\n(2.47)53.47\n(6.13)22.46\n(0.99)22.20\n(0.83)23.08\n(0.52)47.93\n(1.58)48.63\n(1.67)47.22\n(0.81)\nTWEETSPIN (Vijayaraghavan\nand V osoughi, 2022)23.08\n(1.51)23.18\n(1.11)23.33\n(1.25)60.09\n(1.87)59.65\n(1.48)59.25\n(1.85)33.32\n(1.54)33.38\n(1.36)33.46\n(1.46)64.03\n(1.05)63.50\n(1.06)63.85\n(1.41)\nHQP -weak (weak labels on our"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "(1.41)\nHQP -weak (weak labels on our\nHQP )16.42\n(0.17)16.39\n(0.31)16.16\n(0.18)69.24\n(1.38)69.94\n(3.03)68.22\n(2.64)26.55\n(0.30)26.56\n(0.61)26.13\n(0.43)56.71\n(0.99)56.79\n(2.07)56.64\n(0.76)\nHQP (ours) 61.52\n(5.77)66.68\n(2.30)68.86\n(2.37)64.65\n(3.83)70.80\n(2.85)70.65\n(2.52)62.77\n(1.92)68.64\n(1.80)69.70\n(1.31)88.21\n(0.62)91.76\n(0.62)92.25\n(0.80)\nStated: mean (SD)."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "(0.62)92.25\n(0.80)\nStated: mean (SD).\nTable 5: Results of propaganda detection for different PLMs trained on weak vs. high-quality labels.\nFigure 4 compares the performance across the\ndifferent values for k0and the prompt-based learn-\ning methods. Generally, a larger k0tends to im-\nprove the performance. For example, for k0= 128\nand LM-BFF, we register a mean F1-score of 43.03"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "and a mean AUC of 79.74. As expected, this is\nlower than for \ufb01ne-tuned PLMs but it is a promis-\ning \ufb01nding since only 2.13% of the labeled exam-\nples are used for training and validation. Using\nLM-BFF-AT with an elastic net as the classi\ufb01ca-\ntion head consistently improves the performance of\nprompt-based learning across all k0. Fork0= 128 ,\nwe achieve a 2.8% improvement in the F1-score"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "(44.22) and a 0.7% improvement in AUC (80.27).\nOn average, over all k0, the improvement amounts\nto 1.25% for the F1-score and 0.51% for the AUC.\nGenerally, the variant with an elastic net tends to\nbe better than the variant with a neural network,\nlikely due to the small size of the training sample.9\n6 Discussion\nWe introduce HQP: the \ufb01rst dataset for online pro-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "paganda detection with human annotations. Our\nexperiments further have direct implications for the\nNLP community.\n\u000fImplication 1: When identifying propaganda,\nthere is a substantial discrepancy between weak\nlabeling and human annotations. This pinpoints\nweaknesses in existing datasets for online propa-\nganda detection (Wang et al., 2020; Vijayaraghavan"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "and V osoughi, 2022), since these make exclusive\nuse of weak labeling. To this end, our work high-\nlights the importance of human feedback for sensi-\ntive NLP tasks such as propaganda detection.\n\u000fImplication 2: High-quality labels are crucial\nto detect online propaganda. Our experiments are\nintentionally based on state-of-the-art PLMs to en-\nsure reliability and comparability of our results."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "9We report evaluations of the auxiliary task (i.e., prompt-\nbased learning for PSL) in Appendix D.\n/uni00000014/uni00000019 /uni00000016/uni00000015 /uni00000019/uni00000017 /uni00000014/uni00000015/uni0000001b/uni00000016/uni00000013/uni00000016/uni00000018/uni00000017/uni00000013/uni00000017/uni00000018/uni00000029/uni00000014"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni00000030/uni00000048/uni00000057/uni0000004b/uni00000052/uni00000047\n/uni0000002f/uni00000030/uni00000010/uni00000025/uni00000029/uni00000029\n/uni0000002f/uni00000030/uni00000010/uni00000025/uni00000029/uni00000029/uni00000010/uni00000024/uni00000037/uni00000003/uni0000000e/uni00000003/uni00000028/uni00000031"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni0000002f/uni00000030/uni00000010/uni00000025/uni00000029/uni00000029/uni00000010/uni00000024/uni00000037/uni00000003/uni0000000e/uni00000003/uni00000031/uni00000031"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni00000014/uni00000019 /uni00000016/uni00000015 /uni00000019/uni00000017 /uni00000014/uni00000015/uni0000001b/uni00000019/uni00000013/uni00000019/uni00000018/uni0000001a/uni00000013/uni0000001a/uni00000018/uni0000001b/uni00000013/uni00000024/uni00000038/uni00000026\n/uni00000030/uni00000048/uni00000057/uni0000004b/uni00000052/uni00000047"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni0000002f/uni00000030/uni00000010/uni00000025/uni00000029/uni00000029\n/uni0000002f/uni00000030/uni00000010/uni00000025/uni00000029/uni00000029/uni00000010/uni00000024/uni00000037/uni00000003/uni0000000e/uni00000003/uni00000028/uni00000031"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni0000002f/uni00000030/uni00000010/uni00000025/uni00000029/uni00000029/uni00000010/uni00000024/uni00000037/uni00000003/uni0000000e/uni00000003/uni00000031/uni00000031\n/uni00000014/uni00000019 /uni00000016/uni00000015 /uni00000019/uni00000017 /uni00000014/uni00000015/uni0000001b\n/uni0000004e/uni0000000a/uni00000015\n/uni00000014"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni00000014\n/uni00000013/uni00000014/uni00000015/uni00000016/uni00000008/uni00000003/uni0000002c/uni00000050/uni00000053/uni00000055/uni00000052/uni00000059/uni00000048/uni00000050/uni00000048/uni00000051/uni00000057/uni00000003/uni0000004c/uni00000051/uni00000003/uni00000029/uni00000014"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni00000014/uni00000019 /uni00000016/uni00000015 /uni00000019/uni00000017 /uni00000014/uni00000015/uni0000001b\n/uni0000004e/uni0000000a/uni00000014/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000018/uni00000008/uni00000003/uni0000002c/uni00000050/uni00000053/uni00000055/uni00000052/uni00000059/uni00000048/uni00000050/uni00000048/uni00000051/uni00000057/uni00000003/uni0000004c/uni00000051/uni00000003/uni00000024/uni00000038/uni00000026Figure 4: Results for prompt-based learning for LM-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "BFF vs. LM-BFF-AT (left: F1, right: AUC, top: ab-\nsolute performance, bottom: %-improvement over LM-\nBFF). EN (NN) refers to the elastic net (neural net) clas-\nsi\ufb01cation head. k0refers to the number of examples\nsampled from each class for both training and valida-\ntion, while k= 4\u0002k0is the overall number of samples.\nError bars denote the standard errors across 5 runs."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Generally, PLMs fail to detect propaganda when\n\ufb01ne-tuned with weak labels. In contrast, there is\na large improvement ( \u001844%) when using high-\nquality labels.\n\u000fImplication 3: Few-shot learning can be an ef-\nfective remedy to reduce the cost of human annota-\ntion of propaganda. To the best of our knowledge,\nour work is the \ufb01rst to adapt few-shot learning (via"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "prompt-based learning) to propaganda detection.\nInterestingly, our performance is similar to that\nin related NLP tasks such as, e.g., detecting ru-\nmors (Lin et al., 2023) and humor (Li et al., 2023).\nDespite the challenging nature of our task, the per-\nformance of few-shot learning is promising. For\nexample, only k= 64 (k0= 16 ) high-quality an-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "notated samples are needed to outperform propa-ganda detection with weak labels. For k= 512\n(k0= 128 ), we already achieve an improvement\nover weak labels of 24.54%.\n7 Limitations\nAs with other works, ours is not free of limitation.\nFirst, there is no universal rule to determine what\npropaganda is and what not. Hence, the percep-\ntion may vary across individuals. We address this"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "by having our dataset annotated through multiple\nraters and showing raters a task description that in-\ncludes a widely accepted de\ufb01nition of propaganda\n(see Smith, 2022). Second, we are further aware\nthat PLMs may embed biases that are populated in\ndownstream tasks. Hence, we call for careful use\nwhen deploying our methods in practice. Third, nar-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ratives that fall under the scope of propaganda may\nchange over time. Hence, we recommend that both\nthe dataset construction and the PLM \ufb01ne-tuning\nis repeated regularly. To this end, we provide a\ncost-effective approach through few-shot learning.\n8 Ethics Statement\nOur dataset will bene\ufb01t research on improving so-\ncial media integrity. The construction of our dataset"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "follows best-practice for ethical research (Rivers\nand Lewis, 2014). The dataset construction and us-\nage was approved as ethically unproblematic by the\nethics commission of the Faculty of Mathematics,\nInformatics and Statistics at LMU Munich (ethics\napproval number: EK-MIS-2023-160). In partic-\nular, our dataset contains only publicly available\ninformation. The privacy policy of Twitter warns"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "users that their content can be viewed by the gen-\neral public. Further, we respect the privacy of users\nand only report aggregate results throughout our\npaper. Although we believe the intended use of\nthis work is largely positive, there exists potential\nfor misuse (e.g., by propaganda campaigns to run\nadversarial attacks and develop techniques to avoid"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "detection). To this end, we call for meaningful re-\nsearch by the NLP community to further improve\nsocial media integrity. Finally, we encourage care-\nful use of our dataset, as it contains potentially of-\nfensive language and manipulative content, which\nlies in the nature of the task.\nReferences\nPinkesh Badjatiya, Shashank Gupta, Manish Gupta,\nand Vasudeva Varma. 2017. Deep learning for hate"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "speech detection in tweets. In WWW Companion .Alberto Barr\u00f3n-Cede\u00f1o, Israa Jaradat, Giovanni Da\nSan Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nTian Bian, Xi Xiao, Tingyang Xu, Peilin Zhao, Wen-\nbing Huang, Yu Rong, and Junzhou Huang. 2020."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Rumor detection on social media with bi-directional\ngraph convolutional networks. In AAAI .\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D. Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, et al. 2020. Language models are\nfew-shot learners. In NeurIPS .\nJacob Cohen. 1960. A coef\ufb01cient of agreement for"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "nominal scales. Educational and Psychological\nMeasurement , 20(1):37\u201346.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarr\u00f3n-Cede\u00f1o, Rostislav Petrov, and Preslav\nNakov. 2019. Fine-grained analysis of propaganda\nin news articles. In EMNLP-IJCNLP .\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "standing. In NAACL .\nNing Ding, Shengding Hu, Weilin Zhao, Yulin Chen,\nZhiyuan Liu, Haitao Zheng, and Maosong Sun.\n2022. OpenPrompt: An open-source framework for\nprompt-learning. In ACL.\nAntigoni Founta, Constantinos Djouvas, Despoina\nChatzakou, Ilias Leontiadis, Jeremy Blackburn, Gi-\nanluca Stringhini, Athena Vakali, Michael Siriv-\nianos, and Nicolas Kourtellis. 2018. Large scale"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "crowdsourcing and characterization of Twitter abu-\nsive behavior. In ICWSM .\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021.\nMaking pre-trained language models better few-shot\nlearners. In ACL-IJCNLP .\nDominique Geissler, Dominik B\u00e4r, Nicolas Pr\u00f6llochs,\nand Stefan Feuerriegel. 2022. Russian propaganda\non social media during the 2022 invasion of Ukraine .\narXiv."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "arXiv.\nYiqiao Jin, Xiting Wang, Ruichao Yang, Yizhou Sun,\nWei Wang, Hao Liao, and Xing Xie. 2022. Towards\n\ufb01ne-grained reasoning for fake news detection. In\nAAAI .\nAdam Kowalski. 2022. Disinformation and Russia\u2019s\nwar of aggression against Ukraine: Threats and gov-\nernance responses. OECD Report .\nKlaus Krippendorff, Yann Mathet, St\u00e9phane Bouvry,\nand Antoine Widl\u00f6cher. 2016. On the reliability"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "of unitizing textual continua: Further developments.\nQuality & Quantity , 50(6):2347\u20132364.Valerio La Gatta, Chiyu Wei, Luca Luceri, Francesco\nPierri, and Emilio Ferrara. 2023. Retrieving false\nclaims on Twitter during the Russia-Ukraine con\ufb02ict.\nInWWW Companion .\nJunze Li, Mengjie Zhao, Yubo Xie, Antonis Maroniko-\nlakis, Pearl Pu, and Hinrich Sch\u00fctze. 2023. This"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "joke is [MASK]: Recognizing humor and offense\nwith prompting. Transfer Learning for Natural Lan-\nguage Processing Workshop .\nHongzhan Lin, Pengyao Yi, Jing Ma, Haiyun Jiang,\nZiyang Luo, Shuming Shi, and Ruifang Liu. 2023.\nZero-shot rumor detection with propagation struc-\nture via prompt learning. In AAAI .\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Hiroaki Hayashi, and Graham Neubig. 2023. Pre-\ntrain, prompt, and predict: A systematic survey of\nprompting methods in natural language processing.\nACM Computing Surveys , 55(9):1\u201335.\nYinhan Liu, Myle Ott, Naman Goyal, Du Jingfei, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoBERTa: A robustly optimized BERT pretraining\napproach . arXiv."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "approach . arXiv.\nZhenghao Liu, Chenyan Xiong, Maosong Sun, and\nZhiyuan Liu. 2020. Fine-grained fact veri\ufb01cation\nwith kernel graph attention network. In ACL.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In ICLR .\nYi-Ju Lu and Cheng-Te Li. 2020. GCAN: Graph-aware\nco-attention networks for explainable fake news de-\ntection on social media. In ACL."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "tection on social media. In ACL.\nBinny Mathew, Punyajoy Saha, Seid Muhie Yi-\nmam, Chris Biemann, Pawan Goyal, and Animesh\nMukherjee. 2021. HateXplain: A benchmark\ndataset for explainable hate speech detection. In\nAAAI .\nChristof Naumzik and Stefan Feuerriegel. 2022. De-\ntecting false rumors from retweet dynamics on so-\ncial media. In WWW .\nDat Quoc Nguyen, Thanh Vu, and Anh Tuan Nguyen."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "2020. BERTweet: A pre-trained language model for\nEnglish tweets. In EMNLP .\nJohn Pavlopoulos, Leo Laugier, Alexandros Xenos,\nJeffrey Sorensen, and Ion Androutsopoulos. 2022.\nFrom the detection of toxic spans in online discus-\nsions to the analysis of toxic-to-civil transfer. In\nACL.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nand Dario Amodei. 2019. Language models are un-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "supervised multitask learners. Preprint .\nCollin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nlimits of transfer learning with a uni\ufb01ed text-to-text\ntransformer. JMLR , 21(140):1\u201367.Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "shades: Analyzing language in fake news and politi-\ncal fact-checking. In EMNLP .\nNils Reimers and Iryna Gurevych. 2019. Sentence-\nBERT: Sentence embeddings using siamese BERT-\nnetworks. In EMNLP-IJCNLP .\nCaitlin M. Rivers and Bryan L. Lewis. 2014. Eth-\nical research standards in a world of big data.\nF1000Research , 3(8).\nTimo Schick and Hinrich Sch\u00fctze. 2021. It\u2019s not just"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "size that matters: Small language models are also\nfew-shot learners. In NAACL .\nBruce Lannes Smith. 2022. Propaganda. Encyclopedia\nBritannica .\nVeronika Solopova, Oana-Iuliana Popescu, Christoph\nBenzm\u00fcller, and Tim Landgraf. 2023. Automated\nmultilingual detection of Pro-Kremlin propaganda\nin newspapers and Telegram posts . arXiv.\nHyunjin Song, Petro Tolochko, Jakob-Moritz Eberl,"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Olga Eisele, Esther Greussing, Tobias Heidenre-\nich, Fabienne Lind, Sebastian Galyga, and Hajo G.\nBoomgaarden. 2020. In validations we trust?\nThe impact of imperfect human annotations as a\ngold standard on the quality of validation of auto-\nmated content analysis. Political Communication ,\n37(4):550\u2013572.\nJames Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, and Arpit Mittal. 2018."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "FEVER: A large-scale dataset for Fact Extraction\nand VERi\ufb01cation. In NAACL .\nLaurens van der Maaten and Geoffrey Hinton. 2008.\nVisualizing data using t-SNE. JMLR , 9:2579\u20132605.\nPrashanth Vijayaraghavan and Soroush V osoughi.\n2022. TWEETSPIN: Fine-grained propaganda de-\ntection in social media using multi-view representa-\ntions. In NAACL .\nLiqiang Wang, Xiaoyu Shen, Gerard de Melo, and Ger-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "hard Weikum. 2020. Cross-domain learning for clas-\nsifying propaganda in online contents. In TTO.\nLingwei Wei, Dou Hu, Wei Zhou, Zhaojuan Yue, and\nSonglin Hu. 2021. Towards propagation uncertainty:\nEdge-enhanced bayesian graph convolutional net-\nworks for rumor detection. In ACL-IJCNLP .\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language process-\ning. In EMNLP .Rui Xia, Kaizhou Xuan, and Jianfei Yu. 2020. A state-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "independent and time-evolving network for early ru-\nmor detection in social media. In EMNLP .\nRowan Zellers, Ari Holtzman, Hannah Rashkin,\nYonatan Bisk, Ali Farhadi, Franziska Roesner, and\nYejin Choi. 2019. Defending against neural fake\nnews. In NeurIPS .\nKaimin Zhou, Chang Shu, Binyang Li, and Jey Han\nLau. 2019. Early rumour detection. In NAACL .A Keywords for Dataset Construction"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Table A.1 lists the keywords used in our dataset\nconstruction process to obtain candidate tweets for\nthe positive class ( D+) via accusations in replies.\nTable A.2 shows the keywords that are used to col-\nlect candidate tweets for the negative class ( D\u0000).\nGenerally, keywords relevant to the positive class\nshould mostly be terms that express accusations of"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "propaganda, while keywords relevant to the neg-\native class should be mostly terms that refer to\ngeneral activities of the war. The keywords in both\nlists contain further results from our construction\nprocedure in that we list the iteration in which they\nwere added to the list.\nKeywords ( D+) Iteration\nrussia(n)^propaganda 1\nrussia(n)^propagandist 1\nkremlin^propaganda 2\nkremlin^propagandist 2"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "kremlin^propagandist 2\nputinist(s) 2\nputinism 2\nrussia(n)^lie(s) 3\nwar^propaganda 3\nwar^lie(s) 3\nputin^propaganda 3\nputin^propagandist 3\nrussia(n)^fake news 3\nTable A.1: List of keywords used to get propaganda\naccusations and the corresponding iteration they were\nadded to the keyword list. The ^-operator indicates that\nboth keywords have to appear.\nKeywords ( D\u0000) Iteration\nrussia^war 1"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Keywords ( D\u0000) Iteration\nrussia^war 1\nukraine^war 1\n#istandwithrussia 1\n#istandwithputin 1\nrussian^war 2\nukrainian^war 2\n#russianukrainianwar 2\n#ukrainerussiawar 2\n#standwithrussia 2\n#standwithputin 2\n#russia 2\n#russiaukraine 2\n#ukraine 2\nputin^war 3\n#putin 3\n#lavrov 3\n#zakharova 3\n#nato 3\n#donbass 3\n#mariupol 3\nTable A.2: List of keywords used to get war-related"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "tweets and the corresponding iteration they were added\nto the keyword list. The ^-operator indicates that both\nkeywords have to appear.B Annotation Instructions\nFigure B.1 shows the instructions of batch an-\nnotations we present to the workers on Proli\ufb01c\n(https://www.prolific.co/ ). We follow best\npractices (Song et al., 2020). That is, we provide a"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "detailed and comprehensible description of the task,\na precise de\ufb01nition of the labels, and a transparent\ndisclosure that we use attention checks.\nGiven the complexity and subjective nature of\npropaganda, we put great emphasis on providing\nmeaningful and precise instructions for annotation.\nTherefore, the \ufb01nal instructions in Figure B.1 are\na result of several iterations of improvement, each"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "followed by an internal discussion and analysis.\nIn each iteration, we had three workers from Pro-\nli\ufb01c annotate a random sample of 100 tweets using\nthe current version of the instructions. We ana-\nlyzed the resulting annotations and focused on the\nsamples with disagreement. We then aimed to ad-\ndress the corresponding issues in the next update"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "of our instructions. In each iteration, we calculated\nthe inter-annotator agreement using Krippendorff\u2019s\nalpha (Krippendorff et al., 2016) and stopped iter-\nating after surpassing an agreement of 0.8 for the\n\ufb01rst time. As a result, we updated the instructions\nthree times.\nWe also followed best practices and applied at-\ntention checks. Participants failing the attention"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "checks were removed, and the annotation was re-\npeated.Instructions\nFirst, we would like to thank you for your interest on helping with Tweet annotations regarding their propagandistic\ncontent. Please read the following instructions carefully.\nDefinition: Please use the following defintion of Propaganda to guide you through the annotation process:"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "\u201dPropaganda is expression of opinion or action by individuals or groups deliberately designed to influence opinions\nor actions of other individuals or groups with reference to predetermined ends.\u201d\nPropaganda Detection: Y our task will be to annotate 100 Tweets regarding their propagandistic content. All Tweets"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "included in this task relate to the Russian-Ukrainian conflict. If you feel like you need more background information\non the Russian-Ukrainian conflict, we provide you with the following articles:\n\u2022 Russian government accounts are using a Twitter loophole to spread disinformation (theconversation.com)\n\u2022 Russia is swaying Twitter users outside the West to its side - The Economist (economist.com)"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "\u2022 Russia Takes Censorship to New Extremes, Stifling War Coverage - The New Y ork Times (nytimes.com)\n\u2022 Key Moments in the Russia-Ukraine War: A Timeline - The New Y ork Times (nytimes.com)\nIn your collection of Tweets, some of them will refer to certain conflict related events or facts. To know whether these"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Tweets contain Russian misinformation (which is a common propagandistic strategy), we ask you to perform a quick\nfact checking, if needed.\nTo further help you with the annotations, we provide the following list of notes on what to regard as propaganda and\nwhat not:\n\u2022 Misinformation in favour of the Russian government is regarded as propaganda"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "\u2022 Propaganda which is not in favour of the Russian gouvernment is not regarded as propaganda here (we are\nonly interested in detecting Russian propaganda)\n\u2022 If only small parts of the Tweet contains propagandistic content, we regard the entire tweet as propagandistic\n\u2022 Tweets containing a website/image/video URL and where the Tweet content itself does not classify into propa-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ganda or not, we regard as non-propagandistic\n\u2022 Tweets designed to spread pro-Russian-government stance (in form of e.g. slogans, hashtags, ...) are also\nregarded as propaganda\nPropaganda Strategy: In addition, we ask you to annotate the strategy behind the propagandistic content. Rus-\nsian propaganda is known to influence opinions around the world not only regarding the Russian government. If"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "you decided that a specific tweet contains propaganda, please specify whether it is designed to influence opinions\nregarding:\n\u2022 against Western countries\n\u2022 against Ukraine\n\u2022 pro Russian government\n\u2022 aimed at other countries\nAttention Checks: Please note that we have included attention checks to ensure reliable annotations. On the"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "following page we will ask you some basic questions regarding these instructions. If you have read these instructions\ncarefully, you will be able to answer them all correctly. Furthermore please note, that during the attention check\nyou can go back to the instructions and find the answers to the questions. If your answers to these questions are"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "incorrect, the survey will redirect you to Prolific and you will not be rewarded. Furthermore, we included synthetic\nTweets, where the classification into propaganda or no-propaganda is obvious.Figure B.1: Instructions for annotators.C Implemenation Details for Full\nFine-tuning\nFor \ufb01ne-tuning, we add a linear layer to the hidden\nrepresentation of the [CLS] token. The PLMs are"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "then \ufb01ne-tuned using the transformer framework\nfrom Huggingface (Wolf et al., 2020). We set the\nmaximum sequence length to 128. We use a train-\ning batch size of 32 and a learning rate of 4e-5. We\nfreeze the \ufb01rst 16 layers of the PLMs. For BERT-\nlarge and RoBERTa-large, we add emoji-tokens to\nthe vocabulary due to their frequent and meaning-\nful use in social media.10Weight updates are per-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "formed using the AdamW-optimizer (Loshchilov\nand Hutter, 2019). We \ufb01ne-tune for a maximum\nnumber of 5 epochs. We validate the performance\nevery 500 steps for \ufb01ne-tuning with TWEETSPIN\nand every 50 steps otherwise. Early stopping is\nused when the loss on the validation set does not\ndecrease for more than 5 validation steps.\nD Evaluation of the Auxiliary Task in\nLM-BFF-AT"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "LM-BFF-AT\nIn Table D.1, we report the performance of the\nauxiliary task in LM-BFF-AT, i.e., the performance\nof prompt-based learning using PSL.\nk\u2019 Weighted\nPrecisionWeighted\nRecallWeighted\nF1\n16 75.06\n(2.54)66.17\n(6.81)69.84\n(4.02)\n32 75.6\n(1.21)64.93\n(10.73)68.75\n(7.48)\n64 77.46\n(2.19)75.31\n(4.45)76.13\n(2.15)\n128 77.18\n(3.45)74.39\n(3.87)75.41\n(1.86)\nStated: mean (SD)."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "(3.87)75.41\n(1.86)\nStated: mean (SD).\nTable D.1: Evaluation results for the auxiliary task of\nprompt-based learning using PSL onHQP .\nE Hyper-Parameters for Classi\ufb01cation\nHeads of LM-BFF-AT\nFor our extension of the LM-BFF method, namely\nLM-BFF-AT, we perform hyper-parameter tuning\nusing grid search for the two classi\ufb01cation heads,\ni.e., the elastic net and the neural net. The tuning"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "grids are reported in Table E.1. We implement the\nelastic net using Python\u2019s scikit-learn module. The\nneural net is implemented using PyTorch.\n10For BERTweet-large, emoji-tokens were already incorpo-\nrated in the vocabulary during training.Classi\ufb01cation\nheadHyper-parameter Grid\nElastic netCost {0.1, 0.25, 0.5, 1, 2, 4, 8}\nL1-ratio {0.1, 0.15, 0.2, 0.25, 0.3,\n0.35}"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "0.35}\nNeural netDropout {0.2, 0.4, 0.6}\nLearning rate {0.001, 0.01, 0.02}\nBatch size {2, 4, 8, 16}\nNeurons in hidden\nlayerinput _dim\u0003{0.5, 1, 1.5, 2}\nTable E.1: Grids for hyper-parameter tuning of the\ntwo classi\ufb01cation heads for prompt-based learning with\nLM-BFF-AT. The cost C=1\n\u0015is the inverse of the regu-\nlarization strength. L1-ratio is the elastic net mixing pa-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "rameter (i.e., is equivalent to only using an L2-penalty\n(or L1-penalty) for L1-ratio = 0 (or L1-ratio = 1) and\nmixes both for 0<L1-ratio <1). Here, input _dim is\nthe number of input features and therefore depends on\nwhether only probabilities from the verbalizers or also\nauthor representations are used.\nF Propaganda Detection with Additional\nMeta Information"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Meta Information\nWe extend our propaganda detection so that we\nnot only use the content but the additional meta\ninformation (i.e., author features and pinned-tweet\nfeatures) for propaganda detection.\nF.1 Data Enrichment\nWe enrich HQP with additional meta information\nfrom the social network. Here, we use a compre-\nhensive set of author features (e.g., number of fol-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "lowers, account age, veri\ufb01ed status) and pinned-\ntweet11features (e.g., tweet age, number of likes,\nnumber of retweets). Our data further includes\nthe pro\ufb01le description of authors using embed-\ndings from SBERT (Reimers and Gurevych, 2019).\nWe choose SBERT due to its strength in captur-\ning meaningful representations from short text\n(Reimers and Gurevych, 2019). A few tweets cor-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "responded to authors whose accounts were already\ndeleted, which reduces our dataset to the \ufb01nal size\nofN= 29;596. We note that for fair benchmark-\ning we used the dataset of size N= 29;596for\nall experiments. The full list of features is in Ap-\npendix F.2.\nF.2 Summary Statistics\nTable F.1 reports summary statistics of the author\nfeatures for HQP. We compare mean and standard"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "11Every Twitter user can choose to pin one (self-written)\ntweet to her/his account, which is then always displayed at the\ntop of the pro\ufb01le.Propaganda = true Propaganda = false\nMean Median Mean Median\nVeri\ufb01ed (=1; not=0) 0.09 0 0.19 0\n#Followers 102784.72 513 595308.01 13405\n#Following 1927.58 530.5 3237.82 786\n#Tweets 37780.17 11123.5 64060.48 16811\n#Listed\u0003633.36 5 2449.10 11"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "#Listed\u0003633.36 5 2449.10 11\nAccount age (in days) 2272.17 1938 2763.28 2895\n#Followers divided by Account age 28.05 0.37 161.74 0.71\n#Following divided by Account age 1.19 0.34 1.48 0.34\n#Tweets divided by Account age 19.34 7.915 25.76 8.58\n\u0003Number of Twitter lists (i.e., a curated group of accounts) comprising the account of the author.\nTable F.1: Summary statistics of author features in HQP ."}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "Propaganda = true Propaganda = false\nMean Median Mean Median\nAccount age (in days) 365.30 198 366.82 170\n#Retweets 573.12 13 1051.95 17\n#Replies 251.85 6 416.71 7\n#Likes 2232.50 39 4336.85 62\n#Quotes 70.19 2 131.85 2\n#Retweets divided by account age 16.70 0.08 30.49 0.14\n#Replies\ndivided by account age5.09 0.03 11.95 0.05\n#Likes divided by account age 59.17 0.25 111.47 0.5"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "#Quotes divided by account age 1.14 0.01 3.18 0.01\nTable F.2: Summary statistics for pinned-tweet features of authors in HQP .\ndeviation separately for both propagandistic and\nnon-propagandistic content. In line with previous\n\ufb01ndings (Geissler et al., 2022), we \ufb01nd that authors\nof propagandistic content are, on average, less often\nveri\ufb01ed, have fewer followers and tweets, and are"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "characterized by a younger account age. Table F.2\nreports summary statistics for the pinned-tweet fea-\ntures of the authors in HQP.\nF.3 Adaptation of Methods\n(i) Full \ufb01ne-tuning: We modify the classi\ufb01cation\nhead so that we perform full \ufb01ne-tuning with author\nand pinned-tweet features. The self-description of\ntweet authors is encoded into a 768-dimensional"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "vector using SBERT. We normalize the numerical\nfeatures from Table F.1 and Table F.2 and append\nthem to the self-description vector to get an author\nrepresentation. We concatenate the hidden repre-\nsentation of the [CLS] token generated by the PLM\nand the author representation and again feed them\nto a linear layer. The \ufb01ne-tuning procedure and the\nhyper-parameters are identical to those described"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "in Section 4.1.\n(ii) Prompt-based learning: We create the\nsame author representation as in (i). Here, we con-\ncatenate the author representation with the verbal-\nizer probabilities for both BLandPSL and again\nfeed them to a classi\ufb01cation head as in LM-BFF-AT.\nThe prompt-based learning procedure is identical tothat in Section 4.2, i.e., we select the optimal tem-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "plate and verbalizer from each run in Section 5.3.\nThe tuning grids for hyper-parameter tuning for the\ntwo classi\ufb01cation heads are identical to those in\nTable E.1.\nF.4 Results\nTable F.3 reports the prediction performance when\nadditionally using author features. Values are in\nbold if the model that uses additional author and\npinned-tweet features outperforms the counterpart"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "without author features. Overall, we observe a ten-\ndency that the results improve when additionally\nusing author features. This tendency is seen for\nboth full \ufb01ne-tuning and prompt-based learning.\nHowever, the performance gain from using the con-\ntent is larger than the performance gain from using\nauthor features. This can be expected as propa-"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "ganda spreaders typically do not explicitly disclose\ntheir manipulative intention but instead aim to de-\nceive users.PLM P R F1 AUC(i) Full \ufb01ne-tuningBERT 64.58\n(3.19)62.40\n(1.94)63.42\n(1.64)88.54\n(0.81)\nRoBERTa 67.61\n(3.05)69.59\n(3.02)68.52\n(2.04)91.37\n(1.02)\nBERTweet 67.06\n(3.39)72.68\n(1.54)69.71\n(1.79)92.06\n(0.86)\nk0P R F1 AUC(ii) Prompt-based learning16 22.38\n(3.37)64.94\n(9.79)32.98"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "(3.37)64.94\n(9.79)32.98\n(3.49)64.99\n(4.16)\n32 24.75\n(6.24)65.16\n(3.6)35.70\n(4.16)69.29\n(4.48)\n64 27.73\n(2.80)70.72\n(4.07)39.74\n(2.88)74.88\n(2.21)\n128 30.81\n(2.86)76.38\n(1.52)43.86\n(3.02)79.46\n(2.89)\nStated: mean (SD). P: precision. R: recall.\nTable F.3: Evaluation results of (i) full \ufb01ne-tuning and\n(ii) prompt-based learning on HQP while incorporating"}, {"source": "A Human-Annotated Dataset for Detecting Online Propaganda.pdf", "text": "author and pinned-tweet features. Results are shown in\nbold if the performance with author and pinned-tweet\nfeatures is better than the performance without author\nfeatures."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "Fine-Grained Analysis of Propaganda in News Articles\nGiovanni Da San Martino1Seunghak Yu2Alberto Barr \u00b4on-Cede \u02dcno3\nRostislav Petrov4Preslav Nakov1\n1Qatar Computing Research Institute, HBKU, Qatar\n2MIT Computer Science and Arti\ufb01cial Intelligence Laboratory, Cambridge, MA, USA\n3Universit `a di Bologna, Forl `\u0131, Italy,4A Data Pro, So\ufb01a, Bulgaria\nfgmartino, pnakov g@hbku.edu.qa"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "fgmartino, pnakov g@hbku.edu.qa\nseunghak@csail.mit.edu ,a.barron@unibo.it\nrostislav.petrov@adata.pro\nAbstract\nPropaganda aims at in\ufb02uencing people\u2019s\nmindset with the purpose of advancing a spe-\nci\ufb01c agenda. Previous work has addressed\npropaganda detection at the document level,\ntypically labelling allarticles from a propa-\ngandistic news outlet as propaganda. Such"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "noisy gold labels inevitably affect the quality\nof any learning system trained on them. A\nfurther issue with most existing systems is the\nlack of explainability. To overcome these lim-\nitations, we propose a novel task: performing\n\ufb01ne-grained analysis of texts by detecting all\nfragments that contain propaganda techniques\nas well as their type. In particular, we cre-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ate a corpus of news articles manually anno-\ntated at the fragment level with eighteen pro-\npaganda techniques and we propose a suit-\nable evaluation measure. We further design\na novel multi-granularity neural network, and\nwe show that it outperforms several strong\nBERT-based baselines.\n1 Introduction\nResearch on detecting propaganda has focused"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "primarily on articles (Barr \u00b4on-Cedeno et al., 2019;\nRashkin et al., 2017). In many cases, there are no\nlabeled data for individual articles, but there are\nsuch labels for entire news outlets. Thus, often all\narticles from the same news outlet get labeled the\nway that this outlet is labeled. Yet, it has been\nobserved that propagandistic sources could post"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "objective non-propagandistic articles periodically\nto increase their credibility (Horne et al., 2018).\nSimilarly, media generally recognized as objec-\ntive might occasionally post articles that promote a\nparticular editorial agenda and are thus propagan-\ndistic. Thus, it is clear that transferring the label\nof the news outlet to each of its articles, could in-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "troduce noise. Such labels can still be useful for\ntraining robust systems, but they cannot be used to\nget a fair assessment of a system at testing time.One option to deal with the lack of labels for arti-\ncles is to crowdsource the annotation. However, in\npreliminary experiments we observed that the av-\nerage annotator cannot detach her personal mind-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "set from the judgment of propaganda and bias,\ni.e., if a clearly propagandistic text expresses ideas\naligned with the annotator\u2019s beliefs, it is unlikely\nthat she would judge it as such.\nWe argue that in order to study propaganda in a\nsound and reliable way, we need to rely on high-\nquality trusted professional annotations and it is\nbest to do so at the fragment level, targeting spe-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ci\ufb01c techniques rather than using a label for an en-\ntire document or an entire news outlet.\nOurs is the \ufb01rst work that goes at a \ufb01ne-grained\nlevel: identifying speci\ufb01c instances of propaganda\ntechniques used within an article. In particular, we\ncreate a corresponding corpus. For this purpose,\nwe asked six experts to annotate articles from\nnews outlets recognized as propagandistic and"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "non-propagandistic, marking speci\ufb01c text spans\nwith eighteen propaganda techniques. We also\ndesigned appropriate evaluation measures. Taken\ntogether, the annotated corpus and the evalua-\ntion measures represent the \ufb01rst manually-curated\nevaluation framework for the analysis of \ufb01ne-\ngrained propaganda. We release the corpus (350K\ntokens) as well as our code in order to enable fu-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ture research.1Our contributions are as follows:\n\u000fWe formulate a new problem: detect the use\nof speci\ufb01c propaganda techniques in text.\n\u000fWe build a new large corpus for this problem.\n\u000fWe propose a suitable evaluation measure.\n\u000fWe design a novel multi-granularity neural\nnetwork, and we show that it outperforms\nseveral strong BERT-based baselines."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "several strong BERT-based baselines.\n1The corpus, the evaluation measures, and the models are\navailable at http://propaganda.qcri.org/arXiv:1910.02517v1  [cs.CL]  6 Oct 2019Our corpus could enable research in propagandis-\ntic and non-objective news, including the devel-\nopment of explainable AI systems. A system that\ncan detect instances of use of speci\ufb01c propagan-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "distic techniques would be able to make it explicit\nto the users why a given article was predicted to be\npropagandistic. It could also help train the users to\nspot the use of such techniques in the news.\nThe remainder of this paper is organized as\nfollows: Section 2 presents the propagandistic\ntechniques we focus on. Section 3 describes\nour corpus. Section 4 discusses an evaluation"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "measures for comparing labeled fragments. Sec-\ntion 5 presents the formulation of the task and\nour proposed models. Section 6 describes our ex-\nperiments and the evaluation results. Section 7\npresents some relevant related work. Finally, Sec-\ntion 8 concludes and discusses future work.\n2 Propaganda and its Techniques\nPropaganda comes in many forms, but it can"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "be recognized by its persuasive function, sizable\ntarget audience, the representation of a speci\ufb01c\ngroup\u2019s agenda, and the use of faulty reasoning\nand/or emotional appeals (Miller, 1939). Since\npropaganda is conveyed through the use of a num-\nber of techniques, their detection allows for a\ndeeper analysis at the paragraph and the sentence\nlevel that goes beyond a single document-level"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "judgment on whether a text is propagandistic.\nWhereas the de\ufb01nition of propaganda is widely\naccepted in the literature, the set of propaganda\ntechniques differs between scholars (Torok, 2015).\nFor instance, Miller (1939) considers seven tech-\nniques, whereas Weston (2018) lists at least 24,\nand Wikipedia discusses 69.2The differences are\nmainly due to some authors ignoring some tech-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "niques, or using de\ufb01nitions that subsume the def-\ninition used by other authors. Below, we describe\nthe propaganda techniques we consider: a curated\nlist of eighteen items derived from the aforemen-\ntioned studies. The list only includes techniques\nthat can be found in journalistic articles and can\nbe judged intrinsically, without the need to retrieve"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "supporting information from external resources.\nFor example, we do not include techniques such as\ncard stacking (Jowett and O\u2019Donnell, 2012, page\n237), since it would require comparing against ex-\nternal sources of information.\n2http://en.wikipedia.org/wiki/\nPropaganda_techniques ; last visit May 2019.The eighteen techniques we consider are as fol-\nlows (cf. Table 1 for examples):"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "lows (cf. Table 1 for examples):\n1. Loaded language. Using words/phrases with\nstrong emotional implications (positive or nega-\ntive) to in\ufb02uence an audience (Weston, 2018, p. 6).\nEx.: \u201c[. . . ] a lone lawmaker\u2019s childish shouting.\u201d\n2. Name calling or labeling. Labeling the ob-\nject of the propaganda campaign as either some-\nthing the target audience fears, hates, \ufb01nds un-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "desirable or otherwise loves or praises (Miller,\n1939). Ex.: \u201cRepublican congressweasels\u201d, \u201cBush\nthe Lesser.\u201d\n3. Repetition. Repeating the same message over\nand over again, so that the audience will eventually\naccept it (Torok, 2015; Miller, 1939).\n4. Exaggeration or minimization. Either rep-\nresenting something in an excessive manner: mak-\ning things larger, better, worse (e.g., \u201cthe best of"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "the best\u201d, \u201cquality guaranteed\u201d) or making some-\nthing seem less important or smaller than it ac-\ntually is (Jowett and O\u2019Donnell, 2012, p. 303),\ne.g., saying that an insult was just a joke. Ex.:\n\u201cDemocrats bolted as soon as Trumps speech\nended in an apparent effort to signal they can\u2019t\neven stomach being in the same room as the pres-\nident\u201d; \u201cI was not \ufb01ghting with her; we were just\nplaying.\u201d"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "playing.\u201d\n5. Doubt. Questioning the credibility of some-\none or something. Ex.: A candidate says about his\nopponent: \u201cIs he ready to be the Mayor?\u201d\n6. Appeal to fear/prejudice. Seeking to build\nsupport for an idea by instilling anxiety and/or\npanic in the population towards an alternative,\npossibly based on preconceived judgments. Ex.:\n\u201cstop those refugees; they are terrorists.\u201d"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "7. Flag-waving. Playing on strong national feel-\ning (or with respect to a group, e.g., race, gender,\npolitical preference) to justify or promote an ac-\ntion or idea (Hobbs and Mcgee, 2008). Ex.: \u201cen-\ntering this war will make us have a better future in\nour country.\u201d\n8. Causal oversimpli\ufb01cation. Assuming one\ncause when there are multiple causes behind an"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "issue. We include scapegoating as well: the trans-\nfer of the blame to one person or group of people\nwithout investigating the complexities of an issue.\nEx.: \u201cIf France had not declared war on Germany,\nWorld War II would have never happened.\u201dDoc ID Technique \u000fSnippet\n783702663 loaded language \u000funtil forced to act by a worldwide storm of outrage ."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "732708002 name calling, labeling \u000fdismissing the protesters as lefties and hugging Barros publicly\n701225819 repetition\u000fFarrakhan repeatedly refers to Jews as Satan . He states to his audience [. . . ] call them by\ntheir real name, \u2018 Satan .\u2019\n782086447 exaggeration, minimization \u000fheal the situation of extremely grave immoral behavior"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "761969038 doubt\u000fCan the same be said for the Obama Administration ?\n696694316 appeal to fear/prejudice \u000fA dark, impenetrable and irreversible winter of persecution of the\nfaithful by their own shepherds will fall .\n776368676 flag-waving\u000fcon\ufb02icted, and his 17 Angry Democrats that are doing his dirty work are a disgrace to\nUSA ! \u2014Donald J. Trump"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "USA ! \u2014Donald J. Trump\n776368676 flag-waving\u000fattempt (Mueller) to stop the will of We the People !!! It\u2019s time to jail Mueller\n735815173 causal oversimplification \u000fhe said The people who talk about the \u201dJewish question\u201d are gen-\nerally anti-Semites . Somehow I don\u2019t think\n781768042 causal oversimplification \u000fwill not be reversed, which leaves no alternative as to why God"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "judges and is judging America today\n111111113 slogans\u000fBUILD THE WALL!\u201d Trump tweeted.\n783702663 appeal to authority \u000fMonsignor Jean-Franois Lantheaume, who served as \ufb01rst Counsellor of\nthe Nunciature in Washington, con\ufb01rmed that \u201cVigan said the truth. Thats all\u201d\n783702663 black-and-white fallacy \u000fFrancis said these words: Everyone is guilty for the good he could have"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "done and did not do . . . If we do not oppose evil, we tacitly feed it .\n729410793 thought-terminating cliches \u000fI do not really see any problems there. Marx is the President\n770156173 whataboutism\u000fPresident Trump \u2014 who himself avoided national military service in the 1960\u2019s\u2014 keeps\nbeating the war drums over North Korea"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "beating the war drums over North Korea\n778139122 reductio ad hitlerum \u000f\u201cVichy journalism,\u201d a term which now \ufb01ts so much of the mainstream media.\nIt collaborates in the same way that the Vichy government in France collaborated with the Nazis.\n778139122 red herring\u000fIt describes the tsunami of vindictive personal abuse that has been heaped upon Julian from"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "well-known journalists, many claiming liberal credentials. The Guardian, which used to consider itself the\nmost enlightened newspaper in the country , has probably been the worst.\n698018235 bandwagon\u000fHe tweeted, \u201c EU no longer considers #Hamas a terrorist group. Time for US to do same.\u201d"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "729410793 obfusc., int. vagueness, confusion \u000fThe cardinal\u2019s of\ufb01ce maintains that rather than saying \u201cyes,\u201d there is\na possibility of liturgical \u201cblessing\u201d of gay unions, he answered the question in a more subtle way without\ngiving an explicit \u201cyes.\u201d\n783702663 straw man\u000f\u201cTake it seriously, but with a large grain of salt.\u201d Which is just Allen\u2019s more nuanced way of\nsaying: \u201cDon\u2019t believe it .\u201d"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "saying: \u201cDon\u2019t believe it .\u201d\nTable 1: Instances of the different propaganda techniques from our corpus. We show the document ID, the tech-\nnique, and the text snippet, in bold. When necessary, some context is provided to better understand the example.\n9. Slogans. A brief and striking phrase that may\ninclude labeling and stereotyping. Slogans tend to"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "act as emotional appeals (Dan, 2015). Ex.: \u201cMake\nAmerica great again!\u201d\n10. Appeal to authority. Stating that a claim is\ntrue simply because a valid authority/expert on the\nissue supports it, without any other supporting ev-\nidence (Goodwin, 2011). We include the special\ncase where the reference is not an authority/expert,\nalthough it is referred to as testimonial in the liter-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ature (Jowett and O\u2019Donnell, 2012, p. 237).\n11. Black-and-white fallacy, dictatorship. Pre-\nsenting two alternative options as the only pos-\nsibilities, when in fact more possibilities exist\n(Torok, 2015). As an extreme case, telling the\naudience exactly what actions to take, eliminat-\ning any other possible choice ( dictatorship ).Ex.:\n\u201cYou must be a Republican or Democrat; you are"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "not a Democrat. Therefore, you must be a Repub-\nlican\u201d; \u201cThere is no alternative to war.\u201d12. Thought-terminating clich \u00b4e.Words or\nphrases that discourage critical thought and mean-\ningful discussion about a given topic. They are\ntypically short, generic sentences that offer seem-\ningly simple answers to complex questions or\nthat distract attention away from other lines of"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "thought (Hunter, 2015, p. 78). Ex.: \u201cit is what it\nis\u201d; \u201cyou cannot judge it without experiencing it\u201d;\n\u201cit\u2019s common sense\u201d, \u201cnothing is permanent ex-\ncept change\u201d, \u201cbetter late than never\u201d; \u201cmind your\nown business\u201d; \u201cnobody\u2019s perfect\u201d; \u201cit doesn\u2019t\nmatter\u201d; \u201cyou can\u2019t change human nature.\u201d\n13. Whataboutism. Discredit an opponent\u2019s posi-\ntion by charging them with hypocrisy without di-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "rectly disproving their argument (Richter, 2017).\nFor example, mentioning an event that discred-\nits the opponent: \u201cWhat about . . . ?\u201d (Richter,\n2017). Ex.: Russia Today had a proclivity for\nwhataboutism in its coverage of the 2015 Balti-\nmore and Ferguson protests in the US, which re-vealed a consistent refrain: \u201cthe oppression of\nblacks in the US has become so unbearable that"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "the eruption of violence was inevitable\u201d, and that\nthe US therefore lacks \u201cthe moral high ground to\ndiscuss human rights issues in countries like Rus-\nsia and China.\u201d\n14. Reductio ad Hitlerum. Persuading an audi-\nence to disapprove an action or idea by suggest-\ning that the idea is popular with groups hated in\ncontempt by the target audience. It can refer to"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "any person or concept with a negative connota-\ntion (Teninbaum, 2009). Ex.: \u201cOnly one kind of\nperson can think this way: a communist.\u201d\n15. Red herring. Introducing irrelevant mate-\nrial to the issue being discussed, so that every-\none\u2019s attention is diverted away from the points\nmade (Weston, 2018, p. 78). Those subjected to\na red herring argument are led away from the is-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "sue that had been the focus of the discussion and\nurged to follow an observation or claim that may\nbe associated with the original claim, but is not\nhighly relevant to the issue in dispute (Teninbaum,\n2009). Ex.: \u201cYou may claim that the death penalty\nis an ineffective deterrent against crime \u2013 but what\nabout the victims of crime? How do you think sur-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "viving family members feel when they see the man\nwho murdered their son kept in prison at their ex-\npense? Is it right that they should pay for their\nson\u2019s murderer to be fed and housed?\u201d\n16. Bandwagon. Attempting to persuade the tar-\nget audience to join in and take the course of ac-\ntion because \u201ceveryone else is taking the same ac-\ntion\u201d (Hobbs and Mcgee, 2008). Ex.: \u201cWould you"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "vote for Clinton as president? 57% say yes.\u201d\n17. Obfuscation, intentional vagueness, confu-\nsion. Using deliberately unclear words, so that the\naudience may have its own interpretation (Supra-\nbandari, 2007; Weston, 2018, p. 8). For instance,\nwhen an unclear phrase with multiple possible\nmeanings is used within the argument, and, there-\nfore, it does not really support the conclusion. Ex.:"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "\u201cIt is a good idea to listen to victims of theft.\nTherefore, if the victims say to have the thief shot,\nthen you should do it.\u201d\n18. Straw man. When an opponent\u2019s proposition\nis substituted with a similar one which is then re-\nfuted in place of the original (Walton, 1996). We-\nston (2018, p. 78) speci\ufb01es the characteristics of\nthe substituted proposition: \u201ccaricaturing an op-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "posing view so that it is easy to refute.\u201dProp Non-prop All\narticles 372 79 451\navg length (lines) 49.8 34.4 47.1\navg length (words) 973.2 635.4 914.0\navg length (chars) 5,942 3,916 5,587\nTable 2: Statistics about the articles retrieved\nwith respect to the category of the media source:\nprop agandistic, non-prop agandistic, and all together.\nNews Outlet # News Outlet #"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "News Outlet # News Outlet #\nFreedom Outpost 133 The Remnant Magazine 14\nFrontpage Magazine 56 Breaking911 11\nshtfplan.com 55 truthuncensored.net 8\nLew Rockwell 26 The Washington Standard 6\nvdare.com 20 www.unz.com 5\nremnantnewspaper.com 19 www.clashdaily.com 1\nPersonal Liberty 18\nTable 3: Number of articles retrieved from news outlets\ndeemed propagandistic by Media Bias/Fact Check."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "We provided the above de\ufb01nitions, together\nwith some examples and an annotation schema, to\nour professional annotators, so that they can man-\nually annotate news articles. The details are pro-\nvided in the next section.\n3 Data Creation\nWe retrieved 451 news articles from 48 news out-\nlets, both propagandistic and non-propagandistic,\nwhich we annotated as described below.\n3.1 Article Retrieval"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "3.1 Article Retrieval\nFirst, we selected 13 propagandistic and 36 non-\npropagandistic news media outlets, as labeled by\nMedia Bias/Fact Check.3Then, we retrieved arti-\ncles from these sources, as shown in Table 2. Note\nthat 82.5% of the articles are from propagandistic\nsources, and these articles tend to be longer.\nTable 3 shows the number of articles re-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "trieved from each propagandistic outlet. Over-\nall, we have 350k word tokens, which is compa-\nrable to standard datasets for other \ufb01ne-grained\ntext analysis tasks, such as named entity recog-\nnition, e.g., CoNLL\u201902 and CoNLL\u201903 covered\n381K, 333K, 310K, and 301K tokens for Spanish,\nDutch, German, and English, respectively (Tjong\nKim Sang, 2002; Tjong Kim Sang and De Meul-\nder, 2003)."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "der, 2003).\n3http://mediabiasfactcheck.com/3.2 Manual Annotation\nWe aim at obtaining text fragments annotated with\nany of the 18 techniques described in Section 2\n(see Figure 1 for an example). Since the time re-\nquired to understand and memorize all the pro-\npaganda techniques is signi\ufb01cant, this annotation\ntask is not well-suited for crowdsourcing. We part-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "nered instead with a company that performs pro-\nfessional annotations, A Data Pro.4Appendix A\nshows details about the instructions and the tools\nprovided to the annotators.\nWe computed the \rinter-annotator agree-\nment (Mathet et al., 2015). We chose \rbecause\n(i) it is designed for tasks where both the span and\nits label are to be found and ( ii) it can deal with"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "overlaps in the annotations by the same annotator5\n(e.g., instances of doubt often use name calling or\nloaded language to reinforce their message). We\ncomputed\rs, where we only consider the iden-\nti\ufb01ed spans, regardless of the technique, and \rsl,\nwhere we consider both the spans and their labels.\nLetabe an annotator. In a preliminary exer-\ncise, four annotators a[1;::;4]annotated six articles"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "independently, and the agreement was \rs= 0:34\nand\rsl= 0:31. Even taking into account that\n\ris a pessimistic measure (Mathet et al., 2015),\nthese values are low. Thus, we designed an an-\nnotation schema composed of two stages and in-\nvolving two annotator teams, each of which cov-\nered about 220documents. In stage 1, both a1and\na2annotated the same documents independently."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "In stage 2, they gathered with a consolidator c1to\ndiscuss all instances and to come up with a \ufb01nal\nannotation. Annotators a3anda4and consolida-\ntorc2followed the same procedure. Annotating\nthe full corpus took 395 man hours.\nTable 4 shows the \ragreements on the full cor-\npus. As in the preliminary annotation, the agree-\nments for both teams are relatively low: 0.30 and"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "0.34 for span selection, and slightly lower when la-\nbeling is considered as well. After the annotators\ndiscussed with the consolidator on the disagreed\ncases, the\rvalues got much higher: up to 0.74\nand 0.76 for each team. We further analyzed the\nannotations to determine the main cause for the\ndisagreement by computing the percentage of in-\nstances spotted by one annotator only in the \ufb01rst"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "stage that are retained as gold annotations.\n4http://www.aiidatapro.com\n5See (Meyer et al., 2014; Mathet et al., 2015) for other\nalternatives, which lack some properties; ( ii) in particular.Annotations spans ( \rs) +labels ( \rsl)\na1a2 0.30 0.24\na3a4 0.34 0.28\na1c1 0.58 0.54\na2c1 0.74 0.72\na3c2 0.76 0.74\na4c2 0.42 0.39\nTable 4:\rinter-annotator agreement between an-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "notators spotting spans alone ( spans ) and spotting\nspans+labeling ( +labels ). The top-2 rows refer to the\n\ufb01rst stage: agreement between annotators. The bottom\n4 rows refer to the consolidation stage: agreement be-\ntween each annotator and the \ufb01nal gold annotation.\nFigure 1: Example given to the annotators.\nOverall the percentage is 53% (5;921 out of\n11;122), and for each annotator is a1= 70% ,"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "a2= 48% ,a3= 57% ,a4= 31% . Observ-\ning such percentages together with the relatively\nlow differences in Table 4 between \rsand\rslfor\nthe same pairs (ai;aj)and(ai;cj), we can con-\nclude that disagreements are in general not due to\nthe two annotators assigning different labels to the\nsame or mostly overlapping spans, but rather be-\ncause one has missed an instance in the \ufb01rst stage."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "3.3 Statistics about the Dataset\nThe total number of technique instances found\nin the articles, after the consolidation phase, is\n7;485, with respect to a total number of 21;230\nsentences (35.2%). Table 5 reports some statistics\nabout the annotations. The average propagandis-\ntic fragment has a length of 47characters and the\naverage length of a sentence is 112.5 characters."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "On average, the propagandistic techniques are\nhalf a sentence long. The most common ones are\nloaded language andname calling, labeling with\n2;547and1;294occurrences, respectively. They\nappear 6.7 and 4.7 times per article, while no other\ntechnique appears more than twice. Note that rep-\netition are in\ufb02ated as we asked the annotators to"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "mark both the original and the repeated instances.Propaganda Technique inst avg. length\nloaded language 2,547 23:70\u000625:30\nname calling, labeling 1,294 26:10\u000619:88\nrepetition 767 16:90\u000618:92\nexaggeration, minimization 571 45:36\u000635:55\ndoubt 562 123:21\u000697:65\nappeal to fear/prejudice 367 93:56\u000674:59\n\ufb02ag-waving 330 61:88\u000668:61\ncausal oversimpli\ufb01cation 233 121:03\u000671:66\nslogans 172 25:30\u000613:49"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "slogans 172 25:30\u000613:49\nappeal to authority 169 131:23\u0006123:2\nblack-and-white fallacy 134 98:42\u000673:66\nthought-terminating cliches 95 34:85\u000629:28\nwhataboutism 76 120:93\u000669:62\nreductio ad hitlerum 66 94:58\u000664:16\nred herring 48 63:79\u000661:63\nbandwagon 17 100:29\u000697:05\nobfusc., int. vagueness, confusion 17 107:88\u000686:74\nstraw man 15 79:13\u000650:72\nall 7,485 46:99\u000661:45"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "all 7,485 46:99\u000661:45\nTable 5: Corpus statistics including instances per tech-\nnique and their avg. length in terms of characters.\n4 Evaluation Measures\nOur task is a sequence labeling one, with the fol-\nlowing key characteristics: ( i) a large number of\ntechniques whose spans might overlap in the text,\nand ( ii) large lengths of these spans. This requires"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "an evaluation measure that gives credit for par-\ntial overlaps.6We derive an ad hoc measure fol-\nlowing related work on named entity recognition\n(NER) (Nadeau and Sekine, 2007) and (intrinsic)\nplagiarism detection (PD) (Potthast et al., 2010).\nWhile in NER, the relevant fragments tend to be\nshort multi-word strings, in PD \u2014and in our pro-\npaganda technique identi\ufb01cation task\u2014 the length"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "varies widely (cf. Table 5), and instances span\nfrom single tokens to full sentences or even longer\npieces of text. Thus, in our precision and re-\ncall versions, we give partial credit to imperfect\nmatches at the character level, as in PD.\nLet document dbe represented as a sequence of\ncharacters. A propagandistic text fragment is then\nrepresented as t= [ti;:::;t j]\u0012d. A document"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "includes a set of (possibly overlapping) fragments\nT. Similarly, a learning algorithm produces a set S\nwith fragments s= [sm;:::;s n], predicted on d.\nA labeling function l(x)2f1;:::; 18gassociates\ns2Sto one of the eighteen techniques. Figure 2\ngives examples of gold and predicted fragments.\n6The evaluation measures for the CoNLL\u201902 and\nCoNLL\u201903 NER tasks, where an instance is considered prop-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "erly identi\ufb01ed if and only if both the boundaries and the label\nare correct (Tsai et al., 2006), are not suitable in our context.\nt1 (c=1)                     t2 (c=2)             t3 (c=3) T\ns1 (c=1)              s2 (c=2) s3(c=2)       s4 (c=4)\nSFigure 2: Example of gold annotation (top) and the pre-\ndictions of a supervised model (bottom) in a document"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "represented as a sequence of characters. The class of\neach fragment is shown in parentheses. s1goes beyond\nt1\u2019s proper boundaries; s2ands3partially spot t2, but\nfail to identify it entirely; s4spots the exact boundaries\noft3, but fails to assign it the right label.\nWe de\ufb01ne the following function to handle par-\ntial overlaps between fragments with same labels:\nC(s;t;h ) =j(s\\t)j"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "C(s;t;h ) =j(s\\t)j\nh\u000e(l(s);l(t)); (1)\nwherehis a normalizing factor and \u000e(a;b) = 1 if\na=b, and 0otherwise. In the future, \u000ecould be\nre\ufb01ned to account for custom distance functions\nbetween classes, e.g., we might consider mistak-\ningloaded language forname calling or labeling\nless problematic than confusing it with Reduction\nad Hitlerum . Given Eq. (1), we now de\ufb01ne vari-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ants of precision and recall able to account for the\nimbalance in the corpus:\nP(S;T) =1\njSjX\ns2S;\nt2TC(s;t;jsj); (2)\nR(S;T) =1\njTjX\ns2S;\nt2TC(s;t;jtj); (3)\nWe de\ufb01ne Eq. (2) to be zero if jSj= 0 and\nEq. (3) to be zero if jTj= 0. Following Potthast\net al. (2010), in Eqs. (2) and (3) we penalize sys-\ntems predicting too many or too few instances by\ndividing byjSjandjTj, respectively, e.g., in Fig-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ure 2P(fs2;s3g;T)< P(fs3g;T). Finally, we\ncombine Eqs. (2) and (3) into an F 1-measure, the\nharmonic mean of precision and recall.\nHaving a separate function Cto be responsible\nfor comparing two annotations gives us some ad-\nditional \ufb02exibility that is missing in standard NER\nmeasures that operate at the token/character level.\nFor example, in Eq. (1) we could easily change the"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "factor that gives credit for partial overlaps by be-\ning more forgiving when only few characters are\nwrong.5 Tasks and Proposed Models\nWe de\ufb01ne two tasks based on the corpus described\nin Section 3: ( i)SLC (Sentence-level Classi\ufb01ca-\ntion) , which asks to predict whether a sentence\ncontains at least one propaganda technique, and\n(ii)FLC (Fragment-level classi\ufb01cation) , which"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "asks to identify both the spans and the type of pro-\npaganda technique. Note that these two tasks are\nof different granularities, g1andg2, i.e., tokens for\nFLC and sentences for SLC. We split the corpus\ninto training, development and test, each contain-\ning 293, 57, 101 articles and 14,857, 2,108, 4,265\nsentences.\n5.1 Baselines\nWe depart from BERT (Devlin et al., 2019), as it"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "has achieved state-of-the-art performance on mul-\ntiple NLP benchmarks, and we design three base-\nlines based on it.\nBERT. We add a linear layer on top of BERT\nand we \ufb01ne-tune it, as suggested in (Devlin et al.,\n2019). For the FLC task, we feed the \ufb01nal hid-\nden representation for each token to a layer Lg2\nthat makes a 19-way classi\ufb01cation: does this to-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ken belong to one of the eighteen propaganda tech-\nniques or to none of them (cf. Figure 3-a). For the\nSLC task, we feed the \ufb01nal hidden representation\nfor the special [CLS] token, which BERT uses to\nrepresent the full sentence, to a two-dimensional\nlayerLg1to make a binary classi\ufb01cation.\nBERT-Joint. We use the layers for both tasks\nin the BERT baseline, Lg1andLg2, and we train"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "for both FLC and SLC jointly (cf. Figure 3-b).\nBERT-Granularity. We modify BERT-Joint to\ntransfer information from SLC directly to FLC.\nInstead of using only the Lg2layer for FLC, we\nconcatenate Lg1andLg2, and we add an extra\n19-dimensional classi\ufb01cation layer Lg1;2on top of\nthat concatenation to perform the prediction for\nFLC (cf. Figure 3-c).\n5.2 Multi-Granularity Network"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "5.2 Multi-Granularity Network\nWe propose a model that can drive the higher-\ngranularity task (FLC) on the basis of the lower-\ngranularity information (SLC), rather than simply\nusing low-granularity information directly. Fig-\nure 3-d shows the architecture of this model. More\ngenerally, suppose there are ktasks of increas-\ning granularity, e.g., document-level, paragraph-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "level, sentence-level, word-level, subword-level,\ncharacter-level.\n...\nBERTToken\nLabel 1Token\nLabel 2Token\nLabel N \nBERTSentence \nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n... ...\nBERTSentence \nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N \n......\n......\nBERTSentence \nLabelToken\nLabel 1Token\nLabel 2Token\nLabel N"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "Label 1Token\nLabel 2Token\nLabel N \n(c) BERT-Granu (d) Multi-Granularity Network(a) BERT (b) BERT-Joint... ... ... ... ...\n... ...\n... ...CLS T 1 T2 TN CLS T 1 T2 TN\nCLS T 1 T2 TNCLS T 1 T2 TNg1o\ng2o g2og1w g1wg1L g2L \ng1,2L \nf fFigure 3: The architecture of the baseline models (a-c),\nand of our proposed multi-granularity network (d).\nEach task has a separated classi\ufb01cation layer Lgk"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "that receives the feature representation of the spe-\nci\ufb01c level of granularity gkand outputs ogk. The\ndimension of the representation depends on the\nembedding layer, while the dimension of the out-\nput depends on the number of classes in the task.\nThe output ogkgenerates a weight for the next\ngranularity task gk+1through a trainable gate f:\nwgk=f(ogk) (4)"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "wgk=f(ogk) (4)\nThe gatefconsists of a projection layer to one\ndimension and an activation function. The result-\ning weight is multiplied by each element of the\noutput of layer Lgk+1to produce the output for\ntaskgk+1:\nogk+1=wgk\u0003ogk+1 (5)\nIfwgk= 0 for a given example, the output of\nthe next granularity task ogk+1would be 0 as well.\nIn our setting this means that, if the sentence-level"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "classi\ufb01er is con\ufb01dent the sentence does not con-\ntain propaganda, i.e., wgk= 0, then ogk+1= 0\nand there would be no propagandistic technique\npredicted for any span within that sentence. Simi-\nlarly, when back-propagating the error, if wgk= 0\nfor a given example, the \ufb01nal entropy loss would\nbecome zero; i.e. the model would not get any in-\nformation from that example. As a result, only ex-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "amples strongly classi\ufb01ed as negative in a lower-\ngranularity task would be ignored in the high-\ngranularity task. Having the lower-granularity as\nthe main task means that higher-granularity infor-\nmation can be selectively used as additional infor-\nmation to improve the performance, but only if the\nexample is not considered as highly negative. We"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "show this in Section 6.3.For the loss function, we use a cross-entropy loss\nwith sigmoid activation for every layer, except for\nthe highest-granularity layer LgK, which uses a\ncross-entropy loss with softmax activation. Un-\nlike softmax, which normalizes over all dimen-\nsions, the sigmoid allows each output component\nof layerLgkto be independent from the rest. Thus,"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "the output of the sigmoid for the positive class\nincreases the degree of freedom by not affecting\nthe negative class, and vice versa. As we have\ntwo tasks, we use sigmoid activation for Lg1and\nsoftmax activation for Lg2. Moreover, we use a\nweighted sum of losses with a hyper-parameter \u000b:\nLJ=Lg1\u0003\u000b+Lg2\u0003(1\u0000\u000b) (6)\nAgain, we use BERT (Devlin et al., 2019) for"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "the contextualized embedding layer and we place\nthe multi-granularity network on top of it.\n6 Experiments and Evaluation\n6.1 Experimental Setup\nWe used the PyTorch framework and the pre-\ntrained BERT model, which we \ufb01ne-tuned for our\ntasks. We trained all models using the follow-\ning hyper-parameters: batch size of 16, sequence\nlength of 210, weight decay of 0.01, and early"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "stopping on validation F 1with patience of 7. For\noptimization, we used Adam with a learning rate\nof 3e-5 and a warmup proportion of 0.1. To deal\nwith class imbalance, we give weight to the binary\ncross-entropy according to the proportion of posi-\ntive samples. For the \u000bin the joint loss function,\nwe use 0.9 for sentence classi\ufb01cation, and 0.1 for\nword-level classi\ufb01cation. In order to reduce the"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "effect of random \ufb02uctuations for BERT, all the re-\nported numbers are the average of three experi-\nmental runs with different random seeds. As it is\nstandard, we tune our models on the dev partition\nand we report results on the test partition.\n6.2 Fragment-Level Propaganda Detection\nTable 6 shows the performance for the three base-\nlines and for our multi-granularity network on the"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "FLC task. For the latter, we vary the degree to\nwhich the gate function is applied: using ReLU is\nmore aggressive compared to using the Sigmoid,\nas the ReLU outputs zero for a negative input.\nNote that, even though we train the model to pre-\ndict both the spans and the labels, we also evalu-\nated it with respect to the spans only.ModelSpans Full Task\nP R F 1 P R F 1"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "P R F 1 P R F 1\nBERT 39.57 36.42 37.90 21.48 21.39 21.39\nJoint 39.26 35.48 37.25 20.11 19.74 19.92\nGranu 43.08 33.98 37.93 23.85 20.14 21.80\nMulti-Granularity\nReLU 43.29 34.74 38.28 23.98 20.33 21.82\nSigmoid 44.12 35.01 38.98 24.42 21.05 22.58\nTable 6: Fragment-level experiments (FLC task).\nShown are two evaluations: ( i)Spans checks only\nwhether the model has identi\ufb01ed the fragment spans"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "correctly, while ( ii)Full task is evaluation wrt the ac-\ntual task of identifying the spans and also assigning the\ncorrect propaganda technique for each span.\nTable 6 shows that joint learning (BERT-Joint)\nhurts the performance compared to single-task\nBERT. However, using additional information\nfrom the sentence-level for the token-level classi-\n\ufb01cation (BERT-Granularity) yields small improve-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ments. The multi-granularity models outperform\nall baselines thanks to their higher precision. This\nshows the effect of the model excluding sen-\ntences that it determined to be non-propagandistic\nfrom being considered for token-level classi\ufb01ca-\ntion. Nevertheless, the performance of sentence-\nlevel classi\ufb01cation is far from perfect, achieving\nan F1of up to 60.98 (cf. Table 7). The information"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "it contributes to the \ufb01nal classi\ufb01cation is noisy and\nthe more conservative removal of instances per-\nformed by the Sigmoid function yields better per-\nformance than the more aggressive ReLU.\n6.3 Sentence-Level Propaganda Detection\nTable 7 shows the results for the SLC task. We\napply our multi-granularity network model to the\nsentence-level classi\ufb01cation task to see its effect"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "on low granularity when we train the model with a\nhigh granularity task. Interestingly, it yields huge\nperformance improvements on the sentence-level\nclassi\ufb01cation result. Compared to the BERT base-\nline, it increases the recall by 8.42%, resulting in\na 3.24% increase of the F 1score. In this case, the\nresult of token-level classi\ufb01cation is used as addi-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "tional information for the sentence-level task, and\nit helps to \ufb01nd more positive samples. This shows\nthe opposite effect of our model compared to the\nFLC task. Note also that using ReLU is more ef-\nfective than using the Sigmoid, unlike in token-\nlevel classi\ufb01cation.Model Precision Recall F1\nAll-Propaganda 23.92 100.0 38.61\nBERT 63.20 53.16 57.74\nBERT-Granu 62.80 55.24 58.76"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "BERT-Granu 62.80 55.24 58.76\nBERT-Joint 62.84 55.46 58.91\nMGN Sigmoid 62.27 59.56 60.71\nMGN ReLU 60.41 61.58 60.98\nTable 7: Sentence-level (SLC) results. All-propaganda\nis a baseline which always output the propaganda class.\nThus, since the performance range of the token-\nlevel classi\ufb01cation is low, we think it is more ef-\nfective to get additional information after aggres-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "sively removing negative samples by using ReLU\nas a gate in the model.\n7 Related Work\nPropaganda identi\ufb01cation has been tackled mostly\nat the article level. Rashkin et al. (2017) created\na corpus of news articles labelled as belonging\nto four categories: propaganda, trusted, hoax, or\nsatire. They included articles from eight sources,\ntwo of which are propagandistic. Barr \u00b4on-Cede \u02dcno"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "et al. (2019) experimented with a binarized version\nof the corpus from (Rashkin et al., 2017): propa-\nganda vs. the other three categories. The corpus\nlabels were obtained with distant supervision, as-\nsuming that all articles from a given news outlet\nshare the label of that outlet, which inevitably in-\ntroduces noise (Horne et al., 2018).\nA related \ufb01eld is that of computational argu-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "mentation which, among others, deals with some\nlogical fallacies related to propaganda. Haber-\nnal et al. (2018b) presented a corpus of Web fo-\nrum discussions with cases of ad hominem fal-\nlacy identi\ufb01ed. Habernal et al. (2017, 2018a) in-\ntroduced Argotario , a game to educate people to\nrecognize and create fallacies. A byproduct of Ar-\ngotario is a corpus with 1:3karguments annotated"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "with \ufb01ve fallacies, including ad hominem ,red her-\nring andirrelevant authority , which directly relate\nto propaganda techniques (cf. Section 2). Differ-\nently from (Habernal et al., 2017, 2018a,b), our\ncorpus has 18 techniques annotated on the same\nset of news articles. Moreover, our annotations\naim at identifying the minimal fragments related to"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "a technique instead of \ufb02agging entire arguments.8 Conclusion and Future Work\nWe have argued for a new way to study propa-\nganda in news media: by focusing on identifying\nthe instances of use of speci\ufb01c propaganda tech-\nniques. Going at this \ufb01ne-grained level can yield\nmore reliable systems and it also makes it possible\nto explain to the user why an article was judged as"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "propagandistic by an automatic system.\nIn particular, we designed an annotation schema\nof 18 propaganda techniques, and we annotated\na sizable dataset of documents with instances of\nthese techniques in use. We further designed an\nevaluation measure speci\ufb01cally tailored for this\ntask. We made the schema and the dataset publicly\navailable, thus facilitating further research. We"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "hope that the corpus would raise interest outside\nof the community of researchers studying propa-\nganda: the techniques related to fallacies and the\nones relying on emotions might provide a novel\nsetting for the researchers interested in Argumen-\ntation and Sentiment Analysis.\nWe experimented with a number of BERT-based\nmodels and devised a novel architecture which"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "outperforms standard BERT-based baselines. Our\n\ufb01ne-grained task can complement document-level\njudgments, both to come out with an aggregated\ndecision and to explain why a document \u2014or an\nentire news outlet\u2014 has been \ufb02agged as poten-\ntially propagandistic by an automatic system.\nWe are collaborating with A Data Pro to expand\nthe corpus. In the mid-term, we plan to build an"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "online platform where professors in relevant \ufb01elds\n(e.g., journalism, mass communication) can train\ntheir students to recognize and annotate propa-\nganda techniques. The hope is to be able to ac-\ncumulate annotations as a by-product of using the\nplatform for training purposes.\nAcknowledgments\nThis research is part of the Tanbih project,7which\naims to limit the effect of \u201cfake news\u201d, propa-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ganda and media bias by making users aware\nof what they are reading. The project is de-\nveloped in collaboration between the MIT Com-\nputer Science and Arti\ufb01cial Intelligence Labora-\ntory (CSAIL) and the Qatar Computing Research\nInstitute (QCRI), HBKU.\n7http://tanbih.qcri.org/References\nAlberto Barr \u00b4on-Cede \u02dcno, Giovanni Da San Martino, Is-\nraa Jaradat, and Preslav Nakov. 2019. Proppy: A"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "system to unmask propaganda in online news. In\nProceedings of the 33rd AAAI Conference on Arti\ufb01-\ncial Intelligence , AAAI \u201919, pages 9847\u20139848, Hon-\nolulu, HI, USA.\nAlberto Barr \u00b4on-Cedeno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "56(5):1849\u20131864.\nLavinia Dan. 2015. Techniques for the Translation of\nAdvertising Slogans. In Proceedings of the Interna-\ntional Conference Literature, Discourse and Multi-\ncultural Dialogue , LDMD \u201915, pages 13\u201323, Mures,\nRomania.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "standing. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies , NAACL-HLT \u201919, pages 4171\u20134186, Min-\nneapolis, MN, USA.\nJean Goodwin. 2011. Accounting for the force of the\nappeal to authority. In Proceedings of the 9th Inter-\nnational Conference of the Ontario Society for the"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "Study of Argumentation , OSSA \u201911, pages 1\u20139, On-\ntario, Canada.\nIvan Habernal, Raffael Hannemann, Christian Pol-\nlak, Christopher Klamm, Patrick Pauli, and Iryna\nGurevych. 2017. Argotario: Computational argu-\nmentation meets serious games. In Proceedings\nof the Conference on Empirical Methods in Natu-\nral Language Processing , EMNLP \u201917, pages 7\u201312,\nCopenhagen, Denmark."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "Copenhagen, Denmark.\nIvan Habernal, Patrick Pauli, and Iryna Gurevych.\n2018a. Adapting serious game for fallacious argu-\nmentation to German: pitfalls, insights, and best\npractices. In Proceedings of the Eleventh Interna-\ntional Conference on Language Resources and Eval-\nuation , LREC \u201918, Miyazaki, Japan.\nIvan Habernal, Henning Wachsmuth, Iryna Gurevych,"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "and Benno Stein. 2018b. Before name-calling: Dy-\nnamics and triggers of ad hominem fallacies in web\nargumentation. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies , NAACL-HLT \u201918, pages 386\u2013\n396, New Orleans, LA, USA.\nRenee Hobbs and Sandra Mcgee. 2008. Teaching"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "about propaganda: An examination of the historical\nroots of media literacy. Journal of Media Literacy\nEducation , 6(62):56\u201367.Benjamin D Horne, Sara Khedr, and Sibel Adali. 2018.\nSampling the news producers: A large news and fea-\nture data set for the study of the complex media land-\nscape. In International AAAI Conference on Web\nand Social Media , ICWSM \u201918, Stanford, CA, USA."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "John Hunter. 2015. Brainwashing in a large group\nawareness training? The classical conditioning hy-\npothesis of brainwashing. Master\u2019s thesis, Uni-\nversity of Kwazulu-Natal, Pietermaritzburg, South\nAfrica.\nGarth S. Jowett and Victoria O\u2019Donnell. 2012. What is\npropaganda, and how does it differ from persuasion?\nInPropaganda & Persuasion , chapter 1, pages 1\u201348.\nSage Publishing."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "Sage Publishing.\nYann Mathet, Antoine Widl \u00a8ocher, and Jean-Philippe\nM\u00b4etivier. 2015. The uni\ufb01ed and holistic method\ngamma (\r) for inter-annotator agreement mea-\nsure and alignment. Computational Linguistics ,\n41(3):437\u2013479.\nChristian M. Meyer, Margot Mieskes, Christian Stab,\nand Iryna Gurevych. 2014. DKPro agreement: An\nopen-source Java library for measuring inter-rater"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "agreement. In Proceedings of the International\nConference on Computational Linguistics , COL-\nING \u201914, pages 105\u2013109, Dublin, Ireland.\nClyde R. Miller. 1939. The Techniques of Propaganda.\nFrom \u201cHow to Detect and Analyze Propaganda,\u201d an\naddress given at Town Hall. The Center for learning.\nDavid Nadeau and Satoshi Sekine. 2007. A sur-\nvey of named entity recognition and classi\ufb01cation."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "Lingvisticae Investigationes , 30(1):3\u201326.\nMartin Potthast, Benno Stein, Alberto Barr \u00b4on-Cede \u02dcno,\nand Paolo Rosso. 2010. An evaluation framework\nfor plagiarism detection. In Proceedings of the In-\nternational Conference on Computational Linguis-\ntics, COLING \u201910, pages 997\u20131005, Beijing, China.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "shades: Analyzing language in fake news and polit-\nical fact-checking. In Proceedings of the 2017 Con-\nference on Empirical Methods in Natural Language\nProcessing , EMNLP \u201917, pages 2931\u20132937, Copen-\nhagen, Denmark.\nMonika L Richter. 2017. The Kremlin\u2019s platform for\n\u2018useful idiots\u2019 in the West: An overview of RT\u2019s ed-\nitorial strategy and evidence of impact. Technical\nreport, Kremlin Watch."}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "report, Kremlin Watch.\nFrancisca Niken Vitri Suprabandari. 2007. Ameri-\ncan propaganda in John Steinbeck\u2019s The Moon is\nDown. Master\u2019s thesis, Sanata Dharma University,\nYogyakarta, Indonesia.\nGabriel H Teninbaum. 2009. Reductio ad Hitlerum:\nTrumping the judicial Nazi card. Michigan State\nLaw Review , page 541.Erik F. Tjong Kim Sang. 2002. Introduction to the"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "CoNLL-2002 shared task: Language-independent\nnamed entity recognition. In Proceedings of the\n6th Conference on Natural Language Learning ,\nCoNLL \u201902, pages 155\u2013158, Taipei, Taiwan.\nErik F. Tjong Kim Sang and Fien De Meulder.\n2003. Introduction to the CoNLL-2003 shared task:\nLanguage-independent named entity recognition. In\nProceedings of the 7th Conference on Natural Lan-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "guage Learning , CoNLL \u201903, pages 142\u2013147, Ed-\nmonton, Canada.\nRobyn Torok. 2015. Symbiotic radicalisation strate-\ngies: Propaganda tools and neuro linguistic pro-\ngramming. In Proceedings of the Australian Se-\ncurity and Intelligence Conference , pages 58\u201365,\nPerth, Australia.\nRichard Tzong-Han Tsai, Shih-Hung Wu, Wen-Chi\nChou, Yu-Chun Lin, Ding He, Jieh Hsiang, Ting-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "Yi Sung, and Wen-Lian Hsu. 2006. Various criteria\nin the evaluation of biomedical named entity recog-\nnition. BMC bioinformatics , 7:92.\nDouglas Walton. 1996. The straw man fallacy . Royal\nNetherlands Academy of Arts and Sciences.\nAnthony Weston. 2018. A rulebook for arguments .\nHackett Publishing.\nA Annotation Guidelines\nWe provided the de\ufb01nitions in Section 2 together"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "with some examples and an annotation schema,\nto our professional annotators, so that they could\nmanually annotate news articles. The annotators\nperformed their task following the instructions dis-\nplayed in Figure A.1. In order to help them, we\nbuilt the \ufb02owchart displayed in the same \ufb01gure. It\npartitions the set of techniques hierarchically and\ncan be traversed by answering a series of ques-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "tions. These instructions and the \ufb02owchart were\nalways available to the annotators, next to the an-\nnotation interface (cf. Figure 1). As an example of\nthe process for generating the questions, the \ufb01rst\nsubdivision is inspired by the following descrip-\ntion of propaganda: \u201cPropaganda comes in many\nforms, but you can recognize it by [. . . ] the use of"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "faulty reasoning and/or emotional appeals\u201d. The\ndescription distinguishes between logical fallacies\nand techniques appealing to emotions.We aim at identifying propagandistic techniques in news ar-\nticles. We provide you with a news article and a \ufb02owchart\nto guide you through the identi\ufb01cation of propaganda tech-\nniques. The de\ufb01nition of each technique is shown when set-"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ting the mouse pointer on the name of the technique in the\n\ufb02owchart. You are free to annotate single words, phrases,\nor sentences, but we encourage you to select the minimal\namount of text in which the propaganda technique appears.\n1. Let us look at the \ufb02owchart [below]\n2. Let us look at an example which includes four propa-\nganda techniques [cf. Figure 1]"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "ganda techniques [cf. Figure 1]\n\u000fName calling : the democrats are being called \u201dbabies\u201d\n\u000fBlack-and-white fallacy : obstruction vs progress\n\u000fLoaded language : stupid, petty, killing\u000fExaggeration : killing a grandma, stomaching the\npresence of a person\nUse the \ufb02owchart as your guide to spot propaganda. If you\nare not sure about a propaganda technique (any rounded box"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "in the \ufb02owchart), just click on it and a new page will open\nwith explanations and examples when necessary. [cf. Sec-\ntion 2]\nTIPS\n\u000fSome sentences might be tricky. Please try to select the\nright technique(s)\n\u000fYour emotions have nothing to do with the articles, as\nyou are requested to spot propagandistic techniques,\nnot their message: try to distance yourself from the"}, {"source": "Grained Analysis of Propaganda in News Articles.pdf", "text": "contents and avoid being biased.\n\u000fOne text fragment may include more than one tech-\nnique at the same time\nFigure A.1: Instructions as provided to the professional annotators in the Anafora-based annotation process (top).\nFlowchart to drive the identi\ufb01cation of propaganda techniques (bottom)."}, {"source": "2023.semeval-1.317v2.pdf", "text": "SemEval-2023 Task 3: Detecting the Category, the Framing,\nand the Persuasion Techniques in Online News in a Multi-lingual Setup\nJakub Piskorski1, Nicolas Stefanovitch2, Giovanni Da San Martino3, Preslav Nakov4\n1Institute of Computer Science, Polish Academy of Science, Poland jpiskorski@gmail.com\n2European Commission Joint Research Centre, Italy nicolas.stefanovitch@ec.europa.eu"}, {"source": "2023.semeval-1.317v2.pdf", "text": "3Department of Mathematics, University of Padova, Italy dasan@math.unipd.it\n4Mohamed bin Zayed University of Artificial Intelligence, UAE preslav.nakov@mbzuai.ac.ae\nAbstract\nWe describe SemEval-2023 task 3 on Detect-\ning the Category, the Framing, and the Per-\nsuasion Techniques in Online News in a Multi-\nlingual Setup : the dataset, the task organization"}, {"source": "2023.semeval-1.317v2.pdf", "text": "process, the evaluation setup, the results, and\nthe participating systems. The task focused on\nnews articles in nine languages (six known to\nthe participants upfront: English ,French ,Ger-\nman,Italian ,Polish , and Russian ), and three ad-\nditional ones revealed to the participants at the\ntesting phase: Spanish ,Greek , and Georgian ).\nThe task featured three subtasks: (1) determin-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ing the genre of the article (opinion, reporting,\nor satire), (2) identifying one or more frames\nused in an article from a pool of 14 generic\nframes, and (3) identify the persuasion tech-\nniques used in each paragraph of the article,\nusing a taxonomy of 23 persuasion techniques.\nThis was a very popular task: a total of 181\nteams registered to participate, and 41 even-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "tually made an official submission on the test\nset.\n1 Introduction\nThe widespread use of Internet and the advances in\nInternet-related technologies paved the way to eas-\nily create direct communication channels between\ninformation producers and consumers, potentially\nleaving the latter exposed to manipulative, propa-\ngandistic, and deceptive content. Given the poten-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "tially huge audience that can be reached through\nonline channels, major public events and debates re-\nvolving around relevant topics could be influenced\nas a result. Therefore, there is an ever-growing\nneed to develop automated tools supporting experts\nin analysing the news ecosystem and identifying\nlarge-scale manipulation attempts, and facilitating"}, {"source": "2023.semeval-1.317v2.pdf", "text": "the study of how different events, global topics,\nand policies are being embraced by media in var-\nious countries, in order to carry out cross-country\nanalysis and to gather knowledge on the ways how\nmedia informs public opinion, i.e., what aspectsare being highlighted and linked to a topic, what\npros and cons are mentioned, the way opinions are"}, {"source": "2023.semeval-1.317v2.pdf", "text": "conveyed, and what rhetorical devices, i.e., logical\nfallacies and appeal to emotions, are used to sup-\nport flawed argumentation, potentially leading to\nmanipulation.\nTo foster research in this direction, there have\nbeen several shared tasks asking to detect the use of\nspecific propaganda techniques in text, as well as\nthe specific span of each instance. This includes the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "NLP4IF-2019 shared task on Fine-Grained Propa-\nganda Detection (Da San Martino et al., 2019),\nSemEval-2020 task 11 on Detection of Persua-\nsion Techniques in News Articles (Da San Martino\net al., 2020a), SemEval-2021 task 6 on Detection of\nPersuasion Techniques in Texts and Images (Dim-\nitrov et al., 2021b), and WANLP-2022 Shared Task\non Propaganda Detection in Arabic (Alam et al.,\n2022)."}, {"source": "2023.semeval-1.317v2.pdf", "text": "2022).\nOur task is an extension of the above ones and\nintroduces several novelties. First, it is multilin-\ngual, covering nine languages. Second, it adds ad-\nditional dimensions for better news understanding,\ni.e., framing and news genre detection. Finally, our\ntaxonomy of persuasion techniques is an extension\ncompared to previous inventories, and it contains"}, {"source": "2023.semeval-1.317v2.pdf", "text": "23 techniques organised in a two-tier hierarchy.\n2 The Tasks\nThe shared task comprises three subtasks:\nSubtask 1 (ST1): News Genre Categorization.\nGiven a news article, determine whether: (a) it\nis an opinion piece, (b) aims at objective news\nreporting , or (c) is satirical .1This is a multi-class\nclassification task at the article level.\nSubtask 2 (ST2): Framing Detection. Given a"}, {"source": "2023.semeval-1.317v2.pdf", "text": "news article, identify one or more frames used in\n1A satirical piece is a factually incorrect article, with the\nintent not to deceive, but rather to call out, ridicule, or expose\nbehaviours considered \u2018bad\u2019. It deliberately exposes real-\nworld individuals, organisations and events to ridicule.the article from a pool of 14 generic framing dimen-\nsions (introduced in Card et al. (2015)): Economic ,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Capacity and resources ,Morality ,Fairness and\nequality ,Legality, constitutionality and jurispru-\ndence ,Policy prescription and evaluation ,Crime\nand punishment ,Security and defense ,Health and\nsafety ,Quality of life ,Cultural identity ,Public\nopinion ,Political ,External regulation and reputa-\ntion. This is a multi-class multi-label classification\ntask at the article level."}, {"source": "2023.semeval-1.317v2.pdf", "text": "task at the article level.\nSubtask 3 (ST3): Persuasion Techniques Detec-\ntion. Given a news article, identify the persuasion\ntechniques used in each paragraph of the article.\nThe pool of persuasion techniques consists of 23\ntechniques, and is an extension of the taxonomy\nintroduced in Da San Martino et al. (2019); Dim-\nitrov et al. (2021b)2. This is a multi-class multi-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "label classification task at the paragraph level. The\npersuasion techniques are grouped into six main\ncategories:\nAttack on reputation: The argument does not\naddress the topic, but rather targets the participant\n(personality, experience, deeds) in order to question\nand/or to undermine their credibility. The object of\nthe argumentation can also refer to a group of indi-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "viduals, an organization, an object, or an activity.\nJustification: The argument is made of two parts,\na statement and an explanation or an appeal, where\nthe latter is used to justify and/or to support the\nstatement.\nSimplification: The argument excessively simpli-\nfies a problem, usually regarding the cause, the\nconsequence or the existence of choices."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Distraction: The argument takes the focus away\nfrom the main topic or argument to distract the\nreader.\nCall: The text is not an argument, but an encour-\nagement to act or to think in a particular way.\nManipulative wording: the text is not an argument\nper se, but uses specific language, which contains\nwords or phrases that are either non-neutral, confus-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ing, exaggerating, loaded, etc., in order to impact\nthe reader emotionally.\nFigure 1 gives an overview of the two-tier per-\nsuasion techniques taxonomy.\n3 Related Work\nThis section discusses prior work related to each of\nthe subtasks of the shared task.\n2the second paper has five additional techniques with re-\nspect to the previous oneATTACK ON REPUTATION"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Name Calling or Labelling [AR:NCL]: a form of argument in which\nloaded labels are directed at an individual, group, object or activity,\ntypically in an insulting or demeaning way, but also using labels the target\naudience finds desirable.\nGuilt by Association [AR:GA]: attacking the opponent or an activity by\nassociating it with another group, activity, or concept that has sharp"}, {"source": "2023.semeval-1.317v2.pdf", "text": "negative connotations for the target audience.\nCasting Doubt [AR:D]: questioning the character or the personal\nattributes of someone or something in order to question their general\ncredibility or quality.\nAppeal to Hypocrisy [AR:AH]: the target of the technique is attacked\nbased on their reputation by charging them with hypocrisy/inconsistency."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Questioning the Reputation [AR:QR]: the target is attacked by making\nstrong negative claims about it, focusing specially on undermining its\ncharacter and moral stature rather than relying on an argument about the\ntopic.\nJUSTIFICATION\nFlag Waiving [J:FW]: justifying an idea by exhaling the pride of a group\nor highlighting the benefits for that specific group."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Appeal to Authority [J:AA]: a weight is given to an argument, an idea or\ninformation by simply stating that a particular entity considered as an\nauthority is the source of the information.\nAppeal to Popularity [J:AP]: a weight is given to an argument or idea by\njustifying it on the basis that allegedly \u201ceverybody\u201d (or the large majority)\nagrees with it or \u201cnobody\u201d disagrees with it."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Appeal to Values [J:A V]: a weight is given to an idea by linking it to\nvalues seen by the target audience as positive.\nAppeal to Fear, Prejudice [J:AF]: promotes or rejects an idea through the\nrepulsion or fear of the audience towards this idea.\nDISTRACTION\nStrawman [D:SM]: consists in making an impression of refuting an\nargument of the opponent\u2019s proposition, whereas the real subject of the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "argument was not addressed or refuted, but instead was replaced with a\nfalse one.\nRed Herring [D:RH]: consists in diverting the attention of the audience\nfrom the main topic being discussed, by introducing another topic, which\nis irrelevant.\nWhataboutism [D:W]: a technique that attempts to discredit an\nopponent\u2019s position by charging them with hypocrisy without directly\ndisproving their argument."}, {"source": "2023.semeval-1.317v2.pdf", "text": "disproving their argument.\nSIMPLIFICATION\nCausal Oversimplification [S:CaO]: assuming a single cause or reason\nwhen there are actually multiple causes for an issue.\nFalse Dilemma or No Choice [S:FDNC]: a logical fallacy that presents\nonly two options or sides when there are many options or sides. In\nextreme, the author tells the audience exactly what actions to take,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "eliminating any other possible choices.\nConsequential Oversimplification [S:CoO]: is an assertion one is\nmaking of some \u201cfirst\u201d event/action leading to a domino-like chain of\nevents that have some significant negative (positive) effects and\nconsequences that appear to be ludicrous or unwarranted or with each step\nin the chain more and more improbable.\nCALL"}, {"source": "2023.semeval-1.317v2.pdf", "text": "CALL\nSlogans [C:S]: a brief and striking phrase, often acting like an emotional\nappeal, that may include labeling and stereotyping.\nConversation Killer [A:CK]: words or phrases that discourage critical\nthought and meaningful discussion about a given topic.\nAppeal to Time [C:AT]: the argument is centred around the idea that time\nhas come for a particular action.\nMANIPULATIVE WORDING"}, {"source": "2023.semeval-1.317v2.pdf", "text": "MANIPULATIVE WORDING\nLoaded Language [MW:LL]: use of specific words and phrases with\nstrong emotional implications (either positive or negative) to influence and\nconvince the audience that an argument is valid.\nObfuscation, Intentional Vagueness, Confusion [MW:OVC]: use of\nwords that are deliberately not clear, vague, or ambiguous so that the\naudience may have its own interpretations."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Exaggeration or Minimisation [MW:EM]: consists of either\nrepresenting something in an excessive manner or making something seem\nless important or smaller than it really is.\nRepetition [MW:R]: the speaker uses the same phrase repeatedly with the\nhope that the repetition will lead to persuade the audience.\nFigure 1: Persuasion techniques taxonomy. The six"}, {"source": "2023.semeval-1.317v2.pdf", "text": "coarse-grained techniques are subdivided into 23 fine-\ngrained ones. An acronym for each technique is given\nin squared brackets.3.1 News Genre Categorization\nRashkin et al. (2017) developed a corpus with\ndocument-level annotations into four classes\n(trusted ,satire ,hoax , and propaganda ), annotated\nusing distant supervision. Horne and Adali (2017)"}, {"source": "2023.semeval-1.317v2.pdf", "text": "studied the relationship between fake news, real\nnews, and satire with focus on style. They found\nthat fake news is more similar to satire than to real\nnews. Golbeck et al. (2018) developed a dataset\nof fake news and satire stories and analyzed and\ncompared their thematic content. Satire was also\none of the categories in the NELA-GT-2018 dataset"}, {"source": "2023.semeval-1.317v2.pdf", "text": "(N\u00f8rregaard et al., 2019), as well as in its extended\nversion NELA-GT-2019 (Gruppi et al., 2020).\nThe set up of our shared task is different, and\nfocusing on distinguishing between objective news\nreporting vs. opinion piece vs. satire.\n3.2 Framing Detection\nFraming is a strategic device and a central con-\ncept in political communication for representing"}, {"source": "2023.semeval-1.317v2.pdf", "text": "different salient aspects and perspectives for the\npurpose of conveying the latent meaning about an\nissue (Entman, 1993). It is important for news\nmedia as the same topics can be discussed from\ndifferent perspectives. There has been work on\nautomatically identifying media frames, including\nannotation schemes and datasets such as the Media\nFrames Corpus (Card et al., 2015), systems to au-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "tomatically detect media frames (Liu et al., 2019;\nZhang et al., 2019), large-scale automatic analysis\nof New York Times Articles (Kwak et al., 2020),\nand a semi-supervised approach to detecting frames\nin online news sources (Cheeks et al., 2020).\nIn our shared task, we adopt the frame inventory\nof the Media Frames Corpus.\n3.3 Persuasion Techniques Detection"}, {"source": "2023.semeval-1.317v2.pdf", "text": "3.3 Persuasion Techniques Detection\nWork on persuasion detection overlaps to a large\nextent with work on propaganda detection, as there\nare many commonalities between the two.\nEarly work on propaganda detection focused on\ndocument-level analysis. Rashkin et al. (2017) pre-\ndicted four classes ( trusted ,satire ,hoax , and propa-\nganda ), labeled using distant supervision. Barr\u00f3n-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Cedeno et al. (2019) developed a corpus with two\nlabels (i.e., propaganda vs.non-propaganda ) and\nfurther investigated writing style and readability\nlevel. Their findings confirmed that using distant\nsupervision, in conjunction with rich representa-\ntions, might encourage the model to predict thesource of the article, rather than to discriminate\npropaganda from non-propaganda."}, {"source": "2023.semeval-1.317v2.pdf", "text": "propaganda from non-propaganda.\nAn alternative line of research focused on de-\ntecting the use of specific propaganda techniques\nin text, e.g., Habernal et al. (2017, 2018) devel-\noped a corpus with 1.3k arguments annotated with\nfive fallacies that directly relate to propaganda tech-\nniques. A more fine-grained analysis was done by\nDa San Martino et al. (2019), who developed a cor-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "pus of news articles annotated for 18 propaganda\ntechniques, considering separately the task of tech-\nnique spans detection and classification. They fur-\nther tackled a sentence-level propaganda detection\ntask, and proposed a multi-granular gated deep\nneural network. Subsequently, the Prta system was\nreleased (Da San Martino et al., 2020c), and im-\nproved models were proposed addressing the limi-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "tations of transformers (Chernyavskiy et al., 2021),\nor looking into interpretable propaganda detection\n(Yu et al., 2021). Finally, there is work addressing\nthe detection of use of propaganda techniques in\nmemes (Dimitrov et al., 2021a), the relationship\nbetween propaganda and coordination (Hristakieva\net al., 2022), and work studying COVID-19 related"}, {"source": "2023.semeval-1.317v2.pdf", "text": "propaganda in social media (Nakov et al., 2021a,b).\nSee (Da San Martino et al., 2020b) for a survey on\ncomputational propaganda detection.\nSeveral shared tasks on propaganda detecting in\ntext were also organized. SemEval-2020 task 11\non Detection of Persuasion Techniques in News Ar-\nticles (Da San Martino et al., 2020a) focused on\nnews articles, and asked to detect the text spans"}, {"source": "2023.semeval-1.317v2.pdf", "text": "where propaganda techniques are used, and to pre-\ndict their type (14 techniques). Closely related to\nthat is the NLP4IF-2019 task on Fine-Grained Pro-\npaganda Detection (Da San Martino et al., 2019),\nwhich asked to detect the spans of use in news ar-\nticles of each of 18 propaganda techniques. The\nSemEval-2021 task 6 on Detection of Persuasion\nTechniques in Texts and Images focused on 22"}, {"source": "2023.semeval-1.317v2.pdf", "text": "propaganda techniques in memes (Dimitrov et al.,\n2021b), while WANLP\u20192022 shared task asked to\ndetect the use of 20 propaganda techniques in Ara-\nbic tweets (Alam et al., 2022). Here, we extend\nand redesign the above annotation schemes.\n4 The Dataset\nThis section provides a brief description of the\ndataset, whereas detailed guidelines, definitions\nand examples are provided in a separate technical"}, {"source": "2023.semeval-1.317v2.pdf", "text": "report (Piskorski et al., 2023).We collected articles in nine languages: En-\nglish, French, German, Georgian, Greek, Italian,\nPolish, Russian, and Spanish published in the pe-\nriod between 2020 and mid-2022, and revolving\naround various globally discussed topics, including\nthe COVID-19 pandemic, abortion-related legisla-\ntion, migration, Russo-Ukrainian war, some local"}, {"source": "2023.semeval-1.317v2.pdf", "text": "events such as parliamentary elections, etc. We con-\nsidered both mainstream media and \u201calternative\u201d\nmedia sources that could potentially spread mis-\n/disinformation. For the former, we used various\nnews aggregation engines, e.g., Google News3and\nEurope Media Monitor4, etc., which cover sources\nwith different political orientation, whereas for the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "latter, we used online services such as MediaBias-\nFactCheck5and NewsGuard.6We extracted the ar-\nticle texts either using Trafilatura (Barbaresi, 2021)\nor, in few cases, ad hoc procedures.\nWe annotated each text for genre, framing, and\npersuasion techniques using the taxonomy de-\nscribed in Section 2. While genre and framing\nwere annotated at the document level, we anno-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "tated the persuasion techniques at the span level.\nWe had about 40 annotators, who were either media\nanalysts, disinformation specialists or NLP experts,\nmost of which had prior experience in performing\nlinguistic annotations. All annotators were either\nnative or near-native speakers of the language they\nannotated for. We used the INCEpTION (Klie et al.,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "2018) platform for carrying out the annotations.\nThe annotation interface for an example document\nusing INCEpTION is shown in Figure 2.\nFigure 2: Example of a multi-label annotation using In-\nception: news genre is annotated as document metadata\n(left), while the persuasion techniques and the framings\nare highlighted in blue and green, respectively.\nAs regards English, we exploited the texts from"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Da San Martino et al. (2019), but the annotations\n3https://news.google.com\n4https://emm.newsbrief.eu\n5https://mediabiasfactcheck.com\n6https://www.newsguardtech.comfor persuasion techniques have been slightly modi-\nfied in order to match the extended taxonomy, most\nnotably Whataboutism included two meanings: dis-\ntracting from the main argument and calling the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "hypocrisy of the speaker; the latter meaning is\nnow covered by the technique Appeal to Hypocrisy .\nMoreover, we added annotations for framing and\nnews genre.\ntrain\nlang #docs #chars #spans #ne-par #avg-fr #avg-pt\nEnglish 446 2,431K 7201 9498 3.7 16.1\nFrench 158 737K 5,595 2196 3.0 35.4\nGerman 132 581K 4,501 1484 4.3 34.1\nItalian 227 927K 6,027 2552 3.8 26.6\nPolish 145 765K 2,839 2294 5.0 19.6"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Polish 145 765K 2,839 2294 5.0 19.6\nRussian 143 590K 3,399 1876 2.5 23.8\ndevelopment\nlang #docs #chars #spans #ne-par #avg-fr #avg-pt\nEnglish 90 403K 1,801 3,127 5.1 20.0\nFrench 53 222K 1,586 610 3.0 29.9\nGerman 45 171K 1,236 522 4.6 27.5\nItalian 76 287K 1,934 882 3.9 25.4\nPolish 49 264K 985 800 4.9 20.1\nRussian 48 163K 739 515 2.3 15.4\ntest\nlang #docs #chars #spans #ne-par #avg-fr #avg-pt"}, {"source": "2023.semeval-1.317v2.pdf", "text": "English 54 228K 1,775 910 4.7 32.9\nFrench 50 181K 1,681 510 3.1 33.6\nGerman 50 259K 1,904 790 5.7 38.1\nItalian 61 245K 2,351 593 3.8 38.5\nPolish 47 349K 1,491 1006 5.9 31.7\nRussian 72 161K 944 601 1.2 13.1\nGeorgian 29 46K 218 161 1.7 7.5\nGreek 64 248K 691 947 2.9 10.8\nSpanish 30 109K 546 330 2.3 18.2\nTable 1: Statistics about the training , the development ,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "and the testdatasets: total number of documents (#docs),\ntotal number of characters (#chars), total number of text\nspans annotated (#spans), total number of non-empty\nparagraphs (#ne-par), average number of frames per\ndocument (#avg-fr), and average number of persuasion\ntechniques per document (#avg-pt).\ntrain dev test\nlang op rep sat op rep satire op rep sat\nEnglish 382 41 10 20 54 9 32 17 5"}, {"source": "2023.semeval-1.317v2.pdf", "text": "English 382 41 10 20 54 9 32 17 5\nFrench 103 43 11 35 15 4 37 7 6\nGerman 86 27 19 29 9 7 33 12 5\nItalian 174 44 8 59 15 3 41 13 7\nPolish 104 25 15 35 9 6 35 10 2\nRussian 93 41 8 32 14 3 45 18 9\nGeorgian - - - - - - 19 10 0\nGreek - - - - - - 39 22 3\nSpanish - - - - - - 14 9 7\nall 942 221 71 210 116 32 295 118 44\nTable 2: Number of documents from each genre across"}, {"source": "2023.semeval-1.317v2.pdf", "text": "the languages: opinion (op), reporting (rep), satire (sat).\nEach document was annotated by at least two\nannotators. Once the individual annotations for a\ndocument have been accomplished, a curator (an\nexperienced annotator) with the help of annotatorsconsolidated the final annotation. The consolida-\ntion consisted of: (a) merging complementary an-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "notations (tagged only by one annotator), (b) decid-\ning whether overlapping annotations are to be kept\nas they are (multi-labels) or joined into a single-\nlabeled annotation, and (c) carrying out global con-\nsistency analysis. The detailed description of the\nannotation and the consolidation process are de-\nscribed in a detailed technical report (Piskorski"}, {"source": "2023.semeval-1.317v2.pdf", "text": "et al., 2023). In order to assess the annotation qual-\nity, we computed the Inter-Annotator Agreement\n(IAA) using Krippendorf\u2019s \u03b1: the value was 0.342,\nwhich is lower than the recommended threshold\nof 0.667, but we should note that this value repre-\nsents the agreement before the consolidation, and\nas such, it is more representative of the consoli-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "dation difficulty rather than of the quality of the\nfinal consolidated annotations. Actually, we used\nIAA to allocate consolidation roles and to eliminate\nlow-performing annotators.\nWe further studied the IAA by ranking the an-\nnotators by their performance with respect to the\nground truth on the subset of documents they anno-\ntated. We then split them into two groups, topand"}, {"source": "2023.semeval-1.317v2.pdf", "text": "low, based on the median micro- F1scores. Their\nrespective \u03b1scores were 0.415 and 0.250. Finally,\nwe considered the value of \u03b1of the group of anno-\ntators, based on Italian, the only language with two\ncurators, achieving 0.588, which is lower but close\nto the recommended value.\nThe annotated data, consisting of 2,049 docu-\nments in total, were divided into train ,dev, and test"}, {"source": "2023.semeval-1.317v2.pdf", "text": "datasets, whose high-level statistics are provided in\nTable 1. Georgian, Greek, and Spanish-annotated\ndata was used only for testing (surprise languages).\nTable 2 shows the distribution of articles per lan-\nguage in terms of genre. Detailed statistics about\nthe fine-grained persuasion techniques are shown\nin Table 17 in Annex A.\n5 Evaluation Framework\n5.1 Evaluation Measures"}, {"source": "2023.semeval-1.317v2.pdf", "text": "5.1 Evaluation Measures\nSubtask 1 is a multi-class classification problem.\nWe used macro F 1as the official evaluation mea-\nsure, but we also computed micro F 1.\nSubtask 2 is a multi-label multi-class classification\nproblem. We used micro F 1as the official evalua-\ntion measure, but we also computed macro F 1.\nSubtask 3 is a multi-label multi-class classification"}, {"source": "2023.semeval-1.317v2.pdf", "text": "problem. We used micro F 1as the official eval-\nuation measure. The official score was computedusing the 23 fine-grained persuasion technique la-\nbels. We also computed macro F 1.\n5.2 Task Organization\nThe shared task was run in two phases:\nDevelopment Phase: initially, only training and\ndevelopment data were made available to the par-\nticipants, and no gold labels were provided for the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "latter. The participants competed against each other\nto achieve the best performance on the develop-\nment set. They could make an unlimited number\nof submissions, and the best score for each team,\nregardless of the submission time, was shown in\nreal time on a public leaderboard.\nTest Phase: in the second phase, the gold labels\nfor the development and the testsets were released,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "and the participants were given a week to submit\ntheir final predictions on the testset. It is impor-\ntant to note that the test data contained news in\nthree additional languages, i.e., Georgian, Greek,\nand Spanish, which were not known upfront to the\nparticipants (surprise languages). The participants\ncould again submit multiple runs, but they would"}, {"source": "2023.semeval-1.317v2.pdf", "text": "not get any feedback on their performance. Only\nthe latest submission of each team was considered\nas official and was used for the final team ranking.\nOverall, 41 teams made official submissions to all\nthe tasks, where 27, 22, and 22 teams submitted\nresults for ST1, ST2, ST3, respectively. Moreover,\n13, 14, and 14 teams submitted results for all lan-\nguages for ST1, ST2, ST3, respectively."}, {"source": "2023.semeval-1.317v2.pdf", "text": "guages for ST1, ST2, ST3, respectively.\nThe results for the development and the test\nphases are available on the leaderboard7page. Af-\nter the competition was over, we left the submission\nsystem open for the test dataset for post-shared task\nevaluations and to monitor the state of the art for\nthe different subtasks across the languages.\n6 Participants and Results"}, {"source": "2023.semeval-1.317v2.pdf", "text": "6 Participants and Results\n6.1 Subtask 1: News Genre Categorization\nThe full results for Subtask 1 are shown in Tables 3\nand 4 (surprise languages). We used a linear SVM8\nwith class balancing, trained on 5-char n-grams as a\nbaseline (highlighted in blue in the tables). Table 5\nshows an overview of the approaches. Almost all\nparticipants used transformers. The scarcity of the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "annotated data was dealt with either by combining\nthe datasets for all languages, e.g., via multilingual\n7https://propaganda.math.unipd.it/\nsemeval2023task3/leaderboard.php\n8https://scikit-learn.orgEnglish Italian Russian French German Polish\nTEAM mac mic TEAM mac mic TEAM mac mic TEAM mac mic TEAM mac mic TEAM mac mic"}, {"source": "2023.semeval-1.317v2.pdf", "text": "MELODI .784 .815 Hitachi .768 .852 Hitachi .755 .750 UMUTeam .835 .880 UMUTeam .820 .820 FTD .786 .936\nMLModeler5 .616 .630 QUST .767 .836 SheffieldVeraAI .729 .722 QCRI .767 .800 SheffieldVeraAI .820 .820 Hitachi .779 .872\nSheffieldVeraAI .613 .704 DSHacker .720 .836 FTD .668 .694 Hitachi .744 .780 DSHacker .813 .820 SheffieldVeraAI .765 .851"}, {"source": "2023.semeval-1.317v2.pdf", "text": "HHU .594 .611 SheffieldVeraAI .720 .836 UMUTeam .645 .681 DSHacker .710 .720 SinaAI .782 .760 MELODI .709 .851\nDSHacker .591 .630 MELODI .587 .754 MELODI .586 .625 SheffieldVeraAI .682 .740 MELODI .779 .780 UMUTeam .664 .809\nUnisa .586 .611 UnedMediaBias .584 .623 QCRI .567 .653 FTD .671 .780 Hitachi .777 .760 SinaAI .663 .809"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Hitachi .553 .593 UMUTeam .553 .754 DSHacker .559 .597 MELODI .656 .740 FTD .713 .720 DSHacker .661 .809\nUnedMediaBias .524 .574 QCRI .541 .787 Spoke .490 .653 SinaAI .638 .680 QCRI .667 .660 kb .653 .809\nSinaAI .506 .667 FTD .517 .754 QUST .472 .514 QUST .621 .700 SATLab .644 .700 SATLab .571 .830"}, {"source": "2023.semeval-1.317v2.pdf", "text": "QUST .506 .630 SinaAI .502 .738 SinaAI .443 .472 Baseline .568 .740 Baseline .630 .760 QCRI .571 .830\nUMUTeam .413 .593 HHU .455 .639 HHU .426 .472 UnedMediaBias .465 .480 QUST .626 .660 QUST .528 .596\nUM6P .394 .519 Riga .436 .574 Baseline .398 .653 SATLab .447 .640 HHU .611 .740 UnedMediaBias .507 .553"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Riga .349 .537 Baseline .389 .672 UnedMediaBias .365 .444 Riga .356 .580 FramingFreaks .569 .700 Baseline .490 .830\nFTD .329 .463 FramingFreaks .360 .656 Riga .271 .389 JUSTR00 .347 .660 Riga .412 .480 Riga .433 .468\nkb .299 .574 SATLab .319 .623 MaChAmp .256 .625 FramingFreaks .341 .660 UnedMediaBias .362 .420 MaChAmp .285 .745"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Baseline .288 .611 JUSTR00 .317 .574 FramingFreaks .236 .319 MaChAmp .284 .740 JUSTR00 .265 .660 FramingFreaks .282 .702\nQCRI .281 .593 MaChAmp .268 .672 E8IJS .175 .306 E8IJS .080 .120 MaChAmp .265 .660 E8IJS .063 .085\nSpoke .265 .444 E8IJS .121 .164 E8IJS .118 .180\nJUSTR00 .257 .370\nFramingFreaks .248 .593\nMaChAmp .248 .593\nssnNlp .248 .593\nSATLab .243 .574\nUTB-NLP .243 .574\nE8IJS .075 .093"}, {"source": "2023.semeval-1.317v2.pdf", "text": "UTB-NLP .243 .574\nE8IJS .075 .093\nTable 3: Results for Subtask 1 for the six main languages: macro F 1(mac), micro F 1(mic), ordered by the former,\nwhich is the official score.\nlanguage models or by automatic translation, or\nby looking for similar datasets in the literature;\nensemble methods have also been very popular.\nSpanish Greek Georgian\nTEAM mac mic TEAM mac mic TEAM mac mic"}, {"source": "2023.semeval-1.317v2.pdf", "text": "TEAM mac mic TEAM mac mic TEAM mac mic\nDSHacker .563 .567 SinaAI .806 .813 Riga 1,000 1,000\nQUST .552 .633 UMUTeam .767 .797 SheffieldVeraAI .963 .966\nQCRI .489 .567 HHU .750 .750 FTD .888 .897\nSheffieldVeraAI .443 .500 QCRI .708 .813 QCRI .622 .897\nMELODI .443 .600 FTD .698 .766 DSHacker .597 .862\nUMUTeam .438 .500 SheffieldVeraAI .687 .734 UMUTeam .582 .862"}, {"source": "2023.semeval-1.317v2.pdf", "text": "FTD .400 .433 MELODI .637 .703 QUST .537 .690\nRiga .385 .500 DSHacker .593 .641 SATLab .519 .724\nUnedMediaBias .336 .367 UnedMediaBias .521 .563 MELODI .490 .724\nHHU .327 .433 QUST .492 .609 UnedMediaBias .486 .690\nSinaAI .323 .433 Riga .412 .578 SinaAI .468 .690\nFramingFreaks .317 .467 SATLab .254 .406 MaChAmp .396 .655\nSATLab .282 .433 MaChAmp .252 .609 Baseline .256 .345"}, {"source": "2023.semeval-1.317v2.pdf", "text": "E8IJS .235 .300 FramingFreaks .234 .344 FramingFreaks .255 .621\nMaChAmp .212 .467 Baseline .171 .344 E8IJS .000 .000\nBaseline .154 .300 E8IJS .057 .063\nTable 4: Results for Subtask 1 for the three surprise\nlanguages: macro F 1(mac), micro F 1(mic), ordered\nby the former, which is the official score.\nBelow, we give a short description of the sys-\ntem papers that were top-ranked for at least one"}, {"source": "2023.semeval-1.317v2.pdf", "text": "language.\nSinaAI (EL) used multilingual languages mod-\nels, XLM, mBERT and LABSE, and ensembles\nthereof. They further used data augmentation by\nselecting 30% of the sentences of each document\nto create new synthetic examples.\nDSHacker (ES) created synthetic texts for each\nclass using the OpenAI GPT-3 Davinci language\nmodel. Each language was augmented by approxi-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "mately 500 articles per genre, producing roughly\n13,500 artificially generated articles. Then, they\nfine-tuned a single XLM-RoBERTalarge on theTeam Name\ntransformers\nother representations\nadditional data\ndata augmentation\nensembles\npreprocessing\ntrained on all languages\nknowledge base\nchunk processing\ndata translation\nDSHacker \u2713 \u2713 \u2713 \u2713\nFTD \u2713 \u2713 \u2713 \u2713 \u2713\nHHU \u2713 \u2713 \u2713 \u2713 \u2713\nHitachi \u2713 \u2713 \u2713 \u2713\nMELODI \u2713 \u2713 \u2713"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Hitachi \u2713 \u2713 \u2713 \u2713\nMELODI \u2713 \u2713 \u2713\nMLModeler5 \u2713 \u2713 \u2713 \u2713\nMaChAmp \u2713 \u2713 \u2713\nNLUBot101\nQCRI \u2713 \u2713 \u2713\nQUST \u2713 \u2713 \u2713 \u2713 \u2713\nRiga \u2713 \u2713 \u2713 \u2713\nSheffieldVeraAI \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nUM6P \u2713 \u2713 \u2713\nUMUTeam \u2713 \u2713 \u2713 \u2713\nUTB-NLP \u2713 \u2713 \u2713 \u2713\nUnedMediaBiasTeam \u2713 \u2713 \u2713\nUnisa \u2713 \u2713 \u2713 \u2713\nkb \u2713\nTable 5: ST1: Overview of the approaches and the\nfeatures used by the participating systems. The systems\nhighlighted in bold ranked first for at least one language."}, {"source": "2023.semeval-1.317v2.pdf", "text": "original and the augmented data.\nFTD (PL): They experimented with monolin-\ngual and multilingual models, ensembles, addi-\ntional data, and uncertainty estimation. For Russian\nand English, they fine-tuned models pretrained on\nthe FTD dataset for genre classification. For En-\nglish, they added 1,000 reporting texts from Giga-\nword. For Polish and German, their best results"}, {"source": "2023.semeval-1.317v2.pdf", "text": "were achieved by fine-tuning a monolingual Polish\nBERT and a monolingual German Electra, respec-English Italian Russian French German Polish\nTEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac\nSheffieldVeraAI .579 .539 MarsEclipse .617 .545 MarsEclipse .450 .303 MarsEclipse .553 .537 MarsEclipse .711 .660 MarsEclipse .673 .638"}, {"source": "2023.semeval-1.317v2.pdf", "text": "TeamAmpa .567 .510 QCRI .599 .479 SheffieldVeraAI .441 .356 BERTastic .537 .520 QCRI .660 .606 SheffieldVeraAI .645 .603\nMarsEclipse .562 .490 Hitachi .598 .515 QCRI .434 .364 SheffieldVeraAI .534 .520 SheffieldVeraAI .653 .601 QCRI .642 .599\nHitachi .543 .472 TeamAmpa .597 .483 TeamAmpa .409 .294 Hitachi .514 .488 TeamAmpa .632 .573 UMUTeam .642 .593"}, {"source": "2023.semeval-1.317v2.pdf", "text": "mCPT .535 .482 mCPT .584 .469 mCPT .409 .367 TeamAmpa .506 .479 Hitachi .629 .567 Hitachi .634 .584\nQUST .513 .462 UMUTeam .576 .447 BERTastic .393 .265 TheSyllogist .486 .462 mCPT .622 .564 SATLab .620 .570\nQCRI .513 .419 SheffieldVeraAI .571 .491 TheSyllogist .385 .290 QCRI .480 .430 QUST .616 .545 TeamAmpa .614 .555"}, {"source": "2023.semeval-1.317v2.pdf", "text": "BERTastic .512 .446 TheSyllogist .554 .444 UMUTeam .385 .288 UMUTeam .477 .438 UMUTeam .614 .565 MaChAmp .597 .582\nUMUTeam .508 .415 BERTastic .545 .469 Hitachi .370 .326 mCPT .469 .429 BERTastic .603 .562 mCPT .597 .555\nACCEPT .507 .502 QUST .502 .465 Riga .315 .222 ACCEPT .456 .443 MaChAmp .582 .564 Baseline .594 .532"}, {"source": "2023.semeval-1.317v2.pdf", "text": "MaChAmp .506 .493 Riga .499 .321 ACCEPT .254 .249 QUST .447 .438 SATLab .572 .519 QUST .591 .533\nTheSyllogist .487 .409 ACCEPT .495 .439 QUST .250 .213 Riga .376 .287 FTD .555 .299 FTD .588 .516\nMLModeler5 .477 .427 Baseline .486 .372 Baseline .230 .218 SATLab .375 .352 FramingFreaks .545 .496 BERTastic .587 .535"}, {"source": "2023.semeval-1.317v2.pdf", "text": "FTD .453 .362 SATLab .474 .416 FramingFreaks .219 .159 MaChAmp .359 .355 TheSyllogist .537 .465 FramingFreaks .560 .460\nJUSTR00 .443 .363 FTD .459 .227 FTD .198 .117 Baseline .329 .276 Riga .509 .375 TheSyllogist .553 .501\nRiga .420 .313 FramingFreaks .452 .355 MaChAmp .161 .151 FramingFreaks .327 .300 ACCEPT .496 .460 Riga .542 .412"}, {"source": "2023.semeval-1.317v2.pdf", "text": "SATLab .378 .317 MaChAmp .424 .403 SinaAI .113 .128 FTD .255 .105 Baseline .487 .418 ACCEPT .510 .490\nBaseline .350 .274 SinaAI .251 .200 DigDemLab .070 .055 DigDemLab .220 .192 DigDemLab .335 .279 SinaAI .475 .446\nUTB-NLP .341 .309 DigDemLab .237 .173 SinaAI .187 .157 SinaAI .302 .265 DigDemLab .392 .348\nIA2022Grupa1 .326 .265\nSinaAI .266 .226\nDigDemLab .207 .172\nFramingFreaks .196 .142"}, {"source": "2023.semeval-1.317v2.pdf", "text": "FramingFreaks .196 .142\nTable 6: Results for Subtask 2 for the six main languages: micro F 1(mic), macro F 1(mac), ordered by the former,\nwhich is the official score.\nSpanish Greek Georgian\nTEAM mic mac TEAM mic mac TEAM mic mac\nmCPT .571 .455 SheffieldVeraAI .546 .454 SheffieldVeraAI .654 .679\nUMUTeam .558 .465 TeamAmpa .544 .444 MarsEclipse .645 .639"}, {"source": "2023.semeval-1.317v2.pdf", "text": "SheffieldVeraAI .508 .432 UMUTeam .534 .404 TheSyllogist .561 .493\nTeamAmpa .506 .387 TheSyllogist .530 .440 BERTastic .552 .408\nRiga .489 .426 BERTastic .526 .444 UMUTeam .529 .411\nQCRI .488 .390 QCRI .519 .400 QCRI .517 .457\nMarsEclipse .477 .404 mCPT .516 .410 TeamAmpa .517 .379\nBERTastic .477 .428 MarsEclipse .498 .402 Riga .424 .381\nTheSyllogist .473 .387 QUST .414 .392 mCPT .400 .291"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ACCEPT .388 .387 FramingFreaks .380 .154 FramingFreaks .352 .344\nMaChAmp .385 .269 Riga .377 .195 MaChAmp .313 .225\nSATLab .383 .293 ACCEPT .355 .370 QUST .311 .260\nQUST .374 .353 Baseline .345 .057 Baseline .260 .251\nFTD .265 .201 MaChAmp .293 .206 ACCEPT .220 .290\nFramingFreaks .215 .211 SinaAI .140 .123 SinaAI .133 .205\nSinaAI .181 .163 SATLab .068 .037 SATLab .053 .184\nBaseline .120 .095"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Baseline .120 .095\nTable 7: Results for Subtask 2 for the three surprise\nlanguages: micro F 1(mic), macro F 1(mac), ordered\nby the former, which is the official score.\ntively. For the other languages, their best systems\nused multilingual BERT, XLM-RoBERTa, or en-\nsembles thereof. In all cases, they truncated the\ninput to the first 510 tokens. They further upsam-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "pled the data to balance the distribution between\nthe classes (the results without upsampling were\nlow).\nHitachi (IT, RU) augmented the dataset for sub-\ntask 1 by collecting labelled examples from simi-\nlar datasets. They pretrained (XLM-)RoBERTa in\nmulti-task (one language, subtasks 1 and 2), multi-\nlingual (one subtask, all languages), and multilin-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "gual multi-task (subtasks 1 and 2 in all languages)\nsettings. Besides using the single models, they re-\nport experiments with ensembles of base models\nand different hyper-parameter values.\nMELODI (EN) fine-tuned the domain-specificlanguage model trained on English data, POLI-\nTICS, on the English input articles and on the\narticles in all other languages, which were auto-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "matically translated. In addition, in order to use\nwhole articles as input, they used a sliding win-\ndow and aggregated each window representation\nusing mean-pooling. They also tested other multi-\nlingual approaches, such as XLM-RoBERTa, and\nwere able to process long documents (Longformer),\nwhich were generally less effective.\nUMUTeam (FR, DE) used a multilingual model"}, {"source": "2023.semeval-1.317v2.pdf", "text": "based on XML-RoBERTa, which was fine-tuned\non all languages at once and a sentence transformer\nmodel to extract the most important chunk of text.\nThe input data was truncated to 200 tokens with 50\noverlaps using the sentence-transformer model to\nobtain the subset of text most related to the article\u2019s\ntitle.\nSheffieldVeraAI (DE) deployed an ensemble of\nthree fine-tuned mBERT models and one mBERT"}, {"source": "2023.semeval-1.317v2.pdf", "text": "model with a bottleneck adapter. All used bert-\nbase-multilingual-cased. The pool of training data\nwas also extended by integration additional \u201csatire\u201d\nresources for English. The final predictions were\ndrawn as a majority-voting predicted class.\n6.2 Subtask 2: Framing\nThe full results for subtask 2 on framing classifi-\ncation are provided in Table 6 and 7 (surprise lan-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "guages). We used linear SVM trained using word\nunigrams and bigrams as a baseline (highlighted in\nblue in the tables). Table 8 shows an overview\nof the approaches. Since the models were alltransformer-based, what differentiated the partici-\npating systems were once again the pre-processing\nand the data augmentation techniques. The vast\nmajority of teams trained their systems on all lan-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "guages and used ensembles.\nTeam Name\ntransformers\nother representations\nadditional data\ndata augmentation\nensembles\npreprocessing\ntrained on all languages\nknowledge base\nchunk processing\ndata translation\nACCEPT \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nBERTastic \u2713 \u2713 \u2713 \u2713 \u2713\nFTD \u2713\nHitachi \u2713 \u2713 \u2713\nMLModeler5 \u2713 \u2713 \u2713 \u2713\nMaChAmp \u2713\nMarsEclipse \u2713 \u2713 \u2713\nQCRI \u2713 \u2713 \u2713\nQUST \u2713 \u2713 \u2713 \u2713 \u2713\nRiga \u2713 \u2713 \u2713 \u2713\nSheffieldVeraAI \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nTheSyllogist \u2713 \u2713 \u2713"}, {"source": "2023.semeval-1.317v2.pdf", "text": "TheSyllogist \u2713 \u2713 \u2713\nUMUTeam \u2713 \u2713 \u2713\nUTB-NLP \u2713 \u2713 \u2713 \u2713\nmCPT \u2713 \u2713\nTable 8: ST2: Overview of the approaches and the\nfeatures used by the participating systems. The systems\nhighlighted in bold ranked first for at least one language.\nMarsEclipse (IT, RU, FR, DE, PL): This team\nused a multi-label contrastive loss for fine-tuning\nXLM-RoBERTa using SimCLR and SimCSE and"}, {"source": "2023.semeval-1.317v2.pdf", "text": "XLM-RoBERTa using SimCLR and SimCSE and\nadapting the loss function to a multilabel setup.\nmCPT (ES): This team used a two-phase train-\ning procedure of a transformer model, first by pre-\ntraining jointly on all the languages and then by\nfine-tuning for each language. In both phases, a\nmulti-label contrastive loss was used.\nSheffieldVeraAI (EN, EL, KA): The team"}, {"source": "2023.semeval-1.317v2.pdf", "text": "SheffieldVeraAI (EN, EL, KA): The team\nachieved the best average rank score over all the\nlanguages. They used two different ensembles of\nMUPPET large and of XLM-RoBERTa large with\nadapters and task-adaptive MLM pretraining on the\ntrain+dev+test data. Their data was preprocessed\nand truncated. The models were trained both with\nand without class weighting.\n6.3 Subtask 3: Persuasion Techniques"}, {"source": "2023.semeval-1.317v2.pdf", "text": "6.3 Subtask 3: Persuasion Techniques\nDetection\nThe full results for subtask 3 on persuasion tech-\nniques detection are given in Tables 9 and 10 (sur-\nprise languages). We used linear SVM trained\nusing word uni-grams and bigrams as a baseline\n(highlighted in blue in the tables). Table 11 shows\nan overview of the approaches used by the partic-ipating systems. The big picture is very similar"}, {"source": "2023.semeval-1.317v2.pdf", "text": "to the previous subtasks: multilingual transformer\nmodels were used by all participants, and what\ndifferentiated the approaches was again the pre-\nprocessing and data augmentation strategies, for\nexample, a few teams made use of the span-level\nannotations.\nAPatt (EN): The team combined different fine-\ntuned transformer models (XLNet, RoBERTa,\nBERT, ALBERT, and DeBERTa) through a"}, {"source": "2023.semeval-1.317v2.pdf", "text": "BERT, ALBERT, and DeBERTa) through a\nweighted average. For English, they weighted the\npredictions of the models to give higher importance\nto certain models.\nKInITVeraAI (IT, RU, DE, PL, EL, KA): This\nteam performed overall the best, using a fine-tuned\nXLM-RoBERTa-large transformer model trained\non all the input data. They carefully adjusted the\nprediction threshold for each language using a prin-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "cipled approach. They truncated the input, and also\nfound that preprocessing did not impact the quality\nmuch.\nNAP (FR): The team presented an approach\ncombining predictions of several models in an en-\nsemble, which differ in three main aspects: a)\ntraining data, b) model architecture, and c) in-\nput format to the model. They leveraged trans-\nlation as data augmentation strategies using avail-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "able MarianMT models. Model architectures in-\ncluded XLM-RoBERTa models, Adapters, SetFit,\nand linguistically-informed heuristics for under-\nrepresented techniques which were fine-tuned on\ndifferent combinations of original and augmented\ndata. They fine-tuned models on both paragraph-\nand span-level information.\nTeamAmpa (ES): The team used different over-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "sampling strategies, data truncation, and monolin-\ngual and multilingually trained models, combined\nin an ensemble for the English Task 3 data. The\nsurprise languages were handled using the mul-\ntilingual model only, which where trained using\nXLM-R on all languages with oversampling, for\none of these languages the team ranked first.\n6.4 Aggregated results"}, {"source": "2023.semeval-1.317v2.pdf", "text": "6.4 Aggregated results\nTables 12-14 report the average micro F 1scores of\nthe teams who, for each subtask, submitted solu-\ntions for multiple languages: the 6 for which we\nprovided training data (6L), the 3 surprise ones\n(3L), all of them (9L). Results are ranked by de-\ncreasing value on all.English Italian Russian French German Polish"}, {"source": "2023.semeval-1.317v2.pdf", "text": "TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac TEAM mic mac\nAPatt .376 .129 KInITVeraAI .550 .214 KInITVeraAI .387 .189 NAP .469 .322 KInITVeraAI .513 .233 KInITVeraAI .430 .179\nSheffieldVeraAI .368 .172 NAP .539 .266 TeamAmpa .378 .227 TeamAmpa .434 .305 NAP .510 .272 NAP .422 .246"}, {"source": "2023.semeval-1.317v2.pdf", "text": "AppealForAtt .363 .166 SheffieldVeraAI .525 .282 QCRI .361 .182 KInITVeraAI .432 .214 QCRI .498 .231 DSHacker .390 .170\nKInITVeraAI .362 .133 TeamAmpa .521 .264 NLUBot101 .323 .201 SheffieldVeraAI .414 .324 APatt .484 .177 TeamAmpa .389 .236\nNLUBot101 .361 .197 FTD .516 .176 SheffieldVeraAI .318 .205 QCRI .401 .226 TeamAmpa .476 .266 QCRI .378 .156"}, {"source": "2023.semeval-1.317v2.pdf", "text": "FTD .346 .088 QCRI .513 .209 AppealForAtt .312 .173 NLUBot101 .396 .254 SheffieldVeraAI .447 .237 APatt .366 .150\nTeamAmpa .325 .158 DSHacker .496 .153 APatt .306 .117 DSHacker .388 .201 NLUBot101 .420 .179 SheffieldVeraAI .347 .191\nQCRI .320 .133 ReDASPersuasion .448 .106 NAP .305 .193 APatt .384 .191 AppealForAtt .418 .218 AppealForAtt .344 .201"}, {"source": "2023.semeval-1.317v2.pdf", "text": "DSHacker .320 .140 APatt .441 .166 MaChAmp .271 .148 AppealForAtt .374 .203 DSHacker .408 .154 FTD .327 .122\nCLaC .309 .071 Riga .436 .092 DSHacker .257 .083 kb .362 .266 MaChAmp .405 .178 NLUBot101 .320 .169\nNL4IA .308 .142 NLUBot101 .435 .164 kb .253 .117 MaChAmp .345 .207 ReDASPersuasion .384 .078 kb .314 .179"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Unisa .298 .109 SATLab .433 .183 Riga .252 .064 SATLab .338 .241 kb .373 .201 MaChAmp .307 .170\nMaChAmp .295 .149 AppealForAtt .431 .211 FTD .235 .058 Riga .306 .078 Riga .373 .060 SATLab .300 .143\nRiga .280 .062 MaChAmp .422 .166 ReDASPersuasion .219 .050 ReDASPersuasion .301 .115 FTD .363 .110 ReDASPersuasion .238 .112"}, {"source": "2023.semeval-1.317v2.pdf", "text": "NAP .263 .082 kb .399 .201 Baseline .207 .086 FTD .298 .126 SATLab .355 .163 UnedMediaBias .237 .103\nSATLab .259 .103 Baseline .397 .122 CLaC .193 .057 Baseline .240 .099 UnedMediaBias .318 .106 Riga .228 .038\nReDASPersuasion .251 .045 UnedMediaBias .317 .111 UnedMediaBias .183 .100 CLaC .239 .066 Baseline .317 .083 CLaC .190 .050"}, {"source": "2023.semeval-1.317v2.pdf", "text": "UnedMediaBias .241 .078 CLaC .313 .063 SinaAI .139 .057 UnedMediaBias .236 .121 CLaC .248 .055 Baseline .179 .059\nBaseline .195 .069 QUST .213 .155 QUST .100 .080 QUST .209 .164 QUST .153 .112 QUST .097 .074\nIA2022Grupa1 .193 .072 SinaAI .203 .064 SinaAI .195 .063 SinaAI .042 .034 SinaAI .064 .025\nSinaAI .141 .022\nQUST .135 .103\nkb .060 .031"}, {"source": "2023.semeval-1.317v2.pdf", "text": "QUST .135 .103\nkb .060 .031\nTable 9: Results for subtask 3 for the six main languages: micro F 1(mic), macro F 1(mac), ordered by the former,\nwhich is the official score.\nSpanish Greek Georgian\nTEAM mic mac TEAM mic mac TEAM mic mac\nTeamAmpa .381 .244 KInITVeraAI .267 .126 KInITVeraAI .457 .328\nKInITVeraAI .380 .155 QCRI .265 .129 QCRI .414 .339\nNAP .370 .181 NAP .258 .164 NAP .413 .306"}, {"source": "2023.semeval-1.317v2.pdf", "text": "QCRI .350 .157 TeamAmpa .238 .171 TeamAmpa .408 .259\nAppealForAtt .317 .139 MaChAmp .215 .129 Riga .362 .209\nNLUBot101 .305 .151 AppealForAtt .206 .119 MaChAmp .301 .221\nFTD .281 .074 SheffieldVeraAI .174 .110 AppealForAtt .280 .261\nMaChAmp .276 .139 Riga .164 .036 CLaC .271 .199\nSheffieldVeraAI .275 .130 CLaC .156 .055 NLUBot101 .254 .172"}, {"source": "2023.semeval-1.317v2.pdf", "text": "CLaC .267 .048 NLUBot101 .150 .097 SheffieldVeraAI .249 .296\nBaseline .248 .020 kb .150 .121 UnedMediaBias .180 .221\nkb .245 .143 SinaAI .114 .029 kb .150 .100\nUnedMediaBias .227 .078 UnedMediaBias .106 .026 SinaAI .139 .040\nRiga .199 .045 Baseline .088 .006 Baseline .138 .141\nSATLab .193 .057 QUST .057 .047 QUST .091 .115\nSinaAI .178 .028 SATLab .000 .000 SATLab .076 .158\nQUST .126 .099"}, {"source": "2023.semeval-1.317v2.pdf", "text": "QUST .126 .099\nTable 10: Results for Subtask 3 for the three surprise\nlanguages: micro F 1(mic), macro F 1(mac), ordered\nby the former, which is the official score.\n7 Conclusions and Future Work\nWe presented SemEval-2023 Task 3 on Detecting\nthe Category, the Framing, and the Persuasion\nTechniques in Online News in a Multi-lingual Setup .\nThe task attracted a lot of attention: 181 teams reg-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "istered for the task, 41 teams eventually madevan\nofficial submission on the test set, and 32 teams\nalso submitted a task description paper.\nIn future work, we plan to further increase the\ndata size, cover additional languages, and explore\ndifferent ways of evaluation of the persuasion\ntechnique detection, e.g., by changing the focus\n(sentence- and text span-level evaluation).\n8 Limitations"}, {"source": "2023.semeval-1.317v2.pdf", "text": "8 Limitations\nDataset Representativeness Our dataset covers\na range of topics of public interest (COVID-19,Team Name\ntransformers\nother representations\nadditional data\ndata augmentation\nensembles\npreprocessing\ntrained on all languages\nknowledge base\nchunk processing\ndata translation\nAPatt \u2713 \u2713\nAppealForAtt \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nDSHacker \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nFTD \u2713\nKInITVeraAI \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nNAP \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nNL4IA \u2713 \u2713"}, {"source": "2023.semeval-1.317v2.pdf", "text": "NAP \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nNL4IA \u2713 \u2713\nNLUBot101 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713\nQCRI \u2713 \u2713 \u2713\nQUST \u2713 \u2713 \u2713 \u2713 \u2713\nReDASPersuasion \u2713 \u2713\nRiga \u2713 \u2713 \u2713\nSheffieldVeraAI \u2713 \u2713 \u2713\nUnedMediaBiasTeam \u2713 \u2713 \u2713\nUnisa \u2713 \u2713 \u2713\nkb \u2713 \u2713\nTable 11: ST3: Overview of the approaches and the\nfeatures used by the participating systems. The systems\nhighlighted in bold ranked first for at least one language.\nclimate change, abortion, migration, the Russo-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Ukrainian war, and local elections) as well as media\nfrom all sides of the political spectrum. However,\nit should not be seen as representative of the media\nin any country, nor should it be seen as perfectly\nbalanced in any specific way.\nBiases Human data annotation involves some de-\ngree of subjectivity. To mitigate this, we created\na comprehensive 60-page guidelines document,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "which we updated from time to time to clarify\nnewly arising important cases during the annota-\ntion process. We further had quality control stepsteam 6L 3L 9L\nSheffieldVeraAI 0.779 0.733 0.764\nHitachi 0.768 - -\nMELODI 0.761 0.676 0.732\nUMUTeam 0.756 0.720 0.744\nDSHacker 0.735 0.690 0.720\nFTD 0.725 0.699 0.716\nQCRI 0.720 0.759 0.733\nBaseline 0.711 0.330 0.584\nSinaAI 0.688 0.645 0.673"}, {"source": "2023.semeval-1.317v2.pdf", "text": "SinaAI 0.688 0.645 0.673\nMaChAmp 0.672 0.577 0.641\nQUST 0.656 0.644 0.652\nFramingFreaks 0.605 0.477 0.562\nUnedMediaBiasTeam 0.516 0.540 0.524\nRiga 0.505 0.693 0.567\nE8IJS 0.158 0.121 0.146\nTable 12: Average macro score across language for the\nteams participating in all \u2018provided\u2019 six languages (6L),\nthe three surprise languages (3L), all nine languages\n(9L) for subtask 1.\nteam 6L 3L 9L"}, {"source": "2023.semeval-1.317v2.pdf", "text": "(9L) for subtask 1.\nteam 6L 3L 9L\nMarsEclipse 0.594 0.540 0.576\nSheffieldVeraAI 0.571 0.570 0.570\nQCRI 0.555 0.508 0.539\nTeamAmpa 0.554 0.522 0.543\nHitachi 0.548 - -\nmCPT 0.536 0.496 0.523\nUMUTeam 0.534 0.541 0.536\nBERTastic 0.530 0.518 0.526\nTheSyllogist 0.500 0.521 0.507\nQUST 0.486 0.366 0.446\nACCEPT 0.453 0.321 0.409\nRiga 0.444 0.430 0.439\nMaChAmp 0.438 0.330 0.402\nFTD 0.418 - -"}, {"source": "2023.semeval-1.317v2.pdf", "text": "MaChAmp 0.438 0.330 0.402\nFTD 0.418 - -\nBaseline 0.412 0.242 0.356\nFramingFreaks 0.383 0.316 0.361\nSinaAI 0.266 0.151 0.227\nDigDemLab 0.244 - -\nTable 13: Average micro score across language for the\nteams participating in all \u2018provided\u2019 six languages (6L),\nthe three surprise languages (3L), all nine languages\n(9L) for subtask 2.\nin the data annotation process, and we have been"}, {"source": "2023.semeval-1.317v2.pdf", "text": "excluding low-performing annotators. Despite all\nthis, we are aware that some degree of intrinsic\nsubjectivity will inevitably be present in the dataset\nand will eventually be learned by models trained\non it.\nAcknowledgments\nWe are greatly indebted to all the annotators from\ndifferent organisations, including, i.a., the Euro-\npean Commission, the European Parliament, the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "University of Padua, and the Qatar Computing Re-\nsearch Institute, HBKU, who took part in the anno-team 6L 3L 9L\nKInITVeraAI 0.446 0.368 0.420\nTeamAmpa 0.420 0.343 0.395\nNAP 0.418 0.347 0.394\nQCRI 0.412 0.343 0.389\nSheffieldVeraAI 0.403 0.233 0.346\nAPatt 0.393 - -\nDSHacker 0.376 - -\nNLUBot101 0.376 0.236 0.329\nAPatt 0.374 0.268 0.338\nFTD 0.347 - -\nMaChAmp 0.341 0.264 0.315\nRiga 0.312 0.242 0.289"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Riga 0.312 0.242 0.289\nReDASPersuasion 0.307 - -\nkb 0.294 0.182 0.256\nBaseline 0.256 0.158 0.223\nUnedMediaBias 0.255 0.171 0.227\nCLaC 0.249 0.231 0.243\nQUST 0.151 0.091 0.131\nSinaAI 0.131 0.144 0.135\nTable 14: Average micro score across language for the\nteams participating in all \u2018provided\u2019 six languages (6L),\nthe three surprise languages (3L), all nine languages\n(9L) for subtask 3."}, {"source": "2023.semeval-1.317v2.pdf", "text": "(9L) for subtask 3.\ntations, and notably to the language curators whose\npatience and diligence have been fundamental for\nthe quality of the dataset. We are also thankful\nto Nikolaidis Nikolaos for the preparation of the\nbaseline models and for sharing various ideas.\nPart of this work was supported by IDKT Fund\nTDF 03-1209-210013: Tanbih: Get to Know What\nYou Are Reading .\nReferences"}, {"source": "2023.semeval-1.317v2.pdf", "text": "You Are Reading .\nReferences\nAhmed Al-Qarqaz and Malak Abdullah. 2023. Team\njustr00 at semeval-2023 task 3: Transformers for\nnews articles classification. In Proceedings of the\n17th International Workshop on Semantic Evaluation ,\npages 1213\u20131216, Toronto, Canada. Association for\nComputational Linguistics.\nFiroj Alam, Hamdy Mubarak, Wajdi Zaghouani, Gio-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "vanni Da San Martino, and Preslav Nakov. 2022.\nOverview of the WANLP 2022 shared task on pro-\npaganda detection in Arabic. In Proceedings of the\nSeventh Arabic Natural Language Processing Work-\nshop , Abu Dhabi, UAE.\nHamza Alami, Abdessamad Benlahbib, Abdelkader\nEl Mahdaouy, and Ismail Berrada. 2023. Um6p at\nsemeval-2023 task 3: News genre classification based"}, {"source": "2023.semeval-1.317v2.pdf", "text": "on transformers, graph convolution networks and\nnumber of sentences. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n856\u2013861, Toronto, Canada. Association for Compu-\ntational Linguistics.\nSergiu Amihaesei, Laura Cornei, and George Stoica.\n2023. Appeal for attention at semeval-2023 task 3:Data augmentation extension strategies for detection"}, {"source": "2023.semeval-1.317v2.pdf", "text": "of online news persuasion techniques. In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 616\u2013623, Toronto, Canada. Asso-\nciation for Computational Linguistics.\nMicaela Bangerter, Giuseppe Fenza, Mariacristina\nGallo, Vincenzo Loia, Alberto V olpe, Carmen De\nMaio, and Claudio Stanzione. 2023. Unisa at\nsemeval-2023 task 3: A shap-based method for pro-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "paganda detection. In Proceedings of the 17th Inter-\nnational Workshop on Semantic Evaluation , pages\n885\u2013891, Toronto, Canada. Association for Compu-\ntational Linguistics.\nKatarzyna Baraniak and M Sydow. 2023. Kb at semeval-\n2023 task 3: On multitask hierarchical bert base neu-\nral network for multi-label persuasion techniques de-\ntection. In Proceedings of the 17th International"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Workshop on Semantic Evaluation , pages 1395\u20131400,\nToronto, Canada. Association for Computational Lin-\nguistics.\nAdrien Barbaresi. 2021. Trafilatura: A Web Scrap-\ning Library and Command-Line Tool for Text Dis-\ncovery and Extraction. In Proceedings of the Joint\nConference of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th"}, {"source": "2023.semeval-1.317v2.pdf", "text": "International Joint Conference on Natural Language\nProcessing: System Demonstrations , pages 122\u2013131.\nAssociation for Computational Linguistics.\nAlberto Barr\u00f3n-Cedeno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864."}, {"source": "2023.semeval-1.317v2.pdf", "text": "56(5):1849\u20131864.\nRosina Baumann and Sabrina Deisenhofer. 2023. Fram-\ningfreaks at semeval-2023 task 3: Detecting the cate-\ngory and the framing of texts as subword units with\ntraditional machine learning. In Proceedings of the\n17th International Workshop on Semantic Evalua-\ntion, pages 922\u2013926, Toronto, Canada. Association\nfor Computational Linguistics."}, {"source": "2023.semeval-1.317v2.pdf", "text": "for Computational Linguistics.\nFabian Billert and Stefan Conrad. 2023. Hhu at semeval-\n2023 task 3: An adapter-based approach for news\ngenre classification. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages\n1166\u20131171, Toronto, Canada. Association for Com-\nputational Linguistics.\nDallas Card, Amber E. Boydstun, Justin H. Gross,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Philip Resnik, and Noah A. Smith. 2015. The Media\nFrames Corpus: Annotations of frames across issues.\nInProceedings of the 53rd Annual Meeting of the\nAssociation for Computational Linguistics and the\n7th International Joint Conference on Natural Lan-\nguage Processing , ACL-IJCNLP \u201915, pages 438\u2013444,\nBeijing, China.\nLoretta H Cheeks, Tracy L Stepien, Dara M Wald, and"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Ashraf Gaffar. 2020. Discovering news frames: An\napproach for exploring text, content, and concepts inonline news sources. In Cognitive Analytics: Con-\ncepts, Methodologies, Tools, and Applications , pages\n702\u2013721. IGI Global.\nAnton Chernyavskiy, Dmitry Ilvovsky, and Preslav\nNakov. 2021. Transformers: \u201cThe end of history\u201d\nfor NLP? In Proceedings of the European Confer-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ence on Machine Learning and Principles and Prac-\ntice of Knowledge Discovery in Databases , ECML-\nPKDD\u201921.\nNelson Filipe Costa, Bryce Hamilton, and Leila Kos-\nseim. 2023. Clac at semeval-2023 task 3: Language\npotluck roberta detects online persuasion techniques\nin a multilingual setup. In Proceedings of the 17th In-\nternational Workshop on Semantic Evaluation , pages"}, {"source": "2023.semeval-1.317v2.pdf", "text": "1613\u20131618, Toronto, Canada. Association for Com-\nputational Linguistics.\nJuan Cuadrado, Elizabeth Martinez, Anderson Morillo,\nDaniel Pe\u00f1a, Kevin Sossa, Juan Carlos Martinez-\nSantos, and Edwin Puertas. 2023. Utb-nlp at semeval-\n2023 task 3: Weirdness, lexical features for detecting\ncategorical framings, and persuasion in online news.\nInProceedings of the 17th International Workshop"}, {"source": "2023.semeval-1.317v2.pdf", "text": "on Semantic Evaluation , pages 1551\u20131557, Toronto,\nCanada. Association for Computational Linguistics.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\nNakov. 2020a. SemEval-2020 task 11: Detection\nof propaganda techniques in news articles. In Pro-\nceedings of the International Workshop on Semantic\nEvaluation , SemEval \u201920, Barcelona, Spain."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Giovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o, and\nPreslav Nakov. 2019. Findings of the NLP4IF-2019\nshared task on fine-grained propaganda detection. In\nProceedings of the Second Workshop on Natural Lan-\nguage Processing for Internet Freedom: Censorship,\nDisinformation, and Propaganda , NLP4IF \u201919, pages\n162\u2013170, Hong Kong, China.\nGiovanni Da San Martino, Stefano Cresci, Alberto"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Barr\u00f3n-Cede\u00f1o, Seunghak Yu, Roberto Di Pietro,\nand Preslav Nakov. 2020b. A survey on computa-\ntional propaganda detection. In Proceedings of the\nInternational Joint Conference on Artificial Intelli-\ngence , IJCAI-PRICAI \u201920, pages 4826\u20134832.\nGiovanni Da San Martino, Shaden Shaar, Yifan Zhang,\nSeunghak Yu, Alberto Barr\u00f3n-Cedeno, and Preslav\nNakov. 2020c. Prta: A system to support the analysis"}, {"source": "2023.semeval-1.317v2.pdf", "text": "of propaganda techniques in the news. In Proceed-\nings of the 58th Annual Meeting of the Association for\nComputational Linguistics: System Demonstrations,\nACL 2020, Online, July 5-10, 2020 , pages 287\u2013293.\nAssociation for Computational Linguistics.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarron-Cedeno, Rostislav Petrov, and Preslav Nakov.\n2019. Fine-grained analysis of propaganda in news"}, {"source": "2023.semeval-1.317v2.pdf", "text": "articles. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing ,\nEMNLP \u201919, pages 5636\u20135646, Hong Kong, China.Nicolas Devatine, Philippe Muller, and Chlo\u00e9 Braud.\n2023. Melodi at semeval-2023 task 3: In-domain\npre-training for low-resource classification of news\narticles. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 108\u2013113,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Toronto, Canada. Association for Computational Lin-\nguistics.\nDimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021a. De-\ntecting propaganda techniques in memes. In Pro-\nceedings of the Joint Conference of the 59th Annual\nMeeting of the Association for Computational Lin-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "guistics and the 11th International Joint Conference\non Natural Language Processing , ACL-IJCNLP \u201921,\npages 6603\u20136617.\nDimiter Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021b. Task\n6 at SemEval-2021: Detection of persuasion tech-\nniques in texts and images. In Proceedings of the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "15th International Workshop on Semantic Evalua-\ntion, SemEval \u201921, Bangkok, Thailand.\nRobert M Entman. 1993. Framing: Towards clarifica-\ntion of a fractured paradigm. McQuail\u2019s reader in\nmass communication theory , pages 390\u2013397.\nNeele Falk, Annerose Eichel, and Prisca Piccirilli. 2023.\nNap at semeval-2023 task 3: Is less really more?\n(back-)translation as data augmentation strategies for"}, {"source": "2023.semeval-1.317v2.pdf", "text": "detecting persuasion techniques. In Proceedings of\nthe 17th International Workshop on Semantic Evalua-\ntion, pages 1433\u20131446, Toronto, Canada. Association\nfor Computational Linguistics.\nJennifer Golbeck, Matthew Mauriello, Brooke Aux-\nier, Keval H. Bhanushali, Christopher Bonk, Mo-\nhamed Amine Bouzaghrane, Cody Buntain, Riya\nChanduka, Paul Cheakalos, Jennine B. Everett,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Waleed Falak, Carl Gieringer, Jack Graney, Kelly M.\nHoffman, Lindsay Huth, Zhenya Ma, Mayanka Jha,\nMisbah Khan, Varsha Kori, Elo Lewis, George Mi-\nrano, William T. Mohn IV , Sean Mussenden, Tam-\nmie M. Nelson, Sean Mcwillie, Akshat Pant, Priya\nShetye, Rusha Shrestha, Alexandra Steinheimer,\nAditya Subramanian, and Gina Visnansky. 2018.\nFake news vs satire: A dataset and analysis. In Pro-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ceedings of the 10th ACM Conference on Web Sci-\nence, WebSci \u201918, page 17\u201321, Amsterdam, Nether-\nlands. Association for Computing Machinery.\nMaur\u00edcio Gruppi, Benjamin D. Horne, and Sibel Adali.\n2020. NELA-GT-2019: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. arXiv , 2003.08444.\nIvan Habernal, Raffael Hannemann, Christian Pol-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "lak, Christopher Klamm, Patrick Pauli, and Iryna\nGurevych. 2017. Argotario: Computational argu-\nmentation meets serious games. In Proceedings of\nthe 2017 Conference on Empirical Methods in Nat-\nural Language Processing: System Demonstrations ,\nEMNLP \u201917, pages 7\u201312, Copenhagen, Denmark.Ivan Habernal, Patrick Pauli, and Iryna Gurevych. 2018.\nAdapting serious game for fallacious argumentation"}, {"source": "2023.semeval-1.317v2.pdf", "text": "to German: Pitfalls, insights, and best practices. In\nLREC . European Language Resources Association\n(ELRA).\nMaram Hasanain, Ahmed Oumar El-Shangiti, Ra-\nbindra Nath Nandi, Preslav Nakov, and Firoj Alam.\n2023. Qcri at semeval-2023 task 3: News genre,\nframing and persuasion techniques detection using\nmultilingual models. In Proceedings of the 17th In-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ternational Workshop on Semantic Evaluation , pages\n1237\u20131244, Toronto, Canada. Association for Com-\nputational Linguistics.\nPhilipp Heinisch, Moritz Plenz, Anette Frank, and\nPhilipp Cimiano. 2023. Accept at semeval-2023\ntask 3: An ensemble-based approach to multilingual\nframing detection. In Proceedings of the 17th Inter-\nnational Workshop on Semantic Evaluation , pages"}, {"source": "2023.semeval-1.317v2.pdf", "text": "1347\u20131358, Toronto, Canada. Association for Com-\nputational Linguistics.\nBenjamin Horne and Sibel Adali. 2017. This just in:\nFake news packs a lot in title, uses simpler, repetitive\ncontent in text body, more similar to satire than real\nnews. arXiv , 1703.09398.\nKristina Hristakieva, Stefano Cresci, Giovanni\nDa San Martino, Mauro Conti, and Preslav Nakov."}, {"source": "2023.semeval-1.317v2.pdf", "text": "2022. The spread of propaganda by coordinated\ncommunities on social media. In Proceedings of the\n14th ACM Web Science Conference , WebSci \u201922,\npages 191\u2013201, Barcelona, Spain.\nTimo Hromadka, Timotej Smolen, Tomas Remis,\nBranislav Pecher, and Ivan Srba. 2023. Kinitveraai at\nsemeval-2023 task 3: Simple yet powerful multilin-\ngual fine-tuning for persuasion techniques detection."}, {"source": "2023.semeval-1.317v2.pdf", "text": "InProceedings of the 17th International Workshop\non Semantic Evaluation , pages 629\u2013637, Toronto,\nCanada. Association for Computational Linguistics.\nYe Jiang. 2023. Team qust at semeval-2023 task 3:\nA comprehensive study of monolingual and multi-\nlingual approaches for detecting online news genre,\nframing and persuasion techniques. In Proceedings"}, {"source": "2023.semeval-1.317v2.pdf", "text": "of the 17th International Workshop on Semantic Eval-\nuation , pages 300\u2013306, Toronto, Canada. Association\nfor Computational Linguistics.\nArjun Khanchandani, Nitansh Jain, and Jatin Bedi. 2023.\nMlmodeler5 at semeval-2023 task 3: Detecting the\ncategory and the framing techniques in online news in\na multi-lingual setup. In Proceedings of the 17th In-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ternational Workshop on Semantic Evaluation , pages\n1096\u20131101, Toronto, Canada. Association for Com-\nputational Linguistics.\nJan-Christoph Klie, Michael Bugert, Beto Boullosa,\nRichard Eckart de Castilho, and Iryna Gurevych.\n2018. The inception platform: Machine-assisted and\nknowledge-oriented interactive annotation. In Pro-\nceedings of the 27th International Conference on"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Computational Linguistics: System Demonstrations ,pages 5\u20139. Association for Computational Linguis-\ntics. Event Title: The 27th International Conference\non Computational Linguistics (COLING 2018).\nYuta Koreeda, Ken-ichi Yokote, Hiroaki Ozaki, Atsuki\nYamaguchi, Masaya Tsunokake, and Yasuhiro So-\ngawa. 2023. Hitachi at semeval-2023 task 3: Explor-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ing cross-lingual multi-task strategies for genre and\nframing detection in online news. In Proceedings of\nthe 17th International Workshop on Semantic Evalua-\ntion, pages 1702\u20131711, Toronto, Canada. Association\nfor Computational Linguistics.\nHaewoon Kwak, Jisun An, and Yong-Yeol Ahn. 2020.\nA systematic media frame analysis of 1.5 million\nNew York Times articles from 2000 to 2017. In"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Proceedings of the 12th ACM Conference on Web\nScience , WebSci \u201920, pages 305\u2013314, Southampton,\nUnited Kingdom.\nMikhail Lepekhin and Serge Sharoff. 2023. Ftd at\nsemeval-2023 task 3: News genre and propaganda de-\ntection by comparing mono- and multilingual models\nwith fine-tuning on additional data. In Proceedings of\nthe 17th International Workshop on Semantic Evalu-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ation , pages 549\u2013555, Toronto, Canada. Association\nfor Computational Linguistics.\nQisheng Liao, Meiting Lai, and Preslav Nakov. 2023.\nMarseclipse at semeval-2023 task 3: Multi-lingual\nand multi-label framing detection with contrastive\nlearning. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 83\u201387,\nToronto, Canada. Association for Computational Lin-\nguistics."}, {"source": "2023.semeval-1.317v2.pdf", "text": "guistics.\nGenglin Liu, Yi Fung, and Heng Ji. 2023. Nlubot101 at\nsemeval-2023 task 3: An augmented multilingual nli\napproach towards online news persuasion techniques\ndetection. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 1636\u20131643,\nToronto, Canada. Association for Computational Lin-\nguistics.\nSiyi Liu, Lei Guo, Kate Mays, Margrit Betke, and"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Derry Tanti Wijaya. 2019. Detecting frames in news\nheadlines and its application to analyzing news fram-\ning trends surrounding US gun violence. In Proceed-\nings of the 23rd Conference on Computational Natu-\nral Language Learning , CoNLL \u201919, pages 504\u2013514,\nHong Kong, China.\nTarek Mahmoud and Preslav Nakov. 2023. Bertastic at\nsemeval-2023 task 3: Fine-tuning pretrained multilin-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "gual transformers \u2013 does order matter? In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 58\u201363, Toronto, Canada. Associa-\ntion for Computational Linguistics.\nArkadiusz Modzelewski, Witold Sosnowski, Magdalena\nWilczynska, and Adam Wierzbicki. 2023. Dshacker\nat semeval-2023 task 3: Genres and persuasion tech-\nniques detection with multilingual data augmenta-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "tion through machine translation and text generation.\nInProceedings of the 17th International Workshopon Semantic Evaluation , pages 1582\u20131591, Toronto,\nCanada. Association for Computational Linguistics.\nOsama Mohammed Afzal and Preslav Nakov. 2023.\nTeam thesyllogist at semeval-2023 task 3: Language-\nagnostic framing detection in multi-lingual online"}, {"source": "2023.semeval-1.317v2.pdf", "text": "news: A zero-shot transfer approach. In Proceed-\nings of the 17th International Workshop on Semantic\nEvaluation , pages 2058\u20132061, Toronto, Canada. As-\nsociation for Computational Linguistics.\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni\nDa San Martino, and Yifan Zhang. 2021a. COVID-\n19 in Bulgarian social media: Factuality, harmfulness,\npropaganda, and framing. In Proceedings of the Inter-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "national Conference on Recent Advances in Natural\nLanguage Processing , RANLP \u201921.\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni\nDa San Martino, and Yifan Zhang. 2021b. A second\npandemic? Analysis of fake news about COVID-19\nvaccines in Qatar. In Proceedings of the International\nConference on Recent Advances in Natural Language\nProcessing , RANLP \u201921."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Processing , RANLP \u201921.\nJeppe N\u00f8rregaard, Benjamin D. Horne, and Sibel Adali.\n2019. NELA-GT-2018: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. In Proceedings of the Thirteenth International\nConference on Web and Social Media , ICWSM \u201919,\npages 630\u2013638, Munich, Germany. AAAI Press.\nRonghao Pan, Jos\u00e9 Antonio Garc\u00eda-D\u00edaz, Miguel \u00c1n-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "gel Rodr\u00edguez-Garc\u00eda, and Rafael Valencia-Garc\u00eda.\n2023. Umuteam at semeval-2023 task 3: Multilin-\ngual transformer-based model for detecting the genre,\nthe framing, and the persuasion techniques in on-\nline news. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 609\u2013615,\nToronto, Canada. Association for Computational Lin-\nguistics."}, {"source": "2023.semeval-1.317v2.pdf", "text": "guistics.\nAmalie Pauli, Rafael Pablos Sarabia, Leon Derczynski,\nand Ira Assent. 2023. Teamampa at semeval-2023\ntask 3: Exploring multilabel and multilingual roberta\nmodels for persuasion and framing detection. In Pro-\nceedings of the 17th International Workshop on Se-\nmantic Evaluation , pages 847\u2013855, Toronto, Canada.\nAssociation for Computational Linguistics."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Jakub Piskorski, Nicolas Stefanovitch, Valerie-Anne\nBausier, Nicolo Faggiani, Jens Linge, Sopho Kharazi,\nNikolaos Nikolaidis, Giulia Teodori, Bertrand\nDe Longueville, Brian Doherty, Jason Gonin,\nCamelia Ignat, Bonka Kotseva, Eleonora Mantica,\nLorena Marcaletti, Enrico Rossi, Alessio Spadaro,\nMarco Verile, Giovanni Da San Martino, Firoj Alam,\nand Preslav Nakov. 2023. News categorization, fram-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ing and persuasion techniques: Annotation guide-\nlines. Technical Report JRC-132862, European Com-\nmission Joint Research Centre, Ispra (Italy).\nAlbert Pritzkau. 2023. Nl4ia at semeval-2023 task 3:\nA comparison of sequence classification and tokenclassification to detect persuasive techniques. In Pro-\nceedings of the 17th International Workshop on Se-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "mantic Evaluation , pages 794\u2013799, Toronto, Canada.\nAssociation for Computational Linguistics.\nAntonio Purificato and Roberto Navigli. 2023. Apatt\nat semeval-2023 task 3: The sapienza nlp system for\nensemble-based multilingual propaganda detection.\nInProceedings of the 17th International Workshop\non Semantic Evaluation , pages 382\u2013388, Toronto,\nCanada. Association for Computational Linguistics."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Fatima Zahra Qachfar and Rakesh Verma. 2023.\nRedaspersuasion at semeval-2023 task 3: Persua-\nsion detection using multilingual transformers and\nlanguage agnostic features. In Proceedings of the\n17th International Workshop on Semantic Evaluation ,\npages 2124\u20132132, Toronto, Canada. Association for\nComputational Linguistics.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana"}, {"source": "2023.semeval-1.317v2.pdf", "text": "V olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and politi-\ncal fact-checking. In Proceedings of the Conference\non Empirical Methods in Natural Language Process-\ning, EMNLP \u201917, pages 2931\u20132937, Copenhagen,\nDenmark.\nMarkus Reiter-Haas, Alexander Ertl, Kevin Innerhofer,\nand Elisabeth Lex. 2023. mcpt at semeval-2023 task"}, {"source": "2023.semeval-1.317v2.pdf", "text": "3: Multilingual label-aware contrastive pre-training\nof transformers for few- and zero-shot framing de-\ntection. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 941\u2013949,\nToronto, Canada. Association for Computational Lin-\nguistics.\nFrancisco-Javier Rodrigo-Gin\u00e9s, Laura Plaza, and Jorge\nCarrillo-de Albornoz. 2023. Unedmediabiasteam"}, {"source": "2023.semeval-1.317v2.pdf", "text": "@ semeval-2023 task 3: Can we detect persuasive\ntechniques transferring knowledge from media bias\ndetection? In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 787\u2013793,\nToronto, Canada. Association for Computational Lin-\nguistics.\nAryan Sadeghi, Reza Alipour, Kamyar Taeb, Parimehr\nMorassafar, Nima Salemahim, and Ehsaneddin As-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "gari. 2023. Sinaai at semeval-2023 task 3: A multilin-\ngual transformer language model-based approach for\nthe detection of news genre, framing and persuasion\ntechniques. In Proceedings of the 17th International\nWorkshop on Semantic Evaluation , pages 2168\u20132173,\nToronto, Canada. Association for Computational Lin-\nguistics.\nBen Wu, Olesya Razuvayevskaya, Freddy Heppell,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Jo\u00e3o Leite, Carolina Scarton, Kalina Bontcheva, and\nXingyi Song. 2023. Sheffieldveraai at semeval-2023\ntask 3: Mono and multilingual approaches for news\ngenre, topic and persuasion technique classification.\nInProceedings of the 17th International Workshop\non Semantic Evaluation , pages 1995\u20132008, Toronto,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Canada. Association for Computational Linguistics.Seunghak Yu, Giovanni Da San Martino, Mitra Mo-\nhtarami, James Glass, and Preslav Nakov. 2021. In-\nterpretable propaganda detection in news articles.\nInProceedings of the International Conference on\nRecent Advances in Natural Language Processing ,\nRANLP \u201921, pages 1597\u20131605.\nYifan Zhang, Giovanni Da San Martino, Alberto Barr\u00f3n-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Cede\u00f1o, Salvatore Romeo, Jisun An, Haewoon Kwak,\nTodor Staykovski, Israa Jaradat, Georgi Karadzhov,\nRamy Baly, Kareem Darwish, James Glass, and\nPreslav Nakov. 2019. Tanbih: Get to know what\nyou are reading. In Proceedings of the Conference\non Empirical Methods in Natural Language Process-\ning and the 9th International Joint Conference on\nNatural Language Processing: System Demonstra-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "tions , EMNLP-IJCNLP \u201919, pages 223\u2013228, Hong\nKong, China.\nA Supplementary Corpus Information\nA.1 Statistics\nThis section contains additional statistical informa-\ntion related to the corpus.\nTable 15 provides the statistics for genre for all\nlanguages. One can observe that opinion andsatire\nare the most and least populated classes across the\nlanguages respectively."}, {"source": "2023.semeval-1.317v2.pdf", "text": "languages respectively.\nAnalogously, Table 16 shows the number of dif-\nferent framing dimensions per language. Political\nandSecurity and Defense framings constitute the\ntwo most frequent ones across all languages. The\ndistribution of the different framings varies across\nthe languages though.\nFinally, Table 17 reports the exact count of fine-\ngrained persuasion techniques per language for"}, {"source": "2023.semeval-1.317v2.pdf", "text": "the entire dataset. The two most frequent tech-\nniques irrespective of the language are Loaded\nLanguage andName Calling-Labelling , which ac-\ncount for 18.5% and 23.7% of the dataset, trump-\ning by several order of magnitude the lower popu-\nlated classes. They are followed by Casting Doubt\n(12.5%), Questioning the Reputation (7.6%), Ap-\npeal to Fear-Prejudice (4.8%), and Exageration-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Minimisation (4.7%). These six classes together\nrepresent 71.8% of the entire dataset.\nB Participant Systems\nIn the following we list the systems of all partic-\nipants who submitted a system description paper.\nThe team name used for the submission is in bold;\nin case the team used a different name on the leader-\nboard, it is appended in parentheses; the list of sub-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "tasks the team participated in is also given in brack-\nets; in case the team was ranked first for at leastopinion reporting satire\nEnglish 434 112 24\nFrench 175 65 21\nGerman 148 48 31\nItalian 274 72 18\nPolish 174 44 23\nRussian 170 73 20\nGeorgian 19 10 0\nGreek 39 22 3\nSpanish 14 9 7\nALL 1447 455 147\nTable 15: Statistics for the genre labels for all languages\nand the entire dataset."}, {"source": "2023.semeval-1.317v2.pdf", "text": "and the entire dataset.\na subtask-language pair, the list of all such pairs\nwhere it is ranked first is given; a list of keywords;\nand finally, a short description of the system.\nACCEPT [ST2] (Heinisch et al., 2023) (Key-\nwords: XLM-RoBERTa, ConceptNet ) They used an\nensemble combining XLM-RoBERTa with static\nmultilingual and monolingual word embeddings;"}, {"source": "2023.semeval-1.317v2.pdf", "text": "for the latter, they translated the non-English-texts\nto English using Google Translate. They further\nexperimented with external common sense knowl-\nedge graphs, specifically ConceptNet.\nAPatt [ST3] (Purificato and Navigli, 2023) (first\nfor: ST3:EN) (Keywords: XLNet, RoBERTa, BERT,\nALBERT, DeBERTa ) They used an ensemble of\npre-trained language models fine-tuned on the pro-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "paganda dataset: BERT, RoBERTa, ALBERT, XL-\nNet, DistilBERT, and HerBERT. Whenever more\nLLMs for the same language were available, their\noutput is combined through a weighted average.\nAppeal for attention (AppealForAtt) [ST3]\n(Amihaesei et al., 2023) (Keywords: XLM-\nRoBERTa-Large, WordNet, data augmentation )\nThey focused on data augmentation techniques."}, {"source": "2023.semeval-1.317v2.pdf", "text": "They translated the datasets from each language\ninto all other languages using the DeepTranslator\nAPI, and they extracted synonyms from WordNet\nto generate new sentences. Finally, they trained\nXLM-RoBERTa-large on that augmented data.\nBERTastic [ST2] (Mahmoud and Nakov, 2023)\n(Keywords: mBERT, XLM-RoBERTa ) They used\ncross-lingual transformers, mBERT and XLM-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "RoBERTa, using different orderings of the lan-\nguages when doing fine-tuning. They further used\ntest data augmentation via translation of both the\ntraining and the test sets.\nCLaC (CLAC) [ST3] (Costa et al., 2023) (Key-\nwords) RoBERTa augmented the dataset translat-\ning examples from other languages, focusing on"}, {"source": "2023.semeval-1.317v2.pdf", "text": "articles having least represented techniques in orderto balance the dataset. They used a RoBERTa-base\nmodel trained on the English language and made\npredictions on the other languages by first trans-\nlating the text into English. They report better F 1\nscores with such approach on French and German\nthan using Large Language Models trained directly\non the target language."}, {"source": "2023.semeval-1.317v2.pdf", "text": "on the target language.\nDSHacker [ST1, ST3] (Modzelewski\net al., 2023) (first for: ST1:ES) (Keywords:\nXLMRoBERTa-large, GPT3-Davinci, sequence\nclassification, text generation, Ensemble Learning,\nXGBoost, Logistic Regression, LightGBM, BERT,\nData Augmentation, Summarization ) created,\nfor ST1, synthetic texts for each class using the\nOpenAI GPT-3 Davinci language model. Each"}, {"source": "2023.semeval-1.317v2.pdf", "text": "language was augmented by approximately 500\narticles per genre, producing roughly 13,500\nartificially generated articles. Single XLM-\nRoBERTa-large model was trained using the\noriginal and augmented data. For ST3 they\ndeveloped for Polish an ensemble consisting of\nthree one-vs-rest classifiers: eXtreme Gradient\nBoosting, Logistic Regression and Light Gradient-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Boosting Machine with HerBERT embeddings\nand various stylometric features using StyloMetrix\nlibrary. For all other languages BERT-based\npre-trained models were deployed and they used\nsummarization applied to longer paragraphs.\nFurthermore, training data was augmented through\nmachine translation utilizing the DeepL API.\nFramingFreaks [ST1, ST2] (Baumann and"}, {"source": "2023.semeval-1.317v2.pdf", "text": "FramingFreaks [ST1, ST2] (Baumann and\nDeisenhofer, 2023) (Keywords: SVM, Logistic Re-\ngression ) classified texts by splitting them into sub-\nwords and then using these tokens as input to a\nSupport Vector Machines for ST1 and to Logistic\nregression for ST2.\nFTD [ST1, ST2, ST3] (Lepekhin and Sharoff,\n2023) (first for: ST1:PL) (Keywords: SLM-\nRoBERTa, multilingual BERT, Electra, monolin-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "gual BERT-based models, fine-tuning, uncertainty\nestimation, ensembles ) focused on ST1, where they\nexperimented with monolingual and multilingual\nmodels, ensembles, additional data, and uncertainty\nestimation. For Russian and English, they fine-\ntuned models pre-trained on the FTD dataset for\ngenre classification. For English, they added 1,000\nreporting texts from Gigaword. For Polish and Ger-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "man, their best results were achieved by fine-tuning\na monolingual Polish BERT and a monolingual\nGerman Electra, respectively. For the other lan-\nguages, their best systems used multilingual BERT,Framing English French German Italian Polish Russian Georgian Greek Spanish ALL\nCapacity and resources 56 62 104 120 88 34 1 10 11 486\nCrime and punishment 274 22 44 57 57 51 3 11 4 523"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Cultural identity 42 34 46 43 48 13 1 8 0 235\nEconomic 74 79 108 142 144 68 2 14 4 635\nExternal regulation and reputation 214 85 91 132 86 44 9 9 3 673\nFairness and equality 131 30 35 52 39 21 0 8 2 318\nHealth and safety 86 60 107 97 144 37 4 8 3 546\nLegality, Constitutionality, jurisprudence 281 41 65 73 56 44 0 23 7 590\nMorality 231 62 39 62 63 31 2 5 7 502"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Morality 231 62 39 62 63 31 2 5 7 502\nPolicy prescription and evaluation 154 38 70 129 110 15 2 12 7 537\nPolitical 343 108 130 178 144 55 10 43 6 1017\nPublic opinion 68 34 50 58 74 22 4 10 3 323\nQuality of life 115 40 53 89 85 32 0 5 3 422\nSecurity and defense 222 89 121 155 105 90 10 19 10 821\nTable 16: Statistics for the framing labels for all languages and the entire dataset."}, {"source": "2023.semeval-1.317v2.pdf", "text": "Persuasion technique English French German Italian Polish Russian Georgian Greek Spanish ALL\nName Calling-Labeling 1,945 903 2,818 1,470 1,391 483 42 37 42 9,131\nGuilt by Association 84 210 216 98 234 59 4 8 12 925\nDoubt 887 679 606 2,295 574 957 40 129 37 6,204\nAppeal to Hypocrisy 82 220 307 149 329 167 1 77 14 1,346\nQuestioning the Reputation 162 662 837 819 555 598 23 35 66 3,757"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Flag Waving 434 87 100 72 176 152 3 19 6 1,049\nAppeal to Values 47 219 163 264 246 93 6 26 14 1,078\nAppeal to Popularity 76 149 119 79 86 38 0 7 11 565\nAppeal to Fear-Prejudice 554 443 339 589 245 135 1 12 41 2,359\nAppeal to Authority 207 175 377 118 133 22 2 5 6 1,045\nCausal Oversimplification 265 228 62 88 22 65 2 29 9 770\nFalse Dilemma, No Choice 241 169 55 149 28 59 2 10 22 735"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Consequential Oversimplification 21 215 50 53 47 110 8 33 7 544\nStrawman 64 242 27 111 25 46 2 13 6 536\nRed Herring 97 72 52 48 23 6 10 19 4 331\nWhataboutism 25 93 33 11 22 17 0 13 7 221\nConversation Killer 176 352 235 468 126 172 12 24 26 1,591\nSlogans 234 230 176 122 64 113 3 15 16 973\nAppeal to Time 4 71 33 53 24 41 0 3 8 237\nLoaded Language 3,467 2,533 604 2,878 654 1,347 26 88 134 11,731"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Obfuscation-Vagueness-Confusion 37 185 108 42 66 62 6 34 9 549\nExaggeration-Minimisation 730 527 307 261 197 225 5 37 35 2,324\nRepetition 938 198 17 75 48 115 20 18 14 1,443\nTable 17: Statistics for the fine-grained persuasion techniques for all languages and the entire dataset.\nXLM-RoBERTa, or ensembles thereof. In all cases,\nthey truncated the input to the first 510 tokens."}, {"source": "2023.semeval-1.317v2.pdf", "text": "They further upsampled the data to balance the\ndistribution between the classes (the results with-\nout upsampling were low). For English they fur-\nther, experimented with uncertainty estimation, and\nshowed that replacing the model predictions that\nhave high uncertainty with the majority class on the\ntraining data was helpful on the dev set. For ST2,\nfor each language, they used the model and the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "setup that worked best for ST1, and just retrained\nit on the ST2 data.\nHHU [ST1] (Billert and Conrad, 2023): (Key-\nwords: XLM-RoBERTa, Adapters, AdapterFusion )\nused an Adapter-based configuration: Using XLM-RoBERTa as a base, they stacked first a language-\nspecific adapter and then a task-specific adapter on\ntop of it. Moreover, they augmented each dataset"}, {"source": "2023.semeval-1.317v2.pdf", "text": "by translating the articles from the datasets in the\nother languages.\nHitachi [ST1, ST2] (Koreeda et al., 2023) (first\nfor: ST1:IT, ST1:RU) (Keywords: XLM-RoBERTa,\nRoBERTa ) augmented the dataset for ST1 by col-\nlecting labelled examples from similar datasets.\nThey pretrained (XLM-)RoBERTa in multi-task\n(one language, ST1 and ST2), multilingual (one"}, {"source": "2023.semeval-1.317v2.pdf", "text": "subtask, all languages) and multilingual multi-task\n(ST1 and ST2 in all languages) settings. Besides\nusing the single models, they report experiments\nwith ensemble of base models with different hyper-parameters.\nJUSTR00 [ST1, ST2] (Al-Qarqaz and Abdullah,\n2023): (Keywords: LongFormer, BERT, RoBERTa,\nmBERT, XLM-RoBERTa, BigBird experimented\nwith many state-of-the-art transformer-based lan-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "guage models, both monolingual and multilingual.\nTheir top performing model is based on a trans-\nformer called \u201cLongformer\u201d.\nkb[ST1, ST3] (Baraniak and Sydow, 2023)\n(Keywords: BERT, Bert, hierarchical learning,\nmultitask learning ) tackled ST3 by training a BERT\nmodel to identify the start of a text fragment with a\ntechnique, then the first index of predicted span was"}, {"source": "2023.semeval-1.317v2.pdf", "text": "used to get the BERT embedding for classification.\nKInITVeraAI (KInIT) [ST3] (Hromadka et al.,\n2023): (first for: ST3:IT, ST3:RU, ST3:DE,\nST3:PL, ST3:EL, ST3:KA) (Keywords: XLM-\nRoBERTa large and base, mBERT base, monolin-\ngual RoBERTa base and large, monolingual BERT\nbase, distilBERT, language model fine-tuning with\ndifferent layer freezing strategies ) used a fine-tuned"}, {"source": "2023.semeval-1.317v2.pdf", "text": "XLM-RoBERTa-large transformer model trained\non all the input data. They carefully adjusted the\nprediction threshold for each language using a prin-\ncipled approach. They truncated the input, and also\nfound that pre-processing did not impact the quality\nmuch.\nMarsEclipse [ST2] (Liao et al., 2023): (first for:\nST2:IT, ST2:RU, ST2:FR, ST2:DE, ST2:PL) (Key-\nwords: XLM-RoBERTa, mBERT, SimCSE, Sim-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "words: XLM-RoBERTa, mBERT, SimCSE, Sim-\nCLR) used a multi-label contrastive loss for fine-\ntuning pre-trained language models in a multi-\nlingual setting. They followed the general archi-\ntecture of SimCLR and SimCSE to do contrastive\nlearning, but modified the contrastive loss to make\nit fit for a multi-label setup. This yielded very com-\npetitive results for ST2, and this was the winning"}, {"source": "2023.semeval-1.317v2.pdf", "text": "system for five of the languages.\nmCPT (PolarIce) [ST2] (Reiter-Haas et al.,\n2023) (first for: ST2:ES) (Keywords: paraphrase-\nmultilingual-MiniLM-L12-v2, contrastive pre-\ntraining ) used a two-phase training procedure of a\ntransformer model, first by pre-training jointly on\nall the languages and then by fine-tuning for each\nlanguage. In both phases, a multi-label contrastive\nloss was used."}, {"source": "2023.semeval-1.317v2.pdf", "text": "loss was used.\nMELODI [ST1] (Devatine et al., 2023): (first\nfor: ST1:EN) (Keywords: Translation + POLI-\nTICS (RoBERTa) ) fine-tuned the domain-specific\nlanguage model trained on English data, POLI-\nTICS, on the English input articles and on the arti-cles in all other languages automatically translated.\nIn addition, in order to use whole articles as input,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "they used a sliding window approach and aggre-\ngated each window representation with mean pool-\ning. They also tested other multilingual approaches,\nsuch as XLM-RoBERTa, and approaches able to\nprocess long documents (Longformer), which were\nin general less effective.\nMLModeler5 [ST1, ST2] (Khanchandani et al.,\n2023) (Keywords: RoBERTa, ALBERT ) provided a"}, {"source": "2023.semeval-1.317v2.pdf", "text": "solution for English only. For ST1 they pre-trained\nthe RoBERTa, ALBERT and other deep learning\nmodels using the original training data in English\nand translated versions of the data in other lan-\nguages and performed NLP augmentation using\nNLPAUG library on it. For ST2 a similar-in-nature\napproach was used.\nNAP [ST3] (Falk et al., 2023) (first for: ST3:FR)"}, {"source": "2023.semeval-1.317v2.pdf", "text": "(Keywords: XLM-RoBERTa (base and large),\nsetfit, adapters, translation and backtranslation\nof paragraphs ) presented an approach combin-\ning predictions of several models in an ensem-\nble, which differ in three main aspects: a) train-\ning data, b) model architecture, and c) input\nformat to the model. They leveraged (back-\n)translation as data augmentation strategies using"}, {"source": "2023.semeval-1.317v2.pdf", "text": "available MarianMT models. Model architectures\nincluded XLM-RoBERTa models, Adapters, SetFit,\nand linguistically-informed heuristics for under-\nrepresented techniques which were fine-tuned on\ndifferent combinations of original and augmented\ndata. They fine-tuned models on both paragraph-\nand span-level information.\nNL4IA [ST3] (Pritzkau, 2023) (Keywords:"}, {"source": "2023.semeval-1.317v2.pdf", "text": "NL4IA [ST3] (Pritzkau, 2023) (Keywords:\nRoBERTa ) used RoBERTa and exploited the span\nlevel annotations framing ST3 as a token-level clas-\nsification one, but report better results when treat-\ning the subtask as a sequence classification one.\nNLUBot101 [ST1,ST3] (Liu et al., 2023) (Key-\nwords: mDeBERTa ) built, for ST3, a solution on\ntop of mDeBERTa NLI model and exploit cross-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "lingual data augmentation. The performance could\nbe improved through the exploitation of the ex-\npanded definitions of the persuasion technique\nguidelines from the official annotation guidelines\nvis-a-vis the usage of single words or phrases.\nTheir system achieved the highest macro F1score\nfor the English language.\nQCRI (QCRITeam) [ST1, ST2, ST3] (Hasanain"}, {"source": "2023.semeval-1.317v2.pdf", "text": "et al., 2023) (Keywords: XLM-RoBERTa, French\nEuropeana BERT, Gottbert-base, Italian BERT,HerBERT ) used, for all subtasks, data augmenta-\ntion and then fine-tuned a BERT model specifically\nfor each language, in addition to fine-tuning XLM-\nRoBERTa on all languages at once.\nQUST [ST1,ST2,ST3] (Jiang, 2023): (Key-\nwords) XLM-RoBERTa Their model is build on top"}, {"source": "2023.semeval-1.317v2.pdf", "text": "of XLM-RoBERTa, which is fine-tuned with the\npre-calculated class weights and sample weights\nto combat the imbalanced data. The class weights\nare multiplied by the loss to make the model focus\nmore on the minority class. The sample weights are\ncombined with a weighted sampler to resample the\ndistribution of the training batch. In addition, two\ntypes of fine-tuning strategies, the task-agnostic"}, {"source": "2023.semeval-1.317v2.pdf", "text": "and the task-dependent, where the latter proved\nto help the multilingual model to learn the shared\ninformation between subtasks. The submitted sys-\ntem achieves the second best result for Italian and\nSpanish (zero-shot) in ST1.\nReDASPersuasion [ST3] (Qachfar and Verma,\n2023) (Keywords: XLM-RoBERTa ) uses XLM-\nRoBERTa as a backbone model, incorporating lan-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "guage agnostic features, computed over the articles\ntranslated using Google translation. Such features\ntarget specific techniques, including sentiment- and\npolarity- based features targeting appeal to fear and\nslogans, indefinite pronouns indicative of exagger-\nation and minimisation, a profanity language detec-\ntion to capture loaded language. XLM-RoBERTa"}, {"source": "2023.semeval-1.317v2.pdf", "text": "has been proved to be a powerful multilingual pre-\ntrained language model compared against other\nmodels like Multilingual BERT (M-BERT).\nSheffieldVeraAI (vera) [ST1, ST2, ST3] (Wu\net al., 2023) (first for: ST1: DE, ST2:EN, ST2:EL,\nST2:KA) (Keywords: mBERT, adapters, text pre-\nprocessing, upsampling, XLM-Roberta, Pfeiffer\nAdapters, MUPPET, Task-adaptive Pre-training,"}, {"source": "2023.semeval-1.317v2.pdf", "text": "RoBERTa, class weighting ) deployed an ensem-\nble of three fine-tuned mBERT models and one\nmBERT model with a bottleneck adapter for ST1.\nAll used bert-base-multilingual-cased. For the fine-\ntuned mBERT models, they pre-processed the data\nby filtering out non-informative sentences. The\npool of training data was also extended by integra-\ntion additional \u201csatire\u201d resources for English. In"}, {"source": "2023.semeval-1.317v2.pdf", "text": "the cases where the length of the tokenised arti-\ncle was more than 512 tokens, an equal number of\nsentences from the beginning and the end of the\narticle was selected until the size of 512 tokens in a\nconcatenated text is reached. The final predictions\nwere drawn as a majority-voting predicted classFor ST2 they used two different ensembles of\nMUPPET large, and of XLM-R with adapters"}, {"source": "2023.semeval-1.317v2.pdf", "text": "and task-adaptive MLM pre-training on the\ntrain+dev+test data. Their data was pre-processed\nand truncated. The models were trained both with\nand without class weighting.\nFor ST3 they trained a monolingual RoBERTa-\nBase model for English and a multilingual mBERT-\ncased model for the remaining languages. They\nused class weighting to account for class imbal-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ance. They also experimented with augmenting\ndata through translation, which improved the per-\nformance for the surprise languages.\nSinaAI (SinaaAI) [ST1, ST2, ST3] (Sadeghi\net al., 2023) (first for: ST1:EL) (Keywords: XLM,\nmBERT, LaBSE ) used multilingual languages mod-\nels such as XLM, mBERT and LaBSE, which they\ncombined in an ensemble. For ST1 and ST2, they"}, {"source": "2023.semeval-1.317v2.pdf", "text": "further used data augmentation by selecting 30%\nof the sentences of each document to create new\nsynthetic examples.\nTeamAmpa [ST2, ST3] (Pauli et al., 2023) (first\nfor: ST3:ES) (Keywords: RoBERTa, XML-R, en-\nsemble models) used different oversampling strate-\ngies, data truncation, and multilingual and mono-\nlingually trained models, combined in an ensem-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "ble for the English data. The surprise languages\nwere handled using the multilingual model with\noversampling on English data and data from low-\nrepresented classes.\nTheSyllogist [ST2] (Mohammed Afzal and\nNakov, 2023): (Keywords: BERT ) participated\nin ST2, and experimented with zero-shot transfer:\ntranslating the data for all languages into English"}, {"source": "2023.semeval-1.317v2.pdf", "text": "(using Google Translate), and then training and ap-\nplying an English system. They used fine-tuned\nBERT (bert-base-uncased) with mean-pooling.\nUM6P [ST1, ST3] (Alami et al., 2023): (Key-\nwords: Longformer, RoBERTa, GCN ) fine-tuned\nLongformer and RoBERTa transformers for both\nST1 and ST3. They further added a graph convolu-\ntion network, and a classifier based on the number"}, {"source": "2023.semeval-1.317v2.pdf", "text": "of sentences in each document. Finally, they used\nan ensemble to combine the predictions of these\nmodels.\nUMUTeam [ST1, ST2] (Pan et al., 2023) (first\nfor: ST1:FR, ST1:DE) (Keywords: Sentence\ntransformers, XML-RoBERTa ) used a multilingual\nmodel based on XML-RoBERTa, which they fine-\ntuned on all languages at once and a sentence trans-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "former to extract the most important chunk of textfor ST1 and ST2. They further truncated the input\ndata to 200 tokens with 50 tokens of overlap using\nthe sentence-transformer model to obtain the subset\nof text most related to the article title.\nUnedMediaBiasTeam [ST1, ST3] (Rodrigo-\nGin\u00e9s et al., 2023) (Keywords: XLM-RoBERTa,\nbert-base-multilingual-cased ) solutions are based"}, {"source": "2023.semeval-1.317v2.pdf", "text": "on two-stage fine-tuned multilingual models. For\nST1 they exploit the media bias detection datasets\ncalled BABE and MBIC and XLM-RoBERTa\nmodel fine-tuned in two stages: first with the BABE\nand MBIC datasets, and later with the data pro-\nvided for the task. For ST3 a similar approach is\ndeployed, where instead of training a single model\nin two phases, two models are trained and the cas-"}, {"source": "2023.semeval-1.317v2.pdf", "text": "cading inference is carried out.\nUnisa [ST1, ST3] (Bangerter et al., 2023) (Key-\nwords: DistilBert, SHAP ) built solutions on top\nof DistilBert and leverage the application of the\neXplainable Artificial Intelligence (XAI) method,\nShapley Additive Explanations (SHAP). In ST1,\ndata augmentation was exploited through transla-\ntion data to the target language (English) on top"}, {"source": "2023.semeval-1.317v2.pdf", "text": "of which the model was trained with only the first\n512 tokens of the articles being considered as input\nto the model. SHAP was used to understand what\nwas driving the model to fail so that it could be\nimproved.\nIn ST3, a re-calibration of the Attention Mech-\nanism is realized by extracting critical tokens for\neach technique. XAI is exploited for countering the"}, {"source": "2023.semeval-1.317v2.pdf", "text": "overfitting of the resulting model and attempting to\nimprove the performance when there are few train-\ning samples. First, a binary model first processes\na new incoming paragraph to predict whether it\ncontains any persuasion attempt. If the text is pre-\ndicted to be propaganda, it is compared with SHAP\nV ocabularies previously created, which represent"}, {"source": "2023.semeval-1.317v2.pdf", "text": "the most important words associated with each per-\nsuasion technique. Such comparison defines the ad-\nditional input to pass to the final multi-class model\ntrained to focus on the span that identifies the text\nthat characterizes the persuasion technique.\nUTB-NLP (UTBNLP) [ST1, ST2] (Cuadrado\net al., 2023) (Keywords: ) used a feature-based\nrepresentation: they extracted noun phrases and"}, {"source": "2023.semeval-1.317v2.pdf", "text": "represented them as tf-idf vectors; they consid-\nered several features specific for each of the three\nclasses of ST1, such as psycholinguistic, writing\nstyle, readability, structural characteristics, concep-\ntual embeddings and argumentation-based features.In addition, they used SMOTE to oversample the\nminority classes.\nST2 was tackled by collecting extra texts from"}, {"source": "2023.semeval-1.317v2.pdf", "text": "Wikipedia related to the frames, pre-processing\nthem to create a frame-related lexicon and then to\nuse it to create a bag-of-words representation for\neach input article."}, {"source": "2020.acl-main.747.pdf", "text": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics , pages 8440\u20138451\nJuly 5 - 10, 2020. c\r2020 Association for Computational Linguistics8440Unsupervised Cross-lingual Representation Learning at Scale\nAlexis Conneau\u0003Kartikay Khandelwal\u0003\nNaman Goyal Vishrav Chaudhary Guillaume Wenzek Francisco Guzm \u00b4an\nEdouard Grave Myle Ott Luke Zettlemoyer Veselin Stoyanov"}, {"source": "2020.acl-main.747.pdf", "text": "Facebook AI\nAbstract\nThis paper shows that pretraining multilingual\nlanguage models at scale leads to signi\ufb01cant\nperformance gains for a wide range of cross-\nlingual transfer tasks. We train a Transformer-\nbased masked language model on one hundred\nlanguages, using more than two terabytes of \ufb01l-\ntered CommonCrawl data. Our model, dubbed\nXLM-R , signi\ufb01cantly outperforms multilingual"}, {"source": "2020.acl-main.747.pdf", "text": "BERT (mBERT) on a variety of cross-lingual\nbenchmarks, including +14.6% average accu-\nracy on XNLI, +13% average F1 score on\nMLQA, and +2.4% F1 score on NER. XLM-R\nperforms particularly well on low-resource lan-\nguages, improving 15.7% in XNLI accuracy\nfor Swahili and 11.4% for Urdu over previ-\nous XLM models. We also present a detailed\nempirical analysis of the key factors that are"}, {"source": "2020.acl-main.747.pdf", "text": "required to achieve these gains, including the\ntrade-offs between (1) positive transfer and ca-\npacity dilution and (2) the performance of high\nand low resource languages at scale. Finally,\nwe show, for the \ufb01rst time, the possibility of\nmultilingual modeling without sacri\ufb01cing per-\nlanguage performance; XLM-R is very compet-\nitive with strong monolingual models on the"}, {"source": "2020.acl-main.747.pdf", "text": "GLUE and XNLI benchmarks. We will make\nour code, data and models publicly available.1\n1 Introduction\nThe goal of this paper is to improve cross-lingual\nlanguage understanding (XLU), by carefully study-\ning the effects of training unsupervised cross-\nlingual representations at a very large scale. We\npresent XLM-R a transformer-based multilingual\nmasked language model pre-trained on text in 100"}, {"source": "2020.acl-main.747.pdf", "text": "languages, which obtains state-of-the-art perfor-\nmance on cross-lingual classi\ufb01cation, sequence la-\nbeling and question answering.\n\u0003Equal contribution.\nCorrespondence to faconneau,kartikayk g@fb.com\n1https://github.com/facebookresearch/(fairseq-py,pytext,xlm)Multilingual masked language models (MLM)\nlike mBERT (Devlin et al., 2018) and XLM (Lam-\nple and Conneau, 2019) have pushed the state-"}, {"source": "2020.acl-main.747.pdf", "text": "of-the-art on cross-lingual understanding tasks\nby jointly pretraining large Transformer mod-\nels (Vaswani et al., 2017) on many languages.\nThese models allow for effective cross-lingual\ntransfer, as seen in a number of benchmarks in-\ncluding cross-lingual natural language inference\n(Bowman et al., 2015; Williams et al., 2017; Con-\nneau et al., 2018), question answering (Rajpurkar"}, {"source": "2020.acl-main.747.pdf", "text": "et al., 2016; Lewis et al., 2019), and named en-\ntity recognition (Pires et al., 2019; Wu and Dredze,\n2019). However, all of these studies pre-train on\nWikipedia, which provides a relatively limited scale\nespecially for lower resource languages.\nIn this paper, we \ufb01rst present a comprehensive\nanalysis of the trade-offs and limitations of multi-\nlingual language models at scale, inspired by re-"}, {"source": "2020.acl-main.747.pdf", "text": "cent monolingual scaling efforts (Liu et al., 2019).\nWe measure the trade-off between high-resource\nand low-resource languages and the impact of lan-\nguage sampling and vocabulary size. The experi-\nments expose a trade-off as we scale the number\nof languages for a \ufb01xed model capacity: more lan-\nguages leads to better cross-lingual performance\non low-resource languages up until a point, after"}, {"source": "2020.acl-main.747.pdf", "text": "which the overall performance on monolingual and\ncross-lingual benchmarks degrades. We refer to\nthis tradeoff as the curse of multilinguality , and\nshow that it can be alleviated by simply increas-\ning model capacity. We argue, however, that this\nremains an important limitation for future XLU\nsystems which may aim to improve performance\nwith more modest computational budgets."}, {"source": "2020.acl-main.747.pdf", "text": "with more modest computational budgets.\nOur best model XLM-RoBERTa ( XLM-R ) out-\nperforms mBERT on cross-lingual classi\ufb01cation by\nup to 23% accuracy on low-resource languages. It\noutperforms the previous state of the art by 5.1% av-\nerage accuracy on XNLI, 2.42% average F1-score8441on Named Entity Recognition, and 9.1% average\nF1-score on cross-lingual Question Answering. We"}, {"source": "2020.acl-main.747.pdf", "text": "also evaluate monolingual \ufb01ne tuning on the GLUE\nand XNLI benchmarks, where XLM-R obtains re-\nsults competitive with state-of-the-art monolingual\nmodels, including RoBERTa (Liu et al., 2019).\nThese results demonstrate, for the \ufb01rst time, that\nit is possible to have a single large model for all\nlanguages, without sacri\ufb01cing per-language perfor-\nmance. We will make our code, models and data"}, {"source": "2020.acl-main.747.pdf", "text": "publicly available, with the hope that this will help\nresearch in multilingual NLP and low-resource lan-\nguage understanding.\n2 Related Work\nFrom pretrained word embeddings (Mikolov et al.,\n2013b; Pennington et al., 2014) to pretrained con-\ntextualized representations (Peters et al., 2018;\nSchuster et al., 2019) and transformer based lan-\nguage models (Radford et al., 2018; Devlin et al.,"}, {"source": "2020.acl-main.747.pdf", "text": "2018), unsupervised representation learning has\nsigni\ufb01cantly improved the state of the art in nat-\nural language understanding. Parallel work on\ncross-lingual understanding (Mikolov et al., 2013a;\nSchuster et al., 2019; Lample and Conneau, 2019)\nextends these systems to more languages and to the\ncross-lingual setting in which a model is learned in\none language and applied in other languages."}, {"source": "2020.acl-main.747.pdf", "text": "Most recently, Devlin et al. (2018) and Lam-\nple and Conneau (2019) introduced mBERT and\nXLM - masked language models trained on multi-\nple languages, without any cross-lingual supervi-\nsion. Lample and Conneau (2019) propose transla-\ntion language modeling (TLM) as a way to leverage\nparallel data and obtain a new state of the art on the\ncross-lingual natural language inference (XNLI)"}, {"source": "2020.acl-main.747.pdf", "text": "benchmark (Conneau et al., 2018). They further\nshow strong improvements on unsupervised ma-\nchine translation and pretraining for sequence gen-\neration. Wu et al. (2019) shows that monolingual\nBERT representations are similar across languages,\nexplaining in part the natural emergence of multi-\nlinguality in bottleneck architectures. Separately,\nPires et al. (2019) demonstrated the effectiveness"}, {"source": "2020.acl-main.747.pdf", "text": "of multilingual models like mBERT on sequence la-\nbeling tasks. Huang et al. (2019) showed gains over\nXLM using cross-lingual multi-task learning, and\nSingh et al. (2019) demonstrated the ef\ufb01ciency of\ncross-lingual data augmentation for cross-lingual\nNLI. However, all of this work was at a relatively\nmodest scale, in terms of the amount of trainingdata, as compared to our approach."}, {"source": "2020.acl-main.747.pdf", "text": "The bene\ufb01ts of scaling language model pretrain-\ning by increasing the size of the model as well as\nthe training data has been extensively studied in the\nliterature. For the monolingual case, Jozefowicz\net al. (2016) show how large-scale LSTM models\ncan obtain much stronger performance on language\nmodeling benchmarks when trained on billions of\ntokens. GPT (Radford et al., 2018) also highlights"}, {"source": "2020.acl-main.747.pdf", "text": "the importance of scaling the amount of data and\nRoBERTa (Liu et al., 2019) shows that training\nBERT longer on more data leads to signi\ufb01cant\nboost in performance. Inspired by RoBERTa, we\nshow that mBERT and XLM are undertuned, and\nthat simple improvements in the learning procedure\nof unsupervised MLM leads to much better perfor-\nmance. We train on cleaned CommonCrawls (Wen-"}, {"source": "2020.acl-main.747.pdf", "text": "zek et al., 2019), which increase the amount of data\nfor low-resource languages by two orders of magni-\ntude on average. Similar data has also been shown\nto be effective for learning high quality word em-\nbeddings in multiple languages (Grave et al., 2018).\nSeveral efforts have trained massively multilin-\ngual machine translation models from large par-"}, {"source": "2020.acl-main.747.pdf", "text": "allel corpora. They uncover the high and low re-\nsource trade-off and the problem of capacity dilu-\ntion (Johnson et al., 2017; Tan et al., 2019). The\nwork most similar to ours is Arivazhagan et al.\n(2019), which trains a single model in 103 lan-\nguages on over 25 billion parallel sentences. Sid-\ndhant et al. (2019) further analyze the representa-"}, {"source": "2020.acl-main.747.pdf", "text": "tions obtained by the encoder of a massively multi-\nlingual machine translation system and show that it\nobtains similar results to mBERT on cross-lingual\nNLI. Our work, in contrast, focuses on the unsuper-\nvised learning of cross-lingual representations and\ntheir transfer to discriminative tasks.\n3 Model and Data\nIn this section, we present the training objective,"}, {"source": "2020.acl-main.747.pdf", "text": "languages, and data we use. We follow the XLM\napproach (Lample and Conneau, 2019) as closely\nas possible, only introducing changes that improve\nperformance at scale.\nMasked Language Models. We use a Trans-\nformer model (Vaswani et al., 2017) trained with\nthe multilingual MLM objective (Devlin et al.,\n2018; Lample and Conneau, 2019) using only\nmonolingual data. We sample streams of text from"}, {"source": "2020.acl-main.747.pdf", "text": "each language and train the model to predict the\nmasked tokens in the input. We apply subword tok-8442\nen\nru\nid\nvi\nfa\nuk\nsv\nth\nja\nde\nro\nhu\nbg\nfr\nfi\nko\nes\nno\npt\nel\nzh\nda\npl\nhe\nit\nnl\nar\nsk\nhi\nhr\ntr\ncs\nlt\nta\nca\nsl\nka\nsr\nlv\nbn\nms\nml\naz\nkk\net\nur\nhy\nsq\nmk\nte\nbe\nne\nsi\nis\nkn\ntl\ngl\nmn\nmr\nla\neu\ngu\nsw\nkm\naf\nky\neo\nam\npa\ncy\nps\nuz\nor\nga\nmy\nku\nso\nug\nsa\nyi\nmg\nfy\njv\ngd\nbr\nbs\nas"}, {"source": "2020.acl-main.747.pdf", "text": "my\nku\nso\nug\nsa\nyi\nmg\nfy\njv\ngd\nbr\nbs\nas\nsu10-1100101102103Dataset size (in GB)\nCommonCrawl WikipediaFigure 1: Amount of data in GiB (log-scale) for the 88 languages that appear in both the Wiki-100 corpus used for\nmBERT and XLM-100, and the CC-100 used for XLM-R. CC-100 increases the amount of data by several orders\nof magnitude, in particular for low-resource languages."}, {"source": "2020.acl-main.747.pdf", "text": "enization directly on raw text data using Sentence\nPiece (Kudo and Richardson, 2018) with a unigram\nlanguage model (Kudo, 2018). We sample batches\nfrom different languages using the same sampling\ndistribution as Lample and Conneau (2019), but\nwith\u000b= 0:3. Unlike Lample and Conneau (2019),\nwe do not use language embeddings, which allows\nour model to better deal with code-switching. We"}, {"source": "2020.acl-main.747.pdf", "text": "use a large vocabulary size of 250K with a full soft-\nmax and train two different models: XLM-R Base(L\n= 12, H = 768, A = 12, 270M params) and XLM-R\n(L = 24, H = 1024, A = 16, 550M params). For all\nof our ablation studies, we use a BERT Basearchitec-\nture with a vocabulary of 150K tokens. Appendix B\ngoes into more details about the architecture of the\ndifferent models referenced in this paper."}, {"source": "2020.acl-main.747.pdf", "text": "Scaling to a hundred languages. XLM-R is\ntrained on 100 languages; we provide a full list of\nlanguages and associated statistics in Appendix A.\nFigure 1 speci\ufb01es the iso codes of 88 languages\nthat are shared across XLM-R and XLM-100, the\nmodel from Lample and Conneau (2019) trained\non Wikipedia text in 100 languages.\nCompared to previous work, we replace some"}, {"source": "2020.acl-main.747.pdf", "text": "languages with more commonly used ones such\nas romanized Hindi and traditional Chinese. In\nour ablation studies, we always include the 7 lan-\nguages for which we have classi\ufb01cation and se-\nquence labeling evaluation benchmarks: English,\nFrench, German, Russian, Chinese, Swahili and\nUrdu. We chose this set as it covers a suitable range\nof language families and includes low-resource lan-"}, {"source": "2020.acl-main.747.pdf", "text": "guages such as Swahili and Urdu. We also consider\nlarger sets of 15, 30, 60 and all 100 languages.\nWhen reporting results on high-resource and low-\nresource, we refer to the average of English and\nFrench results, and the average of Swahili and Urdu\nresults respectively.Scaling the Amount of Training Data. Follow-\ning Wenzek et al. (2019)2, we build a clean Com-"}, {"source": "2020.acl-main.747.pdf", "text": "monCrawl Corpus in 100 languages. We use an\ninternal language identi\ufb01cation model in combina-\ntion with the one from fastText (Joulin et al., 2017).\nWe train language models in each language and use\nit to \ufb01lter documents as described in Wenzek et al.\n(2019). We consider one CommonCrawl dump for\nEnglish and twelve dumps for all other languages,\nwhich signi\ufb01cantly increases dataset sizes, espe-"}, {"source": "2020.acl-main.747.pdf", "text": "cially for low-resource languages like Burmese and\nSwahili.\nFigure 1 shows the difference in size between\nthe Wikipedia Corpus used by mBERT and XLM-\n100, and the CommonCrawl Corpus we use. As\nwe show in Section 5.3, monolingual Wikipedia\ncorpora are too small to enable unsupervised rep-\nresentation learning. Based on our experiments,\nwe found that a few hundred MiB of text data is"}, {"source": "2020.acl-main.747.pdf", "text": "usually a minimal size for learning a BERT model.\n4 Evaluation\nWe consider four evaluation benchmarks. For cross-\nlingual understanding, we use cross-lingual natural\nlanguage inference, named entity recognition, and\nquestion answering. We use the GLUE benchmark\nto evaluate the English performance of XLM-R and\ncompare it to other state-of-the-art models.\nCross-lingual Natural Language Inference"}, {"source": "2020.acl-main.747.pdf", "text": "(XNLI). The XNLI dataset comes with ground-\ntruth dev and test sets in 15 languages, and a\nground-truth English training set. The training set\nhas been machine-translated to the remaining 14\nlanguages, providing synthetic training data for\nthese languages as well. We evaluate our model\non cross-lingual transfer from English to other lan-"}, {"source": "2020.acl-main.747.pdf", "text": "2https://github.com/facebookresearch/cc net8443guages. We also consider three machine translation\nbaselines: (i) translate-test : dev and test sets are\nmachine-translated to English and a single English\nmodel is used (ii) translate-train (per-language):\nthe English training set is machine-translated\nto each language and we \ufb01ne-tune a multiligual"}, {"source": "2020.acl-main.747.pdf", "text": "model on each training set (iii) translate-train-all\n(multi-language): we \ufb01ne-tune a multilingual\nmodel on the concatenation of all training sets\nfrom translate-train. For the translations, we use\nthe of\ufb01cial data provided by the XNLI project.\nNamed Entity Recognition. For NER, we con-\nsider the CoNLL-2002 (Sang, 2002) and CoNLL-\n2003 (Tjong Kim Sang and De Meulder, 2003)"}, {"source": "2020.acl-main.747.pdf", "text": "datasets in English, Dutch, Spanish and German.\nWe \ufb01ne-tune multilingual models either (1) on the\nEnglish set to evaluate cross-lingual transfer, (2)\non each set to evaluate per-language performance,\nor (3) on all sets to evaluate multilingual learning.\nWe report the F1 score, and compare to baselines\nfrom Lample et al. (2016) and Akbik et al. (2018).\nCross-lingual Question Answering. We use the"}, {"source": "2020.acl-main.747.pdf", "text": "MLQA benchmark from Lewis et al. (2019), which\nextends the English SQuAD benchmark to Spanish,\nGerman, Arabic, Hindi, Vietnamese and Chinese.\nWe report the F1 score as well as the exact match\n(EM) score for cross-lingual transfer from English.\nGLUE Benchmark. Finally, we evaluate the En-\nglish performance of our model on the GLUE\nbenchmark (Wang et al., 2018) which gathers mul-"}, {"source": "2020.acl-main.747.pdf", "text": "tiple classi\ufb01cation tasks, such as MNLI (Williams\net al., 2017), SST-2 (Socher et al., 2013), or\nQNLI (Rajpurkar et al., 2018). We use BERT Large\nand RoBERTa as baselines.\n5 Analysis and Results\nIn this section, we perform a comprehensive anal-\nysis of multilingual masked language models. We\nconduct most of the analysis on XNLI, which we\nfound to be representative of our \ufb01ndings on other"}, {"source": "2020.acl-main.747.pdf", "text": "tasks. We then present the results of XLM-R on\ncross-lingual understanding and GLUE. Finally,\nwe compare multilingual and monolingual models,\nand present results on low-resource languages.\n5.1 Improving and Understanding\nMultilingual Masked Language Models\nMuch of the work done on understanding the cross-\nlingual effectiveness of mBERT or XLM (Pires"}, {"source": "2020.acl-main.747.pdf", "text": "et al., 2019; Wu and Dredze, 2019; Lewis et al.,2019) has focused on analyzing the performance of\n\ufb01xed pretrained models on downstream tasks. In\nthis section, we present a comprehensive study of\ndifferent factors that are important to pretraining\nlarge scale multilingual models. We highlight the\ntrade-offs and limitations of these models as we\nscale to one hundred languages."}, {"source": "2020.acl-main.747.pdf", "text": "scale to one hundred languages.\nTransfer-dilution Trade-off and Curse of Mul-\ntilinguality. Model capacity (i.e. the number of\nparameters in the model) is constrained due to prac-\ntical considerations such as memory and speed dur-\ning training and inference. For a \ufb01xed sized model,\nthe per-language capacity decreases as we increase\nthe number of languages. While low-resource lan-"}, {"source": "2020.acl-main.747.pdf", "text": "guage performance can be improved by adding sim-\nilar higher-resource languages during pretraining,\nthe overall downstream performance suffers from\nthis capacity dilution (Arivazhagan et al., 2019).\nPositive transfer and capacity dilution have to be\ntraded off against each other.\nWe illustrate this trade-off in Figure 2, which\nshows XNLI performance vs the number of lan-"}, {"source": "2020.acl-main.747.pdf", "text": "guages the model is pretrained on. Initially, as we\ngo from 7 to 15 languages, the model is able to\ntake advantage of positive transfer which improves\nperformance, especially on low resource languages.\nBeyond this point the curse of multilinguality kicks\nin and degrades performance across all languages.\nSpeci\ufb01cally, the overall XNLI accuracy decreases\nfrom 71.8% to 67.7% as we go from XLM-7 to"}, {"source": "2020.acl-main.747.pdf", "text": "XLM-100. The same trend can be observed for\nmodels trained on the larger CommonCrawl Cor-\npus.\nThe issue is even more prominent when the ca-\npacity of the model is small. To show this, we\npretrain models on Wikipedia Data in 7, 30 and\n100 languages. As we add more languages, we\nmake the Transformer wider by increasing the hid-\nden size from 768 to 960 to 1152. In Figure 4, we"}, {"source": "2020.acl-main.747.pdf", "text": "show that the added capacity allows XLM-30 to be\non par with XLM-7, thus overcoming the curse of\nmultilinguality. The added capacity for XLM-100,\nhowever, is not enough and it still lags behind due\nto higher vocabulary dilution (recall from Section 3\nthat we used a \ufb01xed vocabulary size of 150K for\nall models).\nHigh-resource vs Low-resource Trade-off.\nThe allocation of the model capacity across"}, {"source": "2020.acl-main.747.pdf", "text": "languages is controlled by several parameters: the\ntraining set size, the size of the shared subword8444\n7 15 30 60 100\nNumber of languages4050607080Accuracy\nLow res. High res. AllFigure 2: The transfer-\ninterference trade-off: Low-\nresource languages bene\ufb01t from\nscaling to more languages, until\ndilution (interference) kicks in\nand degrades overall performance."}, {"source": "2020.acl-main.747.pdf", "text": "and degrades overall performance.\nLow res. High res. All4050607080Accuracy\nWikipedia CommonCrawlFigure 3: Wikipedia versus Com-\nmonCrawl: An XLM-7 obtains\nsigni\ufb01cantly better performance\nwhen trained on CC, in particular\non low-resource languages.\n7 30 100\nNumber of languages6668707274Accuracy\nFixed capacity Increased capacityFigure 4: Adding more capacity to\nthe model alleviates the curse of"}, {"source": "2020.acl-main.747.pdf", "text": "the model alleviates the curse of\nmultilinguality, but remains an is-\nsue for models of moderate size.\n0.01 0.3 0.7 1.0\nLanguage sampling4050607080Accuracy\nLow res. High res. All\nFigure 5: On the high-resource\nversus low-resource trade-off: im-\npact of batch language sampling\nfor XLM-100.\n32k 64k 128k 256k 512k\nVocabulary size6062646668Accuracy"}, {"source": "2020.acl-main.747.pdf", "text": "Vocabulary size6062646668Accuracy\nFixed capacity Increased capacityFigure 6: On the impact of vocabu-\nlary size at \ufb01xed capacity and with\nincreasing capacity for XLM-100.\n2048 4096 8192 BPE SPM\n   Batch size         Preproc.6062646668Accuracy\n.Figure 7: On the impact of large-\nscale training, and preprocessing\nsimpli\ufb01cation from BPE with tok-\nenization to SPM on raw text data."}, {"source": "2020.acl-main.747.pdf", "text": "enization to SPM on raw text data.\nvocabulary, and the rate at which we sample\ntraining examples from each language. We study\nthe effect of sampling on the performance of high-\nresource (English and French) and low-resource\n(Swahili and Urdu) languages for an XLM-100\nmodel trained on Wikipedia (we observe a similar\ntrend for the construction of the subword vocab)."}, {"source": "2020.acl-main.747.pdf", "text": "Speci\ufb01cally, we investigate the impact of varying\nthe\u000bparameter which controls the exponential\nsmoothing of the language sampling rate. Similar\nto Lample and Conneau (2019), we use a sampling\nrate proportional to the number of sentences in\neach corpus. Models trained with higher values\nof\u000bsee batches of high-resource languages more\noften. Figure 5 shows that the higher the value"}, {"source": "2020.acl-main.747.pdf", "text": "of\u000b, the better the performance on high-resource\nlanguages, and vice-versa. When considering\noverall performance, we found 0:3to be an optimal\nvalue for\u000b, and use this for XLM-R .\nImportance of Capacity and Vocabulary. In\nprevious sections and in Figure 4, we showed the\nimportance of scaling the model size as we increase\nthe number of languages. Similar to the overall"}, {"source": "2020.acl-main.747.pdf", "text": "model size, we argue that scaling the size of theshared vocabulary (the vocabulary capacity) can\nimprove the performance of multilingual models on\ndownstream tasks. To illustrate this effect, we train\nXLM-100 models on Wikipedia data with different\nvocabulary sizes. We keep the overall number of\nparameters constant by adjusting the width of the\ntransformer. Figure 6 shows that even with a \ufb01xed"}, {"source": "2020.acl-main.747.pdf", "text": "capacity, we observe a 2.8% increase in XNLI av-\nerage accuracy as we increase the vocabulary size\nfrom 32K to 256K. This suggests that multilingual\nmodels can bene\ufb01t from allocating a higher pro-\nportion of the total number of parameters to the\nembedding layer even though this reduces the size\nof the Transformer. For simplicity and given the\nsoftmax computational constraints, we use a vocab-"}, {"source": "2020.acl-main.747.pdf", "text": "ulary of 250k for XLM-R .\nWe further illustrate the importance of this pa-\nrameter, by training three models with the same\ntransformer architecture (BERT Base) but with dif-\nferent vocabulary sizes: 128K, 256K and 512K.\nWe observe more than 3% gains in overall accuracy\non XNLI by simply increasing the vocab size from\n128k to 512k.8445Larger-scale Datasets and Training. As shown"}, {"source": "2020.acl-main.747.pdf", "text": "in Figure 1, the CommonCrawl Corpus that we col-\nlected has signi\ufb01cantly more monolingual data than\nthe previously used Wikipedia corpora. Figure 3\nshows that for the same BERT Basearchitecture, all\nmodels trained on CommonCrawl obtain signi\ufb01-\ncantly better performance.\nApart from scaling the training data, Liu et al.\n(2019) also showed the bene\ufb01ts of training MLMs"}, {"source": "2020.acl-main.747.pdf", "text": "longer. In our experiments, we observed similar\neffects of large-scale training, such as increasing\nbatch size (see Figure 7) and training time, on\nmodel performance. Speci\ufb01cally, we found that\nusing validation perplexity as a stopping criterion\nfor pretraining caused the multilingual MLM in\nLample and Conneau (2019) to be under-tuned.\nIn our experience, performance on downstream"}, {"source": "2020.acl-main.747.pdf", "text": "tasks continues to improve even after validation\nperplexity has plateaued. Combining this observa-\ntion with our implementation of the unsupervised\nXLM-MLM objective, we were able to improve\nthe performance of Lample and Conneau (2019)\nfrom 71.3% to more than 75% average accuracy\non XNLI, which was on par with their supervised\ntranslation language modeling (TLM) objective."}, {"source": "2020.acl-main.747.pdf", "text": "Based on these results, and given our focus on\nunsupervised learning, we decided to not use the\nsupervised TLM objective for training our models.\nSimplifying Multilingual Tokenization with\nSentence Piece. The different language-speci\ufb01c\ntokenization tools used by mBERT and XLM-100\nmake these models more dif\ufb01cult to use on raw\ntext. Instead, we train a Sentence Piece model"}, {"source": "2020.acl-main.747.pdf", "text": "(SPM) and apply it directly on raw text data for\nall languages. We did not observe any loss in per-\nformance for models trained with SPM when com-\npared to models trained with language-speci\ufb01c pre-\nprocessing and byte-pair encoding (see Figure 7)\nand hence use SPM for XLM-R .\n5.2 Cross-lingual Understanding Results\nBased on these results, we adapt the setting of Lam-"}, {"source": "2020.acl-main.747.pdf", "text": "ple and Conneau (2019) and use a large Trans-\nformer model with 24 layers and 1024 hidden\nstates, with a 250k vocabulary. We use the multi-\nlingual MLM loss and train our XLM-R model for\n1.5 Million updates on \ufb01ve-hundred 32GB Nvidia\nV100 GPUs with a batch size of 8192. We leverage\nthe SPM-preprocessed text data from Common-\nCrawl in 100 languages and sample languages with"}, {"source": "2020.acl-main.747.pdf", "text": "= 0:3. In this section, we show that it out-performs all previous techniques on cross-lingual\nbenchmarks while getting performance on par with\nRoBERTa on the GLUE benchmark.\nXNLI. Table 1 shows XNLI results and adds\nsome additional details: (i) the number of models\nthe approach induces (#M), (ii) the data on which\nthe model was trained (D), and (iii) the number of"}, {"source": "2020.acl-main.747.pdf", "text": "languages the model was pretrained on (#lg). As\nwe show in our results, these parameters signi\ufb01-\ncantly impact performance. Column #M speci\ufb01es\nwhether model selection was done separately on\nthe dev set of each language ( Nmodels), or on\nthe joint dev set of all the languages (single model).\nWe observe a 0.6 decrease in overall accuracy when\nwe go from Nmodels to a single model - going"}, {"source": "2020.acl-main.747.pdf", "text": "from 71.3 to 70.7. We encourage the community to\nadopt this setting. For cross-lingual transfer, while\nthis approach is not fully zero-shot transfer, we\nargue that in real applications, a small amount of\nsupervised data is often available for validation in\neach language.\nXLM-R sets a new state of the art on XNLI. On\ncross-lingual transfer, XLM-R obtains 80.9% accu-"}, {"source": "2020.acl-main.747.pdf", "text": "racy, outperforming the XLM-100 and mBERT\nopen-source models by 10.2% and 14.6% aver-\nage accuracy. On the Swahili and Urdu low-\nresource languages, XLM-R outperforms XLM-100\nby 15.7% and 11.4%, and mBERT by 23.5% and\n15.8%. While XLM-R handles 100 languages, we\nalso show that it outperforms the former state of\nthe art Unicoder (Huang et al., 2019) and XLM"}, {"source": "2020.acl-main.747.pdf", "text": "(MLM+TLM), which handle only 15 languages, by\n5.5% and 5.8% average accuracy respectively. Us-\ning the multilingual training of translate-train-all,\nXLM-R further improves performance and reaches\n83.6% accuracy, a new overall state of the art for\nXNLI, outperforming Unicoder by 5.1%. Multi-\nlingual training is similar to practical applications\nwhere training sets are available in various lan-"}, {"source": "2020.acl-main.747.pdf", "text": "guages for the same task. In the case of XNLI,\ndatasets have been translated, and translate-train-\nall can be seen as some form of cross-lingual data\naugmentation (Singh et al., 2019), similar to back-\ntranslation (Xie et al., 2019).\nNamed Entity Recognition. In Table 2, we re-\nport results of XLM-R and mBERT on CoNLL-\n2002 and CoNLL-2003. We consider the LSTM"}, {"source": "2020.acl-main.747.pdf", "text": "+ CRF approach from Lample et al. (2016) and\nthe Flair model from Akbik et al. (2018) as base-\nlines. We evaluate the performance of the model8446Model D #M #lg en fr es de el bg ru tr ar vi th zh hi sw ur Avg\nFine-tune multilingual model on English training set (Cross-lingual Transfer)"}, {"source": "2020.acl-main.747.pdf", "text": "Lample and Conneau (2019) Wiki+MT N 15 85.0 78.7 78.9 77.8 76.6 77.4 75.3 72.5 73.1 76.1 73.2 76.5 69.6 68.4 67.3 75.1\nHuang et al. (2019) Wiki+MT N 15 85.1 79.0 79.4 77.8 77.2 77.2 76.3 72.8 73.5 76.4 73.6 76.2 69.4 69.7 66.7 75.4\nDevlin et al. (2018) Wiki N 102 82.1 73.8 74.3 71.1 66.4 68.9 69.0 61.6 64.9 69.5 55.8 69.3 60.0 50.4 58.0 66.3"}, {"source": "2020.acl-main.747.pdf", "text": "Lample and Conneau (2019) Wiki N 100 83.7 76.2 76.6 73.7 72.4 73.0 72.1 68.1 68.4 72.0 68.2 71.5 64.5 58.0 62.4 71.3\nLample and Conneau (2019) Wiki 1 100 83.2 76.7 77.7 74.0 72.7 74.1 72.7 68.7 68.6 72.9 68.9 72.5 65.6 58.2 62.4 70.7\nXLM-R Base CC 1 100 85.8 79.7 80.7 78.7 77.5 79.6 78.1 74.2 73.8 76.5 74.6 76.7 72.4 66.5 68.3 76.2"}, {"source": "2020.acl-main.747.pdf", "text": "XLM-R CC 1 100 89.1 84.1 85.1 83.9 82.9 84.0 81.2 79.6 79.8 80.8 78.1 80.2 76.9 73.9 73.8 80.9\nTranslate everything to English and use English-only model (TRANSLATE-TEST)\nBERT-en Wiki 1 1 88.8 81.4 82.3 80.1 80.3 80.9 76.2 76.0 75.4 72.0 71.9 75.6 70.0 65.8 65.8 76.2\nRoBERTa Wiki+CC 1 1 91.3 82.9 84.3 81.2 81.7 83.1 78.3 76.8 76.6 74.2 74.1 77.5 70.9 66.7 66.8 77.8"}, {"source": "2020.acl-main.747.pdf", "text": "Fine-tune multilingual model on each training set (TRANSLATE-TRAIN)\nLample and Conneau (2019) Wiki N 100 82.9 77.6 77.9 77.9 77.1 75.7 75.5 72.6 71.2 75.8 73.1 76.2 70.4 66.5 62.4 74.2\nFine-tune multilingual model on all training sets (TRANSLATE-TRAIN-ALL)\nLample and Conneau (2019)yWiki+MT 1 15 85.0 80.8 81.3 80.3 79.1 80.9 78.3 75.6 77.6 78.5 76.0 79.5 72.9 72.8 68.5 77.8"}, {"source": "2020.acl-main.747.pdf", "text": "Huang et al. (2019) Wiki+MT 1 15 85.6 81.1 82.3 80.9 79.5 81.4 79.7 76.8 78.2 77.9 77.1 80.5 73.4 73.8 69.6 78.5\nLample and Conneau (2019) Wiki 1 100 84.5 80.1 81.3 79.3 78.6 79.4 77.5 75.2 75.6 78.3 75.7 78.3 72.1 69.2 67.7 76.9\nXLM-R Base CC 1 100 85.4 81.4 82.2 80.3 80.4 81.3 79.7 78.6 77.3 79.7 77.9 80.2 76.1 73.1 73.0 79.1"}, {"source": "2020.acl-main.747.pdf", "text": "XLM-R CC 1 100 89.1 85.1 86.6 85.7 85.3 85.9 83.5 83.2 83.1 83.7 81.5 83.7 81.6 78.0 78.1 83.6\nTable 1: Results on cross-lingual classi\ufb01cation. We report the accuracy on each of the 15 XNLI languages and the\naverage accuracy. We specify the dataset D used for pretraining, the number of models #M the approach requires"}, {"source": "2020.acl-main.747.pdf", "text": "and the number of languages #lg the model handles. Our XLM-R results are averaged over \ufb01ve different seeds.\nWe show that using the translate-train-all approach which leverages training sets from multiple languages, XLM-R\nobtains a new state of the art on XNLI of 83:6% average accuracy. Results withyare from Huang et al. (2019).\nModel train #M en nl es de Avg"}, {"source": "2020.acl-main.747.pdf", "text": "Model train #M en nl es de Avg\nLample et al. (2016) each N 90.74 81.74 85.75 78.76 84.25\nAkbik et al. (2018) each N 93.18 90.44 - 88.27 -\nmBERTy each N 91.97 90.94 87.38 82.82 88.28\nen 1 91.97 77.57 74.96 69.56 78.52\nXLM-R Baseeach N 92.25 90.39 87.99 84.60 88.81\nen 1 92.25 78.08 76.53 69.60 79.11\nall 1 91.08 89.09 87.28 83.17 87.66\nXLM-Reach N 92.92 92.53 89.72 85.81 90.24"}, {"source": "2020.acl-main.747.pdf", "text": "en 1 92.92 80.80 78.64 71.40 80.94\nall 1 92.00 91.60 89.52 84.60 89.43\nTable 2: Results on named entity recognition on\nCoNLL-2002 and CoNLL-2003 (F1 score). Results\nwith yare from Wu and Dredze (2019). Note that\nmBERT and XLM-R do not use a linear-chain CRF, as\nopposed to Akbik et al. (2018) and Lample et al. (2016).\non each of the target languages in three different"}, {"source": "2020.acl-main.747.pdf", "text": "settings: (i) train on English data only (en) (ii) train\non data in target language (each) (iii) train on data\nin all languages (all). Results of mBERT are re-\nported from Wu and Dredze (2019). Note that we\ndo not use a linear-chain CRF on top of XLM-R\nand mBERT representations, which gives an advan-\ntage to Akbik et al. (2018). Without the CRF, our"}, {"source": "2020.acl-main.747.pdf", "text": "XLM-R model still performs on par with the state\nof the art, outperforming Akbik et al. (2018) on\nDutch by 2:09points. On this task, XLM-R also\noutperforms mBERT by 2.42 F1 on average for\ncross-lingual transfer, and 1.86 F1 when trained\non each language. Training on all languages leads\nto an average F1 score of 89.43%, outperformingcross-lingual transfer approach by 8.49%."}, {"source": "2020.acl-main.747.pdf", "text": "Question Answering. We also obtain new state\nof the art results on the MLQA cross-lingual ques-\ntion answering benchmark, introduced by Lewis\net al. (2019). We follow their procedure by training\non the English training data and evaluating on the\n7 languages of the dataset. We report results in\nTable 3. XLM-R obtains F1 and accuracy scores of\n70.7% and 52.7% while the previous state of the art"}, {"source": "2020.acl-main.747.pdf", "text": "was 61.6% and 43.5%. XLM-R also outperforms\nmBERT by 13.0% F1-score and 11.1% accuracy.\nIt even outperforms BERT-Large on English, con-\n\ufb01rming its strong monolingual performance.\n5.3 Multilingual versus Monolingual\nIn this section, we present results of multilingual\nXLM models against monolingual BERT models.\nGLUE: XLM-R versus RoBERTa. Our goal is"}, {"source": "2020.acl-main.747.pdf", "text": "GLUE: XLM-R versus RoBERTa. Our goal is\nto obtain a multilingual model with strong perfor-\nmance on both, cross-lingual understanding tasks\nas well as natural language understanding tasks\nfor each language. To that end, we evaluate XLM-\nRon the GLUE benchmark. We show in Table 4,\nthatXLM-R obtains better average dev performance\nthan BERT Large by 1.6% and reaches performance"}, {"source": "2020.acl-main.747.pdf", "text": "on par with XLNet Large. The RoBERTa model out-\nperforms XLM-R by only 1.0% on average. We\nbelieve future work can reduce this gap even fur-\nther by alleviating the curse of multilinguality and8447Model train #lgs en es de ar hi vi zh Avg\nBERT-Largeyen 1 80.2 / 67.4 - - - - - - -\nmBERTyen 102 77.7 / 65.2 64.3 / 46.6 57.9 / 44.3 45.7 / 29.8 43.8 / 29.7 57.1 / 38.6 57.5 / 37.3 57.7 / 41.6"}, {"source": "2020.acl-main.747.pdf", "text": "XLM-15yen 15 74.9 / 62.4 68.0 / 49.8 62.2 / 47.6 54.8 / 36.3 48.8 / 27.3 61.4 / 41.8 61.1 / 39.6 61.6 / 43.5\nXLM-R Base en 100 77.1 / 64.6 67.4 / 49.6 60.9 / 46.7 54.9 / 36.6 59.4 / 42.9 64.5 / 44.7 61.8 / 39.3 63.7 / 46.3\nXLM-R en 100 80.6 / 67.8 74.1 / 56.0 68.5 / 53.6 63.1 / 43.5 69.2 / 51.6 71.3 / 50.9 68.0 / 45.4 70.7 / 52.7"}, {"source": "2020.acl-main.747.pdf", "text": "Table 3: Results on MLQA question answering We report the F1 and EM (exact match) scores for zero-shot\nclassi\ufb01cation where models are \ufb01ne-tuned on the English Squad dataset and evaluated on the 7 languages of\nMLQA. Results with yare taken from the original MLQA paper Lewis et al. (2019).\nvocabulary dilution. These results demonstrate the\npossibility of learning one model for many lan-"}, {"source": "2020.acl-main.747.pdf", "text": "guages while maintaining strong performance on\nper-language downstream tasks.\nModel #lgs MNLI-m/mm QNLI QQP SST MRPC STS-B Avg\nBERT Largey1 86.6/- 92.3 91.3 93.2 88.0 90.0 90.2\nXLNet Largey1 89.8/- 93.9 91.8 95.6 89.2 91.8 92.0\nRoBERTay1 90.2/90.2 94.7 92.2 96.4 90.9 92.4 92.8\nXLM-R 100 88.9/89.0 93.8 92.3 95.0 89.5 91.2 91.8\nTable 4: GLUE dev results. Results withyare from"}, {"source": "2020.acl-main.747.pdf", "text": "Liu et al. (2019). We compare the performance of XLM-\nRto BERT Large, XLNet and RoBERTa on the English\nGLUE benchmark.\nXNLI: XLM versus BERT. A recurrent criti-\ncism against multilingual models is that they obtain\nworse performance than their monolingual coun-\nterparts. In addition to the comparison of XLM-R\nand RoBERTa, we provide the \ufb01rst comprehen-"}, {"source": "2020.acl-main.747.pdf", "text": "sive study to assess this claim on the XNLI bench-\nmark. We extend our comparison between multilin-\ngual XLM models and monolingual BERT models\non 7 languages and compare performance in Ta-\nble 5. We train 14 monolingual BERT models on\nWikipedia and CommonCrawl (capped at 60 GiB),\nand two XLM-7 models. We increase the vocab-\nulary size of the multilingual model for a better"}, {"source": "2020.acl-main.747.pdf", "text": "comparison. We found that multilingual models\ncan outperform their monolingual BERT counter-\nparts . Speci\ufb01cally, in Table 5, we show that for\ncross-lingual transfer, monolingual baselines out-\nperform XLM-7 for both Wikipedia and CC by\n1.6% and 1.3% average accuracy. However, by\nmaking use of multilingual training (translate-train-\nall) and leveraging training sets coming from mul-"}, {"source": "2020.acl-main.747.pdf", "text": "tiple languages, XLM-7 can outperform the BERT\nmodels: our XLM-7 trained on CC obtains 80.0%\naverage accuracy on the 7 languages, while the\naverage performance of BERT models trained on\nCC is 77.5%. This is a surprising result that shows\nthat the capacity of multilingual models to leverage\ntraining data coming from multiple languages for aparticular task can overcome the capacity dilution"}, {"source": "2020.acl-main.747.pdf", "text": "problem to obtain better overall performance.\nModel D #vocab en fr de ru zh sw ur Avg\nMonolingual baselines\nBERTWiki 40k 84.5 78.6 80.0 75.5 77.7 60.1 57.3 73.4\nCC 40k 86.7 81.2 81.2 78.2 79.5 70.8 65.1 77.5\nMultilingual models (cross-lingual transfer)\nXLM-7Wiki 150k 82.3 76.8 74.7 72.5 73.1 60.8 62.3 71.8\nCC 150k 85.7 78.6 79.5 76.4 74.8 71.2 66.9 76.2\nMultilingual models (translate-train-all)"}, {"source": "2020.acl-main.747.pdf", "text": "XLM-7Wiki 150k 84.6 80.1 80.2 75.7 78 68.7 66.7 76.3\nCC 150k 87.2 82.5 82.9 79.7 80.4 75.7 71.5 80.0\nTable 5: Multilingual versus monolingual models\n(BERT-BASE). We compare the performance of mono-\nlingual models (BERT) versus multilingual models\n(XLM) on seven languages, using a BERT-BASE archi-\ntecture. We choose a vocabulary size of 40k and 150k\nfor monolingual and multilingual models."}, {"source": "2020.acl-main.747.pdf", "text": "5.4 Representation Learning for\nLow-resource Languages\nWe observed in Table 5 that pretraining on\nWikipedia for Swahili and Urdu performed sim-\nilarly to a randomly initialized model; most likely\ndue to the small size of the data for these languages.\nOn the other hand, pretraining on CC improved\nperformance by up to 10 points. This con\ufb01rms our\nassumption that mBERT and XLM-100 rely heav-"}, {"source": "2020.acl-main.747.pdf", "text": "ily on cross-lingual transfer but do not model the\nlow-resource languages as well as XLM-R . Speci\ufb01-\ncally, in the translate-train-all setting, we observe\nthat the biggest gains for XLM models trained on\nCC, compared to their Wikipedia counterparts, are\non low-resource languages; 7% and 4.8% improve-\nment on Swahili and Urdu respectively.\n6 Conclusion"}, {"source": "2020.acl-main.747.pdf", "text": "6 Conclusion\nIn this work, we introduced XLM-R , our new state\nof the art multilingual masked language model\ntrained on 2.5 TB of newly created clean Com-\nmonCrawl data in 100 languages. We show that it\nprovides strong gains over previous multilingual8448models like mBERT and XLM on classi\ufb01cation,\nsequence labeling and question answering. We ex-\nposed the limitations of multilingual MLMs, in"}, {"source": "2020.acl-main.747.pdf", "text": "particular by uncovering the high-resource versus\nlow-resource trade-off, the curse of multilinguality\nand the importance of key hyperparameters. We\nalso expose the surprising effectiveness of multilin-\ngual models over monolingual models, and show\nstrong improvements on low-resource languages.\nReferences\nAlan Akbik, Duncan Blythe, and Roland V ollgraf."}, {"source": "2020.acl-main.747.pdf", "text": "2018. Contextual string embeddings for sequence\nlabeling. In COLING , pages 1638\u20131649.\nNaveen Arivazhagan, Ankur Bapna, Orhan Firat,\nDmitry Lepikhin, Melvin Johnson, Maxim Krikun,\nMia Xu Chen, Yuan Cao, George Foster, Colin\nCherry, et al. 2019. Massively multilingual neural\nmachine translation in the wild: Findings and chal-\nlenges. arXiv preprint arXiv:1907.05019 ."}, {"source": "2020.acl-main.747.pdf", "text": "Samuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nInEMNLP .\nAlexis Conneau, Ruty Rinott, Guillaume Lample, Ad-\nina Williams, Samuel R. Bowman, Holger Schwenk,\nand Veselin Stoyanov. 2018. Xnli: Evaluating cross-\nlingual sentence representations. In EMNLP . Asso-"}, {"source": "2020.acl-main.747.pdf", "text": "ciation for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning.NAACL .\nEdouard Grave, Piotr Bojanowski, Prakhar Gupta, Ar-\nmand Joulin, and Tomas Mikolov. 2018. Learning\nword vectors for 157 languages. In LREC .\nHaoyang Huang, Yaobo Liang, Nan Duan, Ming Gong,"}, {"source": "2020.acl-main.747.pdf", "text": "Linjun Shou, Daxin Jiang, and Ming Zhou. 2019.\nUnicoder: A universal language encoder by pre-\ntraining with multiple cross-lingual tasks. ACL.\nMelvin Johnson, Mike Schuster, Quoc V Le, Maxim\nKrikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat,\nFernanda Vi \u00b4egas, Martin Wattenberg, Greg Corrado,\net al. 2017. Google\u2019s multilingual neural machine\ntranslation system: Enabling zero-shot translation."}, {"source": "2020.acl-main.747.pdf", "text": "TACL , 5:339\u2013351.\nArmand Joulin, Edouard Grave, and Piotr Bo-\njanowski Tomas Mikolov. 2017. Bag of tricks for\nef\ufb01cient text classi\ufb01cation. EACL 2017 , page 427.\nRafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam\nShazeer, and Yonghui Wu. 2016. Exploring\nthe limits of language modeling. arXiv preprint\narXiv:1602.02410 .Taku Kudo. 2018. Subword regularization: Improving"}, {"source": "2020.acl-main.747.pdf", "text": "neural network translation models with multiple sub-\nword candidates. In ACL, pages 66\u201375.\nTaku Kudo and John Richardson. 2018. Sentencepiece:\nA simple and language independent subword tok-\nenizer and detokenizer for neural text processing.\nEMNLP .\nGuillaume Lample, Miguel Ballesteros, Sandeep Sub-\nramanian, Kazuya Kawakami, and Chris Dyer. 2016.\nNeural architectures for named entity recognition."}, {"source": "2020.acl-main.747.pdf", "text": "InNAACL , pages 260\u2013270, San Diego, California.\nAssociation for Computational Linguistics.\nGuillaume Lample and Alexis Conneau. 2019. Cross-\nlingual language model pretraining. NeurIPS .\nPatrick Lewis, Barlas O \u02d8guz, Ruty Rinott, Sebastian\nRiedel, and Holger Schwenk. 2019. Mlqa: Eval-\nuating cross-lingual extractive question answering.\narXiv preprint arXiv:1910.07475 ."}, {"source": "2020.acl-main.747.pdf", "text": "arXiv preprint arXiv:1910.07475 .\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining ap-\nproach. arXiv preprint arXiv:1907.11692 .\nTomas Mikolov, Quoc V Le, and Ilya Sutskever. 2013a.\nExploiting similarities among languages for ma-"}, {"source": "2020.acl-main.747.pdf", "text": "chine translation. arXiv preprint arXiv:1309.4168 .\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-\nrado, and Jeff Dean. 2013b. Distributed representa-\ntions of words and phrases and their compositional-\nity. In NIPS , pages 3111\u20133119.\nJeffrey Pennington, Richard Socher, and Christopher D.\nManning. 2014. Glove: Global vectors for word rep-\nresentation. In EMNLP , pages 1532\u20131543."}, {"source": "2020.acl-main.747.pdf", "text": "Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word repre-\nsentations. NAACL .\nTelmo Pires, Eva Schlinger, and Dan Garrette. 2019.\nHow multilingual is multilingual bert? In ACL.\nAlec Radford, Karthik Narasimhan, Tim Salimans,\nand Ilya Sutskever. 2018. Improving language"}, {"source": "2020.acl-main.747.pdf", "text": "understanding by generative pre-training. URL\nhttps://s3-us-west-2.amazonaws.com/openai-\nassets/research-covers/language-\nunsupervised/language understanding paper.pdf .\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog , 1(8).\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine"}, {"source": "2020.acl-main.747.pdf", "text": "Lee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2019. Exploring the limits\nof transfer learning with a uni\ufb01ed text-to-text trans-\nformer. arXiv preprint arXiv:1910.10683 .8449Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.\nKnow what you don\u2019t know: Unanswerable ques-\ntions for squad. ACL.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and"}, {"source": "2020.acl-main.747.pdf", "text": "Percy Liang. 2016. SQuAD: 100,000+ questions for\nmachine comprehension of text. In EMNLP , pages\n2383\u20132392, Austin, Texas. Association for Compu-\ntational Linguistics.\nErik F Sang. 2002. Introduction to the conll-2002\nshared task: Language-independent named entity\nrecognition. CoNLL .\nTal Schuster, Ori Ram, Regina Barzilay, and Amir\nGloberson. 2019. Cross-lingual alignment of con-"}, {"source": "2020.acl-main.747.pdf", "text": "textual word embeddings, with applications to zero-\nshot dependency parsing. NAACL .\nAditya Siddhant, Melvin Johnson, Henry Tsai, Naveen\nArivazhagan, Jason Riesa, Ankur Bapna, Orhan Fi-\nrat, and Karthik Raman. 2019. Evaluating the cross-\nlingual effectiveness of massively multilingual neu-\nral machine translation. AAAI .\nJasdeep Singh, Bryan McCann, Nitish Shirish Keskar,"}, {"source": "2020.acl-main.747.pdf", "text": "Caiming Xiong, and Richard Socher. 2019. Xlda:\nCross-lingual data augmentation for natural lan-\nguage inference and question answering. arXiv\npreprint arXiv:1905.11471 .\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models\nfor semantic compositionality over a sentiment tree-\nbank. In EMNLP , pages 1631\u20131642."}, {"source": "2020.acl-main.747.pdf", "text": "bank. In EMNLP , pages 1631\u20131642.\nXu Tan, Yi Ren, Di He, Tao Qin, Zhou Zhao, and Tie-\nYan Liu. 2019. Multilingual neural machine transla-\ntion with knowledge distillation. ICLR .\nErik F Tjong Kim Sang and Fien De Meulder. 2003. In-\ntroduction to the conll-2003 shared task: language-\nindependent named entity recognition. In CoNLL ,\npages 142\u2013147. Association for Computational Lin-\nguistics."}, {"source": "2020.acl-main.747.pdf", "text": "guistics.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems , pages 6000\u20136010.\nAlex Wang, Amapreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R Bowman. 2018.\nGlue: A multi-task benchmark and analysis platform"}, {"source": "2020.acl-main.747.pdf", "text": "for natural language understanding. arXiv preprint\narXiv:1804.07461 .\nGuillaume Wenzek, Marie-Anne Lachaux, Alexis Con-\nneau, Vishrav Chaudhary, Francisco Guzman, Ar-\nmand Joulin, and Edouard Grave. 2019. Ccnet: Ex-\ntracting high quality monolingual datasets from web\ncrawl data. arXiv preprint arXiv:1911.00359 .Adina Williams, Nikita Nangia, and Samuel R Bow-"}, {"source": "2020.acl-main.747.pdf", "text": "man. 2017. A broad-coverage challenge corpus\nfor sentence understanding through inference. Pro-\nceedings of the 2nd Workshop on Evaluating Vector-\nSpace Representations for NLP .\nShijie Wu, Alexis Conneau, Haoran Li, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2019. Emerging\ncross-lingual structure in pretrained language mod-\nels.ACL.\nShijie Wu and Mark Dredze. 2019. Beto, bentz, be-"}, {"source": "2020.acl-main.747.pdf", "text": "cas: The surprising cross-lingual effectiveness of\nbert. EMNLP .\nQizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Lu-\nong, and Quoc V Le. 2019. Unsupervised data aug-\nmentation for consistency training. arXiv preprint\narXiv:1904.12848 .8450Appendix\nA Languages and statistics for CC-100 used by XLM-R"}, {"source": "2020.acl-main.747.pdf", "text": "In this section we present the list of languages in the CC-100 corpus we created for training XLM-R . We\nalso report statistics such as the number of tokens and the size of each monolingual corpus.\nISO code Language Tokens (M) Size (GiB) ISO code Language Tokens (M) Size (GiB)\naf Afrikaans 242 1.3 lo Lao 17 0.6\nam Amharic 68 0.8 lt Lithuanian 1835 13.7\nar Arabic 2869 28.0 lv Latvian 1198 8.8"}, {"source": "2020.acl-main.747.pdf", "text": "ar Arabic 2869 28.0 lv Latvian 1198 8.8\nas Assamese 5 0.1 mg Malagasy 25 0.2\naz Azerbaijani 783 6.5 mk Macedonian 449 4.8\nbe Belarusian 362 4.3 ml Malayalam 313 7.6\nbg Bulgarian 5487 57.5 mn Mongolian 248 3.0\nbn Bengali 525 8.4 mr Marathi 175 2.8\n- Bengali Romanized 77 0.5 ms Malay 1318 8.5\nbr Breton 16 0.1 my Burmese 15 0.4\nbs Bosnian 14 0.1 my Burmese 56 1.6"}, {"source": "2020.acl-main.747.pdf", "text": "bs Bosnian 14 0.1 my Burmese 56 1.6\nca Catalan 1752 10.1 ne Nepali 237 3.8\ncs Czech 2498 16.3 nl Dutch 5025 29.3\ncy Welsh 141 0.8 no Norwegian 8494 49.0\nda Danish 7823 45.6 om Oromo 8 0.1\nde German 10297 66.6 or Oriya 36 0.6\nel Greek 4285 46.9 pa Punjabi 68 0.8\nen English 55608 300.8 pl Polish 6490 44.6\neo Esperanto 157 0.9 ps Pashto 96 0.7\nes Spanish 9374 53.3 pt Portuguese 8405 49.1"}, {"source": "2020.acl-main.747.pdf", "text": "et Estonian 843 6.1 ro Romanian 10354 61.4\neu Basque 270 2.0 ru Russian 23408 278.0\nfa Persian 13259 111.6 sa Sanskrit 17 0.3\n\ufb01 Finnish 6730 54.3 sd Sindhi 50 0.4\nfr French 9780 56.8 si Sinhala 243 3.6\nfy Western Frisian 29 0.2 sk Slovak 3525 23.2\nga Irish 86 0.5 sl Slovenian 1669 10.3\ngd Scottish Gaelic 21 0.1 so Somali 62 0.4\ngl Galician 495 2.9 sq Albanian 918 5.4"}, {"source": "2020.acl-main.747.pdf", "text": "gl Galician 495 2.9 sq Albanian 918 5.4\ngu Gujarati 140 1.9 sr Serbian 843 9.1\nha Hausa 56 0.3 su Sundanese 10 0.1\nhe Hebrew 3399 31.6 sv Swedish 77.8 12.1\nhi Hindi 1715 20.2 sw Swahili 275 1.6\n- Hindi Romanized 88 0.5 ta Tamil 595 12.2\nhr Croatian 3297 20.5 - Tamil Romanized 36 0.3\nhu Hungarian 7807 58.4 te Telugu 249 4.7\nhy Armenian 421 5.5 - Telugu Romanized 39 0.3"}, {"source": "2020.acl-main.747.pdf", "text": "id Indonesian 22704 148.3 th Thai 1834 71.7\nis Icelandic 505 3.2 tl Filipino 556 3.1\nit Italian 4983 30.2 tr Turkish 2736 20.9\nja Japanese 530 69.3 ug Uyghur 27 0.4\njv Javanese 24 0.2 uk Ukrainian 6.5 84.6\nka Georgian 469 9.1 ur Urdu 730 5.7\nkk Kazakh 476 6.4 - Urdu Romanized 85 0.5\nkm Khmer 36 1.5 uz Uzbek 91 0.7\nkn Kannada 169 3.3 vi Vietnamese 24757 137.3\nko Korean 5644 54.2 xh Xhosa 13 0.1"}, {"source": "2020.acl-main.747.pdf", "text": "ko Korean 5644 54.2 xh Xhosa 13 0.1\nku Kurdish (Kurmanji) 66 0.4 yi Yiddish 34 0.3\nky Kyrgyz 94 1.2 zh Chinese (Simpli\ufb01ed) 259 46.9\nla Latin 390 2.5 zh Chinese (Traditional) 176 16.6\nTable 6: Languages and statistics of the CC-100 corpus. We report the list of 100 languages and include\nthe number of tokens (Millions) and the size of the data (in GiB) for each language. Note that we also include"}, {"source": "2020.acl-main.747.pdf", "text": "romanized variants of some non latin languages such as Bengali, Hindi, Tamil, Telugu and Urdu.8451B Model Architectures and Sizes\nAs we showed in section 5, capacity is an important parameter for learning strong cross-lingual represen-\ntations. In the table below, we list multiple monolingual and multilingual models used by the research"}, {"source": "2020.acl-main.747.pdf", "text": "community and summarize their architectures and total number of parameters.\nModel #lgs tokenization L HmHff A V #params\nBERT Base 1 WordPiece 12 768 3072 12 30k 110M\nBERT Large 1 WordPiece 24 1024 4096 16 30k 335M\nmBERT 104 WordPiece 12 768 3072 12 110k 172M\nRoBERTa Base 1 bBPE 12 768 3072 8 50k 125M\nRoBERTa 1 bBPE 24 1024 4096 16 50k 355M\nXLM-15 15 BPE 12 1024 4096 8 95k 250M"}, {"source": "2020.acl-main.747.pdf", "text": "XLM-15 15 BPE 12 1024 4096 8 95k 250M\nXLM-17 17 BPE 16 1280 5120 16 200k 570M\nXLM-100 100 BPE 16 1280 5120 16 200k 570M\nUnicoder 15 BPE 12 1024 4096 8 95k 250M\nXLM-R Base 100 SPM 12 768 3072 12 250k 270M\nXLM-R 100 SPM 24 1024 4096 16 250k 550M\nGPT2 1 bBPE 48 1600 6400 32 50k 1.5B\nwide-mmNMT 103 SPM 12 2048 16384 32 64k 3B\ndeep-mmNMT 103 SPM 24 1024 16384 32 64k 3B"}, {"source": "2020.acl-main.747.pdf", "text": "T5-3B 1 WordPiece 24 1024 16384 32 32k 3B\nT5-11B 1 WordPiece 24 1024 65536 32 32k 11B\nTable 7: Details on model sizes. We show the tokenization used by each Transformer model, the number of layers\nL, the number of hidden states of the model Hm, the dimension of the feed-forward layer Hff, the number of"}, {"source": "2020.acl-main.747.pdf", "text": "attention heads A, the size of the vocabulary V and the total number of parameters #params. For Transformer\nencoders, the number of parameters can be approximated by 4LH2\nm+ 2LHmHff+VH m. GPT2 numbers\nare from Radford et al. (2019), mm-NMT models are from the work of Arivazhagan et al. (2019) on massively"}, {"source": "2020.acl-main.747.pdf", "text": "multilingual neural machine translation (mmNMT), and T5 numbers are from Raffel et al. (2019). While XLM-R\nis among the largest models partly due to its large embedding layer, it has a similar number of parameters than\nXLM-100, and remains signi\ufb01cantly smaller that recently introduced Transformer models for multilingual MT and"}, {"source": "2020.acl-main.747.pdf", "text": "transfer learning. While this table gives more hindsight on the difference of capacity of each model, note it does\nnot highlight other critical differences between the models."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Learning Hierarchical Discourse-level Structure for Fake News\nDetection\nHamid Karimi\nComputer Science and Engineering\nMichigan State University\nkarimiha@msu.eduJiliang Tang\nComputer Science and Engineering\nMichigan State University\ntangjili@msu.edu\nAbstract\nOn the one hand, nowadays, fake news ar-\nticles are easily propagated through vari-\nous online media platforms and have be-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "ous online media platforms and have be-\ncome a grand threat to the trustworthi-\nness of information. On the other hand,\nour understanding of the language of fake\nnews is still minimal. Incorporating hierar-\nchical discourse-level structure of fake and\nreal news articles is one crucial step to-\nward a better understanding of how these\narticles are structured. Nevertheless, this"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "has rarely been investigated in the fake\nnews detection domain and faces tremen-\ndous challenges. First, existing methods\nfor capturing discourse-level structure rely\non annotated corpora which are not avail-\nable for fake news datasets. Second, how\nto extract out useful information from such\ndiscovered structures is another challenge.\nTo address these challenges, we propose"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "To address these challenges, we propose\nHierarchical Discourse-level Structure for\nFake news detection. HDSF learns and\nconstructs a discourse-level structure for\nfake/real news articles in an automated\nand data-driven manner. Moreover, we\nidentify insightful structure-related prop-\nerties, which can explain the discovered\nstructures and boost our understating of"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "fake news. Conducted experiments show\nthe e\u000bectiveness of the proposed approach.\nFurther structural analysis suggests that\nreal and fake news present substantial dif-\nferences in the hierarchical discourse-level\nstructures.\n1 Introduction\nIn this work, we focus on detecting fake news\narticles (hereafter referred to as documents )\nbased on their contents. Many existing linguis-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tic approaches for fake news detection (Feng\net al., 2012; Pennebaker et al., 2015; Ott\net al., 2011) overlook a crucial linguistic as-pect of fake/real news documents i.e., the\nhierarchical discourse-level structure. Usu-\nally, in a document, discourse units (e.g., sen-\ntences) are organized in a hierarchical struc-\nture e.g., a tree. The importance of consid-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "ering the hierarchical discourse-level structure\nfor fake news detection is three-fold. First,\nprevious studies (Bachenko et al., 2008; Ru-\nbin and Lukoianova, 2015) explored discourse-\nlevel structure in fake news detection and\ndiscovered that the way two discourse units\nof a document are connected could be quite\nrevealing and insightful about its truthful-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "ness. For instance, (Rubin and Lukoianova,\n2015) applied Rhetorical Structure Theory\n(RST) (Mann and Thompson, 1988) and noted\nthat fake stories lack \\evidence\" as a de\fned\ninter-discourse relation. Second, fake news\nis typically produced by connecting disjoint\npieces of news and unlike well-established jour-\nnalism (e.g., New York Times) fake news pro-\nduction lacks a meticulous editorial board."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Therefore, by incorporating the hierarchical\ndiscourse-level structure, we can investigate\nthe coherence of fake/real news documents\n(we will show this later). Third, a substan-\ntial number of studies have shown that us-\ning hierarchical structures yields a better doc-\nument representation in various downstream\ntasks whose predictions depend on the entire"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "text (Bhatia et al., 2015; Morey et al., 2018; Li\net al., 2014b). Since typically fake news detec-\ntion is considered as a classi\fcation problem\nbased on the entire text, applying discourse\nanalysis has the potential to advance fake news\ndetection (this will be veri\fed later).\nOn the other hand, incorporating the hi-\nerarchical structure at the discourse level for"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "fake news detection faces tremendous chal-\nlenges. First, many existing methods incor-arXiv:1903.07389v6  [cs.CL]  10 Apr 2019porating structural discourse (Li et al., 2014a;\nBhatia et al., 2015) (not for fake news detec-\ntion though) rely on annotated corpora such\nas Penn Discourse Treebank (Prasad et al.,\n2007). Constructing and annotating such cor-\npora is an arduous and costly process. Incor-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "porating hierarchical structure is even more\ndi\u000ecult for fake news detection as there ex-\nists virtually no available annotated discourse\ncorpus in this domain. Therefore, we need to\nlearn the discourse-level structure in a data-\ndriven and automated manner. Second, how\nto use the hierarchical discourse-level struc-\nture and extract insightful information that"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "can boost our understanding of fake news is\nanother challenge.\nIn this study, we embrace the opportuni-\nties and challenges and propose Hierarchical\nDiscourse-level Structure for Fake news de-\ntection (HDSF) framework. HDSF in an auto-\nmated manner learns a hierarchical structure\nfor a given document through an approach\nbased on the dependency parsing at the sen-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tence level (i.e., sentences are discourse units).\nAs an example, Figure 1 illustrates a hier-\narchical structure of a document i.e., a de-\npendency tree of sentences. Sentences repre-\nsent discourse units and two sentences are con-\nnected by a directed link where a sentence at\nthehead of the link semantically depends on a\nsentence at the tailof the link e.g., in Figure 1,"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "the sentence s4depends on the sentence s2.\nOur key contributions are summarized as\nfollow.\n\u000fTo the best of our knowledge, we are the\n\frst to study automatic document struc-\nture learning for fake news detection.\n\u000fWe propose the framework HDSF that\nautomatically and in an end-to-end man-\nner learns structurally rich representa-\ntions for fake and real news documents."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tions for fake and real news documents.\n\u000fWe identify a set of structure-related\nproperties delineating meaningful struc-\ntural di\u000berences between fake and real\nnews documents.\nThe rest of the paper is organized as follows.\nIn Section 2, we formally de\fne the problem.\nSection 3 describes the proposed framework.\nIn Section 4, we introduce several structure-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "related properties to analyze the hierarchical\ns1.Massive protests have broken outinCharlotte, North\nCarolina, after police shot and killed disabled anAfrican -\nAmerican man named Keith Lamont Scott, who was\napparently reading abook inhiscar ,waiting forhisson\ntocome home from school when officers shot him\ndead .\ns2.Details are still sketchy atthe moment, but it"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "appears the police were insearch ofanother armed\nman inthearea .\ns3.Scott isthesixth civilian shot byCharlotte police this\nyear.\ns4.Twelve officers have apparently been injured astear\ngascanisters were fired into thecrowd .\ns5.Scott isthe215thblack man shot bypolice thisyear.A sample document from our corpus\nA hierarchical discourse -level dependency tree \ns3s1\ns2"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "s3s1\ns2\ns4 s5Figure 1: An illustration of the hierarchical\ndiscourse-level structure of a document using a de-\npendency tree\nstructures. Section 5 presents the experiments\nand discussions followed by an overview of the\nrelated work in Section 6. We conclude the\npaper in Section 7 and shed light on a few\nfuture directions.\n2 Notations and Problem\nStatement\nFollowing the previous work (Allcott and"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Gentzkow, 2017; Shu et al., 2017), we de\fne\nthe fake news as follows.\nDe\fnition . We de\fne a news document\nfake if its content is veri\fed to be false and\nrealotherwise.\nLet's brie\ry introduce some notations. Sup-\npose we have a corpus Dof fake and real\nnews documents. Let a document d2D con-\ntainksentencess1;s2;\u0001\u0001\u0001sk. Suppose a sen-\ntencesj2d(1\u0014j\u0014k) includes words"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tencesj2d(1\u0014j\u0014k) includes words\nWj=fw1;w2;\u0001\u0001\u0001;wTjgwhereTjdenotes the\nnumber of words in sentence sj. Addition-\nally, binary labels Y(i.e., fake orreallabels)\nhold ground-truth labels associated with doc-\numents inD.\nGiven the corpus of fake/real news docu-\nments (i.e.,D), we aim to learn model Mthat\ncan automatically learn hierarchical and struc-turally rich representations for documents in"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "D. Meanwhile, given binary labels Y, the\nmodelMuses the hierarchical representations\nto automatically predict the labels of unseen\nnews documents.\n3 The Proposed Framework\nTo incorporate the discourse-level structure for\nfake news detection, we propose the frame-\nwork HDSF illustrated in Figure 2. It provides\nthree components: the Hierarchical Discourse-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "level Structure Learning automatically learns\na proper structure for a given document,\ntheStructural Document-level Representation\nyields a numerical and uni\fed representation\nfor the entire document, which is used by the\nFake News Classi\fcation component to pre-\ndict the label of a document.\n3.1 Hierarchical Discourse-level\nStructure Learning\nIn this component, we aim to construct a hi-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "erarchical structure between discourse units\n(i.e., sentences) without relying on an anno-\ntated corpus. To achieve this, we use a de-\npendency parsing approach (Liu and Lapata,\n2018; Li et al., 2014a; Kim et al., 2017) and\nrepresent the hierarchical structure of a doc-\nument as a dependency tree (see Figure 1 for\nan example of a dependency tree). In depen-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "dency parsing of discourse units, we mainly\nneed to identify if a discourse unit semantically\ndepends on another one. If so, a parent-child\n(ortail-head ) link in the dependency tree can\nbe established. Therefore, as long as the se-\nmantic dependencies between discourse units\nare identi\fed, we can construct a discourse-\nlevel dependency tree without an annotated"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "corpus. In Section 3.1.1, we describe a method\nto discover the semantic dependencies between\ndiscourse units in an automated manner. Af-\nterward, in Section 3.1.2, we utilize these de-\npendencies to construct the dependency tree\nof a document.\n3.1.1 Learning Inter-Discourse\nDependencies\nSince discourse units are de\fned as sentences,\nwe \frst need to get a \fxed representation"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "for each sentence. To this end, we uti-\nlize Bi-directional Long Short-Term Mem-\nory (BLSTM) network (Schuster and Paliwal,1997). We represent each word in a sentence\nsjby a \fxed-size word embedding, and fur-\nther the BLSTM network at each time step\nt2[1;Tj] executes the following functions1:\n\u0000 !ht=F(\u0000 !ht\u00001;wt\u00001)\n \u0000ht=F( \u0000ht\u00001;wTj\u0000t+1)(1)\nwhereFis the LSTM function (Hochreiter and"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Schmidhuber, 1997), and\u0000 !htand \u0000htare out-\nputs of the forward and backward LSTM net-\nworks at time step t, respectively. Then, a\n\fxed representation for a sentence sj, denoted\nasfj, is de\fned as the average of the last out-\nput of forward and backward LSTM networks:\nfj=[\u0000 !hTj+ \u0000hTj]\n2(2)\nSimilarly, we apply the BLSTM network\nto all sentences of a document and obtain"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "a sequence of sentential representations i.e.,\nf1;f2;\u0001\u0001\u0001;fk(see Figure 2).\nAs mentioned before, in dependency pars-\ning, we need to identify the dependency be-\ntween two discourse units in an automated\nmanner. To do this, the HDSF framework\nlearns and optimizes an inter-sentential atten-\ntion matrix A2Rk\u0002k. The entry ( m;n) of\nAholds the probability of the sentence sm"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "being the parent of the sentence snwhere\n1\u0014m;n\u0014kandm6=n. In other words, A\ncontains parent-child probabilities and is com-\nputed as follows.\num=G(W\u0002fm+b)\nun=G(W\u0002fn+b)\nA[m;n] =e(um\fun)\nPk\ni=1eP(ui\fun)(3)\nwhereGis a non-linear activation function, W\nis some weight matrix, bis a bias vector, and\n\fdenotes the dot product operator. Further,\nsince we need a root node in a dependency"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tree, we compute the probability of a sentence\nsjbeing the root node, denoted as rj, as fol-\nlows.\nuj=G(W\u0002fj+b)\nrj=eP\n8yuj[y]\nPk\ni=1eP\n8yui[y](4)\n1Note that the backward LSTM (i.e., the lower part\nof Eq. 1) takes a sequence of words in a reverse order.Corpus\nDs1\ns2\nskBLSTM\nBLSTM...\nBLSTMf1\nf2\nfk...\nDocument dStructural \nDocument -level\nRepresentationxFake News \nClassification Fake\nReal"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Classification Fake\nReal\nHierarchical \nDiscourse -level \nStructure \nLearnings1s2. . .sk...Figure 2: The proposed framework Hierarchical Discourse-level Structure for Fake news detection (HDSF)\nwhereuj[y] is they-th element of vector uj.\nSimilarly, we calculate the root probabilities\nfor all sentences and obtain the array of root\nprobabilities denoted as r=fr1;r2;\u0001\u0001\u0001;rkg\nwhere 0\u0014rj2r\u00141."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "where 0\u0014rj2r\u00141.\n3.1.2 Discourse Dependency Tree\nConstruction\nWe use the learned matrix of inter-sentential\nparent-child probabilities i.e., A(Eq. 3) as well\nas the array of root probabilities i.e., r(Eq. 4)\nand propose a greedy algorithm, illustrated in\nAlgorithm 1, to construct the discourse depen-\ndency tree of a document. A sentence with\nthe maximum value in ris considered the root"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "node and is inserted into the tree (line 5).\nThen, at each iteration, the algorithm \fnds\nthe maximum entry in a block of the matrix A\nwhose rows correspond to the rows of current\nnodes added to the tree (i.e., nodes Vin line 7)\nand its columns correspond to columns of the\nrest of nodes (i.e., nodes NnVin line 7). Note\nthat the columns of the current nodes are ex-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "cluded because their parents have already been\nidenti\fed and also each node should have ex-\nactly one parent (except the root which has no\nparent). Assume the search in line 7 results\nin the entry ( p;c) ofAwhere 1\u0014p;c\u0014k\nandp6=c. Then, the sentence scis added\nas the child node of the sentence sp(line 8).\nAlgorithm 1 continues until all sentences of a\ndocument are added to the tree T."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "document are added to the tree T.\nTo \fx the idea of discourse dependency tree\nconstruction algorithm, we present a step-by-\nstep execution of this algorithm demonstrated\nin Figure 3. In Step 0, the sentence s1is added\nas the root of the tree Tsince it has the max-\nimum value in the array of the root probabil-\nities. Next in Step 1, the algorithm searches"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "for the maximum probability value in the row\ns1while the column s1is excluded. The maxi-\nmum value is this block is 0 :4 and correspondsAlgorithm 1: The proposed algorithm for\ndiscourse dependency tree construction\nInput: A ;r\nOutput: Discourse dependency tree T\n1T=empty\n2N=fs1; s2;\u0001\u0001\u0001; skg// All nodes\n3V=fg// Set of current nodes\n4AddN[argmax (r)] toV\n5T:root =N[argmax (r)]// Adding the root"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "6whilejVj6=kdo\n7 p; c=argmax (A[V; NnV])// Search block\n8T:link (N[c]; N[p])// Child-parent link\n9 V:add (N[c])// Adding the child node\n10end\n11returnT\nto entry (s1,s2). Therefore, the sentence s2is\nadded as the child node of the sentence s1. In\na similar fashion, the algorithm continues until\nall 6 sentences are added to the tree.\n3.2 Structural Document-level\nRepresentation"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Representation\nWe use a similar method presented in (Liu and\nLapata, 2018) to extract a structurally rich\nrepresentation for the entire document. First,\nfor each sentence (i.e., a discourse unit), we\nobtain a structurally-aware representation. To\nachieve this, we take into account the parent-\nchild probabilities as well as the root probabil-\nities as follows.\npj=rj\u0002eroot+kX\nz=1A[z;j]\u0002fz\ncj=kX"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "pj=rj\u0002eroot+kX\nz=1A[z;j]\u0002fz\ncj=kX\nz=1A[j;z]\u0002fj\ngj=G(W[pjjjcjjjfj] +b)(5)\nwhere pjandcjare two context vectors tak-\ning into account possible parents and chil-\ndren of a sentence sj, respectively, erootde-\nnotes a special root embedding vector, jjde-\nnotes vector concatenation operator, and gjs1s2(c) s3s4 s5\ns1(p) 00.4 0.35 0.15 0.2\ns20.1 0 0.25 0.45 0.15\ns30.3 0.15 0 0.3 0.55\ns40.4 0.2 0.3 0 0.1"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "s40.4 0.2 0.3 0 0.1\ns50.2 0.25 0.1 0.1 0S1S2S3S4S5\n0.40.2 0.25 0.1 0.05\ns1\ns1s2s3s4 (c) s5\ns10 0.4 0.35 0.15 0.2\ns2 (p) 0.1 0 0.25 0.45 0.15\ns30.3 0.15 0 0.3 0.55\ns40.4 0.2 0.3 0 0.1\ns50.2 0.25 0.1 0.1 0\ns1 s2s3 (c) s4 s5\ns1(p) 0 0.4 0.35 0.15 0.2\ns20.1 0 0.25 0.45 0.15\ns30.3 0.15 0 0.3 0.55\ns40.4 0.2 0.3 0 0.1\ns50.2 0.25 0.1 0.1 0s1 s2 s3s4s5(c)\ns10 0.4 0.35 0.15 0.2\ns20.1 0 0.25 0.45 0.15"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "s20.1 0 0.25 0.45 0.15\ns3(p) 0.3 0.15 0 0.3 0.55\ns40.4 0.2 0.3 0 0.1\ns50.2 0.25 0.1 0.1 0s1\ns2s1\ns2\ns4\ns3s1\ns2\ns4s3s1\ns2\ns4s5A=r=\nStep 2 Step 1Step 0 (identifying the root)\nStep 3 Step 4Figure 3: An illustration of a step-by-step execu-\ntion of Algorithm 1 for the sample document pre-\nsented in Figure 1. The search block at each iter-\nation has been highlighted. Note the letter `p' for"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "theparent node and `c' for the child node .\nis astructurally-aware representation for sen-\ntencesj. Finally, to extract a structurally rich\nrepresentation for the entire document, we av-\nerage all of its gjvectors:\nx=1\nkkX\nj=1gj (6)\nwherexdenotes the structurally rich\ndocument-level representation .\n3.3 Fake News Classi\fcation\nWe hypothesize that the document-level struc-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "turally rich representations (Eq. 6) o\u000ber a dis-\ncriminatory power to detect fake news docu-\nments. Therefore, as shown in Figure 2, we\nemploy a binary classi\fcation for fake news de-\ntection formulated as follows.\nci=\u0000\u0000\nyilog(pi\nf) + (1\u0000yi)log(pi\nr)\u0001\nL(\u0012) =X\n8di2Dci(7)\nwhereyiis the ground-truth label of a doc-\numentdi2 D ,ciis the cross-entropy loss\nvalue,pi\nfandpi"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "value,pi\nfandpi\nrare probabilities of dibeingfake or real, respectively. pi\nfandpi\nrare ob-\ntained from the representation x(Eq. 6) fed\nto a fully connected layer followed by the sof-\ntamx function. In Eq. 7, \u0012denotes the frame-\nwork's parameters and Lis the total loss of\nthe model. Since the entire framework (Eq. 1\nto 7) is fully di\u000berentiable, we utilize the error"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "backpropagation (Hecht-Nielsen, 1992) to cal-\nculate the gradients followed by the stochas-\ntic gradient descent (Bottou, 2010) to update\nand optimize the parameters. Note that the\ndiscourse dependency tree construction algo-\nrithm presented in Section 3.1.2 is employed\npost hoc. Hence, the gradient calculation over\nargmax operator (line 7 of Algorithm 1) is not\nperformed."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "performed.\n4 Structure-related Properties\nIncorporating discourse-level structure o\u000ber a\ndiscriminatory power distinguishing fake and\nreal documents, which will be veri\fed in Sec-\ntion 5.3. We expect more than this discrimi-\nnatory power. We expect to identify insightful\nand interpretable information from extracted\nstructures which can delineate intrinsic di\u000ber-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "ences between fake and real news documents.\nTo meet this expectation, we de\fne three fun-\ndamental properties of constructed discourse\ndependency trees. Note that we leave the def-\ninitions of more advanced properties as one fu-\nture work. We seek to ful\fll two goals by de\fn-\ning the structure-related properties. First, we\nintend to highlight the way that fake and real"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "news documents are di\u000berent. Second, we in-\ntend to leverage these properties to shed light\non the coherence of fake and real news doc-\numents. Coherence has been the subject of\nmany studies (Barzilay and Lapata, 2008; Lin\net al., 2011; Guinaudeau and Strube, 2013; Li\nand Hovy, 2014) and is concerned with how\nconstituents of a document (e.g., discourse\nunits) are linked together in a way that the"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "entire text creates a clear mental picture to\nthe readers (Storrer, 2002). Notwithstanding\nits importance, coherence has not been inves-\ntigated in the fake news domain in a large-\nscale and systematic fashion. Aiming at \fll-\ning this gap, we naturally connect the de-\n\fned structure-related properties with the co-\nherence of news documents."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "herence of news documents.\nProperty 1 (Number of Leaf Nodes)This property, denoted as Pl, de\fnes the nor-\nmalized number of leaf nodes in a discourse\ndependency tree:\nPl=l\nlog(k)(8)\nwherelis the number of leaf nodes (i.e., sen-\ntences) in the discourse dependency tree of a\ndocument. Recall that kis the total number\nof sentences in a document.\nThe intuition behind de\fning Property 1 is"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "as follows. According to the description of the\ndependency tree in Section 3.1, leaf nodes are\nisolated discourse units and no other discourse\nunits depend on them. Thus, the more the\nnumber of leaf nodes is, the less inter-linked\nthe discourse units will be, and vice versa.\nTherefore, Property 1 is likely to indicate the\ncoherence of a document { the higher Pl, the"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "more isolated sentences and the less coherent\nthe document. Also, for a document with k\nsentences Pl2[1\nlog(k);k\u00001\nlog(k)].\nProperty 2 (Preorder Di\u000berence) This\nproperty, denoted as Pt, de\fnes the nor-\nmalized positional di\u000berence between the\npreorder traversal of a document's discourse\ndependency tree and its original sentential\nsequential order:\nPt=Pk\nj=1jsposition\nj\u0000jj\nlog(k)(9)\nwheresposition"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "j\u0000jj\nlog(k)(9)\nwheresposition\nj denotes the position of a sen-\ntencesjin the preorder traversal1of depen-\ndency tree of a document e.g., sposition\n3 = 4 in\nFigure 1. The position of sjin the original\nsequential order is simply j2. The preorder\ntraversal of the tree in Figure 1 is the sequence\nfs1;s2;s4;s3;s5gand the sentential sequential\norder isfs1;s2;s3;s4;s5g. Therefore, accord-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "ing to the de\fnition of Property 2:\nPt=j1\u00001j+j2\u00002j+j4\u00003j+j3\u00004j+j5\u00005j\nlog(5)\u00192:86.\nThe preorder traversal of a document's dis-\ncourse dependency tree takes into considera-\ntion the organization of a document respect\n1The subtrees are ordered based on when they are\nadded as the child nodes of a parent node in Algo-\nrithm 1. That is why we can compute preorder traver-\nsal."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "sal.\n2We assume that the sentences in the sequential\norder are numbered incrementally from 1 to k.to the dependencies between sentences. Then,\nthe purpose of Property 2 is to measure how\nmuch the organization of a document, cap-\ntured through the preorder traversal, devi-\nates from its sentential sequential order. Sen-\ntence order is highly related to the coherence"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "of a document where the displaced order of\nsentences in a document makes it less coher-\nent (Li and Hovy, 2014). Thus, intuitively,\nthe less the value of Property 2 for a doc-\nument is, the more coherent that document\nshould be. Also, for a document with ksen-\ntences Pt2[k\u00001\nlog(k);(k2\u00001)\n2log(k)] ifkis odd and\nPt2[k\u00001\nlog(k);k2\n2log(k)] ifkis even.\nProperty 3 (Parent-Child Distance)"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Property 3 (Parent-Child Distance)\nThis property, denoted as Pc, de\fnes the nor-\nmalized sum of positional distances between\nchild nodes and their parents when they are\nconsidered in the original sequential order:\nPc=P\n8c;p2Tjcposition\u0000ppositionj\nlog(k)(10)\nwherecposition andpposition denote the posi-\ntions of a child node cand a parent node p,\nrespectively, in the original sentential sequen-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tial order. For instance, in our running exam-\nple, the parent node s3haspposition = 3 (i.e.,\nit is the third sentence) and its child node s5\nhascposition = 5. Therefore, their parent-child\ndistance isj5\u00003j= 2. Following a similar cal-\nculation for other parent-child pairs, we have\nPc=1+2+2+2\nlog(5)\u001910 .\nSimilar to Property 2, Property 3 pertains\nto the organization of a document and takes"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "into consideration the deviation from senten-\ntial sequential order. Intuitively speaking,\nusually, we expect that a child node and its\nparent to be close to each other in the orig-\ninal sequential order. Consequently, the less\nvalue of this property is, the more coherent a\ndocument is likely to be. The range of Prop-\nerty 3 in a document containing ksentences is\nPc2[k\u00001\nlog(k);k(k\u00001)\n2log(k)]."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Pc2[k\u00001\nlog(k);k(k\u00001)\n2log(k)].\n5 Experiments\nTo verify the performance of the proposed\nframework HDSF, we conduct a set of exper-\niments. We seek to answer the following re-\nsearch questions:(1). How does the proposed framework per-\nform on fake news detection?\n(2). How do the de\fned structure-related\nproperties describe the fake and real news doc-\numents?"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "uments?\nIn this section, we \frst describe the datasets\nfollowed by presenting the experimental set-\ntings. Afterward, we evaluate the performance\nof HDSF compared to several representative\nbaselines. Finally, we present a structural\nanalysis of the fake/real news documents.\n5.1 Datasets\nWe utilize \fve available fake news datasets in\nthis study. The \frst two datasets are col-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "lected by (Shu et al., 2017) and include on-\nline articles whose veracities have been iden-\nti\fed by experts in BuzzFeed1and Politi-\nFact2. For the next two datasets, we utilize\ntwo available online fake news datasets pro-\nvided by kaggle.com3 4. Finally, we include\nthe dataset constructed and shared by McIn-\ntire5. Since the proposed framework HDSF\nis a general-purpose framework investigating"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "discourse-level structures of fake/real news\ndocuments based on their textual contents, we\ndo not restrict HDSF to a particular source of\ndata and therefore combine all datasets. Simi-\nlar to the previous work (Shu et al., 2017), we\nbalance the dataset to avoid a trivial solution\nas well as ensuring a fair performance compar-\nison. In total, we have 3360 fake and 3360 real\ndocuments."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "documents.\n5.2 Experimental Settings\nFirst, we pre-process the documents by remov-\ning numbers, non-English characters, stop-\nwords (e.g., `with'), and converting all char-\nacters to lower case. We randomly select\n134 documents as the development set, (67\nfrom each class) and 134 documents (67 from\neach class) as the test set. The remain-\ning 6452 documents are used for training."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "The development set is used for tuning the\nhyper-parameters. We initialize the word em-\n1https://www.buzzfeed.com\n2http://www.politifact.com/\n3https://www.kaggle.com/mrisdal/fake-news/\ndata\n4https://www.kaggle.com/jruvika/\nfake-news-detection\n5https://github.com/GeorgeMcIntire/fake_\nreal_news_datasetbeddings from the Google news pre-trained\nword2vec embeddings (Mikolov et al., 2013)6."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "LeakyReLU (Xu et al., 2015) is used as the\nnon-linear activation function and the number\nof hidden units in the BLSTM network is set to\n100. Each simulation is run for 200 steps with\na random mini-batch size of 40 documents.\nThe learning rate starts at 0 :01 with the decay\nrate of 0:9 after every 50 steps. We use the\nADAM optimizer (Kingma and Ba, 2014) to"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "ADAM optimizer (Kingma and Ba, 2014) to\noptimize the parameters. The PyTorch pack-\nage7is utilized for the implementation and\nthe code and data are publicly available in\nhttps://github.com/hamidkarimi/HDSF .\n5.3 Comparison Results\nTo answer the research question (1), we com-\npare the performance of HDSF with the fol-\nlowing representative baselines.\nN-grams . In this baseline method, we ex-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tract and combine unigrams, bigrams, and tri-\ngrams features and use SVM (Support Vec-\ntor Machines) (Scholkopf and Smola, 2001) for\nclassi\fcation.\nLIWC (Pennebaker et al., 2015). LIWC\n(Linguistic Inquiry and Word Count) o\u000bers a\nset of rich psycholinguistic features for a writ-\nten document. We extract 94 features for each\ndocument and use SVM for classi\fcation."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "document and use SVM for classi\fcation.\nRST (Rubin and Lukoianova, 2015). We\nextract a set of RST relations (Mann and\nThompson, 1988) using the implementation of\nthe method proposed by (Ji and Eisenstein,\n2014). Then, we vectorize the relations and\nemploy SVM for classi\fcation. This baseline\ntakes into account the hierarchical structure of\ndocuments via RST.\nBiGRNN-CNN (Ren and Zhang, 2016)."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "BiGRNN-CNN (Ren and Zhang, 2016).\nA CNN (Convolutional Neural Network) is ap-\nplied at the sentence-level on word embeddings\nand a BiGRNN (Bi-Directional Gated Recur-\nrent Neural Network) extracts features from a\nsequence of extracted sentential features. This\nbaseline takes into consideration a two-level se-\nquential structure for a document.\nLSTM[w+s] . In this baseline, we apply an"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "LSTM network on a sequence of word embed-\ndings belonging to a sentence and then apply\nanother LSTM on a sequence of extracted sen-\n6Out-of-vocabulary words are initialized randomly.\n7https://pytorch.org/tential features. LSTM[w+s] also considers a\ntwo-level sequential structure for a document.\nLSTM[s] . This method is similar to\nLSTM[w+s] except that the mean of word em-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "beddings in a sentence is used instead of ap-\nplying an LSTM network. LSTM[s] considers\na single sequential structure for a document.\nWe use accuracy as the metric of perfor-\nmance evaluation given that the dataset is\nfully balanced. Table 1 shows the compari-\nson results on the test set and we make the\nfollowing observations:\n\u000fN-grams achieve a better performance"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "\u000fN-grams achieve a better performance\nthan LIWC. In line with the previous\nstudy (Ott et al., 2011), this shows that\nfor fake news detection, taking into ac-\ncount the context of a document as n-\ngrams do is more e\u000bective than employ-\ning the existing pre-de\fned dictionaries as\nLIWC does.\n\u000fMost of the time, methods wherein a doc-\nument's structure is somehow taken into"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "ument's structure is somehow taken into\naccount outperform n-grams and LIWC.\nThis observation shows that for fake news\ndetection, the content's structure plays an\nimportant role.\n\u000fThe poor performance of RST is because\nof the following reasons: a) using RST\nwithout an annotated corpus is not very\ne\u000bective, and b) RST relations are ex-\ntracted using auxiliary tools optimized"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tracted using auxiliary tools optimized\nfor other corpora which cannot be ap-\nplied e\u000bectively to the fake news corpus in\nhand. Note that annotating RST for our\ncorpus is extremely unscalable and time-\nconsuming.\n\u000fThe proposed framework HDSF signif-\nicantly outperforms all other methods.\nThis observation shows that hierarchical\ndiscourse-level representations are e\u000bec-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tively rich for fake news prediction.\n5.4 The Inspection of HDSF\nTo further verify the working of the HDSF\nframework, we inspect HDSF in more detail.\nFigure 4a demonstrates the training error dur-\ning model optimization. As we can observe\nfrom this \fgure, the error is decreasing as theTable 1: Comparison results\nMethod Accuracy (%)\nN-grams 72.37\nLIWC 70.26\nRST 67.68\nBiGRNN-CNN 77.06"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "LIWC 70.26\nRST 67.68\nBiGRNN-CNN 77.06\nLSTM[w+s] 80.54\nLSTM[s] 73.63\nHDSF 82.19\n(a) The training error\n (b) The accuracy on dev set\nFigure 4: The Inspection of HDSF\ntraining process proceeds. Furthermore, Fig-\nure 4b demonstrates the accuracy on the devel-\nopment set during the training and it is mono-\ntonically increasing as the training goes on.\nHence, based on these \fgures, we can ensure"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "the framework is getting optimized and learns\nto classify fake news documents correctly.\n5.5 Structural Analysis for Fake/Real\nDocuments\nIn this section, we compute the average val-\nues of structure-related properties, presented\nin Section 4, for the fake/real news documents\nbelonging to the test set. Figure 5 shows the\nresults. We make the two key observations\nbased on this \fgure:"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "based on this \fgure:\n\u000fThere is a signi\fcant di\u000berence in all three\nproperties for fake news documents vs.\nreal news documents. This observation\nshows the fact that structures of fake news\ndocuments at the discourse-level are sub-\nstantially di\u000berent from those of real ones .\n\u000fNoticeably, in all three properties, the real\nnews documents show less value than the\nfake news documents. As described in"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "fake news documents. As described in\nSection 4, all three properties are closely\nconnected to the coherence of a docu-\nment. Therefore, real news documents\nindicate more degree of coherence .Figure 5: Average values of the proposed structure-\nrelated properties for fake and real news documents\n6 Related Work\nContent-based fake news detection has been\nthe subject of many linguistic research en-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "deavors. (DePaulo et al., 2003) investigated\nfake stories introduced insightful cues in fake\nstories and highlighted `unusual' language in\nsuch stories. N-grams and Part-of-Speech\n(POS) tags are fundamental features of a text\nwhich have been utilized for fake news detec-\ntion (Ahmed et al., 2017; Ott et al., 2013).\nAlso, LIWC (Pennebaker et al., 2015) has been"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "employed to investigate the role of individ-\nual words in a document for deception detec-\ntion (Ott et al., 2011). Since POS tags, n-\ngrams, and LIWC features are considered as\n`shallow' and hand-crafted features, deep neu-\nral networks have been utilized for fake news\ndetection where features are extracted auto-\nmatically (Wang, 2017; Ren and Zhang, 2016;"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Volkova et al., 2017; Karimi et al., 2018). In\nthis study, we also utilized an automated fea-\nture extraction instead of relying on hand-\ncraft features.\nSyntax-based approaches have been em-\nployed to take into account the hierarchical\nstructure of textual documents for fake news\ndetection (Feng et al., 2012; P\u0013 erez-Rosas and\nMihalcea, 2015). One caveat of syntax-based"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "approaches is their reliance on auxiliary pars-\ning tools which might propagate error in later\npart of a developed model. Moreover, generat-\ning syntactic production rules in an automated\nmanner is a complicated process.\nAnother way of incorporating structure is\ndiscourse-level parsing (Mann and Thompson,\n1988; Li et al., 2014a; Ren and Zhang, 2016)\nwhich has seldom been explored for fake news"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "detection. The noticeable exception is the ap-\nproach developed by (Rubin and Lukoianova,2015). They extracted a set of RST rela-\ntions in fake and real documents and vector-\nized them using a Vector Space Model (VSM)\nmethod (Strehl and Ghosh, 2000). Unlike\n(Rubin and Lukoianova, 2015), in this work,\nwe proposed an automated and data-driven\ndiscourse-level parsing approach which used"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "neither any annotated corpus nor any exter-\nnal tool.\n7 Conclusion and Future Work\nIn this work, we looked into fake news de-\ntection from a new perspective. We hypoth-\nesized that hierarchical discourse-level struc-\nture of news documents o\u000bers a discrimina-\ntory power for fake news detection. To in-\nvestigate this hypothesis, we proposed a new\nframework HDSF, which can automatically"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "framework HDSF, which can automatically\nextract discourse-level structures of real/fake\nnews documents represented by dependency\ntrees while does not rely on an annotated cor-\npus. Moreover, we de\fned a set of insight-\nful properties describing tree structures. Con-\nducted experiments con\frmed the power of\nour approach where it outperformed represen-\ntative baselines. More importantly, we high-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "lighted noticeable di\u000berences between struc-\ntures of fake and real news documents. These\ndi\u000berences also indicated less coherency in the\nfake news documents.\nThe new perspective pursued in this paper\ncan be continued in several directions. First,\nwe intend to de\fne more advanced properties\nfrom the discourse dependency trees. Second,\ninvestigating the hierarchical structure at the"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "word-level will be an exciting research inquiry.\nFinally, unsupervised discourse-level structure\nextraction of fake/real news documents is a\nworthwhile research topic.\nAcknowledgment\nThis work is supported by the National Sci-\nence Foundation (NSF) under grant numbers\nIIS-1714741, IIS-1715940, IIS-1845081, CNS-\n1815636, and a grant from Criteo Faculty Re-\nsearch Award. We would like to thank Mr."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Tyler Derr and other members of the Data Sci-\nence and Engineering (DSE) lab at Michigan\nState University1for their constructive com-\nments.\n1http://dse.cse.msu.edu/References\nHadeer Ahmed, Issa Traore, and Sherif Saad. 2017.\nDetection of online fake news using n-gram anal-\nysis and machine learning techniques. In Inter-\nnational Conference on Intelligent, Secure, and"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Dependable Systems in Distributed and Cloud\nEnvironments , pages 127{138. Springer.\nHunt Allcott and Matthew Gentzkow. 2017. Social\nmedia and fake news in the 2016 election. Jour-\nnal of Economic Perspectives , 31(2):211{36.\nJoan Bachenko, Eileen Fitzpatrick, and Michael\nSchonwetter. 2008. Veri\fcation and implemen-\ntation of language-based deception indicators in"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "civil and criminal narratives. In Proceedings of\nthe 22nd International Conference on Computa-\ntional Linguistics-Volume 1 , pages 41{48. Asso-\nciation for Computational Linguistics.\nRegina Barzilay and Mirella Lapata. 2008. Model-\ning local coherence: An entity-based approach.\nComputational Linguistics , 34(1):1{34.\nParminder Bhatia, Yangfeng Ji, and Jacob Eisen-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "stein. 2015. Better document-level sentiment\nanalysis from rst discourse parsing. In Proceed-\nings of the 2015 Conference on Empirical Meth-\nods in Natural Language Processing , pages 2212{\n2218.\nL\u0013 eon Bottou. 2010. Large-scale machine learning\nwith stochastic gradient descent. In Proceedings\nof COMPSTAT'2010 , pages 177{186. Springer.\nBella M DePaulo, James J Lindsay, Brian E Mal-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "one, Laura Muhlenbruck, Kelly Charlton, and\nHarris Cooper. 2003. Cues to deception. Psy-\nchological bulletin , 129(1):74.\nSong Feng, Ritwik Banerjee, and Yejin Choi. 2012.\nSyntactic stylometry for deception detection.\nInProceedings of the 50th Annual Meeting of\nthe Association for Computational Linguistics:\nShort Papers-Volume 2 , pages 171{175. Associ-\nation for Computational Linguistics."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "ation for Computational Linguistics.\nCamille Guinaudeau and Michael Strube. 2013.\nGraph-based local coherence modeling. In Pro-\nceedings of the 51st Annual Meeting of the Asso-\nciation for Computational Linguistics (Volume\n1: Long Papers) , volume 1, pages 93{103.\nRobert Hecht-Nielsen. 1992. Theory of the back-\npropagation neural network. In Neural networks\nfor perception , pages 65{93. Elsevier."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "for perception , pages 65{93. Elsevier.\nSepp Hochreiter and J\u007f urgen Schmidhuber. 1997.\nLong short-term memory. Neural computation ,\n9(8):1735{1780.\nYangfeng Ji and Jacob Eisenstein. 2014. Repre-\nsentation learning for text-level discourse pars-\ning. In Proceedings of the 52nd Annual Meetingof the Association for Computational Linguis-\ntics (Volume 1: Long Papers) , volume 1, pages\n13{24."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "13{24.\nHamid Karimi, Proteek Roy, Sari Saba-Sadiya,\nand Jiliang Tang. 2018. Multi-source multi-\nclass fake news detection. In Proceedings of\nthe 27th International Conference on Computa-\ntional Linguistics , pages 1546{1557.\nYoon Kim, Carl Denton, Luong Hoang, and\nAlexander M Rush. 2017. Structured attention\nnetworks. arXiv preprint arXiv:1702.00887 .\nDiederik P Kingma and Jimmy Ba. 2014. Adam:"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "A method for stochastic optimization. arXiv\npreprint arXiv:1412.6980 .\nJiwei Li and Eduard Hovy. 2014. A model of co-\nherence based on distributed sentence represen-\ntation. In Proceedings of the 2014 Conference\non Empirical Methods in Natural Language Pro-\ncessing (EMNLP) , pages 2039{2048.\nJiwei Li, Rumeng Li, and Eduard Hovy. 2014a.\nRecursive deep models for discourse parsing."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "InProceedings of the 2014 Conference on Em-\npirical Methods in Natural Language Processing\n(EMNLP) , pages 2061{2069.\nSujian Li, Liang Wang, Ziqiang Cao, and Wen-\njie Li. 2014b. Text-level discourse dependency\nparsing. In Proceedings of the 52nd Annual\nMeeting of the Association for Computational\nLinguistics (Volume 1: Long Papers) , volume 1,\npages 25{35."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "pages 25{35.\nZiheng Lin, Hwee Tou Ng, and Min-Yen Kan.\n2011. Automatically evaluating text coherence\nusing discourse relations. In Proceedings of\nthe 49th Annual Meeting of the Association for\nComputational Linguistics: Human Language\nTechnologies-Volume 1 , pages 997{1006. Asso-\nciation for Computational Linguistics.\nYang Liu and Mirella Lapata. 2018. Learning"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "structured text representations. Transactions\nof the Association of Computational Linguistics ,\n6:63{75.\nWilliam C Mann and Sandra A Thompson. 1988.\nRhetorical structure theory: Toward a func-\ntional theory of text organization. Text-\nInterdisciplinary Journal for the Study of Dis-\ncourse , 8(3):243{281.\nTomas Mikolov, Kai Chen, Greg Corrado, and Jef-\nfrey Dean. 2013. E\u000ecient estimation of word"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "representations in vector space. arXiv preprint\narXiv:1301.3781 .\nMathieu Morey, Philippe Muller, and Nicholas\nAsher. 2018. A dependency perspective on rst\ndiscourse parsing and evaluation. Computa-\ntional Linguistics , (Just Accepted):1{54.Myle Ott, Claire Cardie, and Je\u000brey T Hancock.\n2013. Negative deceptive opinion spam. In\nProceedings of the 2013 conference of the north"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "american chapter of the association for compu-\ntational linguistics: human language technolo-\ngies, pages 497{501.\nMyle Ott, Yejin Choi, Claire Cardie, and Je\u000brey T\nHancock. 2011. Finding deceptive opinion spam\nby any stretch of the imagination. In Proceed-\nings of the 49th Annual Meeting of the Asso-\nciation for Computational Linguistics: Human\nLanguage Technologies-Volume 1 , pages 309{"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "319. Association for Computational Linguistics.\nJames W Pennebaker, Ryan L Boyd, Kayla Jor-\ndan, and Kate Blackburn. 2015. The develop-\nment and psychometric properties of liwc2015.\nTechnical report.\nVer\u0013 onica P\u0013 erez-Rosas and Rada Mihalcea. 2015.\nExperiments in open domain deception detec-\ntion. In Proceedings of the 2015 Conference\non Empirical Methods in Natural Language Pro-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "cessing , pages 1120{1125.\nRashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh,\nAlan Lee, Aravind Joshi, Livio Robaldo, and\nBonnie L Webber. 2007. The penn discourse\ntreebank 2.0 annotation manual.\nYafeng Ren and Yue Zhang. 2016. Deceptive opin-\nion spam detection using neural network. In\nProceedings of COLING 2016, the 26th Inter-\nnational Conference on Computational Linguis-"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "tics: Technical Papers , pages 140{150.\nVictoria L Rubin and Tatiana Lukoianova. 2015.\nTruth and deception at the rhetorical structure\nlevel. Journal of the Association for Informa-\ntion Science and Technology , 66(5):905{917.Bernhard Scholkopf and Alexander J Smola. 2001.\nLearning with kernels: support vector machines,\nregularization, optimization, and beyond . MIT\npress."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "press.\nMike Schuster and Kuldip K Paliwal. 1997. Bidi-\nrectional recurrent neural networks. IEEE\nTransactions on Signal Processing , 45(11):2673{\n2681.\nKai Shu, Suhang Wang, and Huan Liu. 2017. Ex-\nploiting tri-relationship for fake news detection.\narXiv preprint arXiv:1712.07709 .\nAngelika Storrer. 2002. Coherence in text and hy-\npertext. Document Design , 3(2):156{168."}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Alexander Strehl and Joydeep Ghosh. 2000. Im-\npact of similarity measures on web-page cluster-\ning.\nSvitlana Volkova, Kyle Sha\u000ber, Jin Yea Jang, and\nNathan Hodas. 2017. Separating facts from \fc-\ntion: Linguistic models to classify suspicious and\ntrusted news posts on twitter. In Proceedings\nof the 55th Annual Meeting of the Association\nfor Computational Linguistics (Volume 2: Short"}, {"source": "Learning Hierarchical Discourse-level Structure for Fake News Detection.pdf", "text": "Papers) , volume 2, pages 647{653.\nWilliam Yang Wang. 2017. \" liar, liar pants on\n\fre\": A new benchmark dataset for fake news\ndetection. arXiv preprint arXiv:1705.00648 .\nBing Xu, Naiyan Wang, Tianqi Chen, and Mu Li.\n2015. Empirical evaluation of recti\fed activa-\ntions in convolutional network. arXiv preprint\narXiv:1505.00853 ."}, {"source": "2023.semeval-1.275.pdf", "text": "Proceedings of the The 17th International Workshop on Semantic Evaluation (SemEval-2023) , pages 1995\u20132008\nJuly 13-14, 2023 \u00a92023 Association for Computational Linguistics\nSheffieldVeraAI at SemEval-2023 Task 3: Mono and multilingual\napproaches for news genre, topic and persuasion technique classification\nBen Wu#, Olesya Razuvayevskaya#, Freddy Heppell#, Jo\u00e3o A. Leite#,"}, {"source": "2023.semeval-1.275.pdf", "text": "Carolina Scarton, Kalina Bontcheva , and Xingyi Song\nDepartment of Computer Science, The University of Sheffield, Sheffield, UK\n{bpwu1, o.razuvayevskaya, frheppell1, jaleite1}@sheffield.ac.uk\nAbstract\nThis paper describes our approach for SemEval-\n2023 Task 3: Detecting the category, the fram-\ning, and the persuasion techniques in online\nnews in a multilingual setup. For Subtask 1"}, {"source": "2023.semeval-1.275.pdf", "text": "(News Genre), we propose an ensemble of fully\ntrained and adapter mBERT models which was\nranked joint-first for German, and had the high-\nest mean rank of multi-language teams. For\nSubtask 2 (Framing), we achieved first place in\n3 languages, and the best average rank across\nall the languages, by using two separate ensem-\nbles: a monolingual RoBERTa-MUPPET LARGE"}, {"source": "2023.semeval-1.275.pdf", "text": "and an ensemble of XLM-RoBERTa LARGE with\nadapters and task adaptive pretraining. For Sub-\ntask 3 (Persuasion Techniques), we trained a\nmonolingual RoBERTa-Base model for English\nand a multilingual mBERT model for the re-\nmaining languages, which achieved top 10 for\nall languages, including 2nd for English. For\neach subtask, we compared monolingual and"}, {"source": "2023.semeval-1.275.pdf", "text": "multilingual approaches, and considered class\nimbalance techniques.1\n1 Introduction\nWith the rise of opinion-manipulating news and\nmisinformation surrounding COVID-19, elections\nand wars, the task of propaganda and hyperpartisan\ndetection has received much attention over the last\nfive years. Since 2019, various SemEval tasks have\naddressed detecting hyperpartisan (Kiesel et al.,"}, {"source": "2023.semeval-1.275.pdf", "text": "2019), sarcasm (Abu Farha et al., 2022), and per-\nsuasion techniques in textual and multimodal data\n(Da San Martino et al., 2020; Dimitrov et al., 2021).\nThis task (Piskorski et al., 2023) can be seen as an\nextension of the latter two tasks, suggesting an\nexpanded ontology of persuasion techniques and\naddressing other related aspects of persuasion, such"}, {"source": "2023.semeval-1.275.pdf", "text": "as satire, opinionated news, and framing detection.\n#Equal contribution, listed randomly.\n1Our code is available at https://github.com/\nGateNLP/semeval2023-multilingual-news-detectionThe three subtasks presented in this shared task\nare the detection of: 1) genre: opinion, objective\nreporting or satire; 2) framing techniques: 14 mul-\ntilabel frames; 3) persuasion techniques: 23 mul-"}, {"source": "2023.semeval-1.275.pdf", "text": "tilabel techniques, which can be grouped into 6\nhigh-level classes.\nThe data consists of labelled training and de-\nvelopment sets in English, French, German, Ital-\nian, Polish and Russian, and unlabelled test sets in\nthe same languages plus three zero-shot languages:\nSpanish, Greek and Georgian.\nThe main contributions of this paper are twofold:\n1) evaluation of the viability of monolingual versus"}, {"source": "2023.semeval-1.275.pdf", "text": "multilingual models for each of the subtasks; and\n2) presentation of the models which ranked first in\nfour subtask-language pairs, top three in 16 subtask-\nlanguage pairs, and were within the top 10 for all.\nOur approaches for the three subtasks differ,\ntherefore we present each subtask separately in\nsections 3-5 respectively. An overview of the tech-"}, {"source": "2023.semeval-1.275.pdf", "text": "niques used in each subtask is shown in Table 1.\n2 Background\nFine-grained propaganda technique classification\nwas first introduced by Da San Martino et al.\n(2019), who suggested a multi-granularity network,\nwhere the lower and higher granularity tasks refer\nto the fragment and sentence-level classification re-\nspectively. Other state-of-the-art approaches to this"}, {"source": "2023.semeval-1.275.pdf", "text": "task used an ensemble of RoBERTa models with\nclass weighting, where some models perform a\nsemi-supervised task of span detection (Jurkiewicz\net al., 2020) and an ensemble of 5 different trans-\nformer models (Tian et al., 2021), namely BERT\n(Devlin et al., 2019), RoBERTa (Liu et al., 2019b),\nXLNet (Yang et al., 2019), DeBERTa (He et al.,\n2020) and ALBERT (Lan et al., 2019)."}, {"source": "2023.semeval-1.275.pdf", "text": "2020) and ALBERT (Lan et al., 2019).\nFraming detection specifically has been ad-\ndressed primarily for political news, with the mod-\nels exploring unsupervised probabilistic topic mod-\nels combined with autoregressive distributed-lag1995Tasks Text Clean External Data Oversampling Class Weights Adapters TAPT Unseen languages Ensemble\nSubtask1 /\u22c6/ /\u22c6- /\u2020- Zero-shot /\nSubtask2 / - - / / / \u21d2EN /"}, {"source": "2023.semeval-1.275.pdf", "text": "Subtask2 / - - / / / \u21d2EN /\nSubtask3 - - - / - - \u21d2EN -\nTable 1: An overview of approaches used. TAPT: Task-adaptive Pre-training,\u22c6not used in adapter model for\nsubmission.\u2020as part of ensemble.\nmodels (Tsur et al., 2015), finetuning BERT (Liu\net al., 2019a) and multilingual BERT (mBERT)\n(Aky\u00fcrek et al., 2020). The latter system is the\nclosest to our task since it explores the multilabel"}, {"source": "2023.semeval-1.275.pdf", "text": "multilingual setting and the effect of translating\ntexts for use in monolingual models. However, it\nuses article headlines instead of the full texts as\nthe classification data. The authors found that En-\nglish BERT BASE uncased trained on translated data\nand tested on the data in the target language often\noutperforms the multilingual model. We perform"}, {"source": "2023.semeval-1.275.pdf", "text": "similar comparison experiments for all three sub-\ntasks of this shared task.\nWang and Banko (2021) performed a series of\nexperiments comparing monolingual and multi-\nlingual approaches for hate speech detection and\nsentiment analysis and found that different task-\nlanguage combinations favour either monolingual\nand multilingual settings. The authors also con-"}, {"source": "2023.semeval-1.275.pdf", "text": "cluded that data augmentation in the form of trans-\nlation and task-adaptive pretraining (TAPT) (Gu-\nrurangan et al., 2020) helps to further improve the\nresults.\nAnother important task addressed in fake news\ndetection is satire detection, with the methods rang-\ning from convolutional neural networks (CNNs)\n(Guibon et al., 2019) to adversarial training\n(McHardy et al., 2019) and BERT-based archi-"}, {"source": "2023.semeval-1.275.pdf", "text": "tectures with long-short-term memory (LSTM)\n(Pandey and Singh, 2022; Liu and Xie, 2021) and\nCNN (Kaliyar et al., 2021) layers on top.\nBottleneck Adapters Adapters (Houlsby et al.,\n2019; Bapna and Firat, 2019) represent a fam-\nily of techniques aimed at improving parameter\nefficiency in finetuning by freezing a pretrained\nmodel and inserting low-dimension adapter mod-"}, {"source": "2023.semeval-1.275.pdf", "text": "ules within each layer. Houlsby et al. found that,\ndespite training only 3.6% of the parameters com-\npared to a full model, performance only decreased\nby 0.4%, while Bapna and Firat found that adapters\nproduced comparable, or in some cases better, re-\nsults. Particularly relevant for our task is He et al.\n(2021)\u2019s finding that adapter-based tuning of LLMs"}, {"source": "2023.semeval-1.275.pdf", "text": "is particularly effective for low-resource and cross-\nlingual tasks. For our system, we used two differentconfigurations of the bottleneck adapter modules:\n1) the original Houlsby et al. bottleneck config-\nuration, which places adapter modules after the\nmulti-head attention block and feed-forward block\nof each transformer layer; 2) the Pfeiffer et al. con-"}, {"source": "2023.semeval-1.275.pdf", "text": "figuration, which places adapter modules only after\nthe feed-forward block of each layer.\nChalkidis et al. (2021) also found that for XLM-\nR on the MultiEURLEX dataset, training bottle-\nneck adapters outperforms traditional full finetun-\ning and improves zero-shot cross lingual capability.\nSimilarly to this task, the MultiEURLEX dataset\nwas used for multilingual multilabel classification,"}, {"source": "2023.semeval-1.275.pdf", "text": "though it is significantly larger than the data in\nthis task (covering 23 languages and classifying\nhierarchically from 21 to 567 labels).\n3 System Description for Subtask 1\n3.1 System Overview\nThe system consisted of an ensemble of four mod-\nels, comprising 1) three mBERT models each fine-\ntuned using the organiser training set and 2/3 of\nthe development set; 2) one frozen mBERT model"}, {"source": "2023.semeval-1.275.pdf", "text": "with a finetuned Houlsby adapter2. The ensemble\npredictions were decided by majority vote, with\nrare tie cases handled by selecting the model with\nthe best validation performance.\nFull Finetuning mBERT BASE (Devlin et al.,\n2019) was finetuned on a shuffled combination of\nall languages. Different to previous approaches\n(Wu and Dredze, 2020; Adebara et al., 2020), we"}, {"source": "2023.semeval-1.275.pdf", "text": "chose the epoch with the best validation perfor-\nmance per-language, instead of overall, since the\nbest overall epoch is not necessarily the best for\na given language3. By using three identically-\nconfigured models in the ensemble, the data sacri-\nficed for model selection can be rotated between\nthem, so overall no data is truly unseen.\nAdapter Model A Houlsby bottleneck adapter"}, {"source": "2023.semeval-1.275.pdf", "text": "was applied to a pretrained mBERT BASE model,\nwith a reduction factor of 8 (i.e. d= 96 ), using\nthe AdapterHub (Pfeiffer et al., 2020a) framework.\n2Using a data split described in section 3.2\n3See Appendix C.11996The mBERT model parameters were frozen, so\nonly the adapter and classification head parameters\nwere trained.\nData Preprocessing Since task data is obtained"}, {"source": "2023.semeval-1.275.pdf", "text": "from webpages, it often contains unwanted con-\ntent, such as hyperlinks, account handles, dates and\nauthor biographies. We applied the preprocessing\ndescribed in Appendix B to remove this content.\nLong Article Truncation The organiser anno-\ntation instructions indicate that even human anno-\ntators find it difficult to distinguish opinion from\nreporting andsatire . This is due to subtle differ-"}, {"source": "2023.semeval-1.275.pdf", "text": "ences in how opinionated direct speech could be\nbalanced or reported on. The instructions also men-\ntion that single opinionated sentences, which would\ntrigger the opinion genre, often appear at the end of\nan article. Given the limit on input length for BERT\nmodels, for the articles that were longer than 512\ntokens, we sequentially selected sentences from"}, {"source": "2023.semeval-1.275.pdf", "text": "the beginning and the end of the article, preserving\nthe original sentence order, until the length of 512\ntokens was reached.\nExternal Satire Due to the lack of satire data, our\ntraining set was supplemented with 203 English-\nlanguage satire articles from Golbeck et al. (2018).\nData Oversampling The training data is severely\nimbalanced, with less than 6% of articles annotated"}, {"source": "2023.semeval-1.275.pdf", "text": "assatire and 18% of articles annotated as report-\ning. Although the external satire data improved\nthe balance for English, the performance of the\nsatire class in other languages still remained inade-\nquate. To address this, we performed oversampling\nfor both satire andopinion classes by repeating\nrandom oversampling without replacement on the\noriginal data for a given language and class until"}, {"source": "2023.semeval-1.275.pdf", "text": "the classes were balanced. For English satire class,\nwe applied the same approach but oversampled the\nexternal satire data mentioned earlier rather than\nthe original training set. We also compared the\neffectiveness of the oversampling approach with\nthe class weighting approach in our experiment,\nand the results showed a slight advantage for the\noversampling approach on average."}, {"source": "2023.semeval-1.275.pdf", "text": "oversampling approach on average.\n3.2 Experimental Setup\nFor the final submission, mBERT transformer mod-\nels were finetuned on the organiser training set and\na part of the development set for 30 epochs with the\nlearning rate of 1e-5, AdamW optimiser ( \u03b5=1e-8)Language F1 macro Place Language F1 macro Place\nEnglish 61.282 3 Italian 72.040 3\nFrench 68.157 5 Polish 76.455 3"}, {"source": "2023.semeval-1.275.pdf", "text": "French 68.157 5 Polish 76.455 3\nGerman 81.951\u22c61 Russian 72.871 2\nSpanish 44.293 4 Greek 68.681 6\nGeorgian 96.268 2\nTable 2: Subtask 1 final leaderboard results.\u22c6joint.\nand ReLU activation function. The organiser devel-\nopment set was split into three parts, stratified by\nlabel and language. We then finetuned three mod-\nels, using1\n3of the development set as a test and\nmerging2"}, {"source": "2023.semeval-1.275.pdf", "text": "merging2\n3of the development set with the training\ndata and shuffling the dataset. The held-out part\nof the development set was used to identify the\nlanguage-specific best checkpoints for each model.\nWe utilised the checkpoint with the best overall\nF1macro on the held-out set to make predictions on\nthe surprise languages. As described in section 3.1,"}, {"source": "2023.semeval-1.275.pdf", "text": "all articles were preprocessed and the training data\nwas oversampled for satire andreporting classes\nof each language.\nAdapter models were trained on the combined\norganiser and development set (resplit 80% train,\n10% validation, 10% held-out test, stratified by la-\nbel), for 20 epochs with the learning rate of 1e-4,\nAdamW optimiser ( \u03b5=1e-8) and Tanh activation"}, {"source": "2023.semeval-1.275.pdf", "text": "function in the classifier, and selected the check-\npoint with the highest overall validation F1 macro\nscore. The above preprocessing and oversampling\nwere not used, and articles were truncated at 512\ntokens.\nAfter submission, we conducted additional ex-\nperiments using the organiser training and develop-\nment sets for consistency. For monolingual models,"}, {"source": "2023.semeval-1.275.pdf", "text": "all articles in the training set and the external satire\nwere translated with Google Translate into the lan-\nguage of each monolingual model in question. Due\nto the character length limitation, particularly long\narticles were translated sentence-by-sentence.\n3.2.1 Results and Reflections\nThe final submission results of the ensemble are\nlisted in Table 2."}, {"source": "2023.semeval-1.275.pdf", "text": "listed in Table 2.\nThe final ensemble results achieved a higher\nF1macro score than in the supplementary multilin-\ngual results in all languages, except Polish. In En-\nglish, the ensemble achieved F1 macro score 25%\nhigher than the single mBERT transformer or\nadapter model. It should be noted that the final\nmodels were trained on both training and develop-"}, {"source": "2023.semeval-1.275.pdf", "text": "ment data. However, since the development sets1997are only \u22481\n3the size of the training sets, the dif-\nference in the amount of the training data was not\ndramatic.\nIn the absence of gold standard labels for the test\nset, it is difficult to analyse why the model achieved\na high score in Georgian, despite being zero-shot.\nHowever, our ensemble predictions suggest that"}, {"source": "2023.semeval-1.275.pdf", "text": "there is likely to be no satire articles in the Georgian\ntest set, which was consistently the most difficult\nclass to detect.\nTable 3 shows the differences between monolin-\ngual and multilingual versions of adapter bottle-\nneck and transformer models, evaluated against the\norganiser development set. The multilingual trans-\nformer models always perform better than monolin-"}, {"source": "2023.semeval-1.275.pdf", "text": "gual ones, while for 4 out of 6 languages, adapter\nbottleneck models benefit from the monolingual\nsetup. This may be due to using a fixed reduc-\ntion factor across all languages. Interestingly, the\nmBERT model demonstrates the best average re-\nsult in English for both transformer and bottleneck\nadapter models. For Italian, XLM-R yields the best\nresults for both transformer and adapter bottleneck"}, {"source": "2023.semeval-1.275.pdf", "text": "models. It is also notable that the results for English\nare by far the worst across all the models, possibly\nbecause the models are overly focused on capturing\nsemantic meaning and are not as effective in genre\nclassification.\nEven though transformer XLM-R demon-\nstrated significantly better results than transformer\nmBERT for Italian and German, these differences"}, {"source": "2023.semeval-1.275.pdf", "text": "were only marginal in our main setting where the\nvalidation set was smaller, while the marginally\nbetter results for Russian were not observed at\nall. Given the above observations and the fact\nthat XLM-R yielded higher F1 macro fluctuations,\nsometimes reaching 10%, we opted for the mBERT\nmodel as our main submission.\n3.3 Post-competition Findings\nSince, in our final submission, all languages were"}, {"source": "2023.semeval-1.275.pdf", "text": "evaluated without translation (including the three\nsurprise languages), a natural question we wanted\nto explore after the competition was whether trans-\nlating texts into a different language for evaluation\n(the \u2018translate-test\u2019 approach) would have yielded\nbetter results.\nWe selected the checkpoints that, during training,\nachieved the highest validation F1 macro for each"}, {"source": "2023.semeval-1.275.pdf", "text": "individual language. These \u2018language-optimal\u2019\ncheckpoints were then used to evaluate transla-tions of the other test sets. For example, using\nthe \u2018French\u2019-optimal checkpoint, we translated all\ntests sets into French and made predictions.\nSurprisingly, we found that the translate-test En-\nglish\u2192Russian and Italian \u2192French each im-\nproved the F1 macro performance by 1% on English"}, {"source": "2023.semeval-1.275.pdf", "text": "and Italian respectively, while French \u2192Russian\nimproved by over 6%.\nTwo out of the three surprise languages, Spanish\nand Greek, also benefited from being translated into\nother languages and tested using the corresponding\nbest checkpoints. The Spanish \u2192English setting\nshowed particularly striking increase in F1 macro ,\nfrom 68.7 to 81.7, which is also 21% higher than"}, {"source": "2023.semeval-1.275.pdf", "text": "the score of the winning team for Spanish and is\n20% above the other post-competition results. Ex-\ncept for German, translating the Greek test set into\nthe other 5 main languages and testing using the\ncorresponding checkpoints also provided signifi-\ncant improvements in the range of 5%-13%, which\nis over 1% above the result of the winning system\nand is the current leaderboard-best."}, {"source": "2023.semeval-1.275.pdf", "text": "and is the current leaderboard-best.\n4 System Description for Subtask 2\n4.1 System Overview\nTwo systems were used for submission, depending\non the language. For English and the three surprise\nlanguages, we used a monolingual English ensem-\nbleof 3 RoBERTa-MUPPET LARGE models. For\nthe remaining languages (French, German, Italian,\nRussian, Polish), we used a multilingual ensem-"}, {"source": "2023.semeval-1.275.pdf", "text": "bleof 3 XLM-R LARGE models (with adapters and\ntask-adaptive pre-training (TAPT)).\nAn overview of the two models is shown in Ta-\nble 4. A key difference between these two systems\nis that the monolingual MUPPET models were\ntrained using traditional finetuning of all param-\neters, whereas the XLM-R models 1) underwent\ntask-adaptive pre-training; and 2) were finetuned"}, {"source": "2023.semeval-1.275.pdf", "text": "using Pfeiffer bottleneck adapters.\nFor both systems, we trained our models jointly\non articles in all languages (using English transla-\ntions for our monolingual model). This meant that\nwe produced a single monolingual or multilingual\nsystem that was able to make predictions for all\nlanguages. We chose this approach of joint train-\ning across all languages in order to maximise the"}, {"source": "2023.semeval-1.275.pdf", "text": "number of examples seen for each class, since the\ndataset for Subtask 2 is quite small, particularly\nwhen split by language. Our early experiments\nshowed that this approach was superior to training1998LanguageTransformer Adapter\nMonolingual mBERT XLM-R Monolingual mBERT XLM-R\nEnglish 30.0 \u00b1 5.6\u221736.2 \u00b1 2.5 36.1 \u00b1 2.1 20.5 \u00b1 3.3\u221721.4 \u00b1 6.0 20.0 \u00b1 3.1"}, {"source": "2023.semeval-1.275.pdf", "text": "French 51.2 \u00b1 3.3 62.5 \u00b1 4.6\u221765.5 \u00b1 4.3\u221768.3 \u00b1 0.6 64.2 \u00b1 0.8 61.3 \u00b1 2.7\nGerman 59.9 \u00b1 4.1 59.9 \u00b1 5.0\u221766.9 \u00b1 1.0\u221765.7 \u00b1 3.6 57.8 \u00b1 2.8 62.0 \u00b1 3.2\nItalian 56.7 \u00b1 6.5 55.1 \u00b1 4.3\u221772.6 \u00b1 6.4 51.9 \u00b1 4.7 47.8 \u00b1 2.3\u221760.3 \u00b1 3.1\nPolish 71.7 \u00b1 6.6\u221781.9 \u00b1 3.7 79.4 \u00b1 1.1\u221777.6 \u00b1 2.9 72.9 \u00b1 5.1 76.7 \u00b1 2.2\nRussian 52.8 \u00b1 8.8 52.9 \u00b1 1.6\u221754.7 \u00b1 9.8\u221756.9 \u00b1 9.5 48.3 \u00b1 2.1 48.0 \u00b1 0.8"}, {"source": "2023.semeval-1.275.pdf", "text": "Table 3: Mean F1 macro\u00b11 std (over 3 runs) on subtask 1 organiser development set for multilingual and monolingual\nmodels for transformer and adapter-only architecture.\u2217denotes the best per model per language and bold denotes\nthe overall best per language.\nMUPPET ensemble XLM-R ensemble\nMUPPET LARGE XLM-R LARGE\nMonolingual (English) Multilingual\nTrained on all articles (in"}, {"source": "2023.semeval-1.275.pdf", "text": "Trained on all articles (in\ntranslation)Trained on all articles\n(original)\nNo TAPT TAPT\nFull finetuning Adapter finetuning\nEnsemble size 3 Ensemble size 3\nSubmitted for\nEN, EL, KA, ES All other languages\nTable 4: Summary of the monolingual vs multilingual\nsystems submitted for subtask 2\nmodels on the individual articles in each language.\n4.1.1 The English Monolingual System"}, {"source": "2023.semeval-1.275.pdf", "text": "4.1.1 The English Monolingual System\nFull Finetuning Our monolingual system used a\nfinetuned RoBERTa-MUPPET LARGE (Aghajanyan\net al., 2021) ensemble. RoBERTa-MUPPET im-\nproves on its baseline RoBERTa counterpart by\nadding an additional \u2018pre-finetuning\u2019 stage of multi-\ntask learning. We opted not to use adapters, be-\ncause our cross validation experiments showed this"}, {"source": "2023.semeval-1.275.pdf", "text": "worsened performance (see Appendix Table 13).\nEnglish Translations Because RoBERTa-\nMUPPET is a monolingual model, we translated\nall articles into English for training, and used\nthem for finetuning alongside the original English\narticles. We performed inference on non-English\nlanguages by translating the articles into English:\na \u2018translate-test\u2019 approach.\n4.1.2 Multilingual System"}, {"source": "2023.semeval-1.275.pdf", "text": "4.1.2 Multilingual System\nWe used XLM-RoBERTa LARGE (Conneau et al.,\n2020) for our multilingual model. Our system uses\ntwo techniques to improve performance: TAPT and\nadapter layers.\nTask-adaptive Pre-training We performed task-\nadaptive pre-training on the entire XLM-R model,\nfollowing the approach suggested by Gururangan"}, {"source": "2023.semeval-1.275.pdf", "text": "et al. (2020). Masked-language modelling wasperformed, using all available articles (including\nthe organisers\u2019 development and test sets). We\ntrained for 60 epochs with a learning rate of 1e-4\nand batch size of 128 (for full hyperparameters, see\nAppendix Table 11).\nTAPT could alternatively be performed by freez-\ning the base model and training the adapters with an"}, {"source": "2023.semeval-1.275.pdf", "text": "MLM objective. Despite being a faster approach,\nthis has been found to sometimes decrease perfor-\nmance (Kim et al., 2021).\nAdapters Our multilingual system used the Pfeif-\nfer bottleneck adapter configuration, with a reduc-\ntion factor of 8, which for XLM-R LARGE corre-\nsponds to a bottleneck hidden size of 128.\nAlthough using adapters did result in slightly"}, {"source": "2023.semeval-1.275.pdf", "text": "improved performance, we found that their main\nadvantage came from their low parameter number,\nwhich allowed for faster training and more experi-\nmentation.\n4.2 Ensemble\nPredictions made by our ensembles were decided\nby a majority vote. Each ensemble consisted of 3\nindividual models (MUPPET models for monolin-\ngual; adapter-finetuned XLM-R + TAPT for multi-"}, {"source": "2023.semeval-1.275.pdf", "text": "lingual). Within each ensemble, two models were\ntrained with class-weighting, and one-without.\nClass Weighting Class weighting helped to ac-\ncount for class imbalance by balancing the impact\nof under- and over-represented classes. When cal-\nculating the loss, the logit for each class was multi-\nplied by a class weight that was inversely propor-"}, {"source": "2023.semeval-1.275.pdf", "text": "tional to the frequency of that class in the dataset.\nOverall F1 micro scores were similar for models\nwith or without class weights. Class-weighting\ndid help to improve performance on less frequent\nframes (such as Cultural Identity andPublic Opin-\nion), but at the expense of more frequent classes"}, {"source": "2023.semeval-1.275.pdf", "text": "(such as Political ). Additionally, class weights1999were problematic in the joint language setting, caus-\ning varying performance across languages while\nmaintaining similar overall F1 micro . (A comparison\nfor XLM-R is provided in the Appendix Table 13.)\nFor this reason, we chose to use a mix of class-\nweighted and non-class-weighted models for our"}, {"source": "2023.semeval-1.275.pdf", "text": "ensembles in order to reduce the variance of our\nfinal systems.\n4.3 Experimental setup\n4.3.1 Data Preprocessing\nFor both monolingual and multilingual models, we\ncleaned and preprocessed the article text using a set\nof steps described in appendix B and truncated it to\nthe first 512 tokens. For monolingual English mod-\nels, we used Google Translate to produce English\ntranslations.\n4.3.2 Data Split"}, {"source": "2023.semeval-1.275.pdf", "text": "translations.\n4.3.2 Data Split\nFor subtask 2, we merged the organiser training and\ndevelopment sets, and used 3-fold cross-validation\n(stratified by language) to identify the best model\nconfigurations. We then produced final models\nby training on the entire training and organizer\ndevelopment set (rather than a 2/3 fold).\nAlthough this meant we did not have a validation"}, {"source": "2023.semeval-1.275.pdf", "text": "set to judge the final models that went into our\nensemble, it enabled training on all available data,\nwhich was important due to the small size of the\ndataset.\n4.3.3 Hyperparameters\nWe finetuned our monolingual models for a fixed\n20 epochs using a learning rate of 3e-5 (warm-up\nratio 0.1; linear decay), a batch size of 8, and the\nAdamW optimiser.\nWe used the same hyperparameters for adapter"}, {"source": "2023.semeval-1.275.pdf", "text": "finetuning, except we raised the learning rate to 1e-\n4. In general, adapters require a higher learning rate\nthan traditional finetuning, and this is reflected by\nthe findings of Chalkidis et al. (2021) for a similar\ntask.\n4.3.4 Cross-validation Findings and Language\nSelection\nTable 5 displays a condensed summary of our cross-\nvalidation results (for full version, see Appendix\nTable 13).4 5"}, {"source": "2023.semeval-1.275.pdf", "text": "Table 13).4 5\n4This table shows the average performance of individual\nmodels trained during cross-validation, and not the perfor-\nmance of any ensembles.\n5The Overall F1 micro column refers to the F1 micro of the\nentire validation fold and not the mean F1 micro score acrossFor monolingual models, MUPPET LARGE\nachieves an F1 micro of 70.4 on English, outper-"}, {"source": "2023.semeval-1.275.pdf", "text": "forming the RoBERTa baseline by 2 points. Simi-\nlarly, our XLM-R + TAPT + Adapters demonstrates\nsmall but consistent improvements over the multi-\nlingual XLM-R baseline across most languages.\nWhen comparing across monolingual and mul-\ntilingual models, we see that for English, XLM-R\nmodels are unable to compete with the performance\nof monolingual MUPPET. (They are, however, able"}, {"source": "2023.semeval-1.275.pdf", "text": "to match the performance of their monolingual\ncounterpart RoBERTa). In contrast to this, the\nmultilingual models generally demonstrated bet-\nter performance on non-English languages. This is\nreflected by the overall F1 micro scores: MUPPET\u2019s\n63.5 vs XLMR+TAPT+Adapter\u2019s 64.2. Based on\nthese results, we decided to use MUPPET for En-\nglish and XLM-R for other languages."}, {"source": "2023.semeval-1.275.pdf", "text": "glish and XLM-R for other languages.\nFor the unseen languages, we decided to use the\nmonolingual \u2018translate-test\u2019 approach based on ad-\nditional holdout experiments that indicated better\nMUPPET performance. Although this decision en-\nabled us to achieve 1st place on the evaluation test\nset for Greek and Georgian, our post-competition\nfindings (section 4.5) discovered that submitting"}, {"source": "2023.semeval-1.275.pdf", "text": "our multilingual model may have achieved even\nbetter results.\n4.4 Results and Reflections\nThe scores and positions of our model are shown\nin Table 6.\nThe strong performance of our monolingual\nmodel, which achieved first place in 3 out of 4\nlanguages submitted, suggests that the \u2019translate-\ntest\u2019 approach is competitive for performing mul-\ntilingual classification, especially for a zero-shot"}, {"source": "2023.semeval-1.275.pdf", "text": "cross-lingual scenario.\nAlthough our multilingual model also performed\nwell, the competition results suggest that even bet-\nter performance may be achieved by applying our\nmonolingual approach to other languages i.e. for\neach language, training a native monolingual model\nwith translations.\nArticle truncation poses a limitation on our find-\nings, since news frames can potentially be located"}, {"source": "2023.semeval-1.275.pdf", "text": "in parts of the article that are unseen by the model.\nOne of important future extension of these experi-\nments would be to apply long-document processing\ntechniques to this task.\nlanguages.2000Monolingual English EN DE FR IT PO RU Overall F1 micro\nRoBERTa-Large 68.4 \u00b1 2.0 63.5 \u00b1 2.0 57.9 \u00b1 2.9 60.9 \u00b1 0.2 65.8 \u00b1 3.4 54.5 \u00b1 2.7 63.6 \u00b1 0.1"}, {"source": "2023.semeval-1.275.pdf", "text": "MUPPET-Large 70.4 \u00b1 2.0 62.1 \u00b1 3.7 59.0 \u00b1 0.9 58.3 \u00b1 1.5 65.7 \u00b1 0.9 52.9 \u00b1 1.7 63.5 \u00b1 0.7\nMultilingual\nXLM-R 68.3 \u00b1 1.4 64.4 \u00b1 1.4 58.5 \u00b1 0.7 60.6 \u00b1 0.5 66.5 \u00b1 3.3 54.9 \u00b1 2.0 64.0 \u00b1 1.2\nXLM-R + TAPT + Adapters 68.2 \u00b1 0.9 65.0 \u00b1 1.8 58.5 \u00b1 2.8 61.0 \u00b1 0.6 66.7 \u00b1 3.0 55.7 \u00b1 3.1 64.2 \u00b1 0.3\nTable 5: Mean F1 micro scores of class-weighted models (over 3-fold cross-validation). For complete version with"}, {"source": "2023.semeval-1.275.pdf", "text": "ablations and other configurations, see Table 13\nLanguage Test F1 micro Place\nMonolingual MUPPET\nEnglish 57.895 1\nSpanish\u221750.829 3\nGreek\u221754.630 1\nGeorgian\u221765.421 1\nMultilingual XLM-R\n(+ TAPT + Adpt)\nFrench 53.425 3\nGerman 65.251 3\nItalian 57.079 7\nPolish 64.516 2\nRussian 44.144 2\nTable 6: Subtask 2 final leaderboard results for monolin-\ngual and multilingual systems.\u2217Translated to English"}, {"source": "2023.semeval-1.275.pdf", "text": "4.5 Post-competition Findings\nIs a \u2018translate-test\u2019 monolingual model really\nbetter than a multilingual model?\nAfter the competition ended, we wanted to compare\nthe performance of our two ensembles across all\ntest set languages, as each system had only been\nsubmitted for a subset of languages.\nSurprisingly, in contrast to our cross-validation\nexperiments, we found that for English, our multi-"}, {"source": "2023.semeval-1.275.pdf", "text": "lingual system outperformed our monolingual sub-\nmission: 58.475 (multi) vs 57.895 (mono). The\nmultilingual system also performed better on two\nof the surprise languages: Greek (58.0 vs 54.63)\nand Spanish (52.023 vs 50.829). In contrast to\nthe findings of Xenouleas et al. (2022), who found\ntranslation-based approaches \u201cvastly outperform\ncross-lingual finetuning with adapters\u201d, this sug-"}, {"source": "2023.semeval-1.275.pdf", "text": "gests that the two approaches are competitive with\neach other. It is difficult, however, to draw firm\nconclusions from this finding due to the small size\nof the unseen test set as well as the impact of TAPT.\nFor more details, see Appendix D.\n5 System Description for Subtask 3\n5.1 System Overview\nIn subtask 3, our focus was not only to maximize"}, {"source": "2023.semeval-1.275.pdf", "text": "the overall F1 micro , but also to ensure a balancedmodel performance across all classes6. Due to\nthe highly imbalanced nature of the 23 classes in\nsubtask 3, achieving a balanced model performance\nacross all classes is challenging. To address this\nissue, similarly to subtask 2, we explored cross-\nlingual training and implemented class weighting.\nWe also explored an oversampling technique, but it"}, {"source": "2023.semeval-1.275.pdf", "text": "did not provide any additional benefit compared to\nclass weighting and increased the training time.\nIn contrast to the organiser baseline, which dis-\ncards paragraphs without a label, we assigned them\na class vector of zeros and included them in the\ntraining set. This method lead to a significant im-\nprovement in performance across all languages7.\nWe evaluated the performance of the models on"}, {"source": "2023.semeval-1.275.pdf", "text": "unseen languages by training multilingual models\nwhile holding out each language. However, the\nperformance significantly decreased for every lan-\nguage when held out. Therefore, we translated the\narticles of the three unseen languages into English\nfor the final predictions.\nOur final models were a RoBERTa BASE for the\nsubmission of English and translated unseen lan-"}, {"source": "2023.semeval-1.275.pdf", "text": "guages, and an mBERT BASE for the remaining\nlanguages.\n5.2 Experimental Setup\nRoBERTa BASE was finetuned for 20 epochs only\non English data8, with a batch size of 32, truncated\nto 256 tokens, and AdamW optimizer with a learn-\ning rate of 0.00005, 20% of the training steps as\nlinear warm-up and weight decay of 0.1. A classifi-\ncation threshold of 0.4 was used."}, {"source": "2023.semeval-1.275.pdf", "text": "cation threshold of 0.4 was used.\nmBERT BASE was finetuned on all languages\ncombined and shuffled, with the same hyperparam-\neters as the RoBERTa BASE model, except a batch\nsize of 16.\nWe conducted an experiment to explore cross-\n6We further discuss this in appendix E.3\n7A comparison of these approaches are in appendix E.1.\n8Unlike subtask 2, we finetuned the model only with the"}, {"source": "2023.semeval-1.275.pdf", "text": "original English dataset without adding other translated lan-\nguages.2001LanguageF1micro\u00b11 std\nMonolingual Multilingual\nEnglish 36.2 \u00b1 0.3 31.8 \u00b1 0.6\nFrench 40.5 \u00b1 0.4 43.4 \u00b1 0.4\nGerman 36.9 \u00b1 0.5 40.9 \u00b1 0.7\nItalian 43.4 \u00b1 1.3 47.5 \u00b1 0.3\nPolish 28.9 \u00b1 0.8 30.2 \u00b1 0.8\nRussian 31.5 \u00b1 1.3 37.5 \u00b1 1.7\nTable 7: Monolingual vs. multilingual F1 micro scores"}, {"source": "2023.semeval-1.275.pdf", "text": "on the development set for each language on subtask 3.\nBest F1 micro per language are marked as bold .\nlingual training by comparing monolingual vs. mul-\ntilingual models for each language with fixed hy-\nperparameters, across three runs. The monolingual\nmodels were finetuned and validated on only one\nlanguage, using either RoBERTa-Base for English\nor mBERT for the other languages, while the mul-"}, {"source": "2023.semeval-1.275.pdf", "text": "tilingual version was an mBERT finetuned on all\nthe languages and validated on each language sepa-\nrately.\nFor the final submissions, we merged the train-\ning and development sets and finetuned the models\nwithout validation data. The model with the lowest\ntraining loss across all epochs was selected as the\nbest model. We used the random seed that pro-"}, {"source": "2023.semeval-1.275.pdf", "text": "duced the best F1 micro in the previous development\nset experiments while training the final model.\n5.2.1 Results\nTable 9 presents the final leaderboard results for\nsubtask 3. Although the main metric for this sub-\ntask is F1 micro, we highlight that our placings for\nsubtask 3 improve considerably when measuring\nthrough F1 macro, placing top 5 in all languages ex-"}, {"source": "2023.semeval-1.275.pdf", "text": "cept the three surprise languages and first place\nfor Italian and French, as shown in Table 16 in the\nAppendix.\nResults for the monolingual and multilingual\nexperiments on the official development set are\ndisplayed on Table 7, where we report the F1 micro\nfor each language. Scores are reported over three\nruns on different random seed initialisations. No-"}, {"source": "2023.semeval-1.275.pdf", "text": "tice that English is the only language in which the\nmonolingual model outperforms the multilingual\nversion.\nTable 8 shows the F1 micro for the zero-shot ex-\nperiments, in which a multilingual model was fine-\ntuned on all languages except the one being eval-\nuated. By comparison with Table 7, we see that\nzero-shot drastically hinders the performance on all"}, {"source": "2023.semeval-1.275.pdf", "text": "languages. For this reason, we decided to translateLanguageF1micro\u00b11 std\nZero-Shot\nEnglish 21.6 \u00b1 0.4\nFrench 35.8 \u00b1 0.7\nGerman 28.0 \u00b1 0.6\nItalian 34.3 \u00b1 0.4\nPolish 21.7 \u00b1 0.6\nRussian 18.6 \u00b1 1.1\nTable 8: Subtask 3 F1 micro for the zero-shot experiments.\nLanguage Test F1 micro Place\nMonolingual RoBERTa BASE\nEnglish 36.802 2\nSpanish\u221727.497 9\nGreek\u221717.426 7\nGeorgian\u221724.911 10\nMultilingual mBERT"}, {"source": "2023.semeval-1.275.pdf", "text": "Georgian\u221724.911 10\nMultilingual mBERT\nFrench 41.436 4\nGerman 44.726 6\nItalian 52.494 3\nPolish 34.700 7\nRussian 31.841 5\nTable 9: Subtask 3 final leaderboard results for monolin-\ngual and multilingual systems.\u2217Translated to English.\nthe test sets for the three surprise languages into\nEnglish and perform inference using the English\nmonolingual model. We were unable to experiment"}, {"source": "2023.semeval-1.275.pdf", "text": "with translating into different languages other than\nEnglish due to time constraints.\n6 Conclusion\nWe presented three systems aimed at solving three\nsubtasks within SemEval-2023 Task 3. Our sys-\ntems applied a variety of state-of-the-art techniques\nincluding adapters and TAPT, and consistently\nachieved a high rank across all available languages,\nincluding zero-shot low-resource languages. We"}, {"source": "2023.semeval-1.275.pdf", "text": "additionally presented an analysis of the viabil-\nity of monolingual vs multilingual approaches for\neach subtask, and found that the results of the com-\nparison vary depending on the subtask. For sub-\ntask 1, multilingual transformer models demon-\nstrate better average performance than monolin-\ngual models with translations. A similar effect\nwas observed for subtask 2 and subtask 3 where"}, {"source": "2023.semeval-1.275.pdf", "text": "multilingual settings achieved better performance\nthan monolingual ones in all languages except En-\nglish. We found the impact on bottleneck adapters\nto be unpredictable across tasks \u2013 despite per-\nforming on average better for monolingual mod-\nels in subtask 1, they were more beneficial for\nmultilingual models in subtask 2 (and hindered2002monolingual performance). Finally, we presented"}, {"source": "2023.semeval-1.275.pdf", "text": "post-competition findings, which suggest that sub-\ntask 2 would have benefited from a zero-shot pre-\ndiction using multilingual models, while subtask 1\ncould have achieved much better results with the\n\u2018translate-test\u2019 approach. Further analysis of this\nwill be possible when test labels are released.\n7 Acknowledgments\nThis work has been co-funded by the Euro-"}, {"source": "2023.semeval-1.275.pdf", "text": "pean Union under the Horizon Europe vera.ai\n(grant 101070093) and Vigilant (grant 101073921)\nprojects and the UK\u2019s innovation agency (Innovate\nUK) grants 10039055 and 10039039.\nReferences\nIbrahim Abu Farha, Silviu Vlad Oprea, Steven Wilson,\nand Walid Magdy. 2022. SemEval-2022 task 6: iS-\narcasmEval, intended sarcasm detection in English\nand Arabic. In Proceedings of the 16th International"}, {"source": "2023.semeval-1.275.pdf", "text": "Workshop on Semantic Evaluation (SemEval-2022) ,\npages 802\u2013814, Seattle, United States. Association\nfor Computational Linguistics.\nIfe Adebara, El Moatez Billah Nagoudi, and Muham-\nmad Abdul Mageed. 2020. Translating similar lan-\nguages: Role of mutual intelligibility in multilingual\ntransformers. In Proceedings of the Fifth Conference\non Machine Translation , pages 381\u2013386, Online. As-"}, {"source": "2023.semeval-1.275.pdf", "text": "sociation for Computational Linguistics.\nArmen Aghajanyan, Anchit Gupta, Akshat Shrivastava,\nXilun Chen, Luke Zettlemoyer, and Sonal Gupta.\n2021. Muppet: Massive multi-task representations\nwith pre-finetuning. In Proceedings of the 2021 Con-\nference on Empirical Methods in Natural Language\nProcessing , pages 5799\u20135811, Online and Punta\nCana, Dominican Republic. Association for Com-"}, {"source": "2023.semeval-1.275.pdf", "text": "putational Linguistics.\nAfra Feyza Aky\u00fcrek, Lei Guo, Randa Elanwar, Prakash\nIshwar, Margrit Betke, and Derry Tanti Wijaya. 2020.\nMulti-label and multilingual news framing analysis.\nInProceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics , pages 8614\u2013\n8624, Online. Association for Computational Lin-\nguistics.\nAnkur Bapna and Orhan Firat. 2019. Simple, scal-"}, {"source": "2023.semeval-1.275.pdf", "text": "able adaptation for neural machine translation. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 1538\u2013\n1548, Hong Kong, China. Association for Computa-\ntional Linguistics.\nIlias Chalkidis, Manos Fergadiotis, and Ion Androut-"}, {"source": "2023.semeval-1.275.pdf", "text": "sopoulos. 2021. MultiEURLEX - a multi-lingual andmulti-label legal document classification dataset for\nzero-shot cross-lingual transfer. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natu-\nral Language Processing , pages 6974\u20136996, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nBranden Chan, Stefan Schweter, and Timo M\u00f6ller. 2020."}, {"source": "2023.semeval-1.275.pdf", "text": "German\u2019s next language model. In Proceedings of\nthe 28th International Conference on Computational\nLinguistics , pages 6788\u20136796, Barcelona, Spain (On-\nline). International Committee on Computational Lin-\nguistics.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle-"}, {"source": "2023.semeval-1.275.pdf", "text": "moyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 8440\u2013\n8451, Online. Association for Computational Lin-\nguistics.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nHenning Wachsmuth, Rostislav Petrov, and Preslav"}, {"source": "2023.semeval-1.275.pdf", "text": "Nakov. 2020. SemEval-2020 task 11: Detection of\npropaganda techniques in news articles. In Proceed-\nings of the Fourteenth Workshop on Semantic Evalu-\nation , pages 1377\u20131414, Barcelona (online). Interna-\ntional Committee for Computational Linguistics.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarr\u00f3n-Cede\u00f1o, Rostislav Petrov, and Preslav Nakov."}, {"source": "2023.semeval-1.275.pdf", "text": "2019. Fine-grained analysis of propaganda in news\narticle. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) , pages\n5636\u20135646, Hong Kong, China. Association for Com-\nputational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and"}, {"source": "2023.semeval-1.275.pdf", "text": "Kristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n4171\u20134186, Minneapolis, Minnesota. Association for\nComputational Linguistics."}, {"source": "2023.semeval-1.275.pdf", "text": "Computational Linguistics.\nDimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021.\nSemEval-2021 task 6: Detection of persuasion tech-\nniques in texts and images. In Proceedings of the\n15th International Workshop on Semantic Evaluation\n(SemEval-2021) , pages 70\u201398, Online. Association"}, {"source": "2023.semeval-1.275.pdf", "text": "for Computational Linguistics.\nJennifer Golbeck, Matthew Mauriello, Brooke Aux-\nier, Keval H. Bhanushali, Christopher Bonk, Mo-\nhamed Amine Bouzaghrane, Cody Buntain, Riya\nChanduka, Paul Cheakalos, Jennine B. Everett,2003Waleed Falak, Carl Gieringer, Jack Graney, Kelly M.\nHoffman, Lindsay Huth, Zhenya Ma, Mayanka Jha,\nMisbah Khan, Varsha Kori, Elo Lewis, George Mi-"}, {"source": "2023.semeval-1.275.pdf", "text": "rano, William T. Mohn IV , Sean Mussenden, Tam-\nmie M. Nelson, Sean Mcwillie, Akshat Pant, Priya\nShetye, Rusha Shrestha, Alexandra Steinheimer,\nAditya Subramanian, and Gina Visnansky. 2018.\nFake news vs satire: A dataset and analysis. In\nProceedings of the 10th ACM Conference on Web\nScience , WebSci \u201918, page 17\u201321, New York, NY ,\nUSA. Association for Computing Machinery."}, {"source": "2023.semeval-1.275.pdf", "text": "Ga\u00ebl Guibon, Liana Ermakova, Hosni Seffih, Anton\nFirsov, and Guillaume Le No\u00e9-Bienvenu. 2019. Mul-\ntilingual fake news detection with satire. In CICLing:\nInternational Conference on Computational Linguis-\ntics and Intelligent Text Processing .\nSuchin Gururangan, Ana Marasovi \u00b4c, Swabha\nSwayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,\nand Noah A. Smith. 2020. Don\u2019t stop pretraining:"}, {"source": "2023.semeval-1.275.pdf", "text": "Adapt language models to domains and tasks. In\nProceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics , pages\n8342\u20138360, Online. Association for Computational\nLinguistics.\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2020. DeBERTa: Decoding-enhanced\nBERT with disentangled attention. Computing Re-\nsearch Repository , arXiv:2006.03654. Version 6."}, {"source": "2023.semeval-1.275.pdf", "text": "Ruidan He, Linlin Liu, Hai Ye, Qingyu Tan, Bosheng\nDing, Liying Cheng, Jiawei Low, Lidong Bing, and\nLuo Si. 2021. On the effectiveness of adapter-based\ntuning for pretrained language model adaptation. In\nProceedings of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language"}, {"source": "2023.semeval-1.275.pdf", "text": "Processing (Volume 1: Long Papers) , pages 2208\u2013\n2222, Online. Association for Computational Lin-\nguistics.\nNeil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,\nBruna Morrone, Quentin De Laroussilhe, Andrea\nGesmundo, Mona Attariyan, and Sylvain Gelly. 2019.\nParameter-efficient transfer learning for NLP. In\nProceedings of the 36th International Conference"}, {"source": "2023.semeval-1.275.pdf", "text": "on Machine Learning , volume 97 of Proceedings\nof Machine Learning Research , pages 2790\u20132799.\nPMLR.\nDawid Jurkiewicz, \u0141ukasz Borchmann, Izabela Kos-\nmala, and Filip Grali \u00b4nski. 2020. ApplicaAI at\nSemEval-2020 task 11: On RoBERTa-CRF, span\nCLS and whether self-training helps them. In Pro-\nceedings of the Fourteenth Workshop on Semantic\nEvaluation , pages 1415\u20131424, Barcelona (online)."}, {"source": "2023.semeval-1.275.pdf", "text": "International Committee for Computational Linguis-\ntics.\nRohit Kumar Kaliyar, Anurag Goswami, and Pratik\nNarang. 2021. FakeBERT: Fake news detection\nin social media with a BERT-based deep learn-\ning approach. Multimedia tools and applications ,\n80(8):11765\u201311788.Johannes Kiesel, Maria Mestre, Rishabh Shukla, Em-\nmanuel Vincent, Payam Adineh, David Corney,"}, {"source": "2023.semeval-1.275.pdf", "text": "Benno Stein, and Martin Potthast. 2019. SemEval-\n2019 task 4: Hyperpartisan news detection. In\nProceedings of the 13th International Workshop on\nSemantic Evaluation , pages 829\u2013839, Minneapolis,\nMinnesota, USA. Association for Computational Lin-\nguistics.\nSeungwon Kim, Alex Shum, Nathan Susanj, and\nJonathan Hilgart. 2021. Revisiting pretraining with\nadapters. In Proceedings of the 6th Workshop on"}, {"source": "2023.semeval-1.275.pdf", "text": "Representation Learning for NLP (RepL4NLP-2021) ,\npages 90\u201399, Online. Association for Computational\nLinguistics.\nYuri Kuratov and Mikhail Arkhipov. 2019. Adaptation\nof deep bidirectional multilingual transformers for\nrussian language. Computing Research Repository ,\narXiv:1905.07213. Version 1.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut."}, {"source": "2023.semeval-1.275.pdf", "text": "2019. ALBERT: A lite BERT for self-supervised\nlearning of language representations. Computing\nResearch Repository , arXiv:1909:11942. Version 6.\nHongying Liu and Ling Xie. 2021. Research on sarcasm\ndetection of news headlines based on Bert-LSTM. In\n2021 IEEE international conference on emergency\nscience and information technology (ICESIT) , pages\n89\u201392. IEEE."}, {"source": "2023.semeval-1.275.pdf", "text": "89\u201392. IEEE.\nSiyi Liu, Lei Guo, Kate Mays, Margrit Betke, and\nDerry Tanti Wijaya. 2019a. Detecting frames in\nnews headlines and its application to analyzing news\nframing trends surrounding U.S. gun violence. In\nProceedings of the 23rd Conference on Computa-\ntional Natural Language Learning (CoNLL) , pages\n504\u2013514, Hong Kong, China. Association for Com-\nputational Linguistics."}, {"source": "2023.semeval-1.275.pdf", "text": "putational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du,\nMandar Joshi, Danqi Chen, Omer Levy, Mike\nLewis, Luke Zettlemoyer, and Veselin Stoyanov.\n2019b. RoBERTa: A robustly optimized bert pre-\ntraining approach. Computing Research Repository ,\narXiv:1907.11692. Version 1.\nLouis Martin, Benjamin Muller, Pedro Javier Or-\ntiz Su\u00e1rez, Yoann Dupont, Laurent Romary, \u00c9ric"}, {"source": "2023.semeval-1.275.pdf", "text": "de la Clergerie, Djam\u00e9 Seddah, and Beno\u00eet Sagot.\n2020. CamemBERT: a tasty French language model.\nInProceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics , pages 7203\u2013\n7219, Online. Association for Computational Lin-\nguistics.\nRobert McHardy, Heike Adel, and Roman Klinger. 2019.\nAdversarial training for satire detection: Controlling"}, {"source": "2023.semeval-1.275.pdf", "text": "for confounding variables. In Proceedings of the\n2019 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, Volume 1 (Long and\nShort Papers) , pages 660\u2013665, Minneapolis, Min-\nnesota. Association for Computational Linguistics.2004Rajnish Pandey and Jyoti Prakash Singh. 2022. BERT-\nLSTM model for sarcasm detection in code-mixed"}, {"source": "2023.semeval-1.275.pdf", "text": "social media post. Journal of Intelligent Information\nSystems , pages 1\u201320.\nJonas Pfeiffer, Andreas R\u00fcckl\u00e9, Clifton Poth, Aishwarya\nKamath, Ivan Vuli \u00b4c, Sebastian Ruder, Kyunghyun\nCho, and Iryna Gurevych. 2020a. AdapterHub: A\nframework for adapting transformers. In Proceedings\nof the 2020 Conference on Empirical Methods in Nat-\nural Language Processing: System Demonstrations ,"}, {"source": "2023.semeval-1.275.pdf", "text": "pages 46\u201354, Online. Association for Computational\nLinguistics.\nJonas Pfeiffer, Ivan Vuli \u00b4c, Iryna Gurevych, and Se-\nbastian Ruder. 2020b. MAD-X: An Adapter-Based\nFramework for Multi-Task Cross-Lingual Transfer.\nInProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP) ,\npages 7654\u20137673, Online. Association for Computa-\ntional Linguistics."}, {"source": "2023.semeval-1.275.pdf", "text": "tional Linguistics.\nJakub Piskorski, Nicolas Stefanovitch, Giovanni\nDa San Martino, and Preslav Nakov. 2023. Semeval-\n2023 task 3: Detecting the category, the framing,\nand the persuasion techniques in online news in a\nmulti-lingual setup. In Proceedings of the 17th Inter-\nnational Workshop on Semantic Evaluation , SemEval\n2023, Toronto, Canada.\nJunfeng Tian, Min Gui, Chenliang Li, Ming Yan, and"}, {"source": "2023.semeval-1.275.pdf", "text": "Wenming Xiao. 2021. MinD at SemEval-2021 task 6:\nPropaganda detection using transfer learning and mul-\ntimodal fusion. In Proceedings of the 15th Interna-\ntional Workshop on Semantic Evaluation (SemEval-\n2021) , pages 1082\u20131087, Online. Association for\nComputational Linguistics.\nOren Tsur, Dan Calacci, and David Lazer. 2015. A\nframe of mind: Using statistical models for detec-"}, {"source": "2023.semeval-1.275.pdf", "text": "tion of framing and agenda setting campaigns. In\nProceedings of the 53rd Annual Meeting of the As-\nsociation for Computational Linguistics and the 7th\nInternational Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers) , pages 1629\u2013\n1638, Beijing, China. Association for Computational\nLinguistics.\nCindy Wang and Michele Banko. 2021. Practical"}, {"source": "2023.semeval-1.275.pdf", "text": "transformer-based multilingual text classification. In\nProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies:\nIndustry Papers , pages 121\u2013129, Online. Association\nfor Computational Linguistics.\nShijie Wu and Mark Dredze. 2020. Are all languages\ncreated equal in multilingual BERT? In Proceedings"}, {"source": "2023.semeval-1.275.pdf", "text": "of the 5th Workshop on Representation Learning for\nNLP, pages 120\u2013130, Online. Association for Com-\nputational Linguistics.\nStratos Xenouleas, Alexia Tsoukara, Giannis Panagio-\ntakis, Ilias Chalkidis, and Ion Androutsopoulos. 2022.\nRealistic zero-shot cross-lingual transfer in legaltopic classification. In Proceedings of the 12th Hel-\nlenic Conference on Artificial Intelligence , SETN"}, {"source": "2023.semeval-1.275.pdf", "text": "\u201922, New York, NY , USA. Association for Comput-\ning Machinery.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Car-\nbonell, Ruslan Salakhutdinov, and Quoc V . Le. 2019.\nXlnet: Generalized autoregressive pretraining for lan-\nguage understanding. In Neural Information Process-\ning Systems .\nA Language Models Used\nThe models used in each subtask are shown in Table\n10.\nB Article Preprocessing"}, {"source": "2023.semeval-1.275.pdf", "text": "10.\nB Article Preprocessing\nArticles were preprocessed with the following\nsteps, for all languages:\n\u2022 add a full stop at the end of the title.\n\u2022remove duplicate sentences directly following\neach other;\n\u2022 remove the @ symbol from twitter handles;\n\u2022 remove hyperlinks to websites and images;\nEnglish articles were further preprocessed:\n\u2022remove lines indicating the possibility to share"}, {"source": "2023.semeval-1.275.pdf", "text": "the article on different social media platforms;\n\u2022remove sentences suggesting the user to take\npart in online polls, comments, or advertise-\nments;\n\u2022remove sentences indicating the terms of use;\n\u2022remove sentences indicating the licenses and\ncontaining phrases such as \u2018reprinted with per-\nmission\u2019, \u2018posted with permission\u2019 and \u2018all\nrights reserved\u2019;\n\u2022remove sentences relating to the article author"}, {"source": "2023.semeval-1.275.pdf", "text": "biographies\nC Subtask 1\nC.1 Language-specific performance after each\nepoch on development set\nFigure 1 shows F1 macro scores on the held-out de-\nvelopment set for one of the finetuned transformer\nmodels. As can be seen, Polish reaches its best\nperformance quite early on, while German and Rus-\nsian need more than 17 epochs to achieve the best\nscore.\nD Subtask 2"}, {"source": "2023.semeval-1.275.pdf", "text": "score.\nD Subtask 2\nHyperparameters for Subtask 2 TAPT are shown in\nTable 11. The detailed cross-validation results are\nshown in Table 13.2005Language Huggingface Model Name Publication Subtasks\nEnglish bert-base-cased Devlin et al. (2019) 1\nEnglish RoBERTa-base Liu et al. (2019b) 3\u22c6\nEnglish RoBERTa-large Liu et al. (2019b) 2\nEnglish MUPPET-large Aghajanyan et al. (2021) 2\u22c6"}, {"source": "2023.semeval-1.275.pdf", "text": "French camembert-base Martin et al. (2020) 1\nGerman deepset/gbert-base Chan et al. (2020) 1\nItalian dbmdz/bert-base-italian-cased - 1\nPolish dkleczek/bert-base-polish-cased-v1 - 1\nRussian DeepPavlov/rubert-base-cased Kuratov and Arkhipov (2019) 1\nMultilingual bert-base-multilingual-cased Devlin et al. (2019) 1\u22c63\u22c6\nMultilingual xlm-RoBERTa-base Conneau et al. (2020) 1 3"}, {"source": "2023.semeval-1.275.pdf", "text": "Multilingual xlm-RoBERTa-large Conneau et al. (2020) 2\u22c6\nTable 10: Models used in each subtask.\u22c6denotes the models used in the final submission. Based on model selection\nof Chalkidis et al. (2021).\n0 5 10 15 20 25 30020406080100\nEpochF1macro\nEnglish French German\nItalian Polish Russian\nFigure 1: Validation F1 macro of each language over time,\nwith maximal epoch indicated."}, {"source": "2023.semeval-1.275.pdf", "text": "with maximal epoch indicated.\nD.1 Post-competition Findings\nTable 12 shows the full set of post-competition\nresults. The multilingual model outperforms our\nofficial monolingual submission for test set English,\nGreek, and Spanish, but is much worse for Geor-\ngian. Conversely, our monolingual model does\nbetter than our official multilingual submission for"}, {"source": "2023.semeval-1.275.pdf", "text": "French and Italian. This suggests that neither mono-\nlingual nor multilingual models are consistently\nbetter than the other across all languages.\nTraditional zero-shot cross-lingual experiments\nfocus on finetuning a multilingual model on a sin-\ngle source language and testing in a target language.\nIn our situation, we jointly finetune on multiple lan-"}, {"source": "2023.semeval-1.275.pdf", "text": "guages, which encourages the model to retain mul-\ntilingual representations, even for languages not\nin its training, thus improving its zero-shot cross-Epochs 60\nEffective Batch Size 128\nMax learning rate 1e-4\nWarmup ratio 0.06, linear\nLearning rate decay linear\nOptimiser AdamW\nAdam epsilon 1e-6\nAdam beta weights 0.9, 0.98\nWeight decay 0.01\nTable 11: Subtask 2: TAPT Hyperparameters"}, {"source": "2023.semeval-1.275.pdf", "text": "Language Multilingual Monolingual\nEnglish 58.475 57.895 (1)\nFrench 53.425 (3) 54.181\nGerman 65.251 (3) 62.069\nItalian 57.079 (7) 60.577\nPolish 64.516 (2) 63.581\nRussian 44.144 (2) 40.800\nSpanish 52.023 50.829 (3)\nGreek 58.000 54.630 (1)\nGeorgian 60.870 65.421 (1)\nTable 12: Subtask 2: F1 micro Perfomance on test set -\npost-competition comparison. () indicates ranking for\nofficial submissions."}, {"source": "2023.semeval-1.275.pdf", "text": "official submissions.\nlingual capabilities. This may help to explain the\nimproved performance of our multilingual model.\nHowever, it is important to note that these results\nare not representative of true zero-shot classifica-\ntion, since our multilingual model did perform task-\nadaptive pre-training on articles from the surprise\nlanguages. Unfortunately, because the organisers"}, {"source": "2023.semeval-1.275.pdf", "text": "have not released labels for the test set, we are\nunable to perform error analysis. As mentioned\nin the main section, the small size of the test set\nalso makes it difficult to draw firm conclusions on\nwhether translate-test is better than multilingual\nzero-shot classification.2006Monolingual English EN DE FR IT PO RU Overall F1 micro"}, {"source": "2023.semeval-1.275.pdf", "text": "RoBERTa-Large 68.4 \u00b1 2.0 63.5 \u00b1 2.0 57.9 \u00b1 2.9 60.9 \u00b1 0.2 65.8 \u00b1 3.4 54.5 \u00b1 2.7 63.6 \u00b1 0.1\nMUPPET-Large 70.4 \u00b1 2.0 62.1 \u00b1 3.7 59.0 \u00b1 0.9 58.3 \u00b1 1.5 65.7 \u00b1 0.9 52.9 \u00b1 1.7 63.5 \u00b1 0.7\nMUPPET-Large + Adapters 68.0 \u00b1 1.0 59.5 \u00b1 1.6 54.5 \u00b1 1.9 58.0 \u00b1 0.7 61.9 \u00b1 2.1 51.0 \u00b1 3.7 61.1 \u00b1 0.9\nMultilingual Models\nXLM-R 68.3 \u00b1 1.4 64.4 \u00b1 1.4 58.5 \u00b1 0.7 60.6 \u00b1 0.5 66.5 \u00b1 3.3 54.9 \u00b1 2.0 64.0 \u00b1 1.2"}, {"source": "2023.semeval-1.275.pdf", "text": "XLM-R + Adapters 69.0 \u00b1 1.2 64.0 \u00b1 1.4 58.4 \u00b1 3.0 61.3 \u00b1 0.9 67.4 \u00b1 1.0 53.1 \u00b1 2.7 64.3 \u00b1 0.4\nXLM-R + TAPT + Adapters 68.2 \u00b1 0.9 65.0 \u00b1 1.8 58.5 \u00b1 2.8 61.0 \u00b1 0.6 66.7 \u00b1 3.0 55.7 \u00b1 3.1 64.2 \u00b1 0.3\nXLM-R (no class weights) 68.8 \u00b1 1.7 57.1 \u00b1 2.2 61.6 \u00b1 4.0 61.7 \u00b1 1.2 67.4 \u00b1 2.1 57.0 \u00b1 2.2 65.1 \u00b1 0.2"}, {"source": "2023.semeval-1.275.pdf", "text": "Table 13: Full version of Subtask 2 cross-validation results. Comparison of averaged F1 micro scores on 3-fold\ncross-validation (merged training and organiser-dev set). All models have class-weighting, except where indicated\notherwise.\nLanguageTraining Set Size\nWithout Non-Labelled With Non-Labelled\nEnglish 3760 9498 (+152%)\nFrench 1693 2259 (+33%)\nGerman 1252 1555 (+24%)\nItalian 1745 2623 (+50%)"}, {"source": "2023.semeval-1.275.pdf", "text": "Italian 1745 2623 (+50%)\nPolish 1232 2310 (+32%)\nRussian 1245 1962 (+57%)\nTable 14: Subtask 3 train set sizes for each language\nwithout and with the addition of examples that weren\u2019t\nassigned a class during labelling.\nE Subtask 3\nE.1 Training With vs. Without Non-Labelled\nExamples\nIn the combined training set across all the lan-\nguages, there are 9,280 paragraphs that do not have"}, {"source": "2023.semeval-1.275.pdf", "text": "a label. Although it is expected that this also oc-\ncurs on the test set, the organizer\u2019s baseline ap-\nproach discards these train samples, so it never\nexplicitly trains on unlabelled examples. Table 14\ndisplays the sizes of the train set for each language\nwithout adding non-labelled examples vs. adding\nthem. Table 15 shows the F1 micro results of both"}, {"source": "2023.semeval-1.275.pdf", "text": "approaches, with means and stds computed over\nthree random seed initialisations. Note that adding\nthe non-labelled examples contributes to a consid-\nerable increase in performance for all languages,\nparticularly English, which is also the language\nthat had the biggest increase in train set size.\nE.2 Development Set Fine-grained Results\nTable 17 shows the fine-grained results for the"}, {"source": "2023.semeval-1.275.pdf", "text": "English official development set. Results are\nobtained from the best random seed over three runs.\nAlthough Appeal_to_Time ,Appeal_to_Values ,\nConsequential_Oversimplification and Ques-\ntioning_the_Reputation classes do not haveLanguageF1micro\u00b11 std\nWithout Classless With Classless\nEnglish 27.1 \u00b1 1.0 36.2 \u00b1 0.3\nFrench 41.3 \u00b1 0.1 43.4 \u00b1 0.4\nGerman 40.8 \u00b1 0.1 40.9 \u00b1 0.8\nItalian 44.1 \u00b1 0.6 47.5 \u00b1 0.4"}, {"source": "2023.semeval-1.275.pdf", "text": "Italian 44.1 \u00b1 0.6 47.5 \u00b1 0.4\nPolish 27.8 \u00b1 0.9 30.2 \u00b1 0.1\nRussian 35.7 \u00b1 0.9 37.5 \u00b1 2.0\nTable 15: Subtask 3 F1 micro for best model configura-\ntions for each language with and without the addition\nof classless examples. Best F1 micro per language are\nmarked as bold .\nFinal Submission\nTest F1 micro Place Test F1 macro Place\nEnglish 36.802 2 17.194 2\nFrench 41.436 4 32.424 1"}, {"source": "2023.semeval-1.275.pdf", "text": "French 41.436 4 32.424 1\nGerman 44.726 6 23.679 3\nItalian 52.494 3 28.22 1\nPolish 34.7 7 19.102 4\nRussian 31.841 5 20.522 2\nGreek 17.426 7 11.028 8\nSpanish 27.497 9 13.042 8\nGeorgian 24.911 10 29.553 4\nTable 16: Subtask 3 final submission F1 micro and F1 macro\nand our placement according to both of them.\na single example in development set, there\nare six other classes in which we also obtain"}, {"source": "2023.semeval-1.275.pdf", "text": "0.0F1-Score, namely Appeal_to_Hypocrisy ,\nAppeal_to_Popularity ,Obfuscation-Vagueness-\nConfusion ,Red_Herring ,Straw_Man and\nWhataboutism , although together they account\nfor only 5% of the development set. The three\nbiggest classes, Loaded_Language ,Name_Calling-\nLabeling andDoubt account for 29%, 15% and\n11% of the development set, respectively, thus"}, {"source": "2023.semeval-1.275.pdf", "text": "having a large impact on F1 micro .2007Class Precision Recall F1-Score Samples\nAppeal_to_Authority 0.11 0.07 0.09 28\nAppeal_to_Fear-Prejudice 0.39 0.23 0.29 137\nAppeal_to_Hypocrisy 0 0 0 8\nAppeal_to_Popularity 0 0 0 34\nAppeal_to_Time 0 0 0 0\nAppeal_to_Values 0 0 0 0\nCausal_Oversimplification 0.03 0.04 0.04 24\nConsequential_Oversimplification 0 0 0 0\nConversation_Killer 0.11 0.28 0.16 25"}, {"source": "2023.semeval-1.275.pdf", "text": "Conversation_Killer 0.11 0.28 0.16 25\nDoubt 0.26 0.36 0.3 187\nExaggeration-Minimisation 0.21 0.34 0.26 115\nFalse_Dilemma-No_Choice 0.26 0.16 0.2 63\nFlag_Waving 0.34 0.49 0.4 96\nGuilt_by_Association 0.33 0.25 0.29 4\nLoaded_Language 0.39 0.64 0.48 483\nName_Calling-Labeling 0.42 0.69 0.52 250\nObfuscation-Vagueness-Confusion 0 0 0 13\nQuestioning_the_Reputation 0 0 0 0\nRed_Herring 0 0 0 19"}, {"source": "2023.semeval-1.275.pdf", "text": "Red_Herring 0 0 0 19\nRepetition 0.12 0.24 0.16 141\nSlogans 0.21 0.43 0.29 28\nStraw_Man 0 0 0 9\nWhataboutism 0 0 0 2\nmicro avg 0.31 0.44 0.36 1666\nmacro avg 0.14 0.18 0.15 1666\nTable 17: Subtask 3 fine-grained results for the English development set.\nE.3 Full Leaderboard Results\nTable 16 shows our full final submission scores and\nplacements according to both F1 micro and F1 macro ."}, {"source": "2023.semeval-1.275.pdf", "text": "As we previously point out in section 5.1, we aimed\ntowards a model capable of identifying all the 23\nclasses, thus having high F1 macro , even though\nthe main metric for the subtask is F1 micro . We\nbelieve that a realistic application of a model for\nthis particular label scheme should not disregard\nunder-represented classes, otherwise they should\nsimply be removed from the label scheme. Al-"}, {"source": "2023.semeval-1.275.pdf", "text": "though our placings according to F1 macro are con-\nsiderably higher, we acknowledge that because the\nmain metric for the subtask is not F1 macro , other\nteams\u2019 submissions are likely not focusing on max-\nimizing it, thus making their scores lower on aver-\nage.2008"}, {"source": "N19-1423.pdf", "text": "Proceedings of NAACL-HLT 2019 , pages 4171\u20134186\nMinneapolis, Minnesota, June 2 - June 7, 2019. c\r2019 Association for Computational Linguistics4171BERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding\nJacob Devlin Ming-Wei Chang Kenton Lee Kristina Toutanova\nGoogle AI Language\nfjacobdevlin,mingweichang,kentonl,kristout g@google.com\nAbstract"}, {"source": "N19-1423.pdf", "text": "Abstract\nWe introduce a new language representa-\ntion model called BERT , which stands for\nBidirectional Encoder Representations from\nTransformers. Unlike recent language repre-\nsentation models (Peters et al., 2018a; Rad-\nford et al., 2018), BERT is designed to pre-\ntrain deep bidirectional representations from\nunlabeled text by jointly conditioning on both"}, {"source": "N19-1423.pdf", "text": "left and right context in all layers. As a re-\nsult, the pre-trained BERT model can be \ufb01ne-\ntuned with just one additional output layer\nto create state-of-the-art models for a wide\nrange of tasks, such as question answering and\nlanguage inference, without substantial task-\nspeci\ufb01c architecture modi\ufb01cations.\nBERT is conceptually simple and empirically\npowerful. It obtains new state-of-the-art re-"}, {"source": "N19-1423.pdf", "text": "sults on eleven natural language processing\ntasks, including pushing the GLUE score to\n80.5% (7.7% point absolute improvement),\nMultiNLI accuracy to 86.7% (4.6% absolute\nimprovement), SQuAD v1.1 question answer-\ning Test F1 to 93.2 (1.5 point absolute im-\nprovement) and SQuAD v2.0 Test F1 to 83.1\n(5.1 point absolute improvement).\n1 Introduction\nLanguage model pre-training has been shown to"}, {"source": "N19-1423.pdf", "text": "be effective for improving many natural language\nprocessing tasks (Dai and Le, 2015; Peters et al.,\n2018a; Radford et al., 2018; Howard and Ruder,\n2018). These include sentence-level tasks such as\nnatural language inference (Bowman et al., 2015;\nWilliams et al., 2018) and paraphrasing (Dolan\nand Brockett, 2005), which aim to predict the re-\nlationships between sentences by analyzing them"}, {"source": "N19-1423.pdf", "text": "holistically, as well as token-level tasks such as\nnamed entity recognition and question answering,\nwhere models are required to produce \ufb01ne-grained\noutput at the token level (Tjong Kim Sang and\nDe Meulder, 2003; Rajpurkar et al., 2016).There are two existing strategies for apply-\ning pre-trained language representations to down-\nstream tasks: feature-based and\ufb01ne-tuning . The"}, {"source": "N19-1423.pdf", "text": "feature-based approach, such as ELMo (Peters\net al., 2018a), uses task-speci\ufb01c architectures that\ninclude the pre-trained representations as addi-\ntional features. The \ufb01ne-tuning approach, such as\nthe Generative Pre-trained Transformer (OpenAI\nGPT) (Radford et al., 2018), introduces minimal\ntask-speci\ufb01c parameters, and is trained on the\ndownstream tasks by simply \ufb01ne-tuning allpre-"}, {"source": "N19-1423.pdf", "text": "trained parameters. The two approaches share the\nsame objective function during pre-training, where\nthey use unidirectional language models to learn\ngeneral language representations.\nWe argue that current techniques restrict the\npower of the pre-trained representations, espe-\ncially for the \ufb01ne-tuning approaches. The ma-\njor limitation is that standard language models are"}, {"source": "N19-1423.pdf", "text": "unidirectional, and this limits the choice of archi-\ntectures that can be used during pre-training. For\nexample, in OpenAI GPT, the authors use a left-to-\nright architecture, where every token can only at-\ntend to previous tokens in the self-attention layers\nof the Transformer (Vaswani et al., 2017). Such re-\nstrictions are sub-optimal for sentence-level tasks,"}, {"source": "N19-1423.pdf", "text": "and could be very harmful when applying \ufb01ne-\ntuning based approaches to token-level tasks such\nas question answering, where it is crucial to incor-\nporate context from both directions.\nIn this paper, we improve the \ufb01ne-tuning based\napproaches by proposing BERT: Bidirectional\nEncoder Representations from Transformers.\nBERT alleviates the previously mentioned unidi-"}, {"source": "N19-1423.pdf", "text": "rectionality constraint by using a \u201cmasked lan-\nguage model\u201d (MLM) pre-training objective, in-\nspired by the Cloze task (Taylor, 1953). The\nmasked language model randomly masks some of\nthe tokens from the input, and the objective is to\npredict the original vocabulary id of the masked4172word based only on its context. Unlike left-to-\nright language model pre-training, the MLM ob-"}, {"source": "N19-1423.pdf", "text": "jective enables the representation to fuse the left\nand the right context, which allows us to pre-\ntrain a deep bidirectional Transformer. In addi-\ntion to the masked language model, we also use\na \u201cnext sentence prediction\u201d task that jointly pre-\ntrains text-pair representations. The contributions\nof our paper are as follows:\n\u2022 We demonstrate the importance of bidirectional"}, {"source": "N19-1423.pdf", "text": "pre-training for language representations. Un-\nlike Radford et al. (2018), which uses unidirec-\ntional language models for pre-training, BERT\nuses masked language models to enable pre-\ntrained deep bidirectional representations. This\nis also in contrast to Peters et al. (2018a), which\nuses a shallow concatenation of independently\ntrained left-to-right and right-to-left LMs."}, {"source": "N19-1423.pdf", "text": "\u2022 We show that pre-trained representations reduce\nthe need for many heavily-engineered task-\nspeci\ufb01c architectures. BERT is the \ufb01rst \ufb01ne-\ntuning based representation model that achieves\nstate-of-the-art performance on a large suite\nof sentence-level andtoken-level tasks, outper-\nforming many task-speci\ufb01c architectures.\n\u2022 BERT advances the state of the art for eleven"}, {"source": "N19-1423.pdf", "text": "NLP tasks. The code and pre-trained mod-\nels are available at https://github.com/\ngoogle-research/bert .\n2 Related Work\nThere is a long history of pre-training general lan-\nguage representations, and we brie\ufb02y review the\nmost widely-used approaches in this section.\n2.1 Unsupervised Feature-based Approaches\nLearning widely applicable representations of\nwords has been an active area of research for"}, {"source": "N19-1423.pdf", "text": "decades, including non-neural (Brown et al., 1992;\nAndo and Zhang, 2005; Blitzer et al., 2006) and\nneural (Mikolov et al., 2013; Pennington et al.,\n2014) methods. Pre-trained word embeddings\nare an integral part of modern NLP systems, of-\nfering signi\ufb01cant improvements over embeddings\nlearned from scratch (Turian et al., 2010). To pre-\ntrain word embedding vectors, left-to-right lan-"}, {"source": "N19-1423.pdf", "text": "guage modeling objectives have been used (Mnih\nand Hinton, 2009), as well as objectives to dis-\ncriminate correct from incorrect words in left and\nright context (Mikolov et al., 2013).These approaches have been generalized to\ncoarser granularities, such as sentence embed-\ndings (Kiros et al., 2015; Logeswaran and Lee,\n2018) or paragraph embeddings (Le and Mikolov,"}, {"source": "N19-1423.pdf", "text": "2014). To train sentence representations, prior\nwork has used objectives to rank candidate next\nsentences (Jernite et al., 2017; Logeswaran and\nLee, 2018), left-to-right generation of next sen-\ntence words given a representation of the previous\nsentence (Kiros et al., 2015), or denoising auto-\nencoder derived objectives (Hill et al., 2016).\nELMo and its predecessor (Peters et al., 2017,"}, {"source": "N19-1423.pdf", "text": "2018a) generalize traditional word embedding re-\nsearch along a different dimension. They extract\ncontext-sensitive features from a left-to-right and a\nright-to-left language model. The contextual rep-\nresentation of each token is the concatenation of\nthe left-to-right and right-to-left representations.\nWhen integrating contextual word embeddings\nwith existing task-speci\ufb01c architectures, ELMo"}, {"source": "N19-1423.pdf", "text": "advances the state of the art for several major NLP\nbenchmarks (Peters et al., 2018a) including ques-\ntion answering (Rajpurkar et al., 2016), sentiment\nanalysis (Socher et al., 2013), and named entity\nrecognition (Tjong Kim Sang and De Meulder,\n2003). Melamud et al. (2016) proposed learning\ncontextual representations through a task to pre-\ndict a single word from both left and right context"}, {"source": "N19-1423.pdf", "text": "using LSTMs. Similar to ELMo, their model is\nfeature-based and not deeply bidirectional. Fedus\net al. (2018) shows that the cloze task can be used\nto improve the robustness of text generation mod-\nels.\n2.2 Unsupervised Fine-tuning Approaches\nAs with the feature-based approaches, the \ufb01rst\nworks in this direction only pre-trained word em-\nbedding parameters from unlabeled text (Col-"}, {"source": "N19-1423.pdf", "text": "lobert and Weston, 2008).\nMore recently, sentence or document encoders\nwhich produce contextual token representations\nhave been pre-trained from unlabeled text and\n\ufb01ne-tuned for a supervised downstream task (Dai\nand Le, 2015; Howard and Ruder, 2018; Radford\net al., 2018). The advantage of these approaches\nis that few parameters need to be learned from"}, {"source": "N19-1423.pdf", "text": "scratch. At least partly due to this advantage,\nOpenAI GPT (Radford et al., 2018) achieved pre-\nviously state-of-the-art results on many sentence-\nlevel tasks from the GLUE benchmark (Wang\net al., 2018a). Left-to-right language model-4173\nBERT BERT \nE[CLS] E1 E[SEP] ... ENE1\u2019... EM\u2019\nC\nT1\nT[SEP] ...\n TN\nT1\u2019...\n TM\u2019\n[CLS] Tok 1 [SEP] ... Tok NTok 1 ... TokM \nQuestion Paragraph Start/End Span \nBERT"}, {"source": "N19-1423.pdf", "text": "BERT \nE[CLS] E1 E[SEP] ... ENE1\u2019... EM\u2019\nC\nT1\nT[SEP] ...\n TN\nT1\u2019...\n TM\u2019\n[CLS] Tok 1 [SEP] ... Tok NTok 1 ... TokM \nMasked Sentence A Masked Sentence B \nPre-training Fine-Tuning NSP Mask LM Mask LM \nUnlabeled Sentence A and B Pair SQuAD \nQuestion Answer Pair NER MNLI Figure 1: Overall pre-training and \ufb01ne-tuning procedures for BERT. Apart from output layers, the same architec-"}, {"source": "N19-1423.pdf", "text": "tures are used in both pre-training and \ufb01ne-tuning. The same pre-trained model parameters are used to initialize\nmodels for different down-stream tasks. During \ufb01ne-tuning, all parameters are \ufb01ne-tuned. [CLS] is a special\nsymbol added in front of every input example, and [SEP] is a special separator token (e.g. separating ques-\ntions/answers).\ning and auto-encoder objectives have been used"}, {"source": "N19-1423.pdf", "text": "for pre-training such models (Howard and Ruder,\n2018; Radford et al., 2018; Dai and Le, 2015).\n2.3 Transfer Learning from Supervised Data\nThere has also been work showing effective trans-\nfer from supervised tasks with large datasets, such\nas natural language inference (Conneau et al.,\n2017) and machine translation (McCann et al.,\n2017). Computer vision research has also demon-"}, {"source": "N19-1423.pdf", "text": "strated the importance of transfer learning from\nlarge pre-trained models, where an effective recipe\nis to \ufb01ne-tune models pre-trained with Ima-\ngeNet (Deng et al., 2009; Yosinski et al., 2014).\n3 BERT\nWe introduce BERT and its detailed implementa-\ntion in this section. There are two steps in our\nframework: pre-training and \ufb01ne-tuning . Dur-\ning pre-training, the model is trained on unlabeled"}, {"source": "N19-1423.pdf", "text": "data over different pre-training tasks. For \ufb01ne-\ntuning, the BERT model is \ufb01rst initialized with\nthe pre-trained parameters, and all of the param-\neters are \ufb01ne-tuned using labeled data from the\ndownstream tasks. Each downstream task has sep-\narate \ufb01ne-tuned models, even though they are ini-\ntialized with the same pre-trained parameters. The\nquestion-answering example in Figure 1 will serve"}, {"source": "N19-1423.pdf", "text": "as a running example for this section.\nA distinctive feature of BERT is its uni\ufb01ed ar-\nchitecture across different tasks. There is mini-mal difference between the pre-trained architec-\nture and the \ufb01nal downstream architecture.\nModel Architecture BERT\u2019s model architec-\nture is a multi-layer bidirectional Transformer en-\ncoder based on the original implementation de-"}, {"source": "N19-1423.pdf", "text": "scribed in Vaswani et al. (2017) and released in\nthetensor2tensor library.1Because the use\nof Transformers has become common and our im-\nplementation is almost identical to the original,\nwe will omit an exhaustive background descrip-\ntion of the model architecture and refer readers to\nVaswani et al. (2017) as well as excellent guides\nsuch as \u201cThe Annotated Transformer.\u201d2"}, {"source": "N19-1423.pdf", "text": "such as \u201cThe Annotated Transformer.\u201d2\nIn this work, we denote the number of layers\n(i.e., Transformer blocks) as L, the hidden size as\nH, and the number of self-attention heads as A.3\nWe primarily report results on two model sizes:\nBERT BASE (L=12, H=768, A=12, Total Param-\neters=110M) and BERT LARGE (L=24, H=1024,\nA=16, Total Parameters=340M).\nBERT BASE was chosen to have the same model"}, {"source": "N19-1423.pdf", "text": "size as OpenAI GPT for comparison purposes.\nCritically, however, the BERT Transformer uses\nbidirectional self-attention, while the GPT Trans-\nformer uses constrained self-attention where every\ntoken can only attend to context to its left.4\n1https://github.com/tensor\ufb02ow/tensor2tensor\n2http://nlp.seas.harvard.edu/2018/04/03/attention.html\n3In all cases we set the feed-forward/\ufb01lter size to be 4H,"}, {"source": "N19-1423.pdf", "text": "i.e., 3072 for the H= 768 and 4096 for the H= 1024 .\n4We note that in the literature the bidirectional Trans-4174Input/Output Representations To make BERT\nhandle a variety of down-stream tasks, our input\nrepresentation is able to unambiguously represent\nboth a single sentence and a pair of sentences\n(e.g.,hQuestion, Answeri) in one token sequence."}, {"source": "N19-1423.pdf", "text": "Throughout this work, a \u201csentence\u201d can be an arbi-\ntrary span of contiguous text, rather than an actual\nlinguistic sentence. A \u201csequence\u201d refers to the in-\nput token sequence to BERT, which may be a sin-\ngle sentence or two sentences packed together.\nWe use WordPiece embeddings (Wu et al.,\n2016) with a 30,000 token vocabulary. The \ufb01rst\ntoken of every sequence is always a special clas-"}, {"source": "N19-1423.pdf", "text": "si\ufb01cation token ( [CLS] ). The \ufb01nal hidden state\ncorresponding to this token is used as the ag-\ngregate sequence representation for classi\ufb01cation\ntasks. Sentence pairs are packed together into a\nsingle sequence. We differentiate the sentences in\ntwo ways. First, we separate them with a special\ntoken ( [SEP] ). Second, we add a learned embed-\nding to every token indicating whether it belongs"}, {"source": "N19-1423.pdf", "text": "to sentence Aor sentence B. As shown in Figure 1,\nwe denote input embedding as E, the \ufb01nal hidden\nvector of the special [CLS] token asC2RH,\nand the \ufb01nal hidden vector for the ithinput token\nasTi2RH.\nFor a given token, its input representation is\nconstructed by summing the corresponding token,\nsegment, and position embeddings. A visualiza-\ntion of this construction can be seen in Figure 2."}, {"source": "N19-1423.pdf", "text": "3.1 Pre-training BERT\nUnlike Peters et al. (2018a) and Radford et al.\n(2018), we do not use traditional left-to-right or\nright-to-left language models to pre-train BERT.\nInstead, we pre-train BERT using two unsuper-\nvised tasks, described in this section. This step\nis presented in the left part of Figure 1.\nTask #1: Masked LM Intuitively, it is reason-"}, {"source": "N19-1423.pdf", "text": "able to believe that a deep bidirectional model is\nstrictly more powerful than either a left-to-right\nmodel or the shallow concatenation of a left-to-\nright and a right-to-left model. Unfortunately,\nstandard conditional language models can only be\ntrained left-to-right orright-to-left, since bidirec-\ntional conditioning would allow each word to in-"}, {"source": "N19-1423.pdf", "text": "directly \u201csee itself\u201d, and the model could trivially\npredict the target word in a multi-layered context.\nformer is often referred to as a \u201cTransformer encoder\u201d while\nthe left-context-only version is referred to as a \u201cTransformer\ndecoder\u201d since it can be used for text generation.In order to train a deep bidirectional representa-\ntion, we simply mask some percentage of the input"}, {"source": "N19-1423.pdf", "text": "tokens at random, and then predict those masked\ntokens. We refer to this procedure as a \u201cmasked\nLM\u201d (MLM), although it is often referred to as a\nCloze task in the literature (Taylor, 1953). In this\ncase, the \ufb01nal hidden vectors corresponding to the\nmask tokens are fed into an output softmax over\nthe vocabulary, as in a standard LM. In all of our\nexperiments, we mask 15% of all WordPiece to-"}, {"source": "N19-1423.pdf", "text": "kens in each sequence at random. In contrast to\ndenoising auto-encoders (Vincent et al., 2008), we\nonly predict the masked words rather than recon-\nstructing the entire input.\nAlthough this allows us to obtain a bidirec-\ntional pre-trained model, a downside is that we\nare creating a mismatch between pre-training and\n\ufb01ne-tuning, since the [MASK] token does not ap-"}, {"source": "N19-1423.pdf", "text": "pear during \ufb01ne-tuning. To mitigate this, we do\nnot always replace \u201cmasked\u201d words with the ac-\ntual[MASK] token. The training data generator\nchooses 15% of the token positions at random for\nprediction. If the i-th token is chosen, we replace\nthei-th token with (1) the [MASK] token 80% of\nthe time (2) a random token 10% of the time (3)\nthe unchanged i-th token 10% of the time. Then,"}, {"source": "N19-1423.pdf", "text": "Tiwill be used to predict the original token with\ncross entropy loss. We compare variations of this\nprocedure in Appendix C.2.\nTask #2: Next Sentence Prediction (NSP)\nMany important downstream tasks such as Ques-\ntion Answering (QA) and Natural Language Infer-\nence (NLI) are based on understanding the rela-\ntionship between two sentences, which is not di-"}, {"source": "N19-1423.pdf", "text": "rectly captured by language modeling. In order\nto train a model that understands sentence rela-\ntionships, we pre-train for a binarized next sen-\ntence prediction task that can be trivially gener-\nated from any monolingual corpus. Speci\ufb01cally,\nwhen choosing the sentences AandBfor each pre-\ntraining example, 50% of the time Bis the actual\nnext sentence that follows A(labeled as IsNext ),"}, {"source": "N19-1423.pdf", "text": "and 50% of the time it is a random sentence from\nthe corpus (labeled as NotNext ). As we show\nin Figure 1, Cis used for next sentence predic-\ntion (NSP).5Despite its simplicity, we demon-\nstrate in Section 5.1 that pre-training towards this\ntask is very bene\ufb01cial to both QA and NLI.6\n5The \ufb01nal model achieves 97%-98% accuracy on NSP.\n6The vector Cis not a meaningful sentence representation"}, {"source": "N19-1423.pdf", "text": "without \ufb01ne-tuning, since it was trained with NSP.4175\n[CLS] helikesplay## ing[SEP] mydogiscute[SEP]Input \nE[CLS] Ehe Elikes Eplay E## ing E[SEP] Emy Edog Eis Ecute E[SEP] Token \nEmbeddings \nEA EB EB EB EB EB EA EA EA EA EASegment \nEmbeddings \nE0 E6 E7 E8 E9 E10 E1 E2 E3 E4 E5Position"}, {"source": "N19-1423.pdf", "text": "Embeddings Figure 2: BERT input representation. The input embeddings are the sum of the token embeddings, the segmenta-\ntion embeddings and the position embeddings.\nThe NSP task is closely related to representation-\nlearning objectives used in Jernite et al. (2017) and\nLogeswaran and Lee (2018). However, in prior\nwork, only sentence embeddings are transferred to"}, {"source": "N19-1423.pdf", "text": "down-stream tasks, where BERT transfers all pa-\nrameters to initialize end-task model parameters.\nPre-training data The pre-training procedure\nlargely follows the existing literature on language\nmodel pre-training. For the pre-training corpus we\nuse the BooksCorpus (800M words) (Zhu et al.,\n2015) and English Wikipedia (2,500M words).\nFor Wikipedia we extract only the text passages"}, {"source": "N19-1423.pdf", "text": "and ignore lists, tables, and headers. It is criti-\ncal to use a document-level corpus rather than a\nshuf\ufb02ed sentence-level corpus such as the Billion\nWord Benchmark (Chelba et al., 2013) in order to\nextract long contiguous sequences.\n3.2 Fine-tuning BERT\nFine-tuning is straightforward since the self-\nattention mechanism in the Transformer al-\nlows BERT to model many downstream tasks\u2014"}, {"source": "N19-1423.pdf", "text": "whether they involve single text or text pairs\u2014by\nswapping out the appropriate inputs and outputs.\nFor applications involving text pairs, a common\npattern is to independently encode text pairs be-\nfore applying bidirectional cross attention, such\nas Parikh et al. (2016); Seo et al. (2017). BERT\ninstead uses the self-attention mechanism to unify\nthese two stages, as encoding a concatenated text"}, {"source": "N19-1423.pdf", "text": "pair with self-attention effectively includes bidi-\nrectional cross attention between two sentences.\nFor each task, we simply plug in the task-\nspeci\ufb01c inputs and outputs into BERT and \ufb01ne-\ntune all the parameters end-to-end. At the in-\nput, sentence Aand sentence Bfrom pre-training\nare analogous to (1) sentence pairs in paraphras-\ning, (2) hypothesis-premise pairs in entailment, (3)"}, {"source": "N19-1423.pdf", "text": "question-passage pairs in question answering, and(4) a degenerate text- ?pair in text classi\ufb01cation\nor sequence tagging. At the output, the token rep-\nresentations are fed into an output layer for token-\nlevel tasks, such as sequence tagging or question\nanswering, and the [CLS] representation is fed\ninto an output layer for classi\ufb01cation, such as en-\ntailment or sentiment analysis."}, {"source": "N19-1423.pdf", "text": "tailment or sentiment analysis.\nCompared to pre-training, \ufb01ne-tuning is rela-\ntively inexpensive. All of the results in the pa-\nper can be replicated in at most 1 hour on a sin-\ngle Cloud TPU, or a few hours on a GPU, starting\nfrom the exact same pre-trained model.7We de-\nscribe the task-speci\ufb01c details in the correspond-\ning subsections of Section 4. More details can be\nfound in Appendix A.5."}, {"source": "N19-1423.pdf", "text": "found in Appendix A.5.\n4 Experiments\nIn this section, we present BERT \ufb01ne-tuning re-\nsults on 11 NLP tasks.\n4.1 GLUE\nThe General Language Understanding Evaluation\n(GLUE) benchmark (Wang et al., 2018a) is a col-\nlection of diverse natural language understanding\ntasks. Detailed descriptions of GLUE datasets are\nincluded in Appendix B.1.\nTo \ufb01ne-tune on GLUE, we represent the input"}, {"source": "N19-1423.pdf", "text": "sequence (for single sentence or sentence pairs)\nas described in Section 3, and use the \ufb01nal hid-\nden vectorC2RHcorresponding to the \ufb01rst\ninput token ( [CLS] ) as the aggregate representa-\ntion. The only new parameters introduced during\n\ufb01ne-tuning are classi\ufb01cation layer weights W2\nRK\u0002H, whereKis the number of labels. We com-\npute a standard classi\ufb01cation loss with CandW,\ni.e.,log(softmax( CWT))."}, {"source": "N19-1423.pdf", "text": "i.e.,log(softmax( CWT)).\n7For example, the BERT SQuAD model can be trained in\naround 30 minutes on a single Cloud TPU to achieve a Dev\nF1 score of 91.0%.\n8See (10) in https://gluebenchmark.com/faq .4176System MNLI-(m/mm) QQP QNLI SST-2 CoLA STS-B MRPC RTE Average\n392k 363k 108k 67k 8.5k 5.7k 3.5k 2.5k -\nPre-OpenAI SOTA 80.6/80.1 66.1 82.3 93.2 35.0 81.0 86.0 61.7 74.0"}, {"source": "N19-1423.pdf", "text": "BiLSTM+ELMo+Attn 76.4/76.1 64.8 79.8 90.4 36.0 73.3 84.9 56.8 71.0\nOpenAI GPT 82.1/81.4 70.3 87.4 91.3 45.4 80.0 82.3 56.0 75.1\nBERT BASE 84.6/83.4 71.2 90.5 93.5 52.1 85.8 88.9 66.4 79.6\nBERT LARGE 86.7/85.9 72.1 92.7 94.9 60.5 86.5 89.3 70.1 82.1\nTable 1: GLUE Test results, scored by the evaluation server ( https://gluebenchmark.com/leaderboard )."}, {"source": "N19-1423.pdf", "text": "The number below each task denotes the number of training examples. The \u201cAverage\u201d column is slightly different\nthan the of\ufb01cial GLUE score, since we exclude the problematic WNLI set.8BERT and OpenAI GPT are single-\nmodel, single task. F1 scores are reported for QQP and MRPC, Spearman correlations are reported for STS-B, and"}, {"source": "N19-1423.pdf", "text": "accuracy scores are reported for the other tasks. We exclude entries that use BERT as one of their components.\nWe use a batch size of 32 and \ufb01ne-tune for 3\nepochs over the data for all GLUE tasks. For each\ntask, we selected the best \ufb01ne-tuning learning rate\n(among 5e-5, 4e-5, 3e-5, and 2e-5) on the Dev set.\nAdditionally, for BERT LARGE we found that \ufb01ne-"}, {"source": "N19-1423.pdf", "text": "tuning was sometimes unstable on small datasets,\nso we ran several random restarts and selected the\nbest model on the Dev set. With random restarts,\nwe use the same pre-trained checkpoint but per-\nform different \ufb01ne-tuning data shuf\ufb02ing and clas-\nsi\ufb01er layer initialization.9\nResults are presented in Table 1. Both\nBERT BASE and BERT LARGE outperform all sys-"}, {"source": "N19-1423.pdf", "text": "tems on all tasks by a substantial margin, obtaining\n4.5% and 7.0% respective average accuracy im-\nprovement over the prior state of the art. Note that\nBERT BASE and OpenAI GPT are nearly identical\nin terms of model architecture apart from the at-\ntention masking. For the largest and most widely\nreported GLUE task, MNLI, BERT obtains a 4.6%\nabsolute accuracy improvement. On the of\ufb01cial"}, {"source": "N19-1423.pdf", "text": "GLUE leaderboard10, BERT LARGE obtains a score\nof 80.5, compared to OpenAI GPT, which obtains\n72.8 as of the date of writing.\nWe \ufb01nd that BERT LARGE signi\ufb01cantly outper-\nforms BERT BASE across all tasks, especially those\nwith very little training data. The effect of model\nsize is explored more thoroughly in Section 5.2.\n4.2 SQuAD v1.1\nThe Stanford Question Answering Dataset"}, {"source": "N19-1423.pdf", "text": "The Stanford Question Answering Dataset\n(SQuAD v1.1) is a collection of 100k crowd-\nsourced question/answer pairs (Rajpurkar et al.,\n2016). Given a question and a passage from\n9The GLUE data set distribution does not include the Test\nlabels, and we only made a single GLUE evaluation server\nsubmission for each of BERT BASE and BERT LARGE ."}, {"source": "N19-1423.pdf", "text": "10https://gluebenchmark.com/leaderboardWikipedia containing the answer, the task is to\npredict the answer text span in the passage.\nAs shown in Figure 1, in the question answer-\ning task, we represent the input question and pas-\nsage as a single packed sequence, with the ques-\ntion using the Aembedding and the passage using\ntheBembedding. We only introduce a start vec-"}, {"source": "N19-1423.pdf", "text": "torS2RHand an end vector E2RHduring\n\ufb01ne-tuning. The probability of word ibeing the\nstart of the answer span is computed as a dot prod-\nuct between TiandSfollowed by a softmax over\nall of the words in the paragraph: Pi=eS\u0001TiP\njeS\u0001Tj.\nThe analogous formula is used for the end of the\nanswer span. The score of a candidate span from\npositionito positionjis de\ufb01ned as S\u0001Ti+E\u0001Tj,"}, {"source": "N19-1423.pdf", "text": "and the maximum scoring span where j\u0015iis\nused as a prediction. The training objective is the\nsum of the log-likelihoods of the correct start and\nend positions. We \ufb01ne-tune for 3 epochs with a\nlearning rate of 5e-5 and a batch size of 32.\nTable 2 shows top leaderboard entries as well\nas results from top published systems (Seo et al.,\n2017; Clark and Gardner, 2018; Peters et al.,"}, {"source": "N19-1423.pdf", "text": "2018a; Hu et al., 2018). The top results from the\nSQuAD leaderboard do not have up-to-date public\nsystem descriptions available,11and are allowed to\nuse any public data when training their systems.\nWe therefore use modest data augmentation in\nour system by \ufb01rst \ufb01ne-tuning on TriviaQA (Joshi\net al., 2017) befor \ufb01ne-tuning on SQuAD.\nOur best performing system outperforms the top"}, {"source": "N19-1423.pdf", "text": "leaderboard system by +1.5 F1 in ensembling and\n+1.3 F1 as a single system. In fact, our single\nBERT model outperforms the top ensemble sys-\ntem in terms of F1 score. Without TriviaQA \ufb01ne-\n11QANet is described in Yu et al. (2018), but the system\nhas improved substantially after publication.4177System Dev Test\nEM F1 EM F1\nTop Leaderboard Systems (Dec 10th, 2018)\nHuman - - 82.3 91.2"}, {"source": "N19-1423.pdf", "text": "Human - - 82.3 91.2\n#1 Ensemble - nlnet - - 86.0 91.7\n#2 Ensemble - QANet - - 84.5 90.5\nPublished\nBiDAF+ELMo (Single) - 85.6 - 85.8\nR.M. Reader (Ensemble) 81.2 87.9 82.3 88.5\nOurs\nBERT BASE (Single) 80.8 88.5 - -\nBERT LARGE (Single) 84.1 90.9 - -\nBERT LARGE (Ensemble) 85.8 91.8 - -\nBERT LARGE (Sgl.+TriviaQA) 84.2 91.1 85.1 91.8\nBERT LARGE (Ens.+TriviaQA) 86.2 92.2 87.4 93.2"}, {"source": "N19-1423.pdf", "text": "Table 2: SQuAD 1.1 results. The BERT ensemble\nis 7x systems which use different pre-training check-\npoints and \ufb01ne-tuning seeds.\nSystem Dev Test\nEM F1 EM F1\nTop Leaderboard Systems (Dec 10th, 2018)\nHuman 86.3 89.0 86.9 89.5\n#1 Single - MIR-MRC (F-Net) - - 74.8 78.0\n#2 Single - nlnet - - 74.2 77.1\nPublished\nunet (Ensemble) - - 71.4 74.9\nSLQA+ (Single) - 71.4 74.4\nOurs"}, {"source": "N19-1423.pdf", "text": "SLQA+ (Single) - 71.4 74.4\nOurs\nBERT LARGE (Single) 78.7 81.9 80.0 83.1\nTable 3: SQuAD 2.0 results. We exclude entries that\nuse BERT as one of their components.\ntuning data, we only lose 0.1-0.4 F1, still outper-\nforming all existing systems by a wide margin.12\n4.3 SQuAD v2.0\nThe SQuAD 2.0 task extends the SQuAD 1.1\nproblem de\ufb01nition by allowing for the possibility"}, {"source": "N19-1423.pdf", "text": "that no short answer exists in the provided para-\ngraph, making the problem more realistic.\nWe use a simple approach to extend the SQuAD\nv1.1 BERT model for this task. We treat ques-\ntions that do not have an answer as having an an-\nswer span with start and end at the [CLS] to-\nken. The probability space for the start and end\nanswer span positions is extended to include the"}, {"source": "N19-1423.pdf", "text": "position of the [CLS] token. For prediction, we\ncompare the score of the no-answer span: snull=\nS\u0001C+E\u0001Cto the score of the best non-null span\n12The TriviaQA data we used consists of paragraphs from\nTriviaQA-Wiki formed of the \ufb01rst 400 tokens in documents,\nthat contain at least one of the provided possible answers.System Dev Test\nESIM+GloVe 51.9 52.7\nESIM+ELMo 59.1 59.2\nOpenAI GPT - 78.0"}, {"source": "N19-1423.pdf", "text": "ESIM+ELMo 59.1 59.2\nOpenAI GPT - 78.0\nBERT BASE 81.6 -\nBERT LARGE 86.6 86.3\nHuman (expert)y- 85.0\nHuman (5 annotations)y- 88.0\nTable 4: SWAG Dev and Test accuracies.yHuman per-\nformance is measured with 100 samples, as reported in\nthe SWAG paper.\n^si;j=maxj\u0015iS\u0001Ti+E\u0001Tj. We predict a non-null\nanswer when ^si;j> s null+\u001c, where the thresh-\nold\u001cis selected on the dev set to maximize F1."}, {"source": "N19-1423.pdf", "text": "We did not use TriviaQA data for this model. We\n\ufb01ne-tuned for 2 epochs with a learning rate of 5e-5\nand a batch size of 48.\nThe results compared to prior leaderboard en-\ntries and top published work (Sun et al., 2018;\nWang et al., 2018b) are shown in Table 3, exclud-\ning systems that use BERT as one of their com-\nponents. We observe a +5.1 F1 improvement over\nthe previous best system.\n4.4 SWAG"}, {"source": "N19-1423.pdf", "text": "the previous best system.\n4.4 SWAG\nThe Situations With Adversarial Generations\n(SWAG) dataset contains 113k sentence-pair com-\npletion examples that evaluate grounded common-\nsense inference (Zellers et al., 2018). Given a sen-\ntence, the task is to choose the most plausible con-\ntinuation among four choices.\nWhen \ufb01ne-tuning on the SWAG dataset, we\nconstruct four input sequences, each containing"}, {"source": "N19-1423.pdf", "text": "the concatenation of the given sentence (sentence\nA) and a possible continuation (sentence B). The\nonly task-speci\ufb01c parameters introduced is a vec-\ntor whose dot product with the [CLS] token rep-\nresentation Cdenotes a score for each choice\nwhich is normalized with a softmax layer.\nWe \ufb01ne-tune the model for 3 epochs with a\nlearning rate of 2e-5 and a batch size of 16. Re-"}, {"source": "N19-1423.pdf", "text": "sults are presented in Table 4. BERT LARGE out-\nperforms the authors\u2019 baseline ESIM+ELMo sys-\ntem by +27.1% and OpenAI GPT by 8.3%.\n5 Ablation Studies\nIn this section, we perform ablation experiments\nover a number of facets of BERT in order to better\nunderstand their relative importance. Additional4178Dev Set\nTasks MNLI-m QNLI MRPC SST-2 SQuAD\n(Acc) (Acc) (Acc) (Acc) (F1)"}, {"source": "N19-1423.pdf", "text": "(Acc) (Acc) (Acc) (Acc) (F1)\nBERT BASE 84.4 88.4 86.7 92.7 88.5\nNo NSP 83.9 84.9 86.5 92.6 87.9\nLTR & No NSP 82.1 84.3 77.5 92.1 77.8\n+ BiLSTM 82.1 84.1 75.7 91.6 84.9\nTable 5: Ablation over the pre-training tasks using the\nBERT BASE architecture. \u201cNo NSP\u201d is trained without\nthe next sentence prediction task. \u201cLTR & No NSP\u201d is\ntrained as a left-to-right LM without the next sentence"}, {"source": "N19-1423.pdf", "text": "prediction, like OpenAI GPT. \u201c+ BiLSTM\u201d adds a ran-\ndomly initialized BiLSTM on top of the \u201cLTR + No\nNSP\u201d model during \ufb01ne-tuning.\nablation studies can be found in Appendix C.\n5.1 Effect of Pre-training Tasks\nWe demonstrate the importance of the deep bidi-\nrectionality of BERT by evaluating two pre-\ntraining objectives using exactly the same pre-\ntraining data, \ufb01ne-tuning scheme, and hyperpa-"}, {"source": "N19-1423.pdf", "text": "rameters as BERT BASE :\nNo NSP : A bidirectional model which is trained\nusing the \u201cmasked LM\u201d (MLM) but without the\n\u201cnext sentence prediction\u201d (NSP) task.\nLTR & No NSP : A left-context-only model which\nis trained using a standard Left-to-Right (LTR)\nLM, rather than an MLM. The left-only constraint\nwas also applied at \ufb01ne-tuning, because removing\nit introduced a pre-train/\ufb01ne-tune mismatch that"}, {"source": "N19-1423.pdf", "text": "degraded downstream performance. Additionally,\nthis model was pre-trained without the NSP task.\nThis is directly comparable to OpenAI GPT, but\nusing our larger training dataset, our input repre-\nsentation, and our \ufb01ne-tuning scheme.\nWe \ufb01rst examine the impact brought by the NSP\ntask. In Table 5, we show that removing NSP\nhurts performance signi\ufb01cantly on QNLI, MNLI,"}, {"source": "N19-1423.pdf", "text": "and SQuAD 1.1. Next, we evaluate the impact\nof training bidirectional representations by com-\nparing \u201cNo NSP\u201d to \u201cLTR & No NSP\u201d. The LTR\nmodel performs worse than the MLM model on all\ntasks, with large drops on MRPC and SQuAD.\nFor SQuAD it is intuitively clear that a LTR\nmodel will perform poorly at token predictions,\nsince the token-level hidden states have no right-"}, {"source": "N19-1423.pdf", "text": "side context. In order to make a good faith at-\ntempt at strengthening the LTR system, we added\na randomly initialized BiLSTM on top. This does\nsigni\ufb01cantly improve results on SQuAD, but theresults are still far worse than those of the pre-\ntrained bidirectional models. The BiLSTM hurts\nperformance on the GLUE tasks.\nWe recognize that it would also be possible to"}, {"source": "N19-1423.pdf", "text": "train separate LTR and RTL models and represent\neach token as the concatenation of the two mod-\nels, as ELMo does. However: (a) this is twice as\nexpensive as a single bidirectional model; (b) this\nis non-intuitive for tasks like QA, since the RTL\nmodel would not be able to condition the answer\non the question; (c) this it is strictly less powerful\nthan a deep bidirectional model, since it can use"}, {"source": "N19-1423.pdf", "text": "both left and right context at every layer.\n5.2 Effect of Model Size\nIn this section, we explore the effect of model size\non \ufb01ne-tuning task accuracy. We trained a number\nof BERT models with a differing number of layers,\nhidden units, and attention heads, while otherwise\nusing the same hyperparameters and training pro-\ncedure as described previously.\nResults on selected GLUE tasks are shown in"}, {"source": "N19-1423.pdf", "text": "Table 6. In this table, we report the average Dev\nSet accuracy from 5 random restarts of \ufb01ne-tuning.\nWe can see that larger models lead to a strict ac-\ncuracy improvement across all four datasets, even\nfor MRPC which only has 3,600 labeled train-\ning examples, and is substantially different from\nthe pre-training tasks. It is also perhaps surpris-\ning that we are able to achieve such signi\ufb01cant"}, {"source": "N19-1423.pdf", "text": "improvements on top of models which are al-\nready quite large relative to the existing literature.\nFor example, the largest Transformer explored in\nVaswani et al. (2017) is (L=6, H=1024, A=16)\nwith 100M parameters for the encoder, and the\nlargest Transformer we have found in the literature\nis (L=64, H=512, A=2) with 235M parameters\n(Al-Rfou et al., 2018). By contrast, BERT BASE"}, {"source": "N19-1423.pdf", "text": "contains 110M parameters and BERT LARGE con-\ntains 340M parameters.\nIt has long been known that increasing the\nmodel size will lead to continual improvements\non large-scale tasks such as machine translation\nand language modeling, which is demonstrated\nby the LM perplexity of held-out training data\nshown in Table 6. However, we believe that\nthis is the \ufb01rst work to demonstrate convinc-"}, {"source": "N19-1423.pdf", "text": "ingly that scaling to extreme model sizes also\nleads to large improvements on very small scale\ntasks, provided that the model has been suf\ufb01-\nciently pre-trained. Peters et al. (2018b) presented4179mixed results on the downstream task impact of\nincreasing the pre-trained bi-LM size from two\nto four layers and Melamud et al. (2016) men-\ntioned in passing that increasing hidden dimen-"}, {"source": "N19-1423.pdf", "text": "sion size from 200 to 600 helped, but increasing\nfurther to 1,000 did not bring further improve-\nments. Both of these prior works used a feature-\nbased approach \u2014 we hypothesize that when the\nmodel is \ufb01ne-tuned directly on the downstream\ntasks and uses only a very small number of ran-\ndomly initialized additional parameters, the task-\nspeci\ufb01c models can bene\ufb01t from the larger, more"}, {"source": "N19-1423.pdf", "text": "expressive pre-trained representations even when\ndownstream task data is very small.\n5.3 Feature-based Approach with BERT\nAll of the BERT results presented so far have used\nthe \ufb01ne-tuning approach, where a simple classi\ufb01-\ncation layer is added to the pre-trained model, and\nall parameters are jointly \ufb01ne-tuned on a down-\nstream task. However, the feature-based approach,"}, {"source": "N19-1423.pdf", "text": "where \ufb01xed features are extracted from the pre-\ntrained model, has certain advantages. First, not\nall tasks can be easily represented by a Trans-\nformer encoder architecture, and therefore require\na task-speci\ufb01c model architecture to be added.\nSecond, there are major computational bene\ufb01ts\nto pre-compute an expensive representation of the\ntraining data once and then run many experiments"}, {"source": "N19-1423.pdf", "text": "with cheaper models on top of this representation.\nIn this section, we compare the two approaches\nby applying BERT to the CoNLL-2003 Named\nEntity Recognition (NER) task (Tjong Kim Sang\nand De Meulder, 2003). In the input to BERT, we\nuse a case-preserving WordPiece model, and we\ninclude the maximal document context provided\nby the data. Following standard practice, we for-"}, {"source": "N19-1423.pdf", "text": "mulate this as a tagging task but do not use a CRF\nHyperparams Dev Set Accuracy\n#L #H #A LM (ppl) MNLI-m MRPC SST-2\n3 768 12 5.84 77.9 79.8 88.4\n6 768 3 5.24 80.6 82.2 90.7\n6 768 12 4.68 81.9 84.8 91.3\n12 768 12 3.99 84.4 86.7 92.9\n12 1024 16 3.54 85.7 86.9 93.3\n24 1024 16 3.23 86.6 87.8 93.7\nTable 6: Ablation over BERT model size. #L = the\nnumber of layers; #H = hidden size; #A = number of at-"}, {"source": "N19-1423.pdf", "text": "tention heads. \u201cLM (ppl)\u201d is the masked LM perplexity\nof held-out training data.System Dev F1 Test F1\nELMo (Peters et al., 2018a) 95.7 92.2\nCVT (Clark et al., 2018) - 92.6\nCSE (Akbik et al., 2018) - 93.1\nFine-tuning approach\nBERT LARGE 96.6 92.8\nBERT BASE 96.4 92.4\nFeature-based approach (BERT BASE)\nEmbeddings 91.0 -\nSecond-to-Last Hidden 95.6 -\nLast Hidden 94.9 -"}, {"source": "N19-1423.pdf", "text": "Last Hidden 94.9 -\nWeighted Sum Last Four Hidden 95.9 -\nConcat Last Four Hidden 96.1 -\nWeighted Sum All 12 Layers 95.5 -\nTable 7: CoNLL-2003 Named Entity Recognition re-\nsults. Hyperparameters were selected using the Dev\nset. The reported Dev and Test scores are averaged over\n5 random restarts using those hyperparameters.\nlayer in the output. We use the representation of"}, {"source": "N19-1423.pdf", "text": "the \ufb01rst sub-token as the input to the token-level\nclassi\ufb01er over the NER label set.\nTo ablate the \ufb01ne-tuning approach, we apply the\nfeature-based approach by extracting the activa-\ntions from one or more layers without \ufb01ne-tuning\nany parameters of BERT. These contextual em-\nbeddings are used as input to a randomly initial-\nized two-layer 768-dimensional BiLSTM before\nthe classi\ufb01cation layer."}, {"source": "N19-1423.pdf", "text": "the classi\ufb01cation layer.\nResults are presented in Table 7. BERT LARGE\nperforms competitively with state-of-the-art meth-\nods. The best performing method concatenates the\ntoken representations from the top four hidden lay-\ners of the pre-trained Transformer, which is only\n0.3 F1 behind \ufb01ne-tuning the entire model. This\ndemonstrates that BERT is effective for both \ufb01ne-"}, {"source": "N19-1423.pdf", "text": "tuning and feature-based approaches.\n6 Conclusion\nRecent empirical improvements due to transfer\nlearning with language models have demonstrated\nthat rich, unsupervised pre-training is an integral\npart of many language understanding systems. In\nparticular, these results enable even low-resource\ntasks to bene\ufb01t from deep unidirectional architec-\ntures. Our major contribution is further general-"}, {"source": "N19-1423.pdf", "text": "izing these \ufb01ndings to deep bidirectional architec-\ntures, allowing the same pre-trained model to suc-\ncessfully tackle a broad set of NLP tasks.4180References\nAlan Akbik, Duncan Blythe, and Roland V ollgraf.\n2018. Contextual string embeddings for sequence\nlabeling. In Proceedings of the 27th International\nConference on Computational Linguistics , pages\n1638\u20131649."}, {"source": "N19-1423.pdf", "text": "1638\u20131649.\nRami Al-Rfou, Dokook Choe, Noah Constant, Mandy\nGuo, and Llion Jones. 2018. Character-level lan-\nguage modeling with deeper self-attention. arXiv\npreprint arXiv:1808.04444 .\nRie Kubota Ando and Tong Zhang. 2005. A framework\nfor learning predictive structures from multiple tasks\nand unlabeled data. Journal of Machine Learning\nResearch , 6(Nov):1817\u20131853."}, {"source": "N19-1423.pdf", "text": "Research , 6(Nov):1817\u20131853.\nLuisa Bentivogli, Bernardo Magnini, Ido Dagan,\nHoa Trang Dang, and Danilo Giampiccolo. 2009.\nThe \ufb01fth PASCAL recognizing textual entailment\nchallenge. In TAC. NIST.\nJohn Blitzer, Ryan McDonald, and Fernando Pereira.\n2006. Domain adaptation with structural correspon-\ndence learning. In Proceedings of the 2006 confer-\nence on empirical methods in natural language pro-"}, {"source": "N19-1423.pdf", "text": "cessing , pages 120\u2013128. Association for Computa-\ntional Linguistics.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nInEMNLP . Association for Computational Linguis-\ntics.\nPeter F Brown, Peter V Desouza, Robert L Mercer,\nVincent J Della Pietra, and Jenifer C Lai. 1992."}, {"source": "N19-1423.pdf", "text": "Class-based n-gram models of natural language.\nComputational linguistics , 18(4):467\u2013479.\nDaniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-\nGazpio, and Lucia Specia. 2017. Semeval-2017\ntask 1: Semantic textual similarity multilingual and\ncrosslingual focused evaluation. In Proceedings\nof the 11th International Workshop on Semantic\nEvaluation (SemEval-2017) , pages 1\u201314, Vancou-"}, {"source": "N19-1423.pdf", "text": "ver, Canada. Association for Computational Lin-\nguistics.\nCiprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge,\nThorsten Brants, Phillipp Koehn, and Tony Robin-\nson. 2013. One billion word benchmark for measur-\ning progress in statistical language modeling. arXiv\npreprint arXiv:1312.3005 .\nZ. Chen, H. Zhang, X. Zhang, and L. Zhao. 2018.\nQuora question pairs."}, {"source": "N19-1423.pdf", "text": "Quora question pairs.\nChristopher Clark and Matt Gardner. 2018. Simple\nand effective multi-paragraph reading comprehen-\nsion. In ACL.Kevin Clark, Minh-Thang Luong, Christopher D Man-\nning, and Quoc Le. 2018. Semi-supervised se-\nquence modeling with cross-view training. In Pro-\nceedings of the 2018 Conference on Empirical Meth-\nods in Natural Language Processing , pages 1914\u2013\n1925."}, {"source": "N19-1423.pdf", "text": "1925.\nRonan Collobert and Jason Weston. 2008. A uni\ufb01ed\narchitecture for natural language processing: Deep\nneural networks with multitask learning. In Pro-\nceedings of the 25th international conference on\nMachine learning , pages 160\u2013167. ACM.\nAlexis Conneau, Douwe Kiela, Holger Schwenk, Lo \u00a8\u0131c\nBarrault, and Antoine Bordes. 2017. Supervised\nlearning of universal sentence representations from"}, {"source": "N19-1423.pdf", "text": "natural language inference data. In Proceedings of\nthe 2017 Conference on Empirical Methods in Nat-\nural Language Processing , pages 670\u2013680, Copen-\nhagen, Denmark. Association for Computational\nLinguistics.\nAndrew M Dai and Quoc V Le. 2015. Semi-supervised\nsequence learning. In Advances in neural informa-\ntion processing systems , pages 3079\u20133087."}, {"source": "N19-1423.pdf", "text": "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-\nFei. 2009. ImageNet: A Large-Scale Hierarchical\nImage Database. In CVPR09 .\nWilliam B Dolan and Chris Brockett. 2005. Automati-\ncally constructing a corpus of sentential paraphrases.\nInProceedings of the Third International Workshop\non Paraphrasing (IWP2005) .\nWilliam Fedus, Ian Goodfellow, and Andrew M Dai."}, {"source": "N19-1423.pdf", "text": "2018. Maskgan: Better text generation via \ufb01lling in\nthe.arXiv preprint arXiv:1801.07736 .\nDan Hendrycks and Kevin Gimpel. 2016. Bridging\nnonlinearities and stochastic regularizers with gaus-\nsian error linear units. CoRR , abs/1606.08415.\nFelix Hill, Kyunghyun Cho, and Anna Korhonen. 2016.\nLearning distributed representations of sentences\nfrom unlabelled data. In Proceedings of the 2016"}, {"source": "N19-1423.pdf", "text": "Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies . Association for Computa-\ntional Linguistics.\nJeremy Howard and Sebastian Ruder. 2018. Universal\nlanguage model \ufb01ne-tuning for text classi\ufb01cation. In\nACL. Association for Computational Linguistics.\nMinghao Hu, Yuxing Peng, Zhen Huang, Xipeng Qiu,"}, {"source": "N19-1423.pdf", "text": "Furu Wei, and Ming Zhou. 2018. Reinforced\nmnemonic reader for machine reading comprehen-\nsion. In IJCAI .\nYacine Jernite, Samuel R. Bowman, and David Son-\ntag. 2017. Discourse-based objectives for fast un-\nsupervised sentence representation learning. CoRR ,\nabs/1705.00557.4181Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke\nZettlemoyer. 2017. Triviaqa: A large scale distantly"}, {"source": "N19-1423.pdf", "text": "supervised challenge dataset for reading comprehen-\nsion. In ACL.\nRyan Kiros, Yukun Zhu, Ruslan R Salakhutdinov,\nRichard Zemel, Raquel Urtasun, Antonio Torralba,\nand Sanja Fidler. 2015. Skip-thought vectors. In\nAdvances in neural information processing systems ,\npages 3294\u20133302.\nQuoc Le and Tomas Mikolov. 2014. Distributed rep-\nresentations of sentences and documents. In Inter-"}, {"source": "N19-1423.pdf", "text": "national Conference on Machine Learning , pages\n1188\u20131196.\nHector J Levesque, Ernest Davis, and Leora Morgen-\nstern. 2011. The winograd schema challenge. In\nAaai spring symposium: Logical formalizations of\ncommonsense reasoning , volume 46, page 47.\nLajanugen Logeswaran and Honglak Lee. 2018. An\nef\ufb01cient framework for learning sentence represen-\ntations. In International Conference on Learning"}, {"source": "N19-1423.pdf", "text": "Representations .\nBryan McCann, James Bradbury, Caiming Xiong, and\nRichard Socher. 2017. Learned in translation: Con-\ntextualized word vectors. In NIPS .\nOren Melamud, Jacob Goldberger, and Ido Dagan.\n2016. context2vec: Learning generic context em-\nbedding with bidirectional LSTM. In CoNLL .\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-\nrado, and Jeff Dean. 2013. Distributed representa-"}, {"source": "N19-1423.pdf", "text": "tions of words and phrases and their compositional-\nity. In Advances in Neural Information Processing\nSystems 26 , pages 3111\u20133119. Curran Associates,\nInc.\nAndriy Mnih and Geoffrey E Hinton. 2009. A scal-\nable hierarchical distributed language model. In\nD. Koller, D. Schuurmans, Y . Bengio, and L. Bot-\ntou, editors, Advances in Neural Information Pro-"}, {"source": "N19-1423.pdf", "text": "cessing Systems 21 , pages 1081\u20131088. Curran As-\nsociates, Inc.\nAnkur P Parikh, Oscar T \u00a8ackstr \u00a8om, Dipanjan Das, and\nJakob Uszkoreit. 2016. A decomposable attention\nmodel for natural language inference. In EMNLP .\nJeffrey Pennington, Richard Socher, and Christo-\npher D. Manning. 2014. Glove: Global vectors for\nword representation. In Empirical Methods in Nat-"}, {"source": "N19-1423.pdf", "text": "ural Language Processing (EMNLP) , pages 1532\u2013\n1543.\nMatthew Peters, Waleed Ammar, Chandra Bhagavat-\nula, and Russell Power. 2017. Semi-supervised se-\nquence tagging with bidirectional language models.\nInACL.\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018a. Deep contextualized word rep-"}, {"source": "N19-1423.pdf", "text": "resentations. In NAACL .Matthew Peters, Mark Neumann, Luke Zettlemoyer,\nand Wen-tau Yih. 2018b. Dissecting contextual\nword embeddings: Architecture and representation.\nInProceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing , pages\n1499\u20131509.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-"}, {"source": "N19-1423.pdf", "text": "standing with unsupervised learning. Technical re-\nport, OpenAI.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. Squad: 100,000+ questions for\nmachine comprehension of text. In Proceedings of\nthe 2016 Conference on Empirical Methods in Nat-\nural Language Processing , pages 2383\u20132392.\nMinjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and"}, {"source": "N19-1423.pdf", "text": "Hannaneh Hajishirzi. 2017. Bidirectional attention\n\ufb02ow for machine comprehension. In ICLR .\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models\nfor semantic compositionality over a sentiment tree-\nbank. In Proceedings of the 2013 conference on\nempirical methods in natural language processing ,\npages 1631\u20131642."}, {"source": "N19-1423.pdf", "text": "pages 1631\u20131642.\nFu Sun, Linyang Li, Xipeng Qiu, and Yang Liu.\n2018. U-net: Machine reading comprehension\nwith unanswerable questions. arXiv preprint\narXiv:1810.06638 .\nWilson L Taylor. 1953. Cloze procedure: A new\ntool for measuring readability. Journalism Bulletin ,\n30(4):415\u2013433.\nErik F Tjong Kim Sang and Fien De Meulder.\n2003. Introduction to the conll-2003 shared task:"}, {"source": "N19-1423.pdf", "text": "Language-independent named entity recognition. In\nCoNLL .\nJoseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.\nWord representations: A simple and general method\nfor semi-supervised learning. In Proceedings of the\n48th Annual Meeting of the Association for Compu-\ntational Linguistics , ACL \u201910, pages 384\u2013394.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob"}, {"source": "N19-1423.pdf", "text": "Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems , pages 6000\u20136010.\nPascal Vincent, Hugo Larochelle, Yoshua Bengio, and\nPierre-Antoine Manzagol. 2008. Extracting and\ncomposing robust features with denoising autoen-\ncoders. In Proceedings of the 25th international"}, {"source": "N19-1423.pdf", "text": "conference on Machine learning , pages 1096\u20131103.\nACM.\nAlex Wang, Amanpreet Singh, Julian Michael, Fe-\nlix Hill, Omer Levy, and Samuel Bowman. 2018a.\nGlue: A multi-task benchmark and analysis platform4182for natural language understanding. In Proceedings\nof the 2018 EMNLP Workshop BlackboxNLP: An-\nalyzing and Interpreting Neural Networks for NLP ,\npages 353\u2013355."}, {"source": "N19-1423.pdf", "text": "pages 353\u2013355.\nWei Wang, Ming Yan, and Chen Wu. 2018b. Multi-\ngranularity hierarchical attention fusion networks\nfor reading comprehension and question answering.\nInProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers) . Association for Computational Lin-\nguistics.\nAlex Warstadt, Amanpreet Singh, and Samuel R Bow-"}, {"source": "N19-1423.pdf", "text": "man. 2018. Neural network acceptability judg-\nments. arXiv preprint arXiv:1805.12471 .\nAdina Williams, Nikita Nangia, and Samuel R Bow-\nman. 2018. A broad-coverage challenge corpus\nfor sentence understanding through inference. In\nNAACL .\nYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V\nLe, Mohammad Norouzi, Wolfgang Macherey,\nMaxim Krikun, Yuan Cao, Qin Gao, Klaus"}, {"source": "N19-1423.pdf", "text": "Maxim Krikun, Yuan Cao, Qin Gao, Klaus\nMacherey, et al. 2016. Google\u2019s neural ma-\nchine translation system: Bridging the gap between\nhuman and machine translation. arXiv preprint\narXiv:1609.08144 .\nJason Yosinski, Jeff Clune, Yoshua Bengio, and Hod\nLipson. 2014. How transferable are features in deep\nneural networks? In Advances in neural information\nprocessing systems , pages 3320\u20133328."}, {"source": "N19-1423.pdf", "text": "processing systems , pages 3320\u20133328.\nAdams Wei Yu, David Dohan, Minh-Thang Luong, Rui\nZhao, Kai Chen, Mohammad Norouzi, and Quoc V\nLe. 2018. QANet: Combining local convolution\nwith global self-attention for reading comprehen-\nsion. In ICLR .\nRowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin\nChoi. 2018. Swag: A large-scale adversarial dataset\nfor grounded commonsense inference. In Proceed-"}, {"source": "N19-1423.pdf", "text": "ings of the 2018 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) .\nYukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhut-\ndinov, Raquel Urtasun, Antonio Torralba, and Sanja\nFidler. 2015. Aligning books and movies: Towards\nstory-like visual explanations by watching movies\nand reading books. In Proceedings of the IEEE\ninternational conference on computer vision , pages\n19\u201327."}, {"source": "N19-1423.pdf", "text": "19\u201327.\nAppendix for \u201cBERT: Pre-training of\nDeep Bidirectional Transformers for\nLanguage Understanding\u201d\nWe organize the appendix into three sections:\n\u2022 Additional implementation details for BERT\nare presented in Appendix A;\u2022 Additional details for our experiments are\npresented in Appendix B; and\n\u2022 Additional ablation studies are presented in\nAppendix C.\nWe present additional ablation studies for"}, {"source": "N19-1423.pdf", "text": "BERT including:\n\u2013Effect of Number of Training Steps; and\n\u2013Ablation for Different Masking Proce-\ndures.\nA Additional Details for BERT\nA.1 Illustration of the Pre-training Tasks\nWe provide examples of the pre-training tasks in\nthe following.\nMasked LM and the Masking Procedure As-\nsuming the unlabeled sentence is my dog is\nhairy , and during the random masking procedure"}, {"source": "N19-1423.pdf", "text": "we chose the 4-th token (which corresponding to\nhairy ), our masking procedure can be further il-\nlustrated by\n\u2022 80% of the time: Replace the word with the\n[MASK] token, e.g., my dog is hairy !\nmy dog is [MASK]\n\u2022 10% of the time: Replace the word with a\nrandom word, e.g., my dog is hairy !my\ndog is apple\n\u2022 10% of the time: Keep the word un-\nchanged, e.g., my dog is hairy !my dog"}, {"source": "N19-1423.pdf", "text": "changed, e.g., my dog is hairy !my dog\nis hairy . The purpose of this is to bias the\nrepresentation towards the actual observed\nword.\nThe advantage of this procedure is that the\nTransformer encoder does not know which words\nit will be asked to predict or which have been re-\nplaced by random words, so it is forced to keep\na distributional contextual representation of ev-"}, {"source": "N19-1423.pdf", "text": "eryinput token. Additionally, because random\nreplacement only occurs for 1.5% of all tokens\n(i.e., 10% of 15%), this does not seem to harm\nthe model\u2019s language understanding capability. In\nSection C.2, we evaluate the impact this proce-\ndure.\nCompared to standard langauge model training,\nthe masked LM only make predictions on 15% of\ntokens in each batch, which suggests that more"}, {"source": "N19-1423.pdf", "text": "pre-training steps may be required for the model4183\nBERT (Ours) \nTrm Trm Trm\nTrm Trm Trm...\n...Trm Trm Trm\nTrm Trm Trm...\n...OpenAI GPT \nLstm ELMo \nLstm Lstm \nLstm Lstm Lstm Lstm Lstm Lstm \nLstm Lstm Lstm  T1 T2 TN...\n...\n......\n...\n E1 E2 EN... T1 T2TN...\n E1 E2 EN ... T1 T2 TN..."}, {"source": "N19-1423.pdf", "text": "E1 E2 EN ... T1 T2 TN...\n E1 E2 EN...Figure 3: Differences in pre-training model architectures. BERT uses a bidirectional Transformer. OpenAI GPT\nuses a left-to-right Transformer. ELMo uses the concatenation of independently trained left-to-right and right-to-\nleft LSTMs to generate features for downstream tasks. Among the three, only BERT representations are jointly"}, {"source": "N19-1423.pdf", "text": "conditioned on both left and right context in all layers. In addition to the architecture differences, BERT and\nOpenAI GPT are \ufb01ne-tuning approaches, while ELMo is a feature-based approach.\nto converge. In Section C.1 we demonstrate that\nMLM does converge marginally slower than a left-\nto-right model (which predicts every token), but\nthe empirical improvements of the MLM model"}, {"source": "N19-1423.pdf", "text": "far outweigh the increased training cost.\nNext Sentence Prediction The next sentence\nprediction task can be illustrated in the following\nexamples.\nInput =[CLS] the man went to [MASK] store [SEP]\nhe bought a gallon [MASK] milk [SEP]\nLabel =IsNext\nInput =[CLS] the man [MASK] to the store [SEP]\npenguin [MASK] are flight ##less birds [SEP]\nLabel =NotNext\nA.2 Pre-training Procedure"}, {"source": "N19-1423.pdf", "text": "A.2 Pre-training Procedure\nTo generate each training input sequence, we sam-\nple two spans of text from the corpus, which we\nrefer to as \u201csentences\u201d even though they are typ-\nically much longer than single sentences (but can\nbe shorter also). The \ufb01rst sentence receives the A\nembedding and the second receives the Bembed-\nding. 50% of the time Bis the actual next sentence"}, {"source": "N19-1423.pdf", "text": "that follows Aand 50% of the time it is a random\nsentence, which is done for the \u201cnext sentence pre-\ndiction\u201d task. They are sampled such that the com-\nbined length is\u0014512 tokens. The LM masking is\napplied after WordPiece tokenization with a uni-\nform masking rate of 15%, and no special consid-\neration given to partial word pieces.\nWe train with batch size of 256 sequences (256"}, {"source": "N19-1423.pdf", "text": "sequences * 512 tokens = 128,000 tokens/batch)\nfor 1,000,000 steps, which is approximately 40epochs over the 3.3 billion word corpus. We\nuse Adam with learning rate of 1e-4, \f1= 0:9,\n\f2= 0:999, L2 weight decay of 0:01, learning\nrate warmup over the \ufb01rst 10,000 steps, and linear\ndecay of the learning rate. We use a dropout prob-\nability of 0.1 on all layers. We use a gelu acti-"}, {"source": "N19-1423.pdf", "text": "vation (Hendrycks and Gimpel, 2016) rather than\nthe standard relu , following OpenAI GPT. The\ntraining loss is the sum of the mean masked LM\nlikelihood and the mean next sentence prediction\nlikelihood.\nTraining of BERT BASE was performed on 4\nCloud TPUs in Pod con\ufb01guration (16 TPU chips\ntotal).13Training of BERT LARGE was performed\non 16 Cloud TPUs (64 TPU chips total). Each pre-"}, {"source": "N19-1423.pdf", "text": "training took 4 days to complete.\nLonger sequences are disproportionately expen-\nsive because attention is quadratic to the sequence\nlength. To speed up pretraing in our experiments,\nwe pre-train the model with sequence length of\n128 for 90% of the steps. Then, we train the rest\n10% of the steps of sequence of 512 to learn the\npositional embeddings.\nA.3 Fine-tuning Procedure"}, {"source": "N19-1423.pdf", "text": "A.3 Fine-tuning Procedure\nFor \ufb01ne-tuning, most model hyperparameters are\nthe same as in pre-training, with the exception of\nthe batch size, learning rate, and number of train-\ning epochs. The dropout probability was always\nkept at 0.1. The optimal hyperparameter values\nare task-speci\ufb01c, but we found the following range\nof possible values to work well across all tasks:\n\u2022Batch size : 16, 32"}, {"source": "N19-1423.pdf", "text": "\u2022Batch size : 16, 32\n13https://cloudplatform.googleblog.com/2018/06/Cloud-\nTPU-now-offers-preemptible-pricing-and-global-\navailability.html4184\u2022Learning rate (Adam) : 5e-5, 3e-5, 2e-5\n\u2022Number of epochs : 2, 3, 4\nWe also observed that large data sets (e.g.,\n100k+ labeled training examples) were far less\nsensitive to hyperparameter choice than small data"}, {"source": "N19-1423.pdf", "text": "sets. Fine-tuning is typically very fast, so it is rea-\nsonable to simply run an exhaustive search over\nthe above parameters and choose the model that\nperforms best on the development set.\nA.4 Comparison of BERT, ELMo ,and\nOpenAI GPT\nHere we studies the differences in recent popular\nrepresentation learning models including ELMo,\nOpenAI GPT and BERT. The comparisons be-"}, {"source": "N19-1423.pdf", "text": "tween the model architectures are shown visually\nin Figure 3. Note that in addition to the architec-\nture differences, BERT and OpenAI GPT are \ufb01ne-\ntuning approaches, while ELMo is a feature-based\napproach.\nThe most comparable existing pre-training\nmethod to BERT is OpenAI GPT, which trains a\nleft-to-right Transformer LM on a large text cor-\npus. In fact, many of the design decisions in BERT"}, {"source": "N19-1423.pdf", "text": "were intentionally made to make it as close to\nGPT as possible so that the two methods could be\nminimally compared. The core argument of this\nwork is that the bi-directionality and the two pre-\ntraining tasks presented in Section 3.1 account for\nthe majority of the empirical improvements, but\nwe do note that there are several other differences\nbetween how BERT and GPT were trained:"}, {"source": "N19-1423.pdf", "text": "between how BERT and GPT were trained:\n\u2022 GPT is trained on the BooksCorpus (800M\nwords); BERT is trained on the BooksCor-\npus (800M words) and Wikipedia (2,500M\nwords).\n\u2022 GPT uses a sentence separator ( [SEP] ) and\nclassi\ufb01er token ( [CLS] ) which are only in-\ntroduced at \ufb01ne-tuning time; BERT learns\n[SEP] ,[CLS] and sentence A/Bembed-\ndings during pre-training."}, {"source": "N19-1423.pdf", "text": "dings during pre-training.\n\u2022 GPT was trained for 1M steps with a batch\nsize of 32,000 words; BERT was trained for\n1M steps with a batch size of 128,000 words.\n\u2022 GPT used the same learning rate of 5e-5 for\nall \ufb01ne-tuning experiments; BERT chooses a\ntask-speci\ufb01c \ufb01ne-tuning learning rate which\nperforms the best on the development set.To isolate the effect of these differences, we per-"}, {"source": "N19-1423.pdf", "text": "form ablation experiments in Section 5.1 which\ndemonstrate that the majority of the improvements\nare in fact coming from the two pre-training tasks\nand the bidirectionality they enable.\nA.5 Illustrations of Fine-tuning on Different\nTasks\nThe illustration of \ufb01ne-tuning BERT on different\ntasks can be seen in Figure 4. Our task-speci\ufb01c\nmodels are formed by incorporating BERT with"}, {"source": "N19-1423.pdf", "text": "one additional output layer, so a minimal num-\nber of parameters need to be learned from scratch.\nAmong the tasks, (a) and (b) are sequence-level\ntasks while (c) and (d) are token-level tasks. In\nthe \ufb01gure,Erepresents the input embedding, Ti\nrepresents the contextual representation of token i,\n[CLS] is the special symbol for classi\ufb01cation out-\nput, and [SEP] is the special symbol to separate"}, {"source": "N19-1423.pdf", "text": "non-consecutive token sequences.\nB Detailed Experimental Setup\nB.1 Detailed Descriptions for the GLUE\nBenchmark Experiments.\nThe GLUE benchmark includes the following\ndatasets, the descriptions of which were originally\nsummarized in Wang et al. (2018a):\nMNLI Multi-Genre Natural Language Inference\nis a large-scale, crowdsourced entailment classi\ufb01-"}, {"source": "N19-1423.pdf", "text": "cation task (Williams et al., 2018). Given a pair of\nsentences, the goal is to predict whether the sec-\nond sentence is an entailment ,contradiction , or\nneutral with respect to the \ufb01rst one.\nQQP Quora Question Pairs is a binary classi\ufb01-\ncation task where the goal is to determine if two\nquestions asked on Quora are semantically equiv-\nalent (Chen et al., 2018)."}, {"source": "N19-1423.pdf", "text": "alent (Chen et al., 2018).\nQNLI Question Natural Language Inference is\na version of the Stanford Question Answering\nDataset (Rajpurkar et al., 2016) which has been\nconverted to a binary classi\ufb01cation task (Wang\net al., 2018a). The positive examples are (ques-\ntion, sentence) pairs which do contain the correct\nanswer, and the negative examples are (question,"}, {"source": "N19-1423.pdf", "text": "sentence) from the same paragraph which do not\ncontain the answer.\nSST-2 The Stanford Sentiment Treebank is a\nbinary single-sentence classi\ufb01cation task consist-\ning of sentences extracted from movie reviews4185\nBERT \nE[CLS] E1 E[SEP] ... ENE1\u2019... EM\u2019\nC\nT1\nT[SEP] ...\n TN\nT1\u2019...\n TM\u2019\n[CLS] Tok \n1 [SEP] ...Tok \nNTok \n1...Tok\nM\nQuestion Paragraph BERT \nE[CLS] E1 E2 EN\nC\nT1\n T2\n TN\nSingle Sentence ..."}, {"source": "N19-1423.pdf", "text": "C\nT1\n T2\n TN\nSingle Sentence ...\n...BERT \nTok 1 Tok 2 Tok N ... [CLS]E[CLS] E1 E2 EN\nC\nT1\n T2\n TN\nSingle Sentence \nB-PER O O...\n... E[CLS] E1 E[SEP] Class \nLabel \n... ENE1\u2019... EM\u2019\nC\nT1\nT[SEP] ...\n TN\nT1\u2019...\n TM\u2019\nStart/End Span Class \nLabel \nBERT \nTok 1 Tok 2 Tok N ... [CLS]Tok 1[CLS] [CLS] Tok \n1 [SEP] ...Tok \nNTok \n1...Tok\nM\nSentence 1 \n...Sentence 2"}, {"source": "N19-1423.pdf", "text": "1...Tok\nM\nSentence 1 \n...Sentence 2 \nFigure 4: Illustrations of Fine-tuning BERT on Different Tasks.\nwith human annotations of their sentiment (Socher\net al., 2013).\nCoLA The Corpus of Linguistic Acceptability is\na binary single-sentence classi\ufb01cation task, where\nthe goal is to predict whether an English sentence\nis linguistically \u201cacceptable\u201d or not (Warstadt\net al., 2018)."}, {"source": "N19-1423.pdf", "text": "et al., 2018).\nSTS-B The Semantic Textual Similarity Bench-\nmark is a collection of sentence pairs drawn from\nnews headlines and other sources (Cer et al.,\n2017). They were annotated with a score from 1\nto 5 denoting how similar the two sentences are in\nterms of semantic meaning.\nMRPC Microsoft Research Paraphrase Corpus\nconsists of sentence pairs automatically extracted"}, {"source": "N19-1423.pdf", "text": "from online news sources, with human annotations\nfor whether the sentences in the pair are semanti-\ncally equivalent (Dolan and Brockett, 2005).RTE Recognizing Textual Entailment is a bi-\nnary entailment task similar to MNLI, but with\nmuch less training data (Bentivogli et al., 2009).14\nWNLI Winograd NLI is a small natural lan-\nguage inference dataset (Levesque et al., 2011)."}, {"source": "N19-1423.pdf", "text": "The GLUE webpage notes that there are issues\nwith the construction of this dataset,15and every\ntrained system that\u2019s been submitted to GLUE has\nperformed worse than the 65.1 baseline accuracy\nof predicting the majority class. We therefore ex-\nclude this set to be fair to OpenAI GPT. For our\nGLUE submission, we always predicted the ma-\njority class."}, {"source": "N19-1423.pdf", "text": "jority class.\n14Note that we only report single-task \ufb01ne-tuning results\nin this paper. A multitask \ufb01ne-tuning approach could poten-\ntially push the performance even further. For example, we\ndid observe substantial improvements on RTE from multi-\ntask training with MNLI.\n15https://gluebenchmark.com/faq4186C Additional Ablation Studies\nC.1 Effect of Number of Training Steps"}, {"source": "N19-1423.pdf", "text": "C.1 Effect of Number of Training Steps\nFigure 5 presents MNLI Dev accuracy after \ufb01ne-\ntuning from a checkpoint that has been pre-trained\nforksteps. This allows us to answer the following\nquestions:\n1. Question: Does BERT really need such\na large amount of pre-training (128,000\nwords/batch * 1,000,000 steps) to achieve\nhigh \ufb01ne-tuning accuracy?\nAnswer: Yes, BERT BASE achieves almost"}, {"source": "N19-1423.pdf", "text": "Answer: Yes, BERT BASE achieves almost\n1.0% additional accuracy on MNLI when\ntrained on 1M steps compared to 500k steps.\n2. Question: Does MLM pre-training converge\nslower than LTR pre-training, since only 15%\nof words are predicted in each batch rather\nthan every word?\nAnswer: The MLM model does converge\nslightly slower than the LTR model. How-\never, in terms of absolute accuracy the MLM"}, {"source": "N19-1423.pdf", "text": "model begins to outperform the LTR model\nalmost immediately.\nC.2 Ablation for Different Masking\nProcedures\nIn Section 3.1, we mention that BERT uses a\nmixed strategy for masking the target tokens when\npre-training with the masked language model\n(MLM) objective. The following is an ablation\nstudy to evaluate the effect of different masking\nstrategies."}, {"source": "N19-1423.pdf", "text": "strategies.\nNote that the purpose of the masking strategies\nis to reduce the mismatch between pre-training\n200 400 600 800 1;0007678808284\nPre-training Steps (Thousands)MNLI Dev Accuracy\nBERT BASE (Masked LM)\nBERT BASE (Left-to-Right)\nFigure 5: Ablation over number of training steps. This\nshows the MNLI accuracy after \ufb01ne-tuning, starting\nfrom model parameters that have been pre-trained for"}, {"source": "N19-1423.pdf", "text": "ksteps. The x-axis is the value of k.and \ufb01ne-tuning, as the [MASK] symbol never ap-\npears during the \ufb01ne-tuning stage. We report the\nDev results for both MNLI and NER. For NER,\nwe report both \ufb01ne-tuning and feature-based ap-\nproaches, as we expect the mismatch will be am-\npli\ufb01ed for the feature-based approach as the model\nwill not have the chance to adjust the representa-\ntions."}, {"source": "N19-1423.pdf", "text": "tions.\nMasking Rates Dev Set Results\nMASK SAME RND MNLI NER\nFine-tune Fine-tune Feature-based\n80% 10% 10% 84.2 95.4 94.9\n100% 0% 0% 84.3 94.9 94.0\n80% 0% 20% 84.1 95.2 94.6\n80% 20% 0% 84.4 95.2 94.7\n0% 20% 80% 83.7 94.8 94.6\n0% 0% 100% 83.6 94.9 94.6\nTable 8: Ablation over different masking strategies.\nThe results are presented in Table 8. In the table,"}, {"source": "N19-1423.pdf", "text": "MASK means that we replace the target token with\nthe[MASK] symbol for MLM; S AME means that\nwe keep the target token as is; R NDmeans that\nwe replace the target token with another random\ntoken.\nThe numbers in the left part of the table repre-\nsent the probabilities of the speci\ufb01c strategies used\nduring MLM pre-training (BERT uses 80%, 10%,\n10%). The right part of the paper represents the"}, {"source": "N19-1423.pdf", "text": "Dev set results. For the feature-based approach,\nwe concatenate the last 4 layers of BERT as the\nfeatures, which was shown to be the best approach\nin Section 5.3.\nFrom the table it can be seen that \ufb01ne-tuning is\nsurprisingly robust to different masking strategies.\nHowever, as expected, using only the M ASK strat-\negy was problematic when applying the feature-"}, {"source": "N19-1423.pdf", "text": "based approach to NER. Interestingly, using only\nthe R NDstrategy performs much worse than our\nstrategy as well."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Under review as a conference paper at ICLR 2020\nALBERT: A L ITE BERT FOR SELF-SUPERVISED\nLEARNING OF LANGUAGE REPRESENTATIONS\nAnonymous authors\nPaper under double-blind review\nABSTRACT\nIncreasing model size when pretraining natural language representations often re-\nsults in improved performance on downstream tasks. However, at some point fur-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ther model increases become harder due to GPU/TPU memory limitations, longer\ntraining times, and unexpected model degradation. To address these problems,\nwe present two parameter-reduction techniques to lower memory consumption\nand increase the training speed of BERT (Devlin et al., 2019). Comprehensive\nempirical evidence shows that our proposed methods lead to models that scale"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "much better compared to the original BERT. We also use a self-supervised loss\nthat focuses on modeling inter-sentence coherence, and show it consistently helps\ndownstream tasks with multi-sentence inputs. As a result, our best model estab-\nlishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks\nwhile having fewer parameters compared to BERT-large.\n1 I NTRODUCTION"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "1 I NTRODUCTION\nFull network pre-training (Radford et al., 2018; Devlin et al., 2019) has led to a series of break-\nthroughs in language representation learning. Many nontrivial NLP tasks, including those that have\nlimited training data, have greatly bene\ufb01ted from these pre-trained models. One of the most com-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "pelling signs of these breakthroughs is the evolution of machine performance on a reading com-\nprehension task designed for middle and high-school English exams in China, the RACE test (Lai\net al., 2017): the paper that originally describes the task and formulates the modeling challenge\nreports then state-of-the-art machine accuracy at 44:1%; the latest published result reports their"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "model performance at 83:2%(Liu et al., 2019); the work we present here pushes it even higher\nto89:4%, a stunning 45:3%improvement that is mainly attributable to our current ability to build\nhigh-performance pretrained language representations.\nEvidence from these improvements reveals that a large network is of crucial importance for achiev-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ing state-of-the-art performance (Devlin et al., 2019; Radford et al., 2019). It has become common\npractice to pre-train large models and distill them down to smaller ones (Sun et al., 2019; Turc et al.,\n2019) for real applications. Given the importance of model size, we ask: Is having better NLP\nmodels as easy as having larger models ?"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "An obstacle to answering this question is the memory limitations of available hardware. Given that\ncurrent state-of-the-art models often have hundreds of millions or even billions of parameters, it is\neasy to hit these limitations as we try to scale our models. Training speed can also be signi\ufb01cantly\nhampered in distributed training, as the communication overhead is directly proportional to the"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "number of parameters in the model. We also observe that simply growing the hidden size of a model\nsuch as BERT-large (Devlin et al., 2019) can lead to worse performance. Table 1 and Fig. 1 show\na typical example, where we simply increase the hidden size of BERT-large to be 2x larger and get\nworse results with this BERT-xlarge model.\nModel Hidden Size Parameters RACE (Accuracy)"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "BERT-large (Devlin et al., 2019) 1024 334M 72.0%\nBERT-large (ours) 1024 334M 73.9%\nBERT-xlarge (ours) 2048 1270M 54.3%\nTable 1: Increasing hidden size of BERT-large leads to worse performance on RACE.\n1Under review as a conference paper at ICLR 2020\n0 2 4 6 8 10 12\nSteps (1e4)0123456789Training lossBERT-large\nBERT-xlarge\n0 2 4 6 8 10 12"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "BERT-xlarge\n0 2 4 6 8 10 12\nSteps (1e4)0.00.10.20.30.40.50.6Dev accuracy (MLM) BERT-large\nBERT-xlarge\nFigure 1: Training loss (left) and dev masked LM accuracy (right) of BERT-large and BERT-xlarge\n(2x larger than BERT-large in terms of hidden size). The larger model has lower masked LM accu-\nracy while showing no obvious sign of over-\ufb01tting."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Existing solutions to the aforementioned problems include model parallelization (Shoeybi et al.,\n2019) and clever memory management (Chen et al., 2016; Gomez et al., 2017). These solutions\naddress the memory limitation problem, but not the communication overhead and model degradation\nproblem. In this paper, we address all of the aforementioned problems, by designing A Lite BERT"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "(ALBERT) architecture that has signi\ufb01cantly fewer parameters than a traditional BERT architecture.\nALBERT incorporates two parameter reduction techniques that lift the major obstacles in scaling\npre-trained models. The \ufb01rst one is a factorized embedding parameterization. By decomposing\nthe large vocabulary embedding matrix into two small matrices, we separate the size of the hidden"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "layers from the size of vocabulary embedding. This separation makes it easier to grow the hidden\nsize without signi\ufb01cantly increasing the parameter size of the vocabulary embeddings. The second\ntechnique is cross-layer parameter sharing. This technique prevents the parameter from growing\nwith the depth of the network. Both techniques signi\ufb01cantly reduce the number of parameters for"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "BERT without seriously hurting performance, thus improving parameter-ef\ufb01ciency. An ALBERT\ncon\ufb01guration similar to BERT-large has 18x fewer parameters and can be trained about 1.7x faster.\nThe parameter reduction techniques also act as a form of regularization that stabilizes the training\nand helps with generalization."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "and helps with generalization.\nTo further improve the performance of ALBERT, we also introduce a self-supervised loss for\nsentence-order prediction (SOP). SOP primary focuses on inter-sentence coherence and is designed\nto address the ineffectiveness (Yang et al., 2019; Liu et al., 2019) of the next sentence prediction\n(NSP) loss proposed in the original BERT."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "As a result of these design decisions, we are able to scale up to much larger ALBERT con\ufb01gurations\nthat still have fewer parameters than BERT-large but achieve signi\ufb01cantly better performance. We\nestablish new state-of-the-art results on the well-known GLUE, SQuAD, and RACE benchmarks\nfor natural language understanding. Speci\ufb01cally, we push the RACE accuracy to 89:4%, the GLUE"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "benchmark to 89.4, and the F1 score of SQuAD 2.0 to 92.2.\n2 R ELATED WORK\n2.1 S CALING UPREPRESENTATION LEARNING FOR NATURAL LANGUAGE\nLearning representations of natural language has been shown to be useful for a wide range of NLP\ntasks and has been widely adopted (Mikolov et al., 2013; Le & Mikolov, 2014; Peters et al., 2018;"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Devlin et al., 2019; Radford et al., 2018; 2019). One of the most signi\ufb01cant changes in the last\ntwo years is the shift from pre-training word embeddings, whether standard (Mikolov et al., 2013;\nPennington et al., 2014) or contextualized (McCann et al., 2017; Peters et al., 2018), to full-network\npre-training followed by task-speci\ufb01c \ufb01ne-tuning (Radford et al., 2018; Devlin et al., 2019). In"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "this line of work, it is often shown that larger model size improves performance. For example,\nDevlin et al. (2019) show that across three selected natural language understanding tasks, using\nlarger hidden size, more hidden layers, and more attention heads always leads to better performance.\nHowever, they stop at a hidden size of 1024. We show that, under the same setting, increasing the"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "2Under review as a conference paper at ICLR 2020\nhidden size to 2048 leads to model degradation and hence worse performance. Therefore, scaling\nup representation learning for natural language is not as easy as simply increasing model size.\nIn addition, it is dif\ufb01cult to experiment with large models due to computational constraints, espe-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "cially in terms of GPU/TPU memory limitations. Given that current state-of-the-art models often\nhave hundreds of millions or even billions of parameters, we can easily hit memory limits. To ad-\ndress this issue, Chen et al. (2016) propose a method called gradient checkpointing to reduce the\nmemory requirement to be sublinear at the cost of an extra forward pass. Gomez et al. (2017) pro-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "pose a way to reconstruct each layer\u2019s activations from the next layer so that they do not need to store\nthe intermediate activations. Both methods reduce the memory consumption at the cost of speed.\nIn contrast, our parameter-reduction techniques reduce memory consumption and increase training\nspeed.\n2.2 C ROSS -LAYER PARAMETER SHARING"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "2.2 C ROSS -LAYER PARAMETER SHARING\nThe idea of sharing parameters across layers has been previously explored with the Transformer\narchitecture (Vaswani et al., 2017), but this prior work has focused on training for standard encoder-\ndecoder tasks rather than the pretraining/\ufb01netuning setting. Different from our observations, De-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "hghani et al. (2018) show that networks with cross-layer parameter sharing (Universal Transformer,\nUT) get better performance on language modeling and subject-verb agreement than the standard\ntransformer. Very recently, Bai et al. (2019) propose a Deep Equilibrium Model (DQE) for trans-\nformer networks and show that DQE can reach an equilibrium point for which the input embedding"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "and the output embedding of a certain layer stay the same. Our observations show that our em-\nbeddings are oscillating rather than converging. Hao et al. (2019) combine a parameter-sharing\ntransformer with the standard one, which further increases the number of parameters of the standard\ntransformer.\n2.3 S ENTENCE ORDERING OBJECTIVES"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "2.3 S ENTENCE ORDERING OBJECTIVES\nALBERT uses a pretraining loss based on predicting the ordering of two consecutive segments\nof text. Several researchers have experimented with pretraining objectives that similarly relate to\ndiscourse coherence. Coherence and cohesion in discourse have been widely studied and many"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "phenomena have been identi\ufb01ed that connect neighboring text segments (Hobbs, 1979; Halliday &\nHasan, 1976; Grosz et al., 1995). Most objectives found effective in practice are quite simple. Skip-\nthought (Kiros et al., 2015) and FastSent (Hill et al., 2016) sentence embeddings are learned by using\nan encoding of a sentence to predict words in neighboring sentences. Other objectives for sentence"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "embedding learning include predicting future sentences rather than only neighbors (Gan et al., 2017)\nand predicting explicit discourse markers (Jernite et al., 2017; Nie et al., 2019). Our loss is most\nsimilar to the sentence ordering objective of Jernite et al. (2017), where sentence embeddings are\nlearned in order to determine the ordering of two consecutive sentences. Unlike most of the above"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "work, however, our loss is de\ufb01ned on textual segments rather than sentences. BERT (Devlin et al.,\n2019) uses a loss based on predicting whether the second segment in a pair has been swapped\nwith a segment from another document. We compare to this loss in our experiments and \ufb01nd that\nsentence ordering is a more challenging pretraining task and more useful for certain downstream"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "tasks. Concurrently to our work, Wang et al. (2019) also try to predict the order of two consecutive\nsegments of text, but they combine it with the original next sentence prediction in a three-way\nclassi\ufb01cation task rather than empirically comparing the two.\n3 T HEELEMENTS OF ALBERT\nIn this section, we present the design decisions for ALBERT and provide quanti\ufb01ed comparisons"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "against corresponding con\ufb01gurations of the original BERT architecture (Devlin et al., 2019).\n3.1 M ODEL ARCHITECTURE CHOICES\nThe backbone of the ALBERT architecture is similar to BERT in that it uses a transformer en-\ncoder (Vaswani et al., 2017) with GELU nonlinearities (Hendrycks & Gimpel, 2016). We follow the"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "BERT notation conventions and denote the vocabulary embedding size as E, the number of encoder\n3Under review as a conference paper at ICLR 2020\nlayers as L, and the hidden size as H. Following Devlin et al. (2019), we set the feed-forward/\ufb01lter\nsize to be 4Hand the number of attention heads to be H=64.\nThere are three main contributions that ALBERT makes over the design choices of BERT."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Factorized embedding parameterization. In BERT, as well as subsequent modeling improve-\nments such as XLNet (Yang et al., 2019) and RoBERTa (Liu et al., 2019), the WordPiece embedding\nsizeEis tied with the hidden layer size H, i.e.,E\u0011H. This decision appears suboptimal for both\nmodeling and practical reasons, as follows."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "From a modeling perspective, WordPiece embeddings are meant to learn context-independent repre-\nsentations, whereas hidden-layer embeddings are meant to learn context-dependent representations.\nAs experiments with context length indicate (Liu et al., 2019), the power of BERT-like represen-\ntations comes from the use of context to provide the signal for learning such context-dependent"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "representations. As such, untying the WordPiece embedding size Efrom the hidden layer size H\nallows us to make a more ef\ufb01cient usage of the total model parameters as informed by modeling\nneeds, which dictate that H\u001dE.\nFrom a practical perspective, natural language processing usually require the vocabulary size Vto"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "be large.1IfE\u0011H, then increasing Hincreases the size of the embedding matrix, which has size\nV\u0002E. This can easily result in a model with billions of parameters, most of which are only updated\nsparsely during training.\nTherefore, for ALBERT we use a factorization of the embedding parameters, decomposing them"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "into two smaller matrices. Instead of projecting the one-hot vectors directly into the hidden space of\nsizeH, we \ufb01rst project them into a lower dimensional embedding space of size E, and then project\nit to the hidden space. By using this decomposition, we reduce the embedding parameters from\nO(V\u0002H)toO(V\u0002E+E\u0002H). This parameter reduction is signi\ufb01cant when H\u001dE."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Cross-layer parameter sharing. For ALBERT, we propose cross-layer parameter sharing as an-\nother way to improve parameter ef\ufb01ciency. There are multiple ways to share parameters, e.g., only\nsharing feed-forward network (FFN) parameters across layers, or only sharing attention parameters.\nThe default decision for ALBERT is to share all parameters across layers. We compare this design"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "decision against other strategies in our experiments in Sec. 4.5.\nSimilar strategies have been explored by Dehghani et al. (2018) (Universal Transformer, UT) and\nBai et al. (2019) (Deep Equilibrium Models, DQE) for Transformer networks. Different from our\nobservations, Dehghani et al. (2018) show that UT outperforms a vanilla Transformer. Bai et al."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "(2019) show that their DQEs reach an equilibrium point for which the input and output embedding\nof a certain layer stay the same. Our measurement on the L2 distances and cosine similarity show\nthat our embeddings are oscillating rather than converging.\n0 5 10 15 20 25\nLayer ID024681012141618L2 distanceBERT-large\nALBERT-large\n0 5 10 15 20 25"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ALBERT-large\n0 5 10 15 20 25\nLayer ID051015202530354045Cosine Similarity (Degree)BERT-large\nALBERT-large\nFigure 2: The L2 distances and cosine similarity (in terms of degree) of the input and output embed-\nding of each layer for BERT-large and ALBERT-large.\nFigure 2 shows the L2 distances and cosine similarity of the input and output embeddings for each"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "layer, using BERT-large and ALBERT-large con\ufb01gurations (see Table 2). We observe that the tran-\nsitions from layer to layer are much smoother for ALBERT than for BERT. These results show that\n1Similar to BERT, all the experiments in this paper use a vocabulary size Vof 30,000.\n4Under review as a conference paper at ICLR 2020\nModel Parameters Layers Hidden Embedding Parameter-sharing"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "BERTbase 108M 12 768 768 False\nlarge 334M 24 1024 1024 False\nxlarge 1270M 24 2048 2048 False\nALBERTbase 12M 12 768 128 True\nlarge 18M 24 1024 128 True\nxlarge 59M 24 2048 128 True\nxxlarge 233M 12 4096 128 True\nTable 2: The con\ufb01gurations of the main BERT and ALBERT models analyzed in this paper.\nweight-sharing has an effect on stabilizing network parameters. Although there is a drop for both"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "metrics compared to BERT, they nevertheless do not converge to 0 even after 24 layers. This shows\nthat the solution space for ALBERT parameters is very different from the one found by DQE.\nInter-sentence coherence loss. In addition to the masked language modeling (MLM) loss (De-\nvlin et al., 2019), BERT uses an additional loss called next-sentence prediction (NSP). NSP is a"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "binary classi\ufb01cation loss for predicting whether two segments appear consecutively in the original\ntext, as follows: positive examples are created by taking consecutive segments from the training\ncorpus; negative examples are created by pairing segments from different documents; positive and\nnegative examples are sampled with equal probability. The NSP objective was designed to improve"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "performance on downstream tasks, such as natural language inference, that require reasoning about\nthe relationship between sentence pairs. However, subsequent studies (Yang et al., 2019; Liu et al.,\n2019) found NSP\u2019s impact unreliable and decided to eliminate it, a decision supported by an im-\nprovement in downstream task performance across several tasks."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "We conjecture that the main reason behind NSP\u2019s ineffectiveness is its lack of dif\ufb01culty as a task,\nas compared to MLM. As formulated, NSP con\ufb02ates topic prediction andcoherence prediction in a\nsingle task2. However, topic prediction is easier to learn compared to coherence prediction, and also\noverlaps more with what is learned using the MLM loss."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "We maintain that inter-sentence modeling is an important aspect of language understanding, but we\npropose a loss based primarily on coherence . That is, for ALBERT, we use a sentence-order pre-\ndiction (SOP) loss, which avoids topic prediction and instead focuses on modeling inter-sentence\ncoherence. The SOP loss uses as positive examples the same technique as BERT (two consecu-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "tive segments from the same document), and as negative examples the same two consecutive seg-\nments but with their order swapped. This forces the model to learn \ufb01ner-grained distinctions about\ndiscourse-level coherence properties. As we show in Sec. 4.6, it turns out that NSP cannot solve the\nSOP task at all (i.e., it ends up learning the easier topic-prediction signal, and performs at random-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "baseline level on the SOP task), while SOP can solve the NSP task to a reasonable degree, pre-\nsumably based on analyzing misaligned coherence cues. As a result, ALBERT models consistently\nimprove downstream task performance for multi-sentence encoding tasks.\n3.2 M ODEL SETUP\nWe present the differences between BERT and ALBERT models with comparable hyperparameter"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "settings in Table 2. Due to the design choices discussed above, ALBERT models have much smaller\nparameter size compared to corresponding BERT models.\nFor example, ALBERT-large has about 18x fewer parameters compared to BERT-large, 18M versus\n334M. If we set BERT to have an extra-large size with H= 2048 , we end up with a model that has"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "1.27 billion parameters and under-performs (Fig. 1). In contrast, an ALBERT-xlarge con\ufb01guration\nwithH= 2048 has only 59M parameters, while an ALBERT-xxlarge con\ufb01guration with H=\n4096 has 233M parameters, i.e., around 70% of BERT-large\u2019s parameters. Note that for ALBERT-\nxxlarge, we mainly report results on a 12-layer network because a 24-layer network (with the same"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "con\ufb01guration) obtains similar results but is computationally more expensive.\n2Since a negative example is constructed using material from a different document, the negative-example\nsegment is misaligned both from a topic and from a coherence perspective.\n5Under review as a conference paper at ICLR 2020\nThis improvement in parameter ef\ufb01ciency is the most important advantage of ALBERT\u2019s design"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "choices. Before we can quantify this advantage, we need to introduce our experimental setup in\nmore detail.\n4 E XPERIMENTAL RESULTS\n4.1 E XPERIMENTAL SETUP\nTo keep the comparison as meaningful as possible, we follow the BERT (Devlin et al., 2019) setup in\nusing the B OOK CORPUS (Zhu et al., 2015) and English Wikipedia (Devlin et al., 2019) for pretrain-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ing baseline models. These two corpora consist of around 16GB of uncompressed text. We format\nour inputs as \u201c[CLS] x1[SEP] x2[SEP]\u201d, where x1=x1;1; x1;2\u0001\u0001\u0001andx2=x1;1; x1;2\u0001\u0001\u0001are\ntwo segments.3We always limit the maximum input length to 512, and randomly generate input\nsequences shorter than 512 with a probability of 10%. Like BERT, we use a vocabulary size of"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "30,000, tokenized using SentencePiece (Kudo & Richardson, 2018) as in XLNet (Yang et al., 2019).\nWe generate masked inputs for the MLM targets using n-gram masking (Joshi et al., 2019), with the\nlength of each n-gram mask selected randomly. The probability for the length nis given by\np(n) =1=nPN\nk=11=k"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "p(n) =1=nPN\nk=11=k\nWe set the maximum length of n-gram (i.e., n) to be 3 (i.e., the MLM target can consist of up to a\n3-gram of complete words, such as \u201cWhite House correspondents\u201d).\nAll the model updates use a batch size of 4096 and a L AMB optimizer with learning rate\n0.00176 (You et al., 2019). We train all models for 125,000 steps unless otherwise speci\ufb01ed. Train-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ing was done on Cloud TPU V3. The number of TPUs used for training ranged from 64 to 1024,\ndepending on model size.\nThe experimental setup described in this section is used for all of our own versions of BERT as well\nas ALBERT models, unless otherwise speci\ufb01ed.\n4.2 E VALUATION BENCHMARKS\n4.2.1 I NTRINSIC EVALUATION"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "4.2.1 I NTRINSIC EVALUATION\nTo monitor the training progress, we create a development set based on the development sets from\nSQuAD and RACE using the same procedure as in Sec. 4.1. We report accuracies for both MLM and\nsentence classi\ufb01cation tasks. Note that we only use this set to check how the model is converging;"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "it has not been used in a way that would affect the performance of any downstream evaluation, such\nas via model selection.\n4.2.2 D OWNSTREAM EVALUATION\nFollowing Yang et al. (2019) and Liu et al. (2019), we evaluate our models on three popular bench-\nmarks: The General Language Understanding Evaluation (GLUE) benchmark (Wang et al., 2018),"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "two versions of the Stanford Question Answering Dataset (SQuAD; Rajpurkar et al., 2016; 2018),\nand the ReAding Comprehension from Examinations (RACE) dataset (Lai et al., 2017). For com-\npleteness, we provide description of these benchmarks in Appendix A.1. As in (Liu et al., 2019), we\nperform early stopping on the development sets, on which we report all comparisons except for our"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "\ufb01nal comparisons based on the task leaderboards, for which we also report test set results.\n4.3 O VERALL COMPARISON BETWEEN BERT AND ALBERT\nWe are now ready to quantify the impact of the design choices described in Sec. 3, speci\ufb01cally the\nones around parameter ef\ufb01ciency. The improvement in parameter ef\ufb01ciency showcases the most"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "important advantage of ALBERT\u2019s design choices, as shown in Table 3: with only around 70% of\n3A segment is usually comprised of more than one natural sentence, which has been shown to bene\ufb01t\nperformance by Liu et al. (2019).\n6Under review as a conference paper at ICLR 2020\nBERT-large\u2019s parameters, ALBERT-xxlarge achieves signi\ufb01cant improvements over BERT-large, as"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "measured by the difference on development set scores for several representative downstream tasks:\nSQuAD v1.1 (+1.7%), SQuAD v2.0 (+4.2%), MNLI (+2.2%), SST-2 (+3.0%), and RACE (+8.5%).\nWe also observe that BERT-xlarge gets signi\ufb01cantly worse results than BERT-base on all metrics.\nThis indicates that a model like BERT-xlarge is more dif\ufb01cult to train than those that have smaller"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "parameter sizes. Another interesting observation is the speed of data throughput at training time\nunder the same training con\ufb01guration (same number of TPUs). Because of less communication and\nfewer computations, ALBERT models have higher data throughput compared to their correspond-\ning BERT models. The slowest one is the BERT-xlarge model, which we use as a baseline. As"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "the models get larger, the differences between BERT and ALBERT models become bigger, e.g.,\nALBERT-xlarge can be trained 2.4x faster than BERT-xlarge.\nModel Parameters SQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg Speedup\nBERTbase 108M 90.5/83.3 80.3/77.3 84.1 91.7 68.3 82.1 17.7x\nlarge 334M 92.4/85.8 83.9/80.8 85.8 92.2 73.8 85.1 3.8x\nxlarge 1270M 86.3/77.9 73.8/70.5 80.5 87.8 39.7 76.7 1.0"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ALBERTbase 12M 89.3/82.1 79.1/76.1 81.9 89.4 63.5 80.1 21.1x\nlarge 18M 90.9/84.1 82.1/79.0 83.8 90.6 68.4 82.4 6.5x\nxlarge 59M 93.0/86.5 85.9/83.1 85.4 91.9 73.9 85.5 2.4x\nxxlarge 233M 94.1/88.3 88.1/85.1 88.0 95.2 82.3 88.7 1.2x\nTable 3: Dev set results for models pretrained over B OOK CORPUS and Wikipedia for 125k steps."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Here and everywhere else, the Avg column is computed by averaging the scores of the downstream\ntasks to its left (the two numbers of F1 and EM for each SQuAD are \ufb01rst averaged).\nNext, we perform ablation experiments that quantify the individual contribution of each of the design\nchoices for ALBERT.\n4.4 F ACTORIZED EMBEDDING PARAMETERIZATION"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Table 4 shows the effect of changing the vocabulary embedding size Eusing an ALBERT-base\ncon\ufb01guration setting (see Table 2), using the same set of representative downstream tasks. Under\nthe non-shared condition (BERT-style), larger embedding sizes give better performance, but not by\nmuch. Under the all-shared condition (ALBERT-style), an embedding of size 128 appears to be the"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "best. Based on these results, we use an embedding size E= 128 in all future settings, as a necessary\nstep to do further scaling.\nModel E Parameters SQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg\nALBERT\nbase\nnot-shared64 87M 89.9/82.9 80.1/77.8 82.9 91.5 66.7 81.3\n128 89M 89.9/82.8 80.3/77.3 83.7 91.5 67.9 81.7\n256 93M 90.2/83.2 80.3/77.4 84.1 91.9 67.3 81.8\n768 108M 90.4/83.2 80.4/77.6 84.5 92.8 68.2 82.3"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ALBERT\nbase\nall-shared64 10M 88.7/81.4 77.5/74.8 80.8 89.4 63.5 79.0\n128 12M 89.3/82.3 80.0/77.1 81.6 90.3 64.0 80.1\n256 16M 88.8/81.5 79.1/76.3 81.5 90.3 63.4 79.6\n768 31M 88.6/81.5 79.2/76.6 82.0 90.6 63.3 79.8\nTable 4: The effect of vocabulary embedding size on the performance of ALBERT-base.\n4.5 C ROSS -LAYER PARAMETER SHARING"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "4.5 C ROSS -LAYER PARAMETER SHARING\nTable 5 presents experiments for various cross-layer parameter-sharing strategies, using an\nALBERT-base con\ufb01guration (Table 2) with two embedding sizes ( E= 768 andE= 128 ). We\ncompare the all-shared strategy (ALBERT-style), the not-shared strategy (BERT-style), and inter-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "mediate strategies in which only the attention parameters are shared (but not the FNN ones) or only\nthe FFN parameters are shared (but not the attention ones).\nThe all-shared strategy hurts performance under both conditions, but it is less severe for E= 128 (-\n1.5 on Avg) compared to E= 768 (-2.5 on Avg). In addition, most of the performance drop appears"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "to come from sharing the FFN-layer parameters, while sharing the attention parameters results in no\ndrop when E= 128 (+0.1 on Avg), and a slight drop when E= 768 (-0.7 on Avg).\n7Under review as a conference paper at ICLR 2020\nModel Parameters SQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg\nALBERT\nbase\nE=768all-shared 31M 88.6/81.5 79.2/76.6 82.0 90.6 63.3 79.8"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "shared-attention 83M 89.9/82.7 80.0/77.2 84.0 91.4 67.7 81.6\nshared-FFN 57M 89.2/82.1 78.2/75.4 81.5 90.8 62.6 79.5\nnot-shared 108M 90.4/83.2 80.4/77.6 84.5 92.8 68.2 82.3\nALBERT\nbase\nE=128all-shared 12M 89.3/82.3 80.0/77.1 82.0 90.3 64.0 80.1\nshared-attention 64M 89.9/82.8 80.7/77.9 83.4 91.9 67.6 81.7\nshared-FFN 38M 88.9/81.6 78.6/75.6 82.3 91.7 64.4 80.2"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "not-shared 89M 89.9/82.8 80.3/77.3 83.2 91.5 67.9 81.6\nTable 5: The effect of cross-layer parameter-sharing strategies, ALBERT-base con\ufb01guration.\n4.6 S ENTENCE ORDER PREDICTION (SOP)\nWe compare head-to-head three experimental conditions for the additional inter-sentence loss: none\n(XLNet- and RoBERTa-style), NSP (BERT-style), and SOP (ALBERT-style), using an ALBERT-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "base con\ufb01guration. Results are shown in Table 6, both over intrinsic (accuracy for the MLM, NSP,\nand SOP tasks) and downstream tasks.\nIntrinsic Tasks Downstream Tasks\nSP tasks MLM NSP SOP SQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg\nNone 54.9 52.4 53.3 88.6/81.5 78.1/75.3 81.5 89.9 61.7 79.0\nNSP 54.5 90.5 52.0 88.4/81.5 77.2/74.6 81.6 91.1 62.3 79.2"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "SOP 54.0 78.9 86.5 89.3/82.3 80.0/77.1 82.0 90.3 64.0 80.1\nTable 6: The effect of sentence-prediction loss, NSP vs. SOP, on intrinsic and downstream tasks.\nThe results on the intrinsic tasks reveal that the NSP loss brings no discriminative power to the SOP\ntask (52.0% accuracy, similar to the random-guess performance for the \u201cNone\u201d condition). This"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "allows us to conclude that NSP ends up modeling only topic shift. In contrast, the SOP loss does\nsolve the NSP task relatively well (78.9% accuracy), and the SOP task even better (86.5% accuracy).\nEven more importantly, the SOP loss appears to consistently improve downstream task performance\nfor multi-sentence encoding tasks (around +1% for SQuAD1.1, +2% for SQuAD2.0, +1.7% for"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "RACE), for an Avg score improvement of around +1%.\n4.7 W HAT IF WE TRAIN FOR THE SAME AMOUNT OF TIME ?\nThe speed-up results in Table 3 indicate that data-throughput for BERT-large is about 3.17x higher\ncompared to ALBERT-xxlarge. Since longer training usually leads to better performance, we per-\nform a comparison in which, instead of controlling for data throughput (number of training steps),"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "we control for the actual training time (i.e., let the models train for the same number of hours). In\nTable 7, we compare the performance of a BERT-large model after 400k training steps (after 34h\nof training), roughly equivalent with the amount of time needed to train an ALBERT-xxlarge model\nwith 125k training steps (32h of training).\nModels Steps Time SQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "BERT-large 400k 34h 93.5/87.4 86.9/84.3 87.8 94.6 77.3 87.2\nALBERT-xxlarge 125k 32h 94.0/88.1 88.3/85.3 87.8 95.4 82.5 88.7\nTable 7: The effect of controlling for training time, BERT-large vs ALBERT-xxlarge con\ufb01gurations.\nAfter training for roughly the same amount of time, ALBERT-xxlarge is signi\ufb01cantly better than\nBERT-large: +1.5% better on Avg, with the difference on RACE as high as +5.2%."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "4.8 A DDITIONAL TRAINING DATA AND DROPOUT EFFECTS\nThe experiments done up to this point use only the Wikipedia and B OOK CORPUS datasets, as in\n(Devlin et al., 2019). In this section, we report measurements on the impact of the additional data\nused by both XLNet (Yang et al., 2019) and RoBERTa (Liu et al., 2019).\n8Under review as a conference paper at ICLR 2020"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Fig. 3a plots the dev set MLM accuracy under two conditions, without and with additional data, with\nthe latter condition giving a signi\ufb01cant boost. We also observe performance improvements on the\ndownstream tasks in Table 8, except for the SQuAD benchmarks (which are Wikipedia-based, and\ntherefore are negatively affected by out-of-domain training material).\n35 40 45 50 55"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "35 40 45 50 55\nSteps (1e4)66.066.567.067.568.068.569.069.570.0Dev accuracy (MLM) %W/O additional data\nW additional data\n(a) Adding data\n90 100 110 120 130 140 150\nSteps (1e4)70.070.571.071.572.072.5Dev accuracy (MLM) %W/ Dropout\nW/O Dropout (b) Removing dropout\nFigure 3: The effects of adding data and removing dropout during training.\nSQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "SQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg\nNo additional data 89.3/82.3 80.0/77.1 81.6 90.3 64.0 80.1\nWith additional data 88.8/81.7 79.1/76.3 82.4 92.8 66.0 80.8\nTable 8: The effect of additional training data using the ALBERT-base con\ufb01guration.\nWe also note that, even after training for 1M steps, our largest models still do not over\ufb01t to their"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "training data. As a result, we decide to remove dropout to further increase our model capacity. The\nplot in Fig. 3b shows that removing dropout signi\ufb01cantly improves MLM accuracy. Intermediate\nevaluation on ALBERT-xxlarge at around 1M training steps (Table 9) also con\ufb01rms that removing\ndropout helps the downstream tasks. There is empirical (Szegedy et al., 2017) and theoretical (Li"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "et al., 2019) evidence showing that a combination of batch normalization and dropout in Convolu-\ntional Neural Networks may have harmful results. To the best of our knowledge, we are the \ufb01rst to\nshow that dropout can hurt performance in large Transformer-based models.\nSQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg\nWith dropout 94.7/89.2 89.6/86.9 90.0 96.3 85.7 90.4"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Without dropout 94.8/89.5 89.9/87.2 90.4 96.5 86.1 90.7\nTable 9: The effect of removing dropout, measured for an ALBERT-xxlarge con\ufb01guration.\n4.9 C URRENT STATE -OF-THE-ART ON NLU T ASKS\nThe results we report in this section make use of the training data used by Devlin et al. (2019), as\nwell as the additional data used by Liu et al. (2019) and Yang et al. (2019). We report state-of-the-art"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "results under two settings for \ufb01ne-tuning: single-model and ensembles. In both settings, we only do\nsingle-task \ufb01ne-tuning4. Following Liu et al. (2019), on the development set we report the median\nresult over \ufb01ve runs.\nThe single-model ALBERT con\ufb01guration incorporates the best-performing settings discussed: an"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ALBERT-xxlarge con\ufb01guration (Table 2) using combined MLM and SOP losses, and no dropout.\nThe checkpoints that contribute to the \ufb01nal ensemble model are selected based on development set\nperformance; the number of checkpoints considered for this selection range from 6 to 17, depending\non the task. For the GLUE (Table 10) and RACE (Table 11) benchmarks, we average the model"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "predictions for the ensemble models, where the candidates are \ufb01ne-tuned from different training\nsteps using the 12-layer and 24-layer architectures. For SQuAD (Table 11), we average the pre-\ndiction scores for those spans that have multiple probabilities; we also average the scores of the\n\u201cunanswerable\u201d decision."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "\u201cunanswerable\u201d decision.\n4Following Liu et al. (2019), we \ufb01ne-tune for RTE, STS, and MRPC using an MNLI checkpoint.\n9Under review as a conference paper at ICLR 2020\nBoth single-model and ensemble results indicate that ALBERT improves the state-of-the-art signif-\nicantly for all three benchmarks, achieving a GLUE score of 89.4, a SQuAD 2.0 test F1 score of"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "92.2, and a RACE test accuracy of 89.4. The latter appears to be a particularly strong improvement,\na jump of +17.4% absolute points over BERT (Devlin et al., 2019), +7.6% over XLNet (Yang et al.,\n2019), +6.2% over RoBERTa (Liu et al., 2019), and 5.3% over DCMI+ (Zhang et al., 2019), an en-\nsemble of multiple models speci\ufb01cally designed for reading comprehension tasks. Our single model"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "achieves an accuracy of 86:5%, which is still 2:4%better than the state-of-the-art ensemble model.\nModels MNLI QNLI QQP RTE SST MRPC CoLA STS WNLI Avg\nSingle-task single models on dev\nBERT-large 86.6 92.3 91.3 70.4 93.2 88.0 60.6 90.0 - -\nXLNet-large 89.8 93.9 91.8 83.8 95.6 89.2 63.6 91.8 - -\nRoBERTa-large 90.2 94.7 92.2 86.6 96.4 90.9 68.0 92.4 - -"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ALBERT (1M) 90.4 95.2 92.0 88.1 96.8 90.2 68.7 92.7 - -\nALBERT (1.5M) 90.8 95.3 92.2 89.2 96.9 90.9 71.4 93.0 - -\nEnsembles on test (from leaderboard as of Sept. 16, 2019)\nALICE 88.2 95.7 90.7 83.5 95.2 92.6 69.2 91.1 80.8 87.0\nMT-DNN 87.9 96.0 89.9 86.3 96.5 92.7 68.4 91.1 89.0 87.6\nXLNet 90.2 98.6 90.3 86.3 96.8 93.0 67.8 91.6 90.4 88.4\nRoBERTa 90.8 98.9 90.2 88.2 96.7 92.3 67.8 92.2 89.0 88.5"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Adv-RoBERTa 91.1 98.8 90.3 88.7 96.8 93.1 68.0 92.4 89.0 88.8\nALBERT 91.3 99.2 90.5 89.2 97.1 93.4 69.1 92.5 91.8 89.4\nTable 10: State-of-the-art results on the GLUE benchmark. For single-task single-model results, we\nreport ALBERT at 1M steps (comparable to RoBERTa) and at 1.5M steps. The ALBERT ensemble\nuses models trained with 1M, 1.5M, and other numbers of steps."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Models SQuAD1.1 dev SQuAD2.0 dev SQuAD2.0 test RACE test (Middle/High)\nSingle model (from leaderboard as of Sept. 23, 2019)\nBERT-large 90.9/84.1 81.8/79.0 89.1/86.3 72.0 (79.6/70.1)\nXLNet 94.5/89.0 88.8/86.1 89.1/86.3 81.8 (85.5/80.2)\nRoBERTa 94.6/88.9 89.4/86.5 89.8/86.8 83.2 (86.5/81.3)\nUPM - - 89.9/87.2 -\nXLNet + SG-Net Veri\ufb01er++ - - 90.1/87.2 -"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ALBERT (1M) 94.8/89.2 89.9/87.2 - 86.0 (88.2/85.1)\nALBERT (1.5M) 94.8/89.3 90.2/87.4 90.9/88.1 86.5 (89.0/85.5)\nEnsembles (from leaderboard as of Sept. 23, 2019)\nBERT-large 92.2/86.2 - - -\nXLNet + SG-Net Veri\ufb01er - - 90.7/88.2 -\nUPM - - 90.7/88.2\nXLNet + DAAF + Veri\ufb01er - - 90.9/88.6 -\nDCMI+ - - - 84.1 (88.5/82.3)\nALBERT 95.5/90.1 91.4/88.9 92.2/89.7 89.4 (91.2/88.6)"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Table 11: State-of-the-art results on the SQuAD and RACE benchmarks.\n5 D ISCUSSION\nWhile ALBERT-xxlarge has less parameters than BERT-large and gets signi\ufb01cantly better results, it\nis computationally more expensive due to its larger structure. An important next step is thus to speed\nup the training and inference speed of ALBERT through methods like sparse attention (Child et al.,"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "2019) and block attention (Shen et al., 2018). An orthogonal line of research, which could provide\nadditional representation power, includes hard example mining (Mikolov et al., 2013) and more\nef\ufb01cient language modeling training (Yang et al., 2019). Additionally, although we have convincing\nevidence that sentence order prediction is a more consistently-useful learning task that leads to better"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "language representations, we hypothesize that there could be more dimensions not yet captured by\nthe current self-supervised training losses that could create additional representation power for the\nresulting representations.\n10Under review as a conference paper at ICLR 2020\nREFERENCES\nShaojie Bai, J. Zico Kolter, and Vladlen Koltun. Deep equilibrium models. In Neural Information"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Processing Systems (NeurIPS) , 2019.\nRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and\nIdan Szpektor. The second PASCAL recognising textual entailment challenge. In Proceedings of\nthe second PASCAL challenges workshop on recognising textual entailment , volume 6, pp. 6\u20134.\nVenice, 2006."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Venice, 2006.\nLuisa Bentivogli, Peter Clark, Ido Dagan, and Danilo Giampiccolo. The \ufb01fth PASCAL recognizing\ntextual entailment challenge. In TAC, 2009.\nDaniel Cer, Mona Diab, Eneko Agirre, I \u02dcnigo Lopez-Gazpio, and Lucia Specia. SemEval-2017 task\n1: Semantic textual similarity multilingual and crosslingual focused evaluation. In Proceedings of"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "the 11th International Workshop on Semantic Evaluation (SemEval-2017) , pp. 1\u201314, Vancouver,\nCanada, August 2017. Association for Computational Linguistics. doi: 10.18653/v1/S17-2001.\nURL https://www.aclweb.org/anthology/S17-2001 .\nTianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. Training deep nets with sublinear\nmemory cost. arXiv preprint arXiv:1604.06174 , 2016."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with sparse\ntransformers. arXiv preprint arXiv:1904.10509 , 2019.\nIdo Dagan, Oren Glickman, and Bernardo Magnini. The PASCAL recognising textual entailment\nchallenge. In Machine Learning Challenges Workshop , pp. 177\u2013190. Springer, 2005."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and \u0141ukasz Kaiser. Universal\ntransformers. arXiv preprint arXiv:1807.03819 , 2018.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep\nbidirectional transformers for language understanding. In Proceedings of the 2019 Conference of"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "the North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) , pp. 4171\u20134186, Minneapolis, Minnesota, June\n2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https:\n//www.aclweb.org/anthology/N19-1423 ."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "//www.aclweb.org/anthology/N19-1423 .\nWilliam B. Dolan and Chris Brockett. Automatically constructing a corpus of sentential paraphrases.\nInProceedings of the Third International Workshop on Paraphrasing (IWP2005) , 2005. URL\nhttps://www.aclweb.org/anthology/I05-5002 .\nZhe Gan, Yunchen Pu, Ricardo Henao, Chunyuan Li, Xiaodong He, and Lawrence Carin. Learn-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ing generic sentence representations using convolutional neural networks. In Proceedings of\nthe 2017 Conference on Empirical Methods in Natural Language Processing , pp. 2390\u20132400,\nCopenhagen, Denmark, September 2017. Association for Computational Linguistics. doi:\n10.18653/v1/D17-1254. URL https://www.aclweb.org/anthology/D17-1254 ."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. The third PASCAL recognizing\ntextual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entail-\nment and Paraphrasing , pp. 1\u20139, Prague, June 2007. Association for Computational Linguistics.\nURL https://www.aclweb.org/anthology/W07-1401 ."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Aidan N Gomez, Mengye Ren, Raquel Urtasun, and Roger B Grosse. The reversible residual net-\nwork: Backpropagation without storing activations. In Advances in neural information processing\nsystems , pp. 2214\u20132224, 2017.\nBarbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. Centering: A framework for modeling the"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "local coherence of discourse. Computational Linguistics , 21(2):203\u2013225, 1995. URL https:\n//www.aclweb.org/anthology/J95-2003 .\nM.A.K. Halliday and Ruqaiya Hasan. Cohesion in English . Routledge, 1976.\n11Under review as a conference paper at ICLR 2020\nJie Hao, Xing Wang, Baosong Yang, Longyue Wang, Jinfeng Zhang, and Zhaopeng Tu. Modeling"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "recurrence for transformer. Proceedings of the 2019 Conference of the North , 2019. doi: 10.\n18653/v1/n19-1122. URL http://dx.doi.org/10.18653/v1/n19-1122 .\nDan Hendrycks and Kevin Gimpel. Gaussian Error Linear Units (GELUs). arXiv preprint\narXiv:1606.08415 , 2016.\nFelix Hill, Kyunghyun Cho, and Anna Korhonen. Learning distributed representations of sentences"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "from unlabelled data. In Proceedings of the 2016 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human Language Technologies , pp. 1367\u20131377.\nAssociation for Computational Linguistics, 2016. doi: 10.18653/v1/N16-1162. URL http:\n//aclweb.org/anthology/N16-1162 .\nJerry R. Hobbs. Coherence and coreference. Cognitive Science , 3(1):67\u201390, 1979."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Shankar Iyer, Nikhil Dandekar, and Kornl Csernai. First quora dataset release: Ques-\ntion pairs, January 2017. URL https://www.quora.com/q/quoradata/\nFirst-Quora-Dataset-Release-Question-Pairs .\nYacine Jernite, Samuel R Bowman, and David Sontag. Discourse-based objectives for fast unsuper-\nvised sentence representation learning. arXiv preprint arXiv:1705.00557 , 2017."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S Weld, Luke Zettlemoyer, and Omer Levy.\nSpanBERT: Improving pre-training by representing and predicting spans. arXiv preprint\narXiv:1907.10529 , 2019.\nRyan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Ur-\ntasun, and Sanja Fidler. Skip-thought vectors. In Proceedings of the 28th International Con-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ference on Neural Information Processing Systems - Volume 2 , NIPS\u201915, pp. 3294\u20133302, Cam-\nbridge, MA, USA, 2015. MIT Press. URL http://dl.acm.org/citation.cfm?id=\n2969442.2969607 .\nTaku Kudo and John Richardson. SentencePiece: A simple and language independent sub-\nword tokenizer and detokenizer for neural text processing. In Proceedings of the 2018 Con-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ference on Empirical Methods in Natural Language Processing: System Demonstrations , pp.\n66\u201371, Brussels, Belgium, November 2018. Association for Computational Linguistics. doi:\n10.18653/v1/D18-2012. URL https://www.aclweb.org/anthology/D18-2012 .\nGuokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. RACE: Large-scale ReAding"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "comprehension dataset from examinations. In Proceedings of the 2017 Conference on Empirical\nMethods in Natural Language Processing , pp. 785\u2013794, Copenhagen, Denmark, September 2017.\nAssociation for Computational Linguistics. doi: 10.18653/v1/D17-1082. URL https://www.\naclweb.org/anthology/D17-1082 .\nQuoc Le and Tomas Mikolov. Distributed representations of sentences and documents. In Proceed-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ings of the 31st ICML , Beijing, China, 2014.\nHector Levesque, Ernest Davis, and Leora Morgenstern. The Winograd schema challenge. In Thir-\nteenth International Conference on the Principles of Knowledge Representation and Reasoning ,\n2012.\nXiang Li, Shuo Chen, Xiaolin Hu, and Jian Yang. Understanding the disharmony between dropout"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "and batch normalization by variance shift. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition , pp. 2682\u20132690, 2019.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike\nLewis, Luke Zettlemoyer, and Veselin Stoyanov. RoBERTa: A robustly optimized BERT pre-\ntraining approach. arXiv preprint arXiv:1907.11692 , 2019."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. Learned in translation:\nContextualized word vectors. In I. Guyon, U. V . Luxburg, S. Bengio, H. Wallach, R. Fergus,\nS. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30 ,\npp. 6294\u20136305. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "7209-learned-in-translation-contextualized-word-vectors.pdf .\n12Under review as a conference paper at ICLR 2020\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed represen-\ntations of words and phrases and their compositionality. In Advances in neural information pro-\ncessing systems , pp. 3111\u20133119, 2013."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "cessing systems , pp. 3111\u20133119, 2013.\nAllen Nie, Erin Bennett, and Noah Goodman. DisSent: Learning sentence representations from ex-\nplicit discourse relations. In Proceedings of the 57th Annual Meeting of the Association for Com-\nputational Linguistics , pp. 4497\u20134510, Florence, Italy, July 2019. Association for Computational"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Linguistics. doi: 10.18653/v1/P19-1442. URL https://www.aclweb.org/anthology/\nP19-1442 .\nJeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word rep-\nresentation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language\nProcessing (EMNLP) , pp. 1532\u20131543, Doha, Qatar, October 2014. Association for Computational"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Linguistics. doi: 10.3115/v1/D14-1162. URL https://www.aclweb.org/anthology/\nD14-1162 .\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and\nLuke Zettlemoyer. Deep contextualized word representations. In Proceedings of the 2018 Con-\nference of the North American Chapter of the Association for Computational Linguistics: Hu-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "man Language Technologies, Volume 1 (Long Papers) , pp. 2227\u20132237, New Orleans, Louisiana,\nJune 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1202. URL\nhttps://www.aclweb.org/anthology/N18-1202 .\nAlec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language\nunderstanding by generative pre-training. https://s3-us-west-2.amazonaws.com/"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "openai-assets/research-covers/language-unsupervised/language_\nunderstanding_paper.pdf , 2018.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language\nmodels are unsupervised multitask learners. OpenAI Blog , 1(8), 2019.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods\nin Natural Language Processing , pp. 2383\u20132392, Austin, Texas, November 2016. Association\nfor Computational Linguistics. doi: 10.18653/v1/D16-1264. URL https://www.aclweb.\norg/anthology/D16-1264 .\nPranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don\u2019t know: Unanswerable questions"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "for SQuAD. In Proceedings of the 56th Annual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pp. 784\u2013789, Melbourne, Australia, July 2018. Association\nfor Computational Linguistics. doi: 10.18653/v1/P18-2124. URL https://www.aclweb.\norg/anthology/P18-2124 .\nTao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, and Chengqi Zhang. Bi-directional block self-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "attention for fast and memory-ef\ufb01cient sequence modeling. arXiv preprint arXiv:1804.00857 ,\n2018.\nMohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan\nCatanzaro. Megatron-LM: Training multi-billion parameter language models using model par-\nallelism, 2019.\nRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng,"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment\ntreebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language\nProcessing , pp. 1631\u20131642, Seattle, Washington, USA, October 2013. Association for Computa-\ntional Linguistics. URL https://www.aclweb.org/anthology/D13-1170 ."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Siqi Sun, Yu Cheng, Zhe Gan, and Jingjing Liu. Patient knowledge distillation for BERT model\ncompression. arXiv preprint arXiv:1908.09355 , 2019.\nChristian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alexander A Alemi. Inception-v4,\ninception-resnet and the impact of residual connections on learning. In Thirty-First AAAI Confer-\nence on Arti\ufb01cial Intelligence , 2017."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ence on Arti\ufb01cial Intelligence , 2017.\n13Under review as a conference paper at ICLR 2020\nIulia Turc, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Well-read students learn better:\nThe impact of student initialization on knowledge distillation. arXiv preprint arXiv:1908.08962 ,\n2019.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information\nprocessing systems , pp. 5998\u20136008, 2017.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. GLUE:\nA multi-task benchmark and analysis platform for natural language understanding. In Proceed-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks\nfor NLP , pp. 353\u2013355, Brussels, Belgium, November 2018. Association for Computational Lin-\nguistics. doi: 10.18653/v1/W18-5446. URL https://www.aclweb.org/anthology/\nW18-5446 .\nWei Wang, Bin Bi, Ming Yan, Chen Wu, Zuyi Bao, Liwei Peng, and Luo Si. StructBERT: Incor-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "porating language structures into pre-training for deep language understanding. arXiv preprint\narXiv:1908.04577 , 2019.\nAlex Warstadt, Amanpreet Singh, and Samuel R Bowman. Neural network acceptability judgments.\narXiv preprint arXiv:1805.12471 , 2018.\nAdina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sen-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "tence understanding through inference. In Proceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technolo-\ngies, Volume 1 (Long Papers) , pp. 1112\u20131122, New Orleans, Louisiana, June 2018. Association\nfor Computational Linguistics. doi: 10.18653/v1/N18-1101. URL https://www.aclweb.\norg/anthology/N18-1101 ."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "org/anthology/N18-1101 .\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V\nLe. XLNet: Generalized autoregressive pretraining for language understanding. arXiv preprint\narXiv:1906.08237 , 2019.\nYang You, Jing Li, Jonathan Hseu, Xiaodan Song, James Demmel, and Cho-Jui Hsieh. Reducing"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "BERT pre-training time from 3 days to 76 minutes. arXiv preprint arXiv:1904.00962 , 2019.\nShuailiang Zhang, Hai Zhao, Yuwei Wu, Zhuosheng Zhang, Xi Zhou, and Xiang Zhou.\nDCMN+: Dual co-matching network for multi-choice reading comprehension. arXiv preprint\narXiv:1908.11511 , 2019.\nYukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Sanja Fidler. Aligning books and movies: Towards story-like visual explanations by watching\nmovies and reading books. In Proceedings of the IEEE international conference on computer\nvision , pp. 19\u201327, 2015.\nA A PPENDIX\nA.1 D OWNSTREAM EVALUATION TASKS\nGLUE GLUE is comprised of 9 tasks, namely Corpus of Linguistic Acceptability"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "(CoLA; Warstadt et al., 2018), Stanford Sentiment Treebank (SST; Socher et al., 2013), Microsoft\nResearch Paraphrase Corpus (MRPC; Dolan & Brockett, 2005), Semantic Textual Similarity Bench-\nmark (STS; Cer et al., 2017), Quora Question Pairs (QQP; Iyer et al., 2017), Multi-Genre NLI\n(MNLI; Williams et al., 2018), Question NLI (QNLI; Rajpurkar et al., 2016), Recognizing Textual"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Entailment (RTE; Dagan et al., 2005; Bar-Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli\net al., 2009) and Winograd NLI (WNLI; Levesque et al., 2012). It focuses on evaluating model\ncapabilities for natural language understanding. When reporting MNLI results, we only report the\n\u201cmatch\u201d condition (MNLI-m). We follow the \ufb01netuning procedures from prior work (Devlin et al.,"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "2019; Liu et al., 2019; Yang et al., 2019) and report the held-out test set performance obtained from\nGLUE submissions. For test set submissions, we perform task-speci\ufb01c modi\ufb01cations for WNLI and\nQNLI as described by Liu et al. (2019) and Yang et al. (2019).\n14Under review as a conference paper at ICLR 2020\nSQuAD SQuAD is an extractive question answering dataset built from Wikipedia. The answers"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "are segments from the context paragraphs and the task is to predict answer spans. We evaluate our\nmodels on two versions of SQuAD: v1.1 and v2.0. SQuAD v1.1 has 100,000 human-annotated\nquestion/answer pairs. SQuAD v2.0 additionally introduced 50,000 unanswerable questions. For\nSQuAD v1.1, we use the same training procedure as BERT, whereas for SQuAD v2.0, models are"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "jointly trained with a span extraction loss and an additional classi\ufb01er for predicting answerabil-\nity (Yang et al., 2019; Liu et al., 2019). We report both development set and test set performance.\nRACE RACE is a large-scale dataset for multi-choice reading comprehension, collected from En-\nglish examinations in China with nearly 100,000 questions. Each instance in RACE has 4 candidate"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "answers. Following prior work (Yang et al., 2019; Liu et al., 2019), we use the concatenation of the\npassage, question, and each candidate answer as the input to models. Then, we use the represen-\ntations from the \u201c[CLS]\u201d token for predicting the probability of each answer. The dataset consists\nof two domains: middle school and high school. We train our models on both domains and report"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "accuracies on both the development set and test set.\nA.2 H YPERPARAMETERS\nHyperparameters for downstream tasks are shown in Table 12. We adapt these hyperparameters\nfrom Liu et al. (2019), Devlin et al. (2019), and Yang et al. (2019).\nLR BSZ ALBERT DR Classi\ufb01er DR TS WS MSL\nCoLA 1.00E-05 16 0 0.1 5336 320 512\nSTS 2.00E-05 16 0 0.1 3598 214 512\nSST-2 1.00E-05 32 0 0.1 20935 1256 512"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "SST-2 1.00E-05 32 0 0.1 20935 1256 512\nMNLI 3.00E-05 128 0 0.1 10000 1000 512\nQNLI 1.00E-05 32 0 0.1 33112 1986 512\nQQP 5.00E-05 128 0.1 0.1 14000 1000 512\nRTE 3.00E-05 32 0.1 0.1 800 200 512\nMRPC 2.00E-05 32 0 0.1 800 200 512\nWNLI 2.00E-05 16 0.1 0.1 2000 250 512\nSQuAD v1.1 5.00E-05 48 0 0.1 3649 365 384\nSQuAD v2.0 3.00E-05 48 0 0.1 8144 814 512\nRACE 2.00E-05 32 0.1 0.1 12000 1000 512"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "RACE 2.00E-05 32 0.1 0.1 12000 1000 512\nTable 12: Hyperparameters for ALBERT in downstream tasks. LR: Learning Rate. BSZ: Batch\nSize. DR: Dropout Rate. TS: Training Steps. WS: Warmup Steps. MSL: Maximum Sequence\nLength.\nA.3 E FFECT OF NETWORK DEPTH AND WIDTH\nIn this section, we check how depth (number of layers) and width (hidden size) affect the perfor-"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "mance of ALBERT. Table 13 shows the performance of an ALBERT-large con\ufb01guration (see Ta-\nble 2) using different numbers of layers. Networks with 3 or more layers are trained by \ufb01ne-tuning\nusing the parameters from the depth before (e.g., the 12-layer network parameters are \ufb01ne-tuned\nfrom the checkpoint of the 6-layer network parameters).5If we compare a 3-layer ALBERT model"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "with a 1-layer ALBERT model, although they have the same number of parameters, the perfor-\nmance increases signi\ufb01cantly. However, there are diminishing returns when continuing to increase\nthe number of layers: the results of a 12-layer network are relatively close to the results of a 24-layer\nnetwork, and the performance of a 48-layer network appears to decline."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "A similar phenomenon, this time for width, can be seen in Table 14 for a 3-layer ALBERT-large\ncon\ufb01guration. As we increase the hidden size, we get an increase in performance with diminishing\nreturns. At a hidden size of 6144, the performance appears to decline signi\ufb01cantly. We note that none\nof these models appear to over\ufb01t the training data, and they all have higher training and development"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "loss compared to the best-performing ALBERT con\ufb01gurations.\n5If we compare the performance of ALBERT-large here to the performance in Table 3, we can see that this\nwarm-start technique does not help to improve the downstream performance. However, it does help the 48-layer\nnetwork to converge. A similar technique has been applied to our ALBERT-xxlarge, where we warm-start from\na 6-layer network."}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "a 6-layer network.\n15Under review as a conference paper at ICLR 2020\nNumber of layers Parameters SQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg\n1 18M 31.1/22.9 50.1/50.1 66.4 80.8 40.1 52.9\n3 18M 79.8/69.7 64.4/61.7 77.7 86.7 54.0 71.2\n6 18M 86.4/78.4 73.8/71.1 81.2 88.9 60.9 77.2\n12 18M 89.8/83.3 80.7/77.9 83.3 91.7 66.7 81.5\n24 18M 90.3/83.3 81.8/79.0 83.3 91.5 68.7 82.1"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "48 18M 90.0/83.1 81.8/78.9 83.4 91.9 66.9 81.8\nTable 13: The effect of increasing the number of layers for an ALBERT-large con\ufb01guration.\nHidden size Parameters SQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg\n1024 18M 79.8/69.7 64.4/61.7 77.7 86.7 54.0 71.2\n2048 59M 83.3/74.1 69.1/66.6 79.7 88.6 58.2 74.6\n4096 223M 85.0/76.4 71.0/68.1 80.3 90.4 60.4 76.3\n6144 497M 84.7/75.8 67.8/65.4 78.1 89.1 56.0 74.0"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "Table 14: The effect of increasing the hidden-layer size for an ALBERT-large 3-layer con\ufb01guration.\nA.4 D O VERY WIDE ALBERT MODELS NEED TO BE DEEP (ER)TOO?\nIn Section A.3, we show that for ALBERT-large ( H=1024), the difference between a 12-layer and a\n24-layer con\ufb01guration is small. Does this result still hold for much wider ALBERT con\ufb01gurations,\nsuch as ALBERT-xxlarge ( H=4096)?"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "such as ALBERT-xxlarge ( H=4096)?\nNumber of layers SQuAD1.1 SQuAD2.0 MNLI SST-2 RACE Avg\n12 94.0/88.1 88.3/85.3 87.8 95.4 82.5 88.7\n24 94.1/88.3 88.1/85.1 88.0 95.2 82.3 88.7\nTable 15: The effect of a deeper network using an ALBERT-xxlarge con\ufb01guration.\nThe answer is given by the results from Table 15. The difference between 12-layer and 24-layer"}, {"source": "1057_albert_a_lite_bert_for_self_su-Original Pdf.pdf", "text": "ALBERT-xxlarge con\ufb01gurations in terms of downstream accuracy is negligible, with the Avg score\nbeing the same. We conclude that, when sharing all cross-layer parameters (ALBERT-style), there\nis no need for models deeper than a 12-layer con\ufb01guration.\n16"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Proceedings of the 14th International Workshop on Semantic Evaluation , pages 1377\u20131414\nBarcelona, Spain (Online), December 12, 2020.1377SemEval-2020 Task 11:\nDetection of Propaganda Techniques in News Articles\nGiovanni Da San Martino1, Alberto Barr \u00b4on-Cede \u02dcno2,\nHenning Wachsmuth3,Rostislav Petrov4and Preslav Nakov1"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "1Qatar Computing Research Institute, HBKU, Qatar2Universit `a di Bologna, Forl `\u0131, Italy\n3Paderborn University, Paderborn, Germany4A Data Pro, So\ufb01a, Bulgaria\nfgmartino, pnakov g@hbku.edu.qa a.barron@unibo.it\nhenningw@upb.de rostislav.petrov@adata.pro\nAbstract\nWe present the results and the main \ufb01ndings of SemEval-2020 Task 11 on Detection of Propa-"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "ganda Techniques in News Articles. The task featured two subtasks. Subtask SI is about Span\nIdenti\ufb01cation : given a plain-text document, spot the speci\ufb01c text fragments containing propaganda.\nSubtask TC is about Technique Classi\ufb01cation : given a speci\ufb01c text fragment, in the context of\na full document, determine the propaganda technique it uses, choosing from an inventory of 14"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "possible propaganda techniques. The task attracted a large number of participants: 250teams\nsigned up to participate and 44made a submission on the test set. In this paper, we present the\ntask, analyze the results, and discuss the system submissions and the methods they used. For both\nsubtasks, the best systems used pre-trained Transformers and ensembles.\n1 Introduction"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "1 Introduction\nPropaganda aims at in\ufb02uencing people\u2019s mindset with the purpose of advancing a speci\ufb01c agenda. It can\nhide in news published by both established and non-established outlets, and, in the Internet era, it has the\npotential of reaching very large audiences (Muller, 2018; Tard \u00b4aguila et al., 2018; Glowacki et al., 2018)."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Propaganda is most successful when it goes unnoticed by the reader, and it often takes some training for\npeople to be able to spot it. The task is way more dif\ufb01cult for inexperienced users, and the volume of text\nproduced on a daily basis makes it dif\ufb01cult for experts to cope with it manually. With the recent interest in"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "\u201cfake news\u201d, the detection of propaganda or highly biased texts has emerged as an active research area.\nHowever, most previous work has performed analysis at the document level only (Rashkin et al., 2017;\nBarr\u00b4on-Cede \u02dcno et al., 2019a) or has analyzed the general patterns of online propaganda (Garimella et al.,\n2015; Chat\ufb01eld et al., 2015)."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "2015; Chat\ufb01eld et al., 2015).\nSemEval-2020 Task 11 offers a different perspective: a \ufb01ne-grained analysis of the text that comple-\nments existing approaches and can, in principle, be combined with them. Propaganda in text (and in other\nchannels) is conveyed through the use of diverse propaganda techniques (Miller, 1939), which range from"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "leveraging on the emotions of the audience \u2014such as using loaded language orappeals to fear \u2014 to using\nlogical fallacies \u2014such as straw men (misrepresenting someone\u2019s opinion), hidden ad-hominem fallacies ,\nandred herring (presenting irrelevant data). Some of these techniques have been studied in tasks such as"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "hate speech detection (Gao et al., 2017) and computational argumentation (Habernal et al., 2018).\nFigure 1 shows the \ufb01ne-grained propaganda identi\ufb01cation pipeline, including the two targeted subtasks.\nOur goal is to facilitate the development of models capable of spotting text fragments where propaganda\ntechniques are used. The task featured the following subtasks:"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Subtask SI (Span Identi\ufb01cation) : Given a plain-text document, identify those speci\ufb01c fragments that\ncontain at least one propaganda technique. (This is a binary sequence tagging task.)\nSubtask TC (Technique Classi\ufb01cation) : Given a propagandistic text snippet and its document context,\nidentify the propaganda technique used in that snippet. (This is a multi-class classi\ufb01cation problem.)"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://\ncreativecommons.org/licenses/by/4.0/ .1378\nSpan\nIdentificationTechnique\nClassificationTask 1 Task 2 Input OutputFigure 1: The full propaganda identi\ufb01cation pipeline, including the two subtasks: Span Identi\ufb01cation and\nTechnique Classi\ufb01cation."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Technique Classi\ufb01cation.\nA total of 250teams registered for the task, 44of them made an of\ufb01cial submission on the test set ( 66\nsubmissions for both subtasks), and 32of the participating teams submitted a system description paper.\nThe rest of the paper is organized as follows. Section 2 introduces the propaganda techniques we"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "considered in this shared task. Section 3 describes the organization of the task, the corpus and the\nevaluation measures. An overview of the participating systems is given in Section 4, while Section 5\ndiscusses the evaluation results. Related work is described in Section 6. Finally, Section 7 draws some\nconclusions, and discusses some directions for future work.\n2 Propaganda and its Techniques"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "2 Propaganda and its Techniques\nPropaganda comes in many forms, but it can be recognized by its persuasive function, sizable target\naudience, the representation of a speci\ufb01c group\u2019s agenda, and the use of faulty reasoning and/or emotional\nappeals (Miller, 1939). The term propaganda was coined in the 17th century, and initially referred to the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "propagation of the Catholic faith in the New World (Jowett and O\u2019Donnell, 2012a, p. 2). It soon took a\npejorative connotation, as its meaning was extended to also mean opposition to Protestantism. In more\nrecent times, the Institute for Propaganda Analysis (Ins, 1938) proposed the following de\ufb01nition:\nPropaganda. Expression of opinion or action by individuals or groups deliberately designed to"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "in\ufb02uence opinions or actions of other individuals or groups with reference to predetermined ends .\nRecently, Bolsover and Howard (2017) dug deeper into this de\ufb01nition identifying its two key elements:\n(i) trying to in\ufb02uence opinion, and ( ii) doing so on purpose.\nPropaganda is a broad concept, which runs short for the aim of annotating speci\ufb01c propaganda fragments."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Yet, in\ufb02uencing opinions is achieved through a series of rhetorical and psychological techniques, and\nin the present task, we focus on identifying the use of such techniques in text. Whereas the de\ufb01nition\nof propaganda is widely accepted in the literature, the set of propaganda techniques considered, and to"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "some extent their de\ufb01nition, differ between different scholars (Torok, 2015). For instance, Miller (1939)\nconsiders seven propaganda techniques, whereas Weston (2000) lists at least 24 techniques, and the\nWikipedia article on the topic includes 67.1Below, we describe the propaganda techniques we consider in"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "the task: a curated list of fourteen techniques derived from the aforementioned studies. We only include\ntechniques that can be found in journalistic articles and can be judged intrinsically, without the need\nto retrieve supporting information from external resources. For example, we do not include techniques"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "such as card stacking (Jowett and O\u2019Donnell, 2012b, p. 237), since it would require comparing multiple\nsources. Note that our list of techniques was initially longer than fourteen, but we decided, after the\nannotation phase, to merge similar techniques with very low frequency in the corpus. A more detailed list"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "with de\ufb01nitions and examples is available online2and in Appendix C, and examples are shown in Table 1.\n1. Loaded language. Using speci\ufb01c words and phrases with strong emotional implications (either\npositive or negative) to in\ufb02uence an audience (Weston, 2000, p. 6).\n2. Name calling or labeling. Labeling the object of the propaganda campaign as either something the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "target audience fears, hates, \ufb01nds undesirable or loves, praises (Miller, 1939).\n1https://en.wikipedia.org/wiki/Propaganda_techniques ; last visit February 2019.\n2http://propaganda.qcri.org/annotations/definitions.html1379# Technique Snippet\n1 Loaded language Outrage as Donald Trump suggests injecting disinfectant to kill virus."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "2 Name calling, labeling WHO: Coronavirus emergency is \u2019 Public Enemy Number 1 \u2019\n3 Repetition I still have a dream . It is a dream deeply rooted in the American dream . I have a dream\nthat one day . . .\n4 Exaggeration, minimization Coronavirus \u2018risk to the American people remains very low\u2019 , Trump said.\n5 Doubt Can the same be said for the Obama Administration ?"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "6 Appeal to fear/prejudice A dark, impenetrable and \u201cirreversible\u201d winter of persecution of the faithful by their\nown shepherds will fall .\n7 Flag-waving Mueller attempts to stop the will of We the People !!! It\u2019s time to jail Mueller.\n8 Causal oversimpli\ufb01cation If France had not have declared war on Germany then World War II would have never\nhappened.\n9 Slogans \u201cBUILD THE WALL!\u201d Trump tweeted."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "10 Appeal to authority Monsignor Jean-Franois Lantheaume, who served as \ufb01rst Counsellor of the Nuncia-\nture in Washington, con\ufb01rmed that \u201cVigan said the truth. That\u2019s all.\u201d\n11 Black-and-white fallacy Francis said these words: \u201c Everyone is guilty for the good he could have done and did\nnot do . . . If we do not oppose evil, we tacitly feed it .\u201d"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "12 Thought-terminating clich \u00b4eI do not really see any problems there. Marx is the President.\n13 Whataboutism President Trump \u2014 who himself avoided national military service in the 1960\u2019s\u2014 keeps\nbeating the war drums over North Korea.\nStraw man \u201cTake it seriously, but with a large grain of salt.\u201d Which is just Allen\u2019s more nuanced way\nof saying: \u201cDon\u2019t believe it .\u201d"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "of saying: \u201cDon\u2019t believe it .\u201d\nRed herring \u201cYou may claim that the death penalty is an ineffective deterrent against crime \u2013 but\nwhat about the victims of crime? How do you think surviving family members feel\nwhen they see the man who murdered their son kept in prison at their expense? Is it\nright that they should pay for their son\u2019s murderer to be fed and housed?\u201d"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "14 Bandwagon He tweeted, \u201c EU no longer considers #Hamas a terrorist group. Time for US to do\nsame.\u201d\nReductio ad hitlerum \u201cVichy journalism,\u201d a term which now \ufb01ts so much of the mainstream media. It collaborates\nin the same way that the Vichy government in France collaborated with the Nazis.\nTable 1: The 14 propaganda techniques with examples, where the propaganda span is shown in bold."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "3. Repetition. Repeating the same message over and over again, so that the audience will eventually\naccept it (Torok, 2015; Miller, 1939).\n4. Exaggeration or minimization. Either representing something in an excessive manner: making\nthings larger, better, worse or making something seem less important or smaller than it actually is (Jowett\nand O\u2019Donnell, 2012b, pag. 303)."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "and O\u2019Donnell, 2012b, pag. 303).\n5. Doubt. Questioning the credibility of someone or something.\n6. Appeal to fear/prejudice. Seeking to build support for an idea by instilling anxiety and/or panic in\nthe population towards an alternative, possibly based on preconceived judgments.\n7. Flag-waving. Playing on strong national feeling (or with respect to any group, e.g., race, gender,"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "political preference) to justify or promote an action or idea (Hobbs and Mcgee, 2008).\n8. Causal oversimpli\ufb01cation. Assuming a single cause or reason when there are multiple causes behind\nan issue. We include in the de\ufb01nition also scapegoating , e.g., transferring the blame to one person or\ngroup of people without investigating the complexities of an issue."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "9. Slogans. A brief and striking phrase that may include labeling and stereotyping. Slogans tend to act\nas emotional appeals (Dan, 2015).\n10. Appeal to authority. Stating that a claim is true simply because a valid authority or expert on the\nissue supports it, without any other supporting evidence (Goodwin, 2011). We include in this technique the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "special case in which the reference is not an authority or an expert, although it is referred to as testimonial\nin the literature (Jowett and O\u2019Donnell, 2012b, pag. 237).\n11. Black-and-white fallacy, dictatorship. Presenting two alternative options as the only possibilities,\nwhen in fact more possibilities exist (Torok, 2015). Dictatorship is an extreme case: telling the audience"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "exactly what actions to take, eliminating any other possible choice.138012. Thought-terminating clich \u00b4e.Words or phrases that discourage critical thought and meaningful\ndiscussion on a topic. They are typically short, generic sentences that offer seemingly simple answers to\ncomplex questions or that distract attention away from other lines of thought (Hunter, 2015, p. 78)."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "13. Whataboutism, straw man, red herring. Here we merge together three techniques, which are\nrelatively rare taken individually: ( i)Whataboutism: Discredit an opponent\u2019s position by charging them\nwith hypocrisy without directly disproving their argument (Richter, 2017). ( ii)Straw man: When an oppo-"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "nent\u2019s proposition is substituted with a similar one, which is then refuted instead of the original (Walton,\n2013). Weston (2000, p. 78) speci\ufb01es the characteristics of the substituted proposition: \u201ccaricaturing an\nopposing view so that it is easy to refute\u201d. ( iii)Red herring: Introducing irrelevant material to the issue"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "being discussed, so that everyone\u2019s attention is diverted away from the points made (Weston, 2000, p. 78).\n14. Bandwagon, reductio ad hitlerum. Here we merge together two techniques, which are relatively\nrare taken individually: ( i)Bandwagon. Attempting to persuade the target audience to join in and take the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "course of action because \u201ceveryone else is taking the same action\u201d (Hobbs and Mcgee, 2008). ( ii)Reductio\nad hitlerum: Persuading an audience to disapprove an action or idea by suggesting that it is popular with\ngroups hated in contempt by the target audience. It can refer to any person or concept with a negative\nconnotation (Teninbaum, 2009)."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "connotation (Teninbaum, 2009).\nWe provided the de\ufb01nitions, together with some examples and an annotation schema, to professional\nannotators, and we asked them to manually annotate selected news articles. The annotators worked with\nan earlier version of the annotation schema, which contained eighteen techniques (Da San Martino et al.,"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "2019b). As some of these techniques were quite rare, which could cause data sparseness issues for the\nparticipating systems, for the purpose of the present SemEval-2020 task 11, we decided to get rid of the\nfour rarest techniques. In particular, we merged Red herring andStraw man with Whataboutism (under"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "technique 13), since all three techniques are trying to divert the attention to an irrelevant topic and away\nfrom the actual argument. We further merged Bandwagon with Reductio ad hitlerum (under technique\n14), since they both try to approve/disapprove an action or idea by pointing to what is popular/unpopular."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Finally, we dropped one rare technique, which we could not easily merge with other techniques: Ob-\nfuscation, Intentional vagueness, Confusion . As a result, we reduced the eighteen original propaganda\ntechniques to fourteen.\n3 Evaluation Framework\nThe SemEval 2020 Task 11 evaluation framework consists of the PTC-SemEval20 corpus and the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "evaluation measures for both the span identi\ufb01cation and the technique classi\ufb01cation subtasks. We describe\nthe organization of the task in Section 3.3; here, we focus on the dataset, the evaluation measure, and the\norganization setup.\n3.1 The PTC-SemEval20 Corpus\nIn order to build the PTC-SemEval20 corpus, we retrieved a sample of news articles from the period"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "starting in mid-2017 and ending in early 2019. We selected 13 propaganda and 36 non-propaganda news\nmedia outlets, as labeled by Media Bias/Fact Check,3and we retrieved articles from these sources. We\ndeduplicated the articles on the basis of word n-gram matching (Barr \u00b4on-Cede \u02dcno and Rosso, 2009), and\nwe discarded faulty entries, e.g., empty entries from blocking websites."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "The annotation job consisted of both spotting a propaganda snippet and, at the same time, labeling\nit with a speci\ufb01c propaganda technique. The annotation guidelines are shown in Appendix C; they\nare also available online.4We ran the annotation in two phases: ( i) two annotators labeled an article"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "independently, and ( ii) the same two annotators gathered together with a consolidator to discuss dubious\ninstances, e.g., spotted only by one annotator, boundary discrepancies, label mismatch, etc. This protocol\nwas designed after a pilot annotation stage, in which a relatively large number of snippets had been spotted\nby one annotator only."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "by one annotator only.\n3An initiative where professional journalists pro\ufb01le news outlets; https://mediabiasfactcheck.com .\n4https://propaganda.qcri.org/annotations/1381\nManchin says Democrats acted like babies at the SOTU\nIn a glaring sign of just how stupid and petty things have become \nin Washington these days [...] State of the Union speech not looking"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "as though Trump killed his grandma. [...]123456 Name_Calling 34        40\n123456 Loaded_Language 83        89123456 Loaded_Language 94        99123456 Loaded_Language 350      368\n... ...Input article Annotation file\nArticle ID Technique  Start     EndFigure 2: Example of a plain-text article (left) and its annotation (right). The Start and the End columns"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "are the indices representing the character span of the spotted technique.\npartition articles average lengths propaganda\nchars tokens snippets\ntraining 371 5,681\u00065,425 927\u0006899 6,128\ndevelopment 75 4,700\u00062,904 770\u0006473 1,063\ntest 90 4,518\u00062,602 744\u0006433 1,790\nall 536 5,348\u00064,789 875\u0006793 8,981\nTable 2: Statistics about the train/dev/test parts of the PTC-SemEval20 corpus, including the number"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "of articles, their average lengths in terms of characters and tokens, and the total number of propaganda\nsnippets they contain.\nThe annotation team consisted of six professional annotators from A Data Pro,5trained to spot and to\nlabel the propaganda snippets in free text. The job was carried out on an instance of the Anafora annotation"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "platform (Chen and Styler, 2013), which we tailored for our propaganda annotation task. Figure 2 shows\nan example of an article and its annotations.\nWe evaluated the quality of the annotation process in terms of \ragreement (Mathet et al., 2015) between\neach of the annotators and the \ufb01nal gold labels. The \ragreement on the annotated articles is on average"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "0:6; see (Da San Martino et al., 2019b) for a more detailed discussion of inter-annotator agreement. The\ntraining and the development part of the PTC-SemEval20 corpus are the same as the training and the\ntesting datasets described in (Da San Martino et al., 2019b). The test part of the PTC-SemEval20 corpus"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "consists of 90 additional articles selected from the same sources as for training and development. For\nthe test articles, we further extended the annotation process by adding one extra consolidation step: we\nrevisited all the articles in that partition and we performed the necessary adjustments to the spans and to"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "the labels as necessary, after a thorough discussion and convergence among at least three experts who\nwere not involved in the initial annotations.\nTable 2 shows some statistics about the corpus we use for the task. It is worth noting that a number of\npropaganda snippets of different classes overlap. Hence, the number of snippets for the span identi\ufb01cation"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "subtask is smaller (e.g., 1,405 for the span identi\ufb01cation subtask vs. 1,790 for the technique classi\ufb01cation\nsubtask on the test set). The full collection of 536 articles contains 8,981 propaganda text snippets,\nbelonging to one of the above-described fourteen classes. Figure 3 zooms into such snippets and shows"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "the number of instances and the mean length for each class. We can see that, by a large margin, the most\ncommon propaganda technique in our news articles is Loaded Language , which is about twice as frequent\nas the second most frequent technique: Name Calling or Labeling . Whereas these two techniques are"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "among the ones that are expressed in the shortest spans, other propaganda techniques such as Exaggeration ,\nCausal Oversimpli\ufb01cation , and Slogans tend to be the longest.\n5https://www.aiidatapro.com1382\n0 Overall 5 Doubt 10 Appeal to authority\n1 Loaded language 6 Appeal to fear/prejudice 11 Black-and-white fallacy, dictatorship"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "2 Name calling or labeling 7 Flag-waving 12 Thought-terminating clich \u00b4e\n3 Repetition 8 Causal oversimpli\ufb01cation 13 Whataboutism, straw man, red herring\n4 Exaggeration or minimization 9 Slogans 14 Bandwagon, reductio ad hitlerum\nFigure 3: Statistics about the propaganda snippets in the different partitions of the PTC-SemEval20 corpus."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Top: number of instances per class. Bottom: mean snippet length per class.\n3.2 Evaluation Measures\nSubtask SI Evaluating subtask SI requires us to match text spans. Our SI evaluation function gives\ncredit to partial matches between gold and predicted spans.\nLetdbe a news article in a set D. A gold span tis a sequence of contiguous indices of the characters"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "composing a text fragment t\u0012d. For example, in Figure 4 (top-left) the gold fragment \u201cstupid and petty\u201d\nis represented by the set of indices t1= [4;19]. We denote with Td=ft1;:::;t ngthe set of all gold\nspans for an article dand withT=fTdgdthe set of all gold annotated spans in D. Similarly, we de\ufb01ne"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Sd=fs1;:::;s mgandSto be the set of predicted spans for an article dand a dataset D, respectively.\nWe compute precision Pand recallRby adapting the formulas in (Potthast et al., 2010):\nP(S; T ) =1\njSj\u0001X\nd2DX\ns2Sd;t2Tdj(s\\t)j\njtj; (1)\nR(S; T ) =1\njTj\u0001X\nd2DX\ns2Sd;t2Tdj(s\\t)j\njsj: (2)\nWe de\ufb01ne Eq. (1) to be zero whenjSj= 0 andEq. (2) to be zero whenjTj= 0. Notice that the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "predicted spans may overlap, e.g., spans s3ands4in Figure 4. Therefore, in order for Eq. 1 and Eq. 2 to\nget values lower than or equal to 1, all overlapping annotations, independently of their techniques, are\nmerged \ufb01rst. For example, s3ands4are merged into one single annotation, corresponding to s4.1383\n0 5 10 15 20 250 5 10 15 20 25 how stupid and petty thingshow stupid and petty things"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "how stupid and petty thingsGold span Examples of predicted spans\nt1 = [4,19]: loaded language s1 = [4,14] s2 = [15,19]\ns3 = [4,19] s4 = [15,19]Figure 4: Example of equivalent annotations for the Span Identi\ufb01cation subtask.\nFinally, the evaluation measure for subtask SI is theF1score, de\ufb01ned as the harmonic mean between\nP(S;T)andR(S;T):\nF1(S; T ) = 2\u0001P(S; T )\u0001R(S; T )\nP(S; T ) +R(S; T ): (3)"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "P(S; T ) +R(S; T ): (3)\nSubtask TC Given a propaganda snippet in an article, subtask TC asks to identify the technique in it.\nSince there are identical spans annotated with different techniques (around 1.8% of the total annotations),\nformally this is a multi-label multi-class classi\ufb01cation problem. However, we decided to consider the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "problem as a single-label multi-class one, by performing the following adjustments: ( i) whenever a span is\nassociated with multiple techniques, the input \ufb01le will have multiple copies of such fragments and ( ii) the\nevaluation function ensures that the best match between the predictions and the gold labels for identical"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "spans is used for the evaluation. In other words, the evaluation score is not affected by the order in which\nthe predictions for identical spans are submitted.\nThe evaluation measure for subtask TC is micro-average F 1. Note that as we have converted this into a\nsingle-label task, micro-average F 1is equivalent to Accuracy (as well as to Precision and to Recall).\n3.3 Task Organization"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "3.3 Task Organization\nWe ran the shared task in two phases:\nPhase 1. Only training and development data were made available, and no gold labels were provided\nfor the latter. The participants competed against each other to achieve the best performance on the\ndevelopment set. A live leaderboard was made available to keep track of all submissions."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Phase 2. The test set was released and the participants were given just a few days to submit their \ufb01nal\npredictions. The release of the test set was done task-by-task, since giving access to the input \ufb01les for the\nTC subtask would have disclosed the gold spans for the SI subtask.\nIn phase 1, the participants could make an unlimited number of submissions on the development set,"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "and they could see the outcomes in their private space. The best team score, regardless of the submission\ntime, was also shown in a public leaderboard. As a result, not only could the participants observe the\nimpact of various modi\ufb01cations in their own systems, but they could also compare against the results by"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "other participating teams. In phase 2, the participants could again submit multiple runs, but they did not\nget any feedback on their performance. Only the last submission of each team was considered of\ufb01cial and\nwas used for the \ufb01nal team ranking.\nIn phase 1, a total of 47 teams made submissions on the development set for the SI subtask, and 46"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "teams submitted for the TC subtask. In phase 2, the number of teams who made of\ufb01cial submissions on\nthe test set for subtasks SI and TC was 35 and 31, respectively: this is a total of 66 submissions for the\ntwo subtasks, which were made by 44 different teams.\nNote that we left the submission system open for submissions on the development set (phase 1) after"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "the competition was over. The up-to-date leaderboards can be found on the website of the competition.6\n6http://propaganda.qcri.org/semeval2020-task11/leaderboard.php13844 Participating Systems\nIn this section, we focus on a general description of the systems participating on both the SI and the TC"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "subtasks. We pay special attention to the most successful approaches. The subindex on the right of each\nteam represents their of\ufb01cial rank in the subtasks. Appendix A includes brief descriptions of all systems.\n4.1 Span Identi\ufb01cation Subtask\nTable 3 shows a quick overview of the systems that took part in the SI subtask.7All systems in the top-10"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "positions relied on some kind of Transformer, in combination with an LSTM or a CRF. In most cases,\nthe Transformer-generated representations were complemented by engineered features, such as named\nentities and the presence of sentiment and subjectivity clues.\nTeam Hitachi (SI:1) achieved the top performance in this subtask (Morio et al., 2020). They used a BIO"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "encoding, which is typical for related segmentation and labeling tasks (e.g., named entity recognition).\nThey relied upon a complex heterogeneous multi-layer neural network, trained end-to-end. The network\nuses pre-trained language models, which generate a representation for each input token. They further"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "added part-of-speech (PoS) and named entity (NE) embeddings. As a result, there are three representations\nfor each token, which are concatenated and used as an input to bi-LSTMs. At this moment, the network\nbranches, as it is trained with three objectives: ( i) the main BIO tag prediction objective and two"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "auxiliary ones, namely ( ii) token-level technique classi\ufb01cation, and ( iii) sentence-level classi\ufb01cation.\nThere is one Bi-LSTM for objectives ( i) and ( ii), and there is another Bi-LSTM for objective ( iii). For\nthe former, they used an additional CRF layer, which helps improve the consistency of the output. A"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "number of architectures were trained independently \u2014using BERT, GPT-2, XLNet, XLM, RoBERTa, or\nXLM-RoBERTa\u2014, and the resulting models were combined in ensembles.\nTeam ApplicaAI (SI:2) (Jurkiewicz et al., 2020) based its success on self-supervision using the\nRoBERTa model. They used a RoBERTa-CRF architecture trained on the provided data and used"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "it to iteratively produce silver data by predicting on 500k sentences and retraining the model with both\ngold and silver data. The \ufb01nal classi\ufb01er was an ensemble of models trained on the original corpus,\nre-weighting, and a model trained also on silver data. ApplicaAI was not the only team that reported"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "performance boost when using additional data. Team UPB (SI:5) (Paraschiv and Cercel, 2020) decided\nnot to stick to the pre-trained models from BERT\u2013base alone and used masked language modeling to\ndomain-adapt it using 9M articles containing fake, suspicious, and hyperpartisan news articles. Team"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "DoNotDistribute (SI:22) (Kranzlein et al., 2020) also opted for generating silver data, but with a different\nstrategy. They report a 5% performance boost when adding 3k new silver training instances. To produce\nthem, they used a library to create near-paraphrases of the propaganda snippets by randomly substituting"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "certain PoS words. Team SkoltechNLP (SI:25) (Dementieva et al., 2020) performed data augmentation\nbased on distributional semantics. Finally, team WMD (SI:33) (Daval-Frerot and Yannick, 2020) applied\nmultiple strategies to augment the data such as back translation, synonym replacement and TF.IDF\nreplacement (replace unimportant words, based on TF.IDF score, by other unimportant words)."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Closing the top-three submissions, Team aschern (SI:3) (Chernyavskiy et al., 2020) \ufb01ne-tuned an\nensemble of two differently intialized RoBERTa models, each with an attached CRF for sequence labeling\nand span character boundary post-processing.\nThere have been several other promising strategies. Team LTIatCMU (SI:4) (Khosla et al., 2020) used a"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "multi-granular BERT BiLSTM model with additional syntactic and semantic features at the word, sentence\nand document level, including PoS, named entities, sentiment, and subjectivity. It was trained jointly for\ntoken and sentence propaganda classi\ufb01cation, with class balancing. They further \ufb01ne-tuned BERT on"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "persuasive language using 10,000 articles from propaganda websites, which turned out to be important.\nTeam PsuedoProp (SI:14) (Chauhan and Diddee, 2020) built a preliminary sentence-level classi\ufb01er using\nan ensemble of XLNet and RoBERTa, before it \ufb01ne-tuned a BERT-based CRF sequence tagger to identify"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "the exact spans. Team BPGC (SI:21) (Patil et al., 2020) went beyond these multigranularity approaches.\nInformation both at the article and at the sentence level was considered when classifying each word as\npropaganda or not, by computing and concatenating vectorial representations for the three inputs."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "7Tables 3 and 4 only include the systems for which a description paper was submitted.1385Rank. Team Transformers Learning Models Representations Misc\nBERT\nRoBERTa\nXLNet\nXLM\nXLM RoBERTa\nALBERT\nGPT-2\nSpanBERT\nLaserTagger\nLSTM\nCNN\nSVM\nNa\u00a8\u0131ve Bayes\nBoosting\nLog regressor\nRandom forest\nCRF\nEmbeddings\nELMo\nNEs\nWords/ n-grams\nChars/ n-grams\nPoS\nTrees\nSentiment\nSubjectivity\nRhetorics\nLIWC\nEnsemble"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Subjectivity\nRhetorics\nLIWC\nEnsemble\nData augmentation\nPost-processing\n1.Hitachi /check_sign/check_sign/check_sign/check_sign/check_sign/check_sign /check_sign /check_sign/check_sign/check_sign/check_sign /check_sign\n2. ApplicaAI /check_sign /check_sign /check_sign\n3.aschern /check_sign /check_sign/check_sign/check_sign /check_sign/check_sign"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "4. LTIatCMU /check_sign /check_sign /check_sign/check_sign/check_sign/check_sign/check_sign/check_sign/check_sign/check_sign\n5.UPB /check_sign /ok /check_sign/ok /check_sign\n7. NoPropaganda /check_sign /check_sign/ok /ok/check_sign/check_sign/check_sign\n8.CyberWallE /check_sign /check_sign/ok /check_sign/check_sign/check_sign"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "9. Transformers /check_sign/check_sign /check_sign/check_sign /check_sign /check_sign\n11.YNUtaoxin /check_sign/ok/ok\n13. newsSweeper /check_sign/ok /ok/ok /ok\n14.PsuedoProp /check_sign/check_sign/check_sign/ok /check_sign\n16. YNUHPCC /ok /check_sign /check_sign\n17.NLFIIT /ok /check_sign /ok/ok/check_sign /ok\n20. TTUI /check_sign/check_sign /check_sign /check_sign/check_sign"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "21.BPGC /ok/check_sign/ok/ok /check_sign\n22. DoNotDistribute /check_sign /ok /check_sign/check_sign/check_sign /check_sign\n23.UTMN /check_sign/check_sign /check_sign\n25. syrapropa /check_sign /check_sign/check_sign\n26.SkoltechNLP /check_sign /ok/ok /ok/check_sign/check_sign\n27. NTUAAILS /check_sign /check_sign\n28.UAIC1860 /ok/ok/ok/check_sign/check_sign/check_sign/check_sign"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "31. 3218IR /check_sign /check_sign\n33.WMD /check_sign /ok/ok/ok/check_sign /check_sign/check_sign/check_sign\n\u2013 UNTLing /ok/ok/ok/ok/ok/ok\n1. (Morio et al., 2020)\n2. (Jurkiewicz et al., 2020)\n3. (Chernyavskiy et al., 2020)\n4. (Khosla et al., 2020)\n5. (Paraschiv and Cercel, 2020)\n7. (Dimov et al., 2020)\n8. (Blaschke et al., 2020)\n9. (Verma et al., 2020)11. (Tao and Zhou, 2020)"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "13. (Singh et al., 2020)\n14. (Chauhan and Diddee, 2020)\n16. (Dao et al., 2020)\n17. (Martinkovic et al., 2020)\n20. (Kim and Bethard, 2020)\n21. (Patil et al., 2020)\n22. (Kranzlein et al., 2020)23. (Mikhalkova et al., 2020)\n25. (Li and Xiao, 2020)\n26. (Dementieva et al., 2020)\n27. (Arsenos and Siolas, 2020)\n28. (Ermurachi and Gifu, 2020)\n31. (Dewantara et al., 2020)"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "31. (Dewantara et al., 2020)\n33. (Daval-Frerot and Yannick, 2020)\n\u2013 (Krishnamurthy et al., 2020)\nTable 3: Overview of the approaches to the span identi\ufb01cation subtask. /check_sign=part of the of\ufb01cial submission;\n/ok=considered in internal experiments. The references to the description papers appear at the bottom."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "A large number of the participating teams built systems that rely heavily on engineered features. For\ninstance, Team CyberWallE (SI:8) (Blaschke et al., 2020) used features modeling sentiment, rhetorical\nstructure, and POS tags, while team UTMN (SI:23) injected the sentiment intensity from V ADER and"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "it was among the only teams not relying on deep learning architectures to produce a computationally\naffordable model.\n4.2 Technique Classi\ufb01cation Subtask\nThe same trends as for the snippet identi\ufb01cation subtask can be observed in the approaches used for the\ntechnique classi\ufb01cation subtask: practically, all top-performing approaches used representations produced\nby some kind of Transformer."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "by some kind of Transformer.\nTeam ApplicaAI (TC:1) achieved the top performance for this subtask (Jurkiewicz et al., 2020). As in\ntheir approach to subtask SI, ApplicaAI produced additional silver data for training. This time, they ran\ntheir high-performing SI model to spot new propaganda snippets in free text and applied their preliminary"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "TC model to produce extra silver-labeled instances. Their \ufb01nal classi\ufb01er consisted of an ensemble of\nmodels trained on the original corpus, re-weighting, and a model trained also on silver data. In all cases,\nthe input to the classi\ufb01ers consisted of propaganda snippets and their context.1386Rank. Team Transformers Learning Models Representations Misc\nBERT\nR BERT\nRoBERTa\nXLNet\nXLM\nXLM RoBERTa"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "R BERT\nRoBERTa\nXLNet\nXLM\nXLM RoBERTa\nALBERT\nGPT-2\nSpanBERT\nDistilBERT\nLSTM\nRNN\nCNN\nSVM\nNa\u00a8\u0131ve Bayes\nBoosting\nLog regressor\nRandom forest\nRegression tree\nCRF\nXGBoost\nEmbeddings\nELMo\nNEs\nWords/ n-grams\nChars/ n-grams\nPoS\nSentiment\nRhetorics\nLexicons\nString matching\nTopics\nEnsemble\nData augmentation\nPost-processing\n1.ApplicaAI /check_sign /check_sign /check_sign/check_sign"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "2. aschern /check_sign /check_sign /check_sign/check_sign\n3.Hitachi /check_sign/check_sign/check_sign/check_sign/check_sign/check_sign /check_sign /check_sign/check_sign/check_sign /check_sign\n4. Solomon /check_sign /ok /check_sign /check_sign/check_sign\n5.newsSweeper /ok/check_sign /ok/ok /ok\n6. NoPropaganda /check_sign/check_sign\n7.Inno /ok/check_sign/ok /ok/ok /ok /ok"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "7.Inno /ok/check_sign/ok /ok/ok /ok /ok\n8. CyberWallE /check_sign /check_sign /check_sign /check_sign\n10.Duth /check_sign /check_sign\n11. DiSaster /check_sign /ok /check_sign /check_sign /check_sign\n13.SocCogCom /check_sign /ok /ok /check_sign/ok\n14. TTUI /check_sign/check_sign /check_sign /check_sign\n15.JUST /check_sign /check_sign\n16. NLFIIT /ok /check_sign /ok/ok/check_sign /ok"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "17.UMSIForeseer /check_sign /check_sign /check_sign\n18. BPGC /check_sign /ok/ok/check_sign /ok/check_sign/check_sign /check_sign/check_sign\n19.UPB /check_sign /check_sign\n20. syrapropa /check_sign /check_sign /check_sign/check_sign /check_sign\n21.WMD /check_sign /ok/ok/ok/ok/check_sign /check_sign/check_sign\n22. YNUHPCC /check_sign /check_sign /ok"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "22. YNUHPCC /check_sign /check_sign /ok\n24.DoNotDistribute /check_sign /check_sign /check_sign/check_sign/check_sign\n25. NTUAAILS /check_sign /check_sign\n26.UAIC1860 /ok/ok/ok/check_sign/check_sign/check_sign/check_sign\n27. UNTLing /check_sign /check_sign/check_sign/check_sign /check_sign\n1. (Jurkiewicz et al., 2020)\n2. (Chernyavskiy et al., 2020)\n3. (Morio et al., 2020)\n4. (Raj et al., 2020)"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "4. (Raj et al., 2020)\n5. (Singh et al., 2020)\n6. (Dimov et al., 2020)\n7. (Grigorev and Ivanov, 2020)\n8. (Blaschke et al., 2020)\n10. (Bairaktaris et al., 2020)11. (Kaas et al., 2020)\n13. (Krishnamurthy et al., 2020)\n14. (Kim and Bethard, 2020)\n15. (Altiti et al., 2020)\n16. (Martinkovic et al., 2020)\n17. (Jiang et al., 2020)\n18. (Patil et al., 2020)"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "18. (Patil et al., 2020)\n19. (Paraschiv and Cercel, 2020)20. (Li and Xiao, 2020)\n21. (Daval-Frerot and Yannick, 2020)\n22. (Dao et al., 2020)\n24. (Kranzlein et al., 2020)\n25. (Arsenos and Siolas, 2020)\n26. (Ermurachi and Gifu, 2020)\n27. (Petee and Palmer, 2020)\n29. (Verma et al., 2020)\nTable 4: Overview of the approaches to the technique classi\ufb01cation subtask. /check_sign=part of the of\ufb01cial"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "submission;/ok=considered in internal experiments. The references to the description papers appear at\nthe bottom.\nTeam aschern (TC:2) (Chernyavskiy et al., 2020) was the second best, and it based its success on\na RoBERTa ensemble with several interesting techniques. They treated the task as one of sequence"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "classi\ufb01cation, using an average embedding of the surrounding tokens and the length of the span as\ncontextual features. They further incorporated knowledge from the span identi\ufb01cation task, using transfer\nlearning: namely, they \ufb01rst pre-trained their model for the SI task, and then continued training for the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "TC task. Finally, they performed task-speci\ufb01c postprocessing in order to increase the consistency for the\nrepetition technique spans and to avoid insertions of techniques inside other techniques.\nTeam Hitachi (TC:3) (Morio et al., 2020) used two distinct feed-forward neural networks (FFNs). The"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "\ufb01rst one is for sentence representation, whereas the second one is for the representation of the tokens in\nthe propaganda span. The propaganda span representation is obtained by concatenating the representation\nof the begin-of-sentence token, the span start token, the span end token, and the aggregated representation"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "obtained using attention and max-pooling. As for their winning approach to SI, team Hitachi trained\non the TC subtask independently with different large-scale pre-trained state-of-the-art language models\n(BERT, GPT-2, XLNet, XLM, RoBERTa, or XLM-RoBERTa), and then combined the resulting models in"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "an ensemble.1387As the top-performing models to subtask TC show, while the two subtasks can be seen as fairly\nindependent, combining them in a reasonable way pays back. Additionally, the context of a propaganda\nsnippet is important to identify the speci\ufb01c propaganda technique it uses. Indeed, other teams tried to make"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "context play a role in their models with certain success. For instance, team newsSweeper (TC:5) (Singh et\nal., 2020) used RoBERTa to obtain and to concatenate representations for both the propaganda snippet and\nits context (i.e., sentence). Team SocCogCom (TC:13) (Krishnamurthy et al., 2020) reduced the context to\na window of three words before and after the propaganda snippet."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "As in the SI subtask, a number of teams achieved sizable improvements when using various features. For\ninstance, team BPGC (TC:18) (Patil et al., 2020) included TF.IDF vectors of words and character n-grams,\ntopic modeling, and sentence-level polarity, among others, to their ensemble model that used BERT and"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "logistic regression. Team SocCogCom (TC:13) (Krishnamurthy et al., 2020) integrated semantic-level emo-\ntional salience features from CrystalFeel (Gupta and Yang, 2018) and word-level psycholinguistic features\nfrom LIWC (Pennebaker et al., 2015). Team CyberWallE (TC:8) (Blaschke et al., 2020) added named"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "entities, rhetorical, and question features, while taking special care of repetitions as part of a complex\nensemble architecture. According to team UNTLing (TC:27) (Petee and Palmer, 2020), considering NEs\nis particularly useful for propaganda techniques such as Loaded Language andFlag Waving (e.g., the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "latter usually includes references to idealized entities) and V AD features were useful for emotion-related\npropaganda techniques such as Appeal to fear/prejudice andDoubt . Team DiSaster (TC:11) (Kaas et al.,\n2020) combined BERT with features including frequency of the fragment in the article and in the sentence"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "it appears in, and the inverse uniqueness of words in a span. The goal of these features was to compensate\nthe inability of BERT to deal with distant context, speci\ufb01cally to target the technique Repetition . Team\nSolomon (TC:4) also targeted Repetition by using dynamic least common sub-sequence, which they used"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "to score the similarity between the fragment and the context. Then, the fragment was considered to be\na repetition if the score was greater than a threshold heuristically set with respect to the length of the\nfragment.\nSome other teams decided to perform a normalization of the input texts, thus trying to reduce the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "representation diversity. This was the case of team DUTH (TC:10) (Bairaktaris et al., 2020), which mapped\ncertain words into classes using named entity recognition with focus on person names and gazetteers\ncontaining names and variations of names of countries (255 entries), religions (35 entries), political"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "ideologies (23 entries), and slogans (41 entries). The recognized categories were replaced by the category\nname in the input, before passing the input to BERT.\nAs the class distribution for subtask TC is heavily skewed, some teams tried balancing techniques. For\nexample, team Inno (TC:7) (Grigorev and Ivanov, 2020) experimented with undersampling (i.e. removing"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "some examples from the bigger classes), team syrapropa (TC:20) applied a cost adjustment to their\nBERT-based model, and team UMSIForeseer (TC:17) (Jiang et al., 2020) used a mix of oversampling and\nundersampling, which they combined using a bagging ensemble.\nFinally, some teams used an overriding strategy on top of the output of their supervised models. For"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "example, team CyberWallE (TC:8) (Blaschke et al., 2020) performed a rule-based label post-processing,\nand team syrapropa (TC:20) applied syntactic rules based on part of speech.\n5 Results and Discussion\n5.1 Results on the Span Identi\ufb01cation Subtask\nTable 5 shows the performance of the participating systems both on the testing and on the development"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "partitions on the SI subtask. The baseline for subtask SI is a simple system that randomly generates spans,\nby \ufb01rst selecting the starting character of a span and then its length. As mentioned in Section 4, practically\nall approaches relied on Transformers to produce representations and then plugged their output into a"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "sequential model, at the token level. It is worth observing that only three of the top-5 systems on the\ndevelopment set appear also among the top-5 systems on the test set. Indeed, teams syrapropa andPALI\nfelt down from positions 1 and 2 on the development set to positions 25 and 18 on the test set, which"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "suggests possible over\ufb01tting. The performance for the \ufb01nal top-3 systems on the test partition \u2014 Hitachi ,\nApplicaAI , and aschern \u2014 re\ufb02ects robust systems that seem to generalize much better.1388\nFigure 5: SI Subtask : performance (P, R, F 1) when combining the output of the top-7 systems using union,"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "intersection, and majority voting. The bottom plots show the number of characters deemed propagandistic\nin each combination.\nFigure 5 shows the performance evolution when combining the output of the top-performing systems on\nthe test set. All operations are carried out at the character level, i.e., we label characters as propagandistic"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "or not, and then we combine into spans the longest possible sequences of neighboring characters that we\nlabeled as propagandistic. The union and the intersection use the corresponding set operations. In union, a\ncharacter is considered propagandistic if at least one of the participating systems has recognized it as part"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "of a propaganda span. In intersection, a character is considered propagandistic if all systems have included\nit as part of a propaganda span. For majority voting, we consider a character propagandistic if more than\n50% of the participating systems had included it as part of a propaganda span. We can see in Figure 5 that"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "the precision and the recall trends behave just as we expected: a lower precision (higher recall) is observed\nwhen more systems are combined with a union operation, and the opposite is true for the intersection.\nDespite the loss in terms of precision, computing the union of the top- [2;3]systems results in a better"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "performance than what each of the top systems could achieve on its own. Such a combination gathers\nlarge ensembles of Transformer representations together with self-supervision to produce additional\ntraining data and boundary post-processing. If we are interested in a high-precision model, applying the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "intersection would make more sense, as it reaches a precision of 66.95 when combining the top-2 systems;\nhowever, this comes at the cost of a sizable lost of spans, which results in considerable drop in recall. The\nmajority voting combination lies somewhere in between: keeping reasonable levels for both the precision\nand the recall.\n5.2 Results on the Technique Classi\ufb01cation Subtask"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Table 6 shows the performance of the participating systems on the test set for the TC subtask, and Table 7\nreports the results on the development set. The baseline system for subtask TC is a logistic regression\nclassi\ufb01er using one feature only: the length of the fragment. A similar pattern as for the SI subtask is"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "observed: only two of the top-5 systems on the development set appear among the top-5 systems on the\ntest set, which is a sign of possible over\ufb01tting for some of the systems. At the same time, systems that\nappeared to have a modest performance on the development set could eventually reach a higher position"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "on test. For instance, team Hitachi , which was ranked 8th on the development set, ended up in the third\nposition on the test set.\nThe tables further show the performance for each of the 14 propaganda techniques. In general, the\nsystems show reasonably good performance when predicting Loaded Language andName Calling or"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Labeling . These two classes are the most frequent ones, by a margin, and are also among the shortest ones\non average (cf. Figure 3). On the other hand, techniques 13 ( Straw man, red herring ) and 14 ( Bandwagon,\nreduction ad hitlerum, whataboutism ) are among the hardest to identify. They are also among the least\nfrequent ones.1389"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "frequent ones.1389\nFigure 6: F 1performance for the technique classi\ufb01cation subtask when combining the top-20 systems\nwith majority voting. The plots show the overall F 1performance (top left) as well as the F 1performance\nfor each of the 14 propaganda techniques.\nOnce again, we studied the performance when combining more approaches. Figure 6 shows the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "performance evolution when combining different numbers of top-performing systems on the test set. As\nthis is a multi-class problem, we combine the systems only on the basis of majority voting. In case of a tie,\nwe prefer the more frequent propaganda technique on the training set. When looking at the overall picture,"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "the performance evolution when adding more systems is fairly \ufb02at, reaching the top performance when\ncombining the top-3 systems: an F 1score of 63.63, which represents more than 1.5 points of absolute\nimprovement over the top-1 system. When zooming into each of the fourteen propaganda techniques, we"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "observe that in general the performance peak is indeed reached when considering three systems, e.g., for\nAppeal to fear\u2013prejudice ,Exaggeration, minimisation , orCausal oversimpli\ufb01cation . Still for Doubt ,\nwhich is the hardest class to recognize, as many as 13 systems are necessary in order to reach a (still"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "discrete) peak performance of 17.78. Finally, note that there are other classes, such as Black-and-white\nfallacy orWhatabaotism, straw men, red herring , for which system combinations do not help.1390Test Development\nTeam Rnk F1 P R Rnk F1 P R\nHitachi 151.55 56.54 47.37 450.12 42.26 61.56\nApplicaAI 249.15 59.95 41.65 352.19 47.15 58.44\naschern 349.10 53.23 45.56 549.99 44.53 56.98"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "LTIatCMU 447.66 50.97 44.76 749.06 43.38 56.47\nUPB 546.06 58.61 37.94 846.79 42.44 52.13\nFragarach 645.96 54.26 39.86 12 44.27 41.68 47.21\nNoPropaganda 744.68 55.62 37.34 946.13 40.65 53.31\nCyberWallE 843.86 42.16 45.70 17 42.39 33.45 57.86\nTransformers 943.60 49.86 38.74 14 43.06 40.85 45.52\nSWEAT 10 43.22 52.77 36.59 16 42.51 42.97 42.06\nYNUtaoxin 11 43.21 55.62 35.33 11 44.35 40.74 48.67"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "DREAM 12 43.10 54.54 35.63 19 42.15 42.66 41.65\nnewsSweeper 13 42.21 46.52 38.63 10 44.45 38.76 52.10\nPsuedoProp 14 41.20 41.54 40.87 22 39.32 34.27 46.11\nSolomon 15 40.68 53.95 32.66 15 42.86 43.24 42.49\nYNUHPCC 16 40.63 36.55 45.74 18 42.27 32.08 61.95\nNLFIIT 17 40.58 50.91 33.73 21 39.67 35.04 45.72\nPALI 18 40.57 53.20 32.79 252.35 49.64 55.37"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "UESTCICSA 19 39.85 56.09 30.90 13 44.17 43.21 45.18\nTTUI 20 39.84 66.88 28.37 649.59 48.76 50.44\nBPGC 21 38.74 49.39 31.88 25 36.79 34.72 39.12\nDoNotDistribute 22 37.86 42.36 34.23 24 37.73 32.41 45.12\nUTMNandOCAS 23 37.49 37.97 37.03 31 34.35 23.65 62.69\nEntropy 24 37.23 41.68 33.63 32 32.89 30.82 35.25\nsyrapropa 25 36.20 49.53 28.52 153.40 39.88 80.80"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "SkoltechNLP 26 34.07 46.52 26.87 26 36.70 34.99 38.59\nNTUAAILS 27 33.60 46.05 26.44 33 31.21 27.95 35.35\nUAIC1860 28 33.21 24.49 51.57 34 30.27 20.69 56.37\nCCNI 29 29.48 38.09 24.05 35 29.61 29.04 30.21\nNCCU-SMRG 30 28.47 17.30 80.37 42 15.83 09.12 59.92\n3218IR 31 23.47 22.63 24.38 40 20.03 15.10 29.76\nWMD 32 20.09 47.11 12.77 27 36.34 33.26 40.05\nLS 33 18.18 34.14 12.39 29 35.49 22.41 85.33"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "HunAlize 34 3.19 23.24 1.71 38 24.45 37.75 18.08\nYOLO 35 0.72 17.20 0.37 46 0.64 9.36 0.33\nBaseline 36 0.31 13.04 0.16 43 1.10 11.00 0.58\nMurgila \u2013 \u2013 \u2013 \u2013 20 41.38 32.96 55.56\nTakeLab \u2013 \u2013 \u2013 \u2013 23 39.06 38.85 39.27\natulcst \u2013 \u2013 \u2013 \u2013 28 36.29 38.15 34.61\nAAA \u2013 \u2013 \u2013 \u2013 30 34.68 30.61 40.00\nCUNLP \u2013 \u2013 \u2013 \u2013 36 27.78 58.23 18.24\nIIITD \u2013 \u2013 \u2013 \u2013 37 25.82 18.81 41.15\nUoB \u2013 \u2013 \u2013 \u2013 39 24.02 22.30 26.04"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "UoB \u2013 \u2013 \u2013 \u2013 39 24.02 22.30 26.04\nUBirmingham \u2013 \u2013 \u2013 \u2013 41 16.95 23.07 13.39\nSocCogCom \u2013 \u2013 \u2013 \u2013 44 0.79 9.97 0.41\nInno \u2013 \u2013 \u2013 \u2013 45 0.64 9.36 0.33\nRaghavan \u2013 \u2013 \u2013 \u2013 47 0.40 0.20 33.45\nCalifornia \u2013 \u2013 \u2013 \u2013 48 0.39 5.92 0.20\nTable 5: Subtask 1: Span Identi\ufb01cation (SI) performance on test and development. The highest"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "scores for each measure are highlighted. ( Note: We found a bug in the evaluation script after the end of\nthe competition. The correct ranking, shown in Appendix B, does not differ substantially from above. )1391\nRnk Team Overall 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n1ApplicaAI 62.07 77.12 74.38 54.55 33.59 56.23 45.49 69.43 22.73 51.28 48.15 49.02 39.22 25.00 8.33"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "2 aschern 62.01 77.02 75.65 53.38 32.65 59.44 41.78 66.35 25.97 54.24 35.29 53.57 42.55 18.87 14.93\n3Hitachi 61.73 75.64 74.20 37.88 34.58 63.43 38.94 68.02 36.62 45.61 40.00 47.92 29.41 26.92 4.88\n4 Solomon 58.94 74.66 70.75 42.53 28.44 61.82 39.39 61.84 19.61 50.75 26.67 42.00 38.10 0.00 4.88\n5newsSweeper 58.44 75.32 74.23 20.69 37.10 56.55 42.80 60.53 19.72 50.75 41.67 25.00 21.62 8.00 13.04"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "6 NoPropaganda 58.27 77.17 73.90 42.71 37.99 56.27 38.02 59.30 12.12 42.42 23.26 8.70 23.26 0.00 0.00\n7Inno 57.99 73.31 74.30 24.89 35.39 58.65 45.09 59.41 24.32 43.75 43.14 40.40 29.63 19.36 10.71\n8 CyberWallE 57.37 74.68 70.92 47.68 28.34 58.65 39.84 54.38 15.39 39.39 14.63 23.68 23.81 0.00 12.25\n9PALI 57.32 74.29 69.09 24.56 28.57 58.97 36.59 61.62 30.59 39.22 27.59 39.62 40.82 20.90 28.57"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "10 DUTH 57.21 73.71 71.41 20.10 28.24 59.16 33.33 58.95 26.23 34.78 44.44 33.33 27.03 17.78 9.30\n11 DiSaster 56.65 74.49 68.10 20.44 30.64 59.12 35.25 58.25 14.63 42.55 51.16 26.67 19.05 4.35 20.41\n12 djichen 56.54 73.21 68.38 29.75 31.42 60.00 33.65 56.19 22.79 30.77 37.50 43.81 27.91 18.87 20.83\n13 SocCogCom 55.81 72.18 67.34 18.88 34.86 60.40 31.62 54.26 6.35 40.91 28.57 26.51 23.53 10.00 9.76"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "14 TTUI 55.64 73.22 68.49 21.18 32.20 57.40 41.48 61.68 23.08 37.50 28.24 35.29 25.00 20.29 24.56\n15 JUST 55.31 71.96 64.73 21.94 29.57 58.26 37.10 62.56 27.27 33.33 48.89 28.89 31.82 28.57 24.49\n16 NLFIIT 55.25 72.55 69.30 21.55 30.30 55.66 24.89 63.32 0.00 41.67 29.63 32.10 13.64 0.00 9.30\n17 UMSIForeseer 55.14 73.02 70.79 21.49 28.57 57.21 31.97 56.14 0.00 39.22 29.41 0.00 14.29 0.00 9.76"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "18 BPGC 54.81 71.58 67.51 23.74 33.47 53.78 33.65 58.93 24.18 40.00 30.77 40.00 20.69 20.90 12.50\n19 UPB 54.30 70.09 68.86 20.00 30.62 52.55 30.00 55.87 16.95 34.62 20.00 19.72 22.86 4.88 0.00\n20 syrapropa 54.25 71.47 68.44 30.77 28.10 56.14 29.77 57.02 21.51 29.03 31.58 30.61 28.57 9.09 19.61\n21 WMD 52.01 69.33 64.67 13.89 25.46 53.94 29.20 52.08 5.71 6.90 7.14 0.00 7.41 0.00 5.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "22 YNUHPCC 50.50 68.08 62.33 17.72 21.54 51.04 26.40 55.56 3.45 27.59 29.79 38.38 17.78 15.00 13.79\n23 UESTCICSA 49.94 68.23 66.88 27.96 25.44 44.99 22.75 53.14 3.74 41.38 12.77 11.27 28.57 3.70 0.00\n24 DoNotDistribute 49.72 68.44 60.65 19.44 27.23 46.25 29.75 53.76 14.89 28.07 22.64 24.49 12.25 9.68 4.55"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "25 NTUAAILS 46.37 65.79 54.55 18.43 29.66 48.75 28.31 46.47 0.00 13.79 36.36 0.00 11.43 4.08 9.76\n26 UAIC1860 41.17 62.33 42.97 11.16 21.01 36.41 22.12 38.78 7.60 11.43 17.39 2.90 5.56 4.26 9.76\n27 UNTLing 39.11 62.57 36.74 7.78 11.82 32.65 5.29 40.48 2.86 17.65 4.35 0.00 0.00 0.00 0.00\n28 HunAlize 37.10 58.59 15.82 2.09 23.81 31.76 11.83 29.95 7.84 4.55 6.45 8.00 0.00 0.00 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "29 Transformers 26.54 47.55 24.06 2.86 0.00 0.98 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n30 Baseline 25.20 46.48 0.00 19.26 14.42 29.14 3.68 6.20 11.56 0.00 0.00 0.00 0.00 0.00 0.00\n31 Entropy 20.39 37.74 15.49 5.83 6.39 12.81 6.32 4.95 7.41 0.00 3.92 2.27 0.00 6.78 0.00\n32 IJSE8 19.72 38.07 14.70 4.92 8.23 15.47 7.07 8.57 2.27 0.00 0.00 0.00 0.00 0.00 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Table 6: Technique classi\ufb01cation F 1performance on the test set . The systems are ordered on the basis of the \ufb01nal ranking. Columns 1to14show the\nperformance for each of the propaganda techniques (cf. Section 2). The best score for each technique appears highlighted. ( Note: We found a bug in the evaluation"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "script after the end of the competition. The correct ranking, shown in Appendix B, does not differ substantially from above. )1392\nRnk Team Overall 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n1ApplicaAI 70.46 80.42 74.11 70.67 60.93 63.57 48.49 82.56 47.06 62.65 42.86 20.00 43.48 41.67 80.00\n2 aschern 68.11 80.00 73.85 67.39 59.36 66.19 45.24 74.25 30.44 63.89 28.57 32.43 33.33 38.46 40.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "8Hitachi 65.19 77.99 71.16 46.98 56.58 62.96 36.96 81.40 50.00 67.61 12.50 22.22 19.05 40.91 75.00\n16 Solomon 59.55 75.92 71.98 33.48 49.65 51.28 39.08 74.68 34.29 45.90 0.00 20.83 32.26 20.83 0.00\n5FakeSolomon 67.17 79.29 74.38 66.04 50.75 61.22 42.72 74.36 31.25 70.00 9.52 18.75 43.48 6.25 88.89"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "10 newsSweeper 62.75 76.23 71.35 45.14 55.32 56.94 44.90 74.29 47.83 60.53 16.67 6.90 16.67 6.45 57.14\n11 NoPropaganda 60.68 77.06 72.49 47.69 38.71 50.36 33.33 75.74 48.00 53.17 0.00 0.00 8.33 0.00 0.00\n13 Inno 60.11 76.57 70.62 34.67 43.75 52.86 40.82 77.97 34.15 59.70 11.77 35.71 18.18 15.39 61.54"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "7CyberWallE 66.42 76.62 81.00 73.29 52.70 53.85 30.61 73.68 21.05 51.35 18.18 21.43 17.39 0.00 22.22\n6 PALI 66.89 78.01 76.34 61.59 48.61 58.46 40.45 79.53 42.11 58.33 41.67 35.56 45.71 27.03 75.00\n23 DUTH 57.86 76.12 70.32 23.08 46.15 48.72 34.41 64.43 42.86 55.39 9.52 11.11 15.39 11.11 50.00\n9 DiSaster 62.84 76.73 77.33 47.11 48.28 56.21 35.29 75.15 23.08 35.09 30.00 0.00 9.09 5.56 28.57"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "26 djichen 57.57 76.04 70.53 24.89 44.60 48.28 36.78 76.36 31.82 51.43 13.33 20.00 10.81 4.55 0.00\n28 SocCogCom 57.01 70.65 64.38 31.78 45.67 53.99 32.91 77.11 28.57 30.19 0.00 21.43 12.90 6.45 57.14\n17 TTUI 58.98 75.08 71.00 32.07 41.96 56.92 34.69 77.53 33.33 50.00 16.22 19.05 20.69 29.09 66.67\n24 JUST 57.67 74.97 72.36 23.64 49.64 48.75 31.07 73.75 23.81 29.03 0.00 0.00 0.00 5.88 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "20 NLFIIT 58.51 74.46 70.48 33.33 41.48 53.13 35.14 75.00 34.29 60.53 13.33 27.78 24.24 24.14 60.00\n19 UMSIForeseer 58.70 74.44 70.95 31.76 51.80 47.95 31.58 75.86 52.63 43.33 10.00 0.00 0.00 10.00 0.00\n18 BPGC 58.80 75.45 70.05 29.75 49.64 52.86 32.43 75.82 27.03 52.31 19.05 18.75 23.08 9.52 0.00\n21 UPB 58.33 74.02 71.64 24.16 50.00 46.15 29.89 70.73 34.29 50.00 7.41 8.70 0.00 6.06 57.14"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "3syrapropa 67.83 77.24 77.00 70.12 51.39 56.74 40.82 78.89 41.86 68.49 20.00 13.79 26.09 24.24 60.00\n33 WMD 52.31 71.57 57.70 40.00 35.12 39.77 26.83 63.10 6.90 15.69 19.05 0.00 0.00 0.00 40.00\n29 YNUHPCC 56.16 70.57 69.45 29.75 36.36 51.39 26.09 73.05 27.27 40.58 6.45 18.18 26.09 21.05 54.55\n25 UESTCICSA 57.57 74.15 65.04 48.37 39.66 46.48 38.71 63.23 26.67 58.82 0.00 0.00 36.36 9.52 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "30 DoNotDistribute 54.00 71.20 67.33 29.38 31.93 45.95 25.58 72.61 25.00 28.99 0.00 0.00 22.86 9.76 0.00\n32 NTUAAILS 53.25 69.76 59.90 27.19 43.64 51.61 21.33 73.03 17.14 27.12 6.67 7.14 0.00 8.00 44.44\n34 UAIC1860 43.84 57.88 40.37 14.12 23.66 42.03 7.02 60.00 0.00 4.55 10.53 0.00 0.00 0.00 33.33\n37 UNTLing 40.92 59.45 33.33 11.83 12.28 35.42 11.94 51.70 26.67 25.00 8.33 0.00 0.00 5.88 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "36 HunAlize 41.02 56.13 40.75 5.32 22.22 41.18 9.23 53.50 33.33 0.00 0.00 0.00 0.00 0.00 0.00\n41 Transformers 30.10 48.50 28.62 12.31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 4.88 0.00\n43 Baseline 26.53 40.58 0.00 38.50 11.68 19.20 9.38 8.28 7.23 0.00 0.00 0.00 0.00 0.00 0.00\n27 Entropy 57.10 75.22 66.50 28.19 45.16 53.60 31.11 74.85 29.27 46.88 13.33 18.18 20.00 10.00 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "4FLZ 67.17 81.09 71.12 70.78 23.38 65.46 20.00 64.08 46.15 64.00 44.44 37.04 28.57 6.67 75.00\n12 Fragarach 60.49 77.12 70.50 38.21 50.69 51.03 40.91 74.12 34.04 45.71 14.29 12.90 16.67 6.06 57.14\n14 NerdyBirdies 59.83 76.23 73.55 33.05 48.65 52.06 36.04 70.30 47.62 48.57 15.39 8.70 20.00 13.33 0.00\n15 CUNLP 59.55 74.38 73.30 47.62 43.66 50.69 34.29 71.90 35.90 55.07 16.22 15.79 19.51 8.89 25.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "22 Tianyi 58.23 75.39 71.22 26.43 44.72 50.36 34.57 75.61 28.57 49.32 13.33 11.77 0.00 0.00 57.14\n31 Murgila 53.53 71.21 66.14 24.55 42.55 37.29 22.47 69.51 30.00 40.58 17.65 13.33 31.58 22.64 44.44\n35 hseteam 41.40 63.65 42.82 22.40 32.26 26.29 11.11 57.52 7.69 26.67 0.00 7.27 0.00 4.76 42.86\n38 HenryAtDuderstadt 34.15 52.97 4.10 0.00 0.00 34.29 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "39 XJPaccelerationMASTER 32.46 48.76 0.00 0.00 0.00 33.06 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n40 SWEAT 30.57 46.83 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n42 NCCU-SMRG 29.26 37.92 34.46 25.53 14.69 36.92 15.09 45.07 9.76 13.33 12.50 16.67 12.50 0.00 23.08\n44 LS 26.23 39.20 0.00 39.31 12.95 19.67 9.09 8.28 8.79 0.00 0.00 0.00 6.25 0.00 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "45 SkoltechNLP 26.23 39.20 0.00 39.31 12.95 19.67 9.09 8.28 8.79 0.00 0.00 0.00 6.25 0.00 0.00\n46 TakeLab 25.31 42.92 24.70 1.37 0.00 6.43 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n47 UTMNandOCAS 23.42 40.53 19.74 18.67 4.44 0.00 10.53 0.00 0.00 0.00 0.00 23.08 8.70 0.00 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Table 7: Technique classi\ufb01cation F 1performance on the development set . The systems are ordered based on the \ufb01nal ranking on the test set (cf. Table 6),\nwhereas the ranking is the one on the development set. Columns 1to14show the performance on each class (cf. Section 2). The best score for each class is bold.13936 Related Work"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Propaganda is particularly visible in the context of \u201cfake news\u201d on social media, which have attracted a\nlot of research recently (Shu et al., 2017). Thorne and Vlachos (2018) surveyed fact-checking approaches\nto fake news and related problems, and Li et al. (2016) focused on truth discovery in general. Two recent"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "articles in Science offered a general discussion on the science of \u201cfake news\u201d (Lazer et al., 2018) and the\nprocess of proliferation of true and false news online (V osoughi et al., 2018).\nWe are particularly interested here in how different forms of propaganda are manifested in text. So\nfar, the computational identi\ufb01cation of propaganda has been tackled mostly at the article level. Rashkin"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "et al. (2017) created a corpus, where news articles are labeled as belonging to one of the following four\ncategories: propaganda ,trusted ,hoax , orsatire . The articles came from eight sources, two of which were\npropagandistic. The labels were obtained using distant supervision, assuming that all articles from a given"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "news source share the label of that source, which introduces noise (Horne et al., 2018). Barr \u00b4on-Cede \u02dcno\net al. (2019b) experimented with a binary version of the problem: propaganda vs.no propaganda . See\n(Da San Martino et al., 2020a) for a recent survey on computational propaganda detection."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "In general, propaganda techniques serve as a means to persuade people, often in argumentative settings.\nWhile they may increase the rhetorical effectiveness of arguments, they naturally harm other aspects of\nargumentation quality (Wachsmuth et al., 2017). In particular, many of the span propaganda techniques"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "considered in this shared task relate to the notion of fallacies , i.e. arguments whose reasoning is \ufb02awed\nin some way, often hidden and often on purpose (Tindale, 2007). Some recent work in computational\nargumentation has dealt with such fallacies. Among these, Habernal et al. (2018) presented and analyzed"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "a corpus of web forum discussions with Ad hominem fallacies, and Habernal et al. (2017) introduced\nArgotario , a game that educates people to recognize fallacies. Argotario also had a corpus as a by-product,\nwith 1.3k arguments annotated for \ufb01ve fallacies, including Ad hominem ,Red herring , and Irrelevant"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "authority , which are related to some of our propaganda techniques (cf. Section 2). Unlike these corpora,\nthe news articles in our corpus are annotated with fourteen propaganda techniques. Moreover, instead of\nlabeling entire arguments, our annotation aims at identifying the minimal text spans related to a technique."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "In the present SemEval task, we departed from the eighteen propaganda techniques and the corpus\ndescribed in (Da San Martino et al., 2019b; Yu et al., 2019).8We used the news articles included in that\ncorpus in a pilot task that ran in January 2019, the Hack the News Datathon ,9as well as in a previous shared"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "task, held as part of the 2019 Workshop on NLP4IF: Censorship, Disinformation, and Propaganda .10Both\nthe datathon and the shared task tackled the identi\ufb01cation of propaganda techniques as one overall task\n(along with a binary sentence-level propaganda classi\ufb01cation task), i.e. without splitting it into subtasks"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "as we did here. As detailed in the overview paper of Da San Martino et al. (2019a), the best-performing\nsystems in the shared task used BERT-based contextual representations. Other systems used contextual\nrepresentations based on RoBERTa, Grover, and ELMo, or context-independent representations based on"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "lexical, sentiment, readability, and TF-IDF features. As in the task at hand, ensembles were also popular.\nStill, the most successful submissions achieved an F 1-score of 24.88 only (and only 10.43 in the datathon).\nThis is why, here we decided to split the task into subtasks in order to allow researchers to focus on one"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "subtask at a time. Moreover, we merged some of the original 18 propaganda techniques to reduce data\nsparseness issues.\nOther related shared tasks include the FEVER 2018 and 2019 tasks on Fact Extraction and VERi\ufb01-\ncation (Thorne et al., 2018), the SemEval 2017 and 2019 tasks on determining the veracity of rumors"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "(Derczynski et al., 2017; Gorrell et al., 2019) and the SemEval 2019 task on Fact-Checking in Community\nQuestion Answering Forums (Mihaylova et al., 2019). Also, the CLEF 2018\u20132020 CheckThat! labs\u2019\nshared tasks (Nakov et al., 2018; Elsayed et al., 2019a; Elsayed et al., 2019b; Barr \u00b4on-Cede \u02dcno et al., 2020a;"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Barr \u00b4on-Cede \u02dcno et al., 2020b), which featured tasks on automatic identi\ufb01cation (Atanasova et al., 2018;\nAtanasova et al., 2019) and veri\ufb01cation (Barr \u00b4on-Cede \u02dcno et al., 2018; Hasanain et al., 2019; Hasanain et\nal., 2020; Shaar et al., 2020) of claims in political debates and in social media."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "8You can also try the Prta system (Da San Martino et al., 2020b) online at: http://www.tanbih.org/prta\n9http://www.datasciencesociety.net/hack-news-datathon/\n10http://www.netcopia.net/nlp4if/2019/13947 Conclusion and Future Work\nWe have described SemEval-2020 Task 11 on Detection of Propaganda Techniques in News Articles."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "The task attracted the interest of a number of researchers: 250 teams signed up to participate, and 44\nmade submissions on the test dataset. We received 35 and 31 submissions for subtask SI and subtask TC,\nrespectively. Overall, subtask SI (segment identi\ufb01cation) was easier and all systems managed to improve"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "over the baseline. However, subtask TC (technique classi\ufb01cation) proved to be much more challenging,\nand some teams could not improve over our baseline.\nIn future work, we plan to extend the dataset to cover more examples as well as more propaganda\ntechniques. We further plan to develop similar datasets for other languages.\nAcknowledgments"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Acknowledgments\nWe thank the anonymous reviewers for their constructive comments and suggestions, which have helped\nus improve the \ufb01nal version of this paper. We further thank Anton Chernyavskiy for pointing us to the\nbug in the evaluation script.\nThe task is organized within the Propaganda Analysis Project,11part of the Tanbih project.12Tanbih"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "aims to limit the effect of \u201cfake news\u201d, propaganda, and media bias by making users aware of what they\nare reading, thus promoting media literacy and critical thinking.\nReferences\nOla Altiti, Malak Abdullah, and Rasha Obiedat. 2020. JUST at SemEval-2020 Task 11: Detecting propaganda\ntechniques using BERT pretrained model. In Proceedings of the 14th International Workshop on Semantic"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Evaluation , SemEval \u201920, Barcelona, Spain.\nAnastasios Arsenos and Georgios Siolas. 2020. NTUAAILS at SemEval-2020 Task 11: Propaganda detection\nand classi\ufb01cation with biLSTMs and ELMo. In Proceedings of the 14th International Workshop on Semantic\nEvaluation , SemEval \u201920, Barcelona, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Pepa Atanasova, Llu \u00b4\u0131s M`arquez, Alberto Barr \u00b4on-Cede \u02dcno, Tamer Elsayed, Reem Suwaileh, Wajdi Zaghouani, Spas\nKyuchukov, Giovanni Da San Martino, and Preslav Nakov. 2018. Overview of the CLEF-2018 CheckThat!\nlab on automatic identi\ufb01cation and veri\ufb01cation of political claims, task 1: Check-worthiness. In CLEF 2018\nWorking Notes , Avignon, France."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Working Notes , Avignon, France.\nPepa Atanasova, Preslav Nakov, Georgi Karadzhov, Mitra Mohtarami, and Giovanni Da San Martino. 2019.\nOverview of the CLEF-2019 CheckThat! Lab on automatic identi\ufb01cation and veri\ufb01cation of claims. Task 1:\nCheck-worthiness. In CLEF 2019 Working Notes , Lugano, Switzerland."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Anastasios Bairaktaris, Symeon Symeonidis, and Avi Arampatzis. 2020. DUTH at SemEval-2020 Task 11: BERT\nwith entity mapping for propaganda classi\ufb01cation. In Proceedings of the 14th International Workshop on Se-\nmantic Evaluation , SemEval \u201920, Barcelona, Spain.\nAlberto Barr \u00b4on-Cede \u02dcno, Tamer Elsayed, Reem Suwaileh, Llu \u00b4\u0131s M`arquez, Pepa Atanasova, Wajdi Zaghouani, Spas"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Kyuchukov, Giovanni Da San Martino, and Preslav Nakov. 2018. Overview of the CLEF-2018 CheckThat! lab\non automatic identi\ufb01cation and veri\ufb01cation of political claims, task 2: Factuality. In CLEF 2018 Working Notes ,\nAvignon, France.\nAlberto Barr \u00b4on-Cede \u02dcno and Paolo Rosso. 2009. On automatic plagiarism detection based on n-grams comparison."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "InProceedings of the 31th European Conference on IR Research , ECIR \u201909, pages 696\u2013700, Toulouse, France.\nAlberto Barr \u00b4on-Cede \u02dcno, Giovanni Da San Martino, Israa Jaradat, and Preslav Nakov. 2019a. Proppy: A sys-\ntem to unmask propaganda in online news. In Proceedings of the Thirty-Third AAAI Conference on Arti\ufb01cial\nIntelligence , AAAI\u201919, pages 9847\u20139848, Honolulu, HI, USA."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Alberto Barr \u00b4on-Cede \u02dcno, Israa Jaradat, Giovanni Da San Martino, and Preslav Nakov. 2019b. Proppy: Organizing\nthe news based on their propagandistic content. Information Processing and Management , 56(5):1849\u20131864,\nSeptember.\n11http://propaganda.qcri.org\n12http://tanbih.qcri.org1395Alberto Barr \u00b4on-Cede \u02dcno, Tamer Elsayed, Preslav Nakov, Giovanni Da San Martino, Maram Hasanain, Reem"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Suwaileh, Fatima Haouari, Nikolay Babulkov, Bayan Hamdan, Alex Nikolov, Shaden Shaar, and Zien Sheikh\nAli. 2020a. Overview of CheckThat! 2020 \u2014 automatic identi\ufb01cation and veri\ufb01cation of claims in social\nmedia. In Proceedings of the 11th International Conference of the CLEF Association: Experimental IR Meets\nMultilinguality, Multimodality, and Interaction , CLEF \u20192020, Thessaloniki, Greece."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Alberto Barr \u00b4on-Cede \u02dcno, Tamer Elsayed, Preslav Nakov, Giovanni Da San Martino, Maram Hasanain, Reem\nSuwaileh, and Fatima Haouari. 2020b. CheckThat! at CLEF 2020: Enabling the automatic identi\ufb01cation\nand veri\ufb01cation of claims in social media. In Proceedings of the 42nd European Conference on Information\nRetrieval , ECIR \u201920, pages 499\u2013507, Lisbon, Portugal."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Verena Blaschke, Maxim Korniyenko, and Sam Tureski. 2020. CyberWallE at SemEval-2020 Task 11: An\nanalysis of feature engineering for ensemble models for propaganda detection. In Proceedings of the 14th\nInternational Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nBolsover and Howard. 2017. Computational propaganda and political big data: Toward a more critical research"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "agenda. Big Data , 5(4):273\u2013276.\nAkemi Takeoka Chat\ufb01eld, Christopher G. Reddick, and Uuf Brajawidagda. 2015. Tweeting propaganda, radi-\ncalization and recruitment: Islamic state supporters multi-sided Twitter networks. In Proceedings of the 16th\nAnnual International Conference on Digital Government Research , pages 239\u2013249, Phoenix, AZ, USA."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Aniruddha Chauhan and Harshita Diddee. 2020. PsuedoProp at SemEval-2020 Task 11: Propaganda span detec-\ntion using BERT-CRF and ensemble sentence level classi\ufb01er. In Proceedings of the 14th International Workshop\non Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nWei-Te Chen and Will Styler. 2013. Anafora: A web-based general purpose annotation tool. In Proceedings of"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies (Demonstration Session) , NAACL-HLT \u201913, pages 14\u201319, Atlanta, GA, USA.\nAnton Chernyavskiy, Dmitry Ilvovsky, and Preslav Nakov. 2020. aschern at SemEval-2020 Task 11: It takes"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "three to tango: RoBERTa, CRF, and transfer learning. In Proceedings of the 14th International Workshop on\nSemantic Evaluation , SemEval \u201920, Barcelona, Spain.\nGiovanni Da San Martino, Alberto Barr \u00b4on-Cede \u02dcno, and Preslav Nakov. 2019a. Findings of the NLP4IF-2019\nshared task on \ufb01ne-grained propaganda detection. In Proceedings of the Second Workshop on Natural Language"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Processing for Internet Freedom: Censorship, Disinformation, and Propaganda , NLP4IF \u201919, pages 162\u2013170,\nHong Kong, China.\nGiovanni Da San Martino, Seunghak Yu, Alberto Barr \u00b4on-Cede \u02dcno, Rostislav Petrov, and Preslav Nakov. 2019b.\nFine-grained analysis of propaganda in news articles. In Proceedings of the 2019 Conference on Empirical"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language\nProcessing , EMNLP-IJCNLP \u201919, pages 5636\u20135646, Hong Kong, China.\nGiovanni Da San Martino, Stefano Cresci, Alberto Barr \u00b4on-Cede \u02dcno, Seunghak Yu, Roberto Di Pietro, and Preslav\nNakov. 2020a. A survey on computational propaganda detection. In Proceedings of the 29th International Joint"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Conference on Arti\ufb01cial Intelligence and the 17th Paci\ufb01c Rim International Conference on Arti\ufb01cial Intelligence ,\nIJCAI-PRICAI \u201920, pages 4826\u20134832, Yokohama, Japan.\nGiovanni Da San Martino, Shaden Shaar, Yifan Zhang, Seunghak Yu, Alberto Barr \u00b4on-Cede \u02dcno, and Preslav Nakov.\n2020b. Prta: A system to support the analysis of propaganda techniques in the news. In Proceedings of the 58th"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Annual Meeting of the Association for Computational Linguistics: System Demonstrations , ACL \u201920, pages\n287\u2013293.\nLavinia Dan. 2015. Techniques for the translation of advertising slogans. In Proceedings of the International\nConference Literature, Discourse and Multicultural Dialogue , pages 13\u201323, Tirgu-Mures, Mures."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Jiaxu Dao, Jin Wang, and Xuejie Zhang. 2020. YNU-HPCC at SemEval-2020 Task 11: LSTM network for\ndetection of propaganda techniques in news articles. In Proceedings of the 14th International Workshop on\nSemantic Evaluation , SemEval \u201920, Barcelona, Spain.\nGuillaume Daval-Frerot and Weis Yannick. 2020. WMD at SemEval-2020 Tasks 7 and 11: Assessing humor"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "and propaganda using unsupervised data augmentation. In Proceedings of the 14th International Workshop on\nSemantic Evaluation , SemEval \u201920, Barcelona, Spain.1396Daryna Dementieva, Igor Markov, and Alexander Panchenko. 2020. SkoltechNLP at SemEval-2020 Task 11:\nExploring unsupervised text augmentation for propaganda detection. In Proceedings of the 14th International"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nLeon Derczynski, Kalina Bontcheva, Maria Liakata, Rob Procter, Geraldine Wong Sak Hoi, and Arkaitz Zubiaga.\n2017. SemEval-2017 Task 8: RumourEval: Determining rumour veracity and support for rumours. In Pro-\nceedings of the 11th International Workshop on Semantic Evaluation , SemEval \u201917, pages 60\u201367, Vancouver,\nCanada."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Canada.\nDimas Sony Dewantara, Indra Budi, and Muhammad Okky Ibrohim. 2020. 3218IR at SemEval-2020 Task 11:\nConv1D and word embedding in propaganda span identi\ufb01cation at news articles. In Proceedings of the 14th\nInternational Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nIlya Dimov, Vladislav Korzun, and Ivan Smurov. 2020. NoPropaganda at SemEval-2020 Task 11: A borrowed"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "approach to sequence tagging and text classi\ufb01cation. In Proceedings of the 14th International Workshop on\nSemantic Evaluation , SemEval \u201920, Barcelona, Spain.\nTamer Elsayed, Preslav Nakov, Alberto Barr \u00b4on-Cede \u02dcno, Maram Hasanain, Reem Suwaileh, Giovanni Da San Mar-\ntino, and Pepa Atanasova. 2019a. CheckThat! at CLEF 2019: Automatic identi\ufb01cation and veri\ufb01cation of"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "claims. In Proceedings of the 41st European Conference on Information Retrieval , ECIR \u201919, pages 309\u2013315,\nCologne, Germany.\nTamer Elsayed, Preslav Nakov, Alberto Barr \u00b4on-Cede \u02dcno, Maram Hasanain, Reem Suwaileh, Giovanni Da San\nMartino, and Pepa Atanasova. 2019b. Overview of the CLEF-2019 CheckThat!: Automatic identi\ufb01cation and"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "veri\ufb01cation of claims. In Proceedings of the 10th International Conference of the CLEF Association , CLEF \u201919,\npages 301\u2013321, Lugano, Switzerland.\nVlad Ermurachi and Daniela Gifu. 2020. UAIC1860 at SemEval-2020 Task 11: Detection of propaganda tech-\nniques in news articles. In Proceedings of the 14th International Workshop on Semantic Evaluation , Sem-\nEval \u201920, Barcelona, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Eval \u201920, Barcelona, Spain.\nLei Gao, Alexis Kuppersmith, and Ruihong Huang. 2017. Recognizing explicit and implicit hate speech using a\nweakly supervised two-path bootstrapping approach. In Proceedings of the Eighth International Joint Confer-\nence on Natural Language Processing , IJCNLP \u201917, pages 774\u2013782, Taipei, Taiwan."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Kiran Garimella, Gianmarco De Francisci Morales, Aristides Gionis, and Michael Mathioudakis. 2015. Quantify-\ning controversy in social media. ACM Transactions on Social Computing , 1(1):1\u201327, jan.\nMonika Glowacki, Vidya Narayanan, Sam Maynard, Gustavo Hirsch, Bence Kollanyi, Lisa-Maria Neudert, Phil"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Howard, Thomas Lederer, and Vlad Barash. 2018. News and political information consumption in Mexico:\nMapping the 2018 Mexican presidential election on Twitter and Facebook. Technical Report COMPROP DATA\nMEMO 2018.2, Oxford University, Oxford, UK, June.\nJean Goodwin. 2011. Accounting for the force of the appeal to authority. In Proceedings of the 9th International"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Conference of the Ontario Society for the Study of Argumentation , pages 1\u20139, Windsor, Canada.\nGenevieve Gorrell, Ahmet Aker, Kalina Bontcheva, Leon Derczynski, Elena Kochkina, Maria Liakata, and Arkaitz\nZubiaga. 2019. SemEval-2019 task 7: RumourEval, determining rumour veracity and support for rumours."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "InProceedings of the 13th International Workshop on Semantic Evaluation , SemEval \u201919, pages 845\u2013854,\nMinneapolis, MN, USA.\nDmitry Grigorev and Vladimir Ivanov. 2020. Inno at SemEval-2020 Task 11: Leveraging pure transfomer for\nmulti-class propaganda detection. In Proceedings of the 14th International Workshop on Semantic Evaluation ,\nSemEval \u201920, Barcelona, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "SemEval \u201920, Barcelona, Spain.\nRaj Kumar Gupta and Yinping Yang. 2018. CrystalFeel at SemEval-2018 task 1: Understanding and detecting\nemotion intensity using affective lexicons. In Proceedings of the 12th International Workshop on Semantic\nEvaluation , SemEval \u201918, pages 256\u2013263, New Orleans, LA, USA."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Ivan Habernal, Raffael Hannemann, Christian Pollak, Christopher Klamm, Patrick Pauli, and Iryna Gurevych.\n2017. Argotario: Computational argumentation meets serious games. In Proceedings of the 2017 Conference\non Empirical Methods in Natural Language Processing: System Demonstrations , EMNLP \u201917, pages 7\u201312,\nCopenhagen, Denmark."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Copenhagen, Denmark.\nIvan Habernal, Henning Wachsmuth, Iryna Gurevych, and Benno Stein. 2018. Before name-calling: Dynamics\nand triggers of ad hominem fallacies in web argumentation. In Proceedings of the 2018 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human Language Technologies ,"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "NAACL-HLT \u201918, pages 386\u2013396, New Orleans, LA, USA.1397Maram Hasanain, Reem Suwaileh, Tamer Elsayed, Alberto Barr \u00b4on-Cede \u02dcno, and Preslav Nakov. 2019. Overview\nof the CLEF-2019 CheckThat! Lab on automatic identi\ufb01cation and veri\ufb01cation of claims. Task 2: Evidence and\nfactuality. In CLEF 2019 Working Notes , Lugano, Switzerland."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Maram Hasanain, Fatima Haouari, Reem Suwaileh, Zien Sheikh Ali, Bayan Hamdan, Tamer Elsayed, Alberto\nBarr\u00b4on-Cede \u02dcno, Giovanni Da San Martino, and Preslav Nakov. 2020. Overview of CheckThat! 2020 Ara-\nbic: Automatic identi\ufb01cation and veri\ufb01cation of claims in social media. In Working Notes of CLEF 2020 ,\nCLEF \u20192020, Thessaloniki, Greece."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "CLEF \u20192020, Thessaloniki, Greece.\nRenee Hobbs and Sandra Mcgee. 2008. Teaching about Propaganda: An Examination of the Historical Roots of\nMedia Literacy. Journal of Media Literacy Education , 6(62):56\u201367.\nBenjamin D. Horne, Sara Khedr, and Sibel Adali. 2018. Sampling the news producers: A large news and feature"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "data set for the study of the complex media landscape. In Proceedings of the Twelfth International Conference\non Web and Social Media , ICWSM \u201918, pages 518\u2013527, Stanford, CA, USA.\nJohn Hunter. 2015. Brainwashing in a large group awareness training? The classical conditioning hypothesis of\nbrainwashing. Master\u2019s thesis, University of Kwazulu-Natal, South Africa."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Ins. 1938. How to detect propaganda. In Propaganda Analysis. Volume I , chapter 2, pages 210\u2013218. Publications\nof the Institute for Propaganda Analysis, New York, NY , USA.\nYunzhe Jiang, Cristina G \u02c6arbacea, and Qiaozhu Mei. 2020. UMSIForeseer at SemEval-2020 Task 11: Propaganda\ndetection by \ufb01ne-tuning BERT with resampling and ensemble learning. In Proceedings of the 14th International"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nGarth S. Jowett and Victoria O\u2019Donnell. 2012a. Propaganda and Persuasion . SAGE, Los Angeles, CA, USA, 5th\nedition.\nGarth S. Jowett and Victoria O\u2019Donnell. 2012b. What is propaganda, and how does it differ from persuasion? In\nPropaganda and Persuasion , chapter 1, pages 1\u201348. Sage Publishing."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Dawid Jurkiewicz, \u0141ukasz Borchmann, Izabela Kosmala, and Filip Grali \u00b4nski. 2020. ApplicaAI at SemEval-2020\nTask 11: On RoBERTa-CRF, Span CLS and whether self-training helps them. In Proceedings of the 14th\nInternational Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nAnders Friis Kaas, Viktor Torp Thomsen, and Barbara Plank. 2020. Team DiSaster at SemEval-2020 Task 11:"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Combining BERT and hand-crafted features for identifying propaganda techniques in news. In Proceedings of\nthe 14th International Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nSopan Khosla, Rishabh Joshi, Ritam Dutt, Alan W. Black, and Yulia Tsvetkov. 2020. LTIatCMU at SemEval-2020"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Task 11: Incorporating multi-level features for multi-granular propaganda span identi\ufb01cation. In Proceedings\nof the 14th International Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nMoonsung Kim and Steven Bethard. 2020. TTUI at SemEval-2020 Task 11: Propaganda detection with transfer"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "learning and ensembles. In Proceedings of the 14th International Workshop on Semantic Evaluation , Sem-\nEval \u201920, Barcelona, Spain.\nMichael Kranzlein, Shabnam Behzad, and Nazli Goharian. 2020. Team DoNotDistribute at SemEval-2020 Task\n11: Features, \ufb01netuning, and data augmentation in neural models for propaganda detection in news articles. In"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Proceedings of the 14th International Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nGangeshwar Krishnamurthy, Raj Kumar Gupta, and Yinping Yangi. 2020. SocCogCom at SemEval-2020 Task\n11: Detecting propaganda techniques in news articles using semantic-level emotional salience features. In"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Proceedings of the 14th International Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nDavid M.J. Lazer, Matthew A. Baum, Yochai Benkler, Adam J. Berinsky, Kelly M. Greenhill, Filippo Menczer,\nMiriam J. Metzger, Brendan Nyhan, Gordon Pennycook, David Rothschild, Michael Schudson, Steven A. Slo-"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "man, Cass R. Sunstein, Emily A. Thorson, Duncan J. Watts, and Jonathan L. Zittrain. 2018. The science of fake\nnews. Science , 359(6380):1094\u20131096.\nJinfen Li and Lu Xiao. 2020. HybridPro at SemEval-2020 Task 11: A hybrid model for propagandistic technique\nclassi\ufb01cation in news articles. In Proceedings of the 14th International Workshop on Semantic Evaluation ,\nSemEval \u201920, Barcelona, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "SemEval \u201920, Barcelona, Spain.\nYaliang Li, Jing Gao, Chuishi Meng, Qi Li, Lu Su, Bo Zhao, Wei Fan, and Jiawei Han. 2016. A survey on truth\ndiscovery. SIGKDD Explor. Newsl. , 17(2):1\u201316, February.1398Matej Martinkovic, Samuel Pecar, and Marian Simko. 2020. NLFIIT at SemEval-2020 Task 11: Neural network"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "architectures for detection of propaganda techniques in news articles. In Proceedings of the 14th International\nWorkshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nYann Mathet, Antoine Widl \u00a8ocher, and Jean-Philippe M \u00b4etivier. 2015. The uni\ufb01ed and holistic method gamma ( \r)\nfor inter-annotator agreement measure and alignment. Computational Linguistics , 41(3):437\u2013479, sep."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Tsvetomila Mihaylova, Georgi Karadzhov, Pepa Atanasova, Ramy Baly, Mitra Mohtarami, and Preslav Nakov.\n2019. SemEval-2019 task 8: Fact checking in community question answering forums. In Proceedings of the\n13th International Workshop on Semantic Evaluation , SemEval \u201919, pages 860\u2013869, Minneapolis, MN, USA."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Elena Mikhalkova, Nadezhda Ganzherli, Anna Glazkova, and Yulia Bidulia. 2020. UTMN at SemEval-2020 task\n11: A kitchen solution to automatic propaganda detection. In Proceedings of the 14th International Workshop\non Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nClyde R. Miller. 1939. The Techniques of Propaganda. From \u201cHow to Detect and Analyze Propaganda,\u201d an"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "address given at Town Hall. The Center for learning.\nGaku Morio, Terufumi Morishita, Hiroaki Ozaki, and Toshinori Miyoshi. 2020. Hitachi at SemEval-2020 Task\n11: An empirical study of pre-trained transformer family for propaganda detection. In Proceedings of the 14th\nInternational Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Robert Muller. 2018. Indictment of Internet Research Agency. pages 1\u201337.\nPreslav Nakov, Alberto Barr \u00b4on-Cede \u02dcno, Tamer Elsayed, Reem Suwaileh, Llu \u00b4\u0131s M `arquez, Wajdi Zaghouani, Pepa\nAtanasova, Spas Kyuchukov, and Giovanni Da San Martino. 2018. Overview of the CLEF-2018 CheckThat!\nlab on automatic identi\ufb01cation and veri\ufb01cation of political claims. In Proceedings of the Ninth International"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Conference of the CLEF Association: Experimental IR Meets Multilinguality, Multimodality, and Interaction ,\nCLEF \u201918, pages 372\u2013387, Avignon, France.\nAndrei Paraschiv and Dumitru-Clementin Cercel. 2020. UPB at SemEval-2020 Task 11: Propaganda detection\nwith domain-speci\ufb01c trained BERT. In Proceedings of the 14th International Workshop on Semantic Evaluation ,\nSemEval \u201920, Barcelona, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "SemEval \u201920, Barcelona, Spain.\nRajaswa Patil, Somesh Singh, and Swati Agarwal. 2020. BPGC at SemEval-2020 Task 11: Propaganda detection\nin news articles with multi-granularity knowledge sharing and linguistic features based ensemble learning. In\nProceedings of the 14th International Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "James W. Pennebaker, Ryan L. Boyd, Kayla Jordan, and Kate Blackburn. 2015. The development and psychome-\ntric properties of LIWC2015.\nMaias Petee and Alexis Palmer. 2020. UNTLing at SemEval-2020 Task 11: Detection of propaganda techniques\nin news articles. In Proceedings of the 14th International Workshop on Semantic Evaluation , SemEval \u201920,\nBarcelona, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Barcelona, Spain.\nMartin Potthast, Benno Stein, Alberto Barr \u00b4on-Cede \u02dcno, and Paolo Rosso. 2010. An evaluation framework for\nplagiarism detection. In Proceedings of the 23rd International Conference on Computational Linguistics , COL-\nING \u201910, pages 997\u20131005, Beijing, China.\nMayank Raj, Ajay Jaiswal, Rohit R.R, Ankita Gupta, Sudeep Sahoo, Vertika Srivastava, and Kim Yeon Hyang."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "2020. Solomon at SemEval-2020 Task 11: Novel ensemble architechture for \ufb01ne-tuned propaganda detection\nin news articles. In Proceedings of the 14th International Workshop on Semantic Evaluation , SemEval \u201920,\nBarcelona, Spain.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana V olkova, and Yejin Choi. 2017. Truth of varying shades: An-"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "alyzing language in fake news and political fact-checking. In Proceedings of the 2017 Conference on Empirical\nMethods in Natural Language Processing , EMNLP 17, pages 2931\u20132937, Copenhagen, Denmark.\nMonika L. Richter. 2017. The Kremlin\u2019s platform for \u2018useful idiots\u2019 in the West: An overview of RT\u2019s editorial\nstrategy and evidence of impact. Kremlin Watch , page 53."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Shaden Shaar, Alex Nikolov, Nikolay Babulkov, Firoj Alam, Alberto Barr \u00b4on-Cede \u02dcno, Tamer Elsayed, Maram\nHasanain, Reem Suwaileh, Fatima Haouari, Giovanni Da San Martino, and Preslav Nakov. 2020. Overview\nof CheckThat! 2020 English: Automatic identi\ufb01cation and veri\ufb01cation of claims in social media. In Working\nNotes of CLEF 2020 , CLEF \u20192020, Thessaloniki, Greece."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake news detection on social media: A\ndata mining perspective. SIGKDD Explor. Newsl. , 19(1):22\u201336, September.1399Paramansh Singh, Siraj Sandhu, Subham Kumar, and Ashutosh Modi. 2020. newsSweeper at SemEval-2020\nTask 11: Context-aware rich feature representations for propaganda classi\ufb01cation. In Proceedings of the 14th"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "International Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nXin Tao and Xiaobing Zhou. 2020. YNUtaoxin at SemEval-2020 Task 11: Identi\ufb01cation fragments of propaganda\ntechnique by neural sequence labeling models with different tagging schemes and pre-trained language model.\nInProceedings of the 14th International Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Cristina Tard \u00b4aguila, Fabr \u00b4\u0131cio Benevenuto, and Pablo Ortellado. 2018. Fake news is poisoning\nbrazilian politics. WhatsApp can stop it. https://www.nytimes.com/2018/10/17/opinion/\nbrazil-election-fake-news-whatsapp.html .\nGabriel H Teninbaum. 2009. Reductio ad hitlerum: Trumping the judicial Nazi card. Michigan State Law Review ,\n2009."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "2009.\nJames Thorne and Andreas Vlachos. 2018. Automated fact checking: Task formulations, methods and future\ndirections. In Proceedings of the 27th International Conference on Computational Linguistics , COLING \u201918,\npages 3346\u20133359, Santa Fe, NM, USA.\nJames Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. 2018. FEVER: a large-scale"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "dataset for fact extraction and VERi\ufb01cation. In Proceedings of the 2018 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies , NAACL-HLT \u201918,\npages 809\u2013819, New Orleans, LA, USA.\nChristopher W. Tindale. 2007. Fallacies and Argument Appraisal. Critical Reasoning and Argumentation . Cam-\nbridge University Press."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "bridge University Press.\nRobyn Torok. 2015. Symbiotic radicalisation strategies: Propaganda tools and neuro linguistic programming. In\nProceedings of the Australian Security and Intelligence Conference , pages 58\u201365, Perth, Australia.\nEkansh Verma, Vinodh Motupalli, and Souradip Chakraborty. 2020. Transformers at SemEval-2020 Task 11:"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Propaganda fragment detection using diversi\ufb01ed bert architectures based ensemble learning. In Proceedings of\nthe 14th International Workshop on Semantic Evaluation , SemEval \u201920, Barcelona, Spain.\nSoroush V osoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science ,\n359(6380):1146\u20131151."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "359(6380):1146\u20131151.\nHenning Wachsmuth, Nona Naderi, Yufang Hou, Yonatan Bilu, Vinodkumar Prabhakaran, Tim Alberdingk Thijm,\nGraeme Hirst, and Benno Stein. 2017. Computational argumentation quality assessment in natural language. In\nProceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics ,\nEACL \u201917, pages 176\u2013187, Valencia, Spain."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Douglas Walton. 2013. The straw man fallacy. In Methods of Argumentation , pages 249\u2013286. Cambridge Univer-\nsity Press.\nAnthony Weston. 2000. A Rulebook for Arguments . Hackett Student Handbooks.\nSeunghak Yu, Giovanni Da San Martino, and Preslav Nakov. 2019. Experiments in detecting persuasion tech-"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "niques in the news. In Proceedings of the NeurIPS 2019 Joint Workshop on AI for Social Good , NeurIPS \u201919,\nVancouver, Canada, December.1400A Summary of all Submitted Systems\nThis appendix includes a brief summary of all systems for both subtasks. We present the teams in\nalphabetical order. The subindex on the right of each team represents its of\ufb01cial test rank in the subtasks."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "The teams appearing in Tables 5, 6, or 7 but not here did not submit a paper describing their approach.\nTeam 3218IR (Dewantara et al., 2020) (SI:31) used a one-dimensional convolutional neural network\n(CNN) with word embeddings, whose number of layers and \ufb01lters as well as kernel and pooling sizes\nwere all tuned empirically."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "were all tuned empirically.\nTeam ApplicaAI (Jurkiewicz et al., 2020) (SI: 2, TC: 1) applied self-supervision using the RoBERTa\nmodel. For the SI subtask, they used a RoBERTa-CRF architecture. The model trained using this\narchitecture was then iteratively used to produce silver data by predicting on 500k sentences and retraining"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "the model with both gold and silver data. As for subtask TC, ApplicaAI opted for feeding their models\nwith propagandas snippets in context. Full sentences are shaped as the input with the speci\ufb01c propaganda\nin them. Once again, silver data was used, taking advantage of the spans detected by their SI model and"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "labeling with their preliminary TC model. The \ufb01nal classi\ufb01er was an ensemble of models trained on the\noriginal corpus, re-weighting, and a model trained also on silver data.\nTeam aschern (Chernyavskiy et al., 2020) (SI: 3, TC: 2) tackled both subtasks. For SI, they \ufb01ne-tuned\nan ensemble of two differently intialized RoBERTa models, each with an attached CRF for sequence"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "labeling and simple span character boundary post-processing. A RoBERTa ensemble was also used for\nTC, treating the task as sequence classi\ufb01cation but using an average embedding of the surrounding tokens\nand the length of a span as contextual features. They further used transfer learning, to pass knowledge"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "about the SI subtask to help the TC subtask. Finally, speci\ufb01c postprocessing was done to increase the\nconsistency of the repetition technique spans and to avoid insertions of techniques in other techniques.\nTeam BPGC (Patil et al., 2020) (SI: 21, TC: 18) used a multi-granularity approach to address subtask SI."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Information about the article and the sentence was considered when classifying each word as propaganda\nor not, by means of computing and concatenating vectorial representations for the three inputs. For subtask\nTC, they used an ensemble of BERT and logistic regression, complemented with engineered features"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "which, as stated by the authors, were particularly useful for the smaller classes. Such features include\nTF.IDF vectors of words and character n-grams, topic modeling, and sentence-level polarity, among\nothers. Different learning models were explored for both tasks, including LSTM and CNN, together with\ndiverse Transformers to build ensembles of classi\ufb01ers."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team CyberWallE (Blaschke et al., 2020) (SI: 8, TC: 8) used BERT embeddings for subtask SI, as\nwell as manual features modeling sentiment, rhetorical structure, and POS tags, which were eventually\nfed into a bi-LSTM to produce IO labels, followed by some post-processing to merge neighboring\nspans. For subtask TC, they extracted the pre-softmax layer of BERT and further added extra features"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "(rhetorical, named entities, question), while taking special care of repetitions as part of a complex ensemble\narchitecture, followed by label post-processing.\nTeam DiSaster (Kaas et al., 2020) (TC:11) used a combination of BERT and hand-crafted features,\nincluding frequency of the fragment in the article and in the sentence it appears in and the inverse"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "uniqueness of words in a span. The goal of the features is to compensate the inability of BERT to deal\nwith distant context, speci\ufb01cally to target the technique Repetition .\nTeam DoNotDistribute (Kranzlein et al., 2020) (SI: 22, TC: 24) opted for a combination of BERT-\nbased models and engineered features (e.g., PoS, NEs, frequency within propaganda snippets in the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "training set). A reported performance increase of 5% was obtained by producing 3k new silver training\ninstances. A library was used to create near-paraphrases of the propaganda snippets by randomly\nsubstituting certain PoS words.1401Team DUTH (Bairaktaris et al., 2020) (TC:10) pre-processed the input including URL normalization,"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "number and punctuation removal, as well as lowercasing. They further mapped certain words into classes\nusing named entity recognition with focus on person names and gazetteers containing names and variations\nof names of countries (255 entries), religions (35 entries), political ideologies (23 entries), and slogans (41"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "entries). The recognized categories were replaced by the category name in the input, before passing the\ninput to BERT.\nTeam Hitachi (Morio et al., 2020) (SI: 1, TC: 3) used BIO encoding for subtask SI, which is typical\nfor related segmentation and labeling tasks such as named entity recognition. They used a complex"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "heterogeneous multi-layer neural network, trained end-to-end. The network used a pre-trained language\nmodel, which generates a representation for each input token. To this were added part-of-speech (PoS) and\nnamed entity (NE) embeddings. As a result, there were three representations for each token, which were"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "concatenated and used as an input to bi-LSTMs. At this moment, the network branches as it is trained\nwith three objectives: ( i) the main BIO tag prediction objective, and two auxiliary objectives, namely\n(ii) token-level technique classi\ufb01cation, and ( iii) sentence-level classi\ufb01cation. There is one Bi-LSTM"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "for objectives ( i) and ( ii), and there is another Bi-LSTM for objective ( iii). For the former, there is an\nadditional CRF layer, which helps improve the consistency of the output. For subtask TC , there are two\ndistinct FFNs, feeding input representation, which are obtained in the same manner as for subtask SI. One"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "of the two FFNs is for sentence representation, and the other one is for the representation of tokens in the\npropaganda span. The propaganda span representation is obtained by concatenating representation of the\nbegin-of-sentence token, span start token, span end token, and aggregated representation by attention and"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "max-pooling. For both subtasks , these architectures were trained independently with different BERT, GPT-\n2, XLNet, XLM, RoBERTa, or XLM-RoBERTa Transformers; and the resulting models were combined\nin ensembles.\nTeam Inno (Grigorev and Ivanov, 2020) (TC:7) used RoBERTa with cost-sensitive learning for subtask"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "TC. They experimented with undersampling, i.e. removing examples from the bigger classes, as well as\nwith modeling the context. They also tried various pre-trained Transformers, but obtained worse results.\nTeam JUST (Altiti et al., 2020) (TC:15) based its approach to the task on the BERT uncased pre-trained\nlanguage model, which used 12 transformer layers that were trained for 15 epochs."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team LTIatCMU (Khosla et al., 2020) (SI:4) used a multi-granular BERT BiLSTM for subtask SI. It\nused additional syntactic, semantic and pragmatic affect features at the word, sentence and document\nlevel. It was jointly trained on token and sentence propaganda classi\ufb01cation, with class balancing. In"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "addition, BERT was \ufb01ne-tuned to persuasive language on about 10,000 articles from propaganda websites,\nwhich turned out to be important in their experiments.\nTeam newsSweeper (Singh et al., 2020) (SI: 13, TC: 5) used BERT with BIOE encoding for subtask\nSI. For the TC subtask, their of\ufb01cial run used RoBERTa to obtain representations for the span and for the"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "sentence, which they concatenated. The team further experimented ( i) with other Transformers (BERT,\nRoBERTa, SpanBERT, and GPT-2), ( ii) with other sequence labeling schemes (P/NP, BIO, BIOES),\n(iii) with concatenating different hidden layers of BERT to obtain a token representation, and ( iv) with\nPOS tags, as well as ( v) with different neural architectures."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team NLFIIT (Martinkovic et al., 2020) (SI: 17, TC: 16) used various combinations of neural archi-\ntecture and embeddings and found out that ELMo combined with BiLSTM (and self attention for subtask\nTC) yielded the best performance.\nTeam NoPropaganda (Dimov et al., 2020) (SI: 7, TC: 6) used the LasetTagger model with the BERT-\nbase encoder for subtask SI. R-BERT was used for subtask TC."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team NTUAAILS (Arsenos and Siolas, 2020) (SI: 27, TC: 25) used a residual biLSTM fed with pre-\ntrained ELMo embeddigns for subtask SI. A biLSTM was used for subtask TC as well, but this time fed\nwith GloVe word embeddings1402Team PsuedoProp (Chauhan and Diddee, 2020) (SI:14) focused on subtask SI. They pre-classi\ufb01ed"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "sentences as propaganda or not using an ensemble of XLNet and RoBERTa, before \ufb01ne-tuning a BERT-\nbased CRF sequence tagger to identify the exact spans.\nTeam SkoltechNLP (Dementieva et al., 2020) (SI: 25, TC: 26) \ufb01ne-tuned BERT for SI, expanding the\noriginal training set through data augmentation techniques based on distributional semantics."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team SocCogCom (Krishnamurthy et al., 2020) (TC:13) approached subtask TC using\nBERT/ALBERT together with ( i) semantic-level emotional salience features from CrystalFeel (Gupta and\nYang, 2018), and ( ii) word-level psycholinguistic features from the LIWC lexicon (Pennebaker et al.,\n2015). They further modeled the context, i.e. three words before and after the target propaganda snippet."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team Solomon (Raj et al., 2020) (TC:4) addressed subtask TC with a system that combines a transfer\nlearning model based on \ufb01ne-tuned RoBERTa (integrating fragment and context information), an ensemble\nof binary classi\ufb01ers for the smaller classes and a novel system to speci\ufb01cally handle Repetition : they used"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "dynamic least common sub-sequence to assess the similarity between the fragment and the context, and\nthen the fragment was considered to be a repetition if the score was greater than a threshold heuristically\nset with respect to the length of the fragment.\nTeam syrapropa (Li and Xiao, 2020) (SI: 25, TC: 20) \ufb01ne-tuned SpanBERT, a variant of BERT for"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "span detection, on the context of spans in terms of the surrounding non-propaganda text for subtask SI.\nFor subtask TC, they used a hybrid model that consists of several submodels, each specializing in some of\nthe relations. These models include ( i) BERT, ( ii) BERT with cost adjustment to address class imbalance,"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "and ( iii) feature-rich logistic regression. The latter uses features such as length, TF.IDF-weighted words,\nrepetitions, superlatives, and lists of \ufb01xed phrases targeting speci\ufb01c propaganda techniques. The output\nfrom the hybrid model was further post-processed using some syntactic rules based on part of speech."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team Transformers (Verma et al., 2020) (SI: 9, TC: 29) explored a manifold of models to address\nthe SI subtask. They considered residual biLSTMs fed with ELMo representations as well as different\nvariations of BERT and RoBERTa with CNNs\nTeam TTUI (Kim and Bethard, 2020) (SI: 20, TC: 14) proposed an ensemble of \ufb01ne-tuned BERT and"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "RoBERTa models. They observed that feeding as input to the neural network a chunk of multiple,\npossibly overlapping sentences yielded the best performance. Moreover, for subtask SI, they applied a\npost-processing to remove gaps in the predictions between adjacent words. For subtask TC, they showed\nthat modeling the context did not help in their experiments."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team UAIC1860 (Ermurachi and Gifu, 2020) (SI: 28, TC: 26) used traditional text representation\ntechniques: character n-grams, word2vec embeddings, and TF.IDF-weighted word-based features. For\nboth subtasks, these features were used in a Random Forest classi\ufb01er. Additional experiments with Na \u00a8\u0131ve\nBayes, Logistic Regression and SVMs yielded worse results."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team UMSIForeseer Jiang et al. (2020) (TC:17) focused on subtask TC. They \ufb01ne-tuned BERT on the\nlabeled training spans, using a mix of oversampling and undersampling that is leveraged using a bagging\nensemble learner.\nTeam UNTLing (Petee and Palmer, 2020) (TC:27) used a logistic regression classi\ufb01er for subtask TC"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "with a number of features, including bag-of-words, embeddings, NE and V AD lexicon features. Their\nanalysis highlights that NE are useful for Loaded Language andFlag Waving . The V AD features were\nuseful for emotion-related techniques such as Appeal to fear/prejudice andDoubt . They performed some"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "experiments on the development set for subtask SI after the deadline. They used CRF with a number of\nfeatures including PoS, syntactic dependency between the token and the previous/next word, BoW of\npreceding/following tokens, and the GloVe embedding of the token.1403Team UPB (Paraschiv and Cercel, 2020) (SI: 5, TC: 19) used models based on BERT-base. Rather"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "than just using the pre-trained models, they used masked language models to domain-adapt it with\n9M-articles with fake, suspicious, and hyperpartisan news articles. They used the same domain-adapted\nmodel for both subtasks. They further used CRF for subtask SI, and a softmax for subtask TC.\nTeam UTMN (Mikhalkova et al., 2020) (SI:23) addressed subtask SI by representing the texts as a"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "concatenation of tokens and context embeddings, together with sentiment intensity from V ADER. They\navoided deep learning architectures in order to produce a computationally affordable model, namely\nlogistic regression.\nTeam WMD (Daval-Frerot and Yannick, 2020) (SI: 33, TC: 21) used an ensemble of BERT-based"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "models, LSTMs, SVMs, gradient boosting, and random forest together with character and word-level\nembeddings. In addition, they used a number of techniques for data augmentation: back-translation,\nsynonym replacement and TF.IDF replacement, i.e., replacing unimportant words, according to their\nTF.IDF score, with other unimportant words."}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Team YNU-HPCC (Dao et al., 2020) (SI: 16, TC: 22) participated in both subtasks using GloVe and\nBERT embeddings in combination with LSTMs, BiLSTMs, and XGBoost.\nTeam YNUtaoxin (Tao and Zhou, 2020) (SI:11) used BERT, RoBERTa and XLNet on subtask SI\nfocusing on determining the optimal input sentence length for the networks.1404B Errata"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "After the shared task has ended, we found a bug in the code for our evaluation tools, which affected both\nsubtasks. Overall, its impact was limited, and the ranking computed with the \ufb01xed code did not change\nsubstantially, in particular for the top-ranked teams. Tables 8 and 9 show the corrected scores on the test"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "sets for subtasks SI and TC, respectively. Any reference to the task results should refer to these numbers.\nTest\nTeam Rnk F1 P R\nHitachi 151.74 55.76 48.27\nApplicaAI 249.88 59.33 43.02\naschern 349.59 52.57 46.93\nLTIatCMU 448.16 50.35 46.15\nUPB 546.63 57.50 39.22\nFragarach 646.43 53.44 41.05\nNoPropaganda 745.17 55.05 38.29\nYNUtaoxin 843.80 54.60 36.57\nTransformers 943.77 49.05 39.52"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Transformers 943.77 49.05 39.52\nSWEAT 10 43.69 52.13 37.61\nDREAM 11 43.60 53.67 36.71\nCyberWallE 12 43.59 40.99 46.54\nnewsSweeper 13 42.20 45.30 39.49\nPsuedoProp 14 41.81 41.24 42.41\nSolomon 15 41.26 53.69 33.51\nNLFIIT 16 41.10 50.17 34.81\nTTUI 17 40.76 66.37 29.41\nPALI 18 40.73 52.10 33.44\nYNUHPCC 19 40.46 36.35 45.63\nUESTCICSA 20 40.41 55.58 31.74\nBPGC 21 38.89 48.50 32.45"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "BPGC 21 38.89 48.50 32.45\nDoNotDistribute 22 37.92 41.47 34.92\nUTMNandOCAS 23 37.71 37.12 38.31\nEntropy 24 37.31 40.82 34.35\nsyrapropa 25 36.92 49.22 29.53\nSkoltechNLP 26 34.36 45.77 27.51\nNTUAAILS 27 34.36 45.62 27.55\nUAIC1860 28 32.67 23.86 51.78\nCCNI 29 29.68 37.73 24.46\nNCCU-SMRG 30 27.69 16.70 80.94\n3218IR 31 23.28 21.95 24.79\nWMD 32 20.51 45.44 13.24\nLS 33 18.14 33.20 12.47"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "LS 33 18.14 33.20 12.47\nHunAlize 34 3.15 22.39 1.69\nYOLO 35 0.74 18.32 0.38\nBaseline 36 0.32 13.04 0.16\nTable 8: Subtask 1: Span Identi\ufb01cation (SI) performance on the test set using the \ufb01xed scorer. The\nhighest score for each measure is highlighted.1405\nRnk Team Overall 1 2 3 4 5 6 7 8 9 10 11 12 13 14"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "1ApplicaAI 63.74 48.15 47.06 8.33 50.98 22.73 56.23 36.64 70.47 78.27 75.80 58.79 58.97 39.22 28.13\n2 aschern 63.30 35.29 41.78 14.93 53.57 25.97 59.44 37.55 66.35 78.32 76.68 56.94 54.24 42.55 22.64\n3Hitachi 63.13 40.00 38.94 4.88 47.92 36.62 63.43 37.38 69.04 76.69 76.22 42.42 52.63 29.41 26.92\n4 NoPropaganda 59.83 23.26 38.02 0.00 8.70 12.12 56.27 39.43 60.30 77.99 76.61 48.14 51.52 27.91 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "5Solomon 59.39 26.67 39.39 4.88 42.00 19.61 61.82 32.00 61.84 75.30 70.75 42.53 50.75 38.10 0.00\n6 CyberWallE 58.99 14.63 39.84 12.25 26.32 15.39 59.24 33.20 56.22 75.81 71.60 52.98 45.46 23.81 0.00\n7newsSweeper 58.44 41.67 42.80 13.04 25.00 19.72 56.55 37.10 60.53 75.32 74.23 20.69 50.75 21.62 8.00\n8 Inno 57.99 43.14 45.09 10.71 40.40 24.32 58.65 35.39 59.41 73.31 74.30 24.89 43.75 29.63 19.36"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "9djichen 57.71 37.50 34.58 20.83 43.81 22.79 60.00 32.18 56.19 73.99 70.43 36.36 30.77 27.91 18.87\n10 PALI 57.43 27.59 36.59 28.57 39.62 30.59 58.97 28.57 61.62 74.29 69.43 25.44 39.22 40.82 20.90\n11 DUTH 57.21 44.44 33.33 9.30 33.33 26.23 59.16 28.24 58.95 73.71 71.41 20.10 34.78 27.03 17.78\n12 DiSaster 56.65 51.16 35.25 20.41 26.67 14.63 59.12 30.64 58.25 74.49 68.10 20.44 42.55 19.05 4.35"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "13 SocCogCom 55.81 28.57 31.62 9.76 26.51 6.35 60.40 34.86 54.26 72.18 67.34 18.88 40.91 23.53 10.00\n14 TTUI 55.64 28.24 41.48 24.56 35.29 23.08 57.40 32.20 61.68 73.22 68.49 21.18 37.50 25.00 20.29\n15 JUST 55.36 48.89 37.10 24.49 31.11 27.27 58.26 29.57 62.56 71.96 64.73 21.94 33.33 31.82 28.57\n16 NLFIIT 55.25 29.63 24.89 9.30 32.10 0.00 55.66 30.30 63.32 72.55 69.30 21.55 41.67 13.64 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "17 UMSIForeseer 55.14 29.41 31.97 9.76 0.00 0.00 57.21 28.57 56.14 73.02 70.79 21.49 39.22 14.29 0.00\n18 BPGC 54.81 30.77 33.65 12.50 40.00 24.18 53.78 33.47 58.93 71.58 67.51 23.74 40.00 20.69 20.90\n19 UPB 54.30 20.00 30.00 0.00 19.72 16.95 52.55 30.62 55.87 70.09 68.86 20.00 34.62 22.86 4.88\n20 syrapropa 54.25 31.58 29.77 19.61 30.61 21.51 56.14 28.10 57.02 71.47 68.44 30.77 29.03 28.57 9.09"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "21 WMD 52.35 7.14 29.20 5.00 0.00 5.71 54.42 26.36 52.08 69.76 64.67 14.82 6.90 7.41 0.00\n22 YNUHPCC 50.50 29.79 26.40 13.79 38.38 3.45 51.04 21.54 55.56 68.08 62.33 17.72 27.59 17.78 15.00\n23 UESTCICSA 49.94 12.77 22.75 0.00 11.27 3.74 44.99 25.44 53.14 68.23 66.88 27.96 41.38 28.57 3.70\n24 DoNotDistribute 49.72 22.64 29.75 4.55 24.49 14.89 46.25 27.23 53.76 68.44 60.65 19.44 28.07 12.25 9.68"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "25 NTUAAILS 46.37 36.36 28.31 9.76 0.00 0.00 48.75 29.66 46.47 65.79 54.55 18.43 13.79 11.43 4.08\n26 UAIC1860 41.17 17.39 22.12 9.76 2.90 7.60 36.41 21.01 38.78 62.33 42.97 11.16 11.43 5.56 4.26\n27 UNTLing 39.11 4.35 5.29 0.00 0.00 2.86 32.65 11.82 40.48 62.57 36.74 7.78 17.65 0.00 0.00\n28 HunAlize 37.10 6.45 11.83 0.00 8.00 7.84 31.76 23.81 29.95 58.59 15.82 2.09 4.55 0.00 0.00"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "29 Transformers 26.54 0.00 0.00 0.00 0.00 0.00 0.98 0.00 0.00 47.55 24.06 2.86 0.00 0.00 0.00\n30 Baseline 25.20 0.00 3.68 0.00 0.00 11.56 29.14 14.42 6.20 46.48 0.00 19.26 0.00 0.00 0.00\n31 IJSE8 20.62 0.00 7.07 0.00 0.00 2.27 17.07 10.70 8.57 39.32 15.39 4.92 0.00 0.00 0.00\n32 Entropy 20.50 3.92 7.12 0.00 2.27 7.41 12.81 6.39 4.95 38.02 15.14 5.83 0.00 0.00 6.78"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Table 9: Technique classi\ufb01cation F 1performance on the test set using the \ufb01xed scorer . The systems are ordered based on the \ufb01nal ranking. Columns 1to14\nshow the performance for each of the fourteen propaganda techniques (cf. Section 2). The best score for each technique is shown in bold.1406C Annotation Instructions"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Below, we show a series of snapshots of the actual annotation instructions and propaganda techniques\nde\ufb01nitions and examples that we showed to the human annotators. These are also available online:\n\u000fhttp://propaganda.qcri.org/annotations/\n\u000fhttps://propaganda.qcri.org/annotations/definitions.html\nFigure 7: Instruction for the annotators.1407"}, {"source": "Detection of Propaganda Techniques in News Articles.pdf", "text": "Figure 8: Annotation instructions: hierarchical diagram to guide the choice of technique.1408\n1409\n1410\n1411\n1412\n1413\n1414"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Proceedings of Recent Advances in Natural Language Processing , pages 1597\u20131605\nSep 1\u20133, 2021.\nhttps://doi.org/10.26615/978-954-452-072-4_1791597Interpretable Propaganda Detection in News Articles\nSeunghak Yu1\u0003Giovanni Da San Martino2\nMitra Mohtarami3James Glass3Preslav Nakov4\n1Amazon Alexa AI, Seattle, WA, USA\n2Department of Mathematics, University of Padova, Italy"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "3MIT Computer Science and Arti\ufb01cial Intelligence Laboratory, Cambridge, MA, USA\n4Qatar Computing Research Institute, HBKU, Qatar\nyuseungh@amazon.com, dasan@math.unipd.it\nfmitra, glassg@csail.mit.edu, pnakov@hbku.edu.qa\nAbstract\nOnline users today are exposed to mislead-\ning and propagandistic news articles and me-\ndia posts on a daily basis. To counter thus,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "a number of approaches have been designed\naiming to achieve a healthier and safer online\nnews and media consumption. Automatic sys-\ntems are able to support humans in detecting\nsuch content; yet, a major impediment to their\nbroad adoption is that besides being accurate,\nthe decisions of such systems need also to be\ninterpretable in order to be trusted and widely"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "adopted by users. Since misleading and pro-\npagandistic content in\ufb02uences readers through\nthe use of a number of deception techniques,\nwe propose to detect and to show the use of\nsuch techniques as a way to offer interpretabil-\nity. In particular, we de\ufb01ne qualitatively de-\nscriptive features and we analyze their suitabil-\nity for detecting deception techniques. We fur-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "ther show that our interpretable features can\nbe easily combined with pre-trained language\nmodels, yielding state-of-the-art results.\n1 Introduction\nWith the rise of the Internet and social media, there\nwas also a rise of fake (Nguyen et al., 2020), biased\n(Baly et al., 2020a,b), hyperpartisan (Potthast et al.,\n2018), and propagandistic content (Da San Martino"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "et al., 2019b). In 2016, news got weaponized, aim-\ning to in\ufb02uence the US Presidential election and\nthe Brexit referendum, making the general public\nconcerned about the dangers of the proliferation of\nfake news (Howard and Kollanyi, 2016; Faris et al.,\n2017; Lazer et al., 2018; V osoughi et al., 2018;\nBovet and Makse, 2019).\nThere ware two reasons for this. First, disinfor-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "mation disguised as news created the illusion that\nthe information is reliable, and thus people tended\nto lower their barrier of doubt compared to when\ninformation came from other types of sources.\n\u0003Work conducted while the author was at MIT CSAIL.\nFigure 1: Comparison of propaganda prediction in-\nterpretability using existing methods. Our proposed"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "method helps users to interpret propaganda predictions\nacross various dimensions, e.g., is there a lot of pos-\nitive/negative sentiment (can signal the use of loaded\nlanguage , which appeals to emotions), are the target\nsentence and the document body related to the title,\ndoes the sentence agree/disagree with the title, etc.\nEach symbol in the top bar chart represents an infor-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "mation source for propaganda detection.\nSecond, the rise of citizen journalism led to the\nproliferation of various online media, and the ve-\nracity of information became an issue. In practice,\nthe effort required to fact-check the news, and its\nbias and propaganda remained the same or even\ngot more complex, compared to traditional media,\nsince the news was re-edited and passed through"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "other media channels.\nPropaganda aims to in\ufb02uence the audi-\nence with the aim of advancing a speci\ufb01c\nagenda (Da San Martino et al., 2020b). Detecting\nit is tricky and arguably more dif\ufb01cult than \ufb01nding\nfalse information in an article. This is because\npropagandistic articles are not intended to simply\nmake up a story with objective errors, but instead"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "use a variety of techniques to convince people,\nsuch as selectively conveying facts or appealing to\nemotions (Jowett and O\u2019Donnell, 2012).1598While many techniques are ethically question-\nable, we can think of propaganda techniques as\nrhetorical expressions that effectively convey the\nauthor\u2019s opinion (O\u2019Shaughnessy, 2004). Due to\nthese characteristics, propagandistic articles are of-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "ten produced primarily for political purposes (but\nare also very common in commercial advertise-\nment), which directly affect our lives, and are com-\nmonly found even in major news media outlets,\nwhich are generally considered credible.\nThe importance of detecting propaganda in\nthe news has been recently emphasized, and re-\nsearch is being conducted from various perspec-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "tives (Rashkin et al., 2017; Barr \u00b4on-Cedeno et al.,\n2019a; Da San Martino et al., 2019b). However,\nwhile previous work has done reasonable job at de-\ntecting propaganda, it has largely ignored the ques-\ntion of why the content is propagandistic, i.e., there\nis a lack of interpretability of the system decisions,\nand in many cases, there is a lack of interpretability"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "of the model as well, i.e., it is hard to understand\nwhat the model actually does even for its creators.\nInterpretability is indispensable if propaganda\ndetection systems are to be trusted and accepted\nby the users. According to the con\ufb01rmation bias\ntheory (Nickerson, 1998), people easily accept new\ninformation that is consistent with their beliefs, but"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "are less likely to do so when it contradicts what they\nalready know. Thus, even if a model can correctly\npredict which news is propagandistic, if it fails to\nexplain the reason for that, people are more likely\nto reject the results and to stick to what they want to\nbelieve. In order to address this issue, we propose\na new formulation of the propaganda detection task"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "and a model that can explain the prediction results.\nFigure 1 compares the coverage of the explanations\nfor pre-existing methods vs. our proposal.\nOur contributions can be summarized as follows:\n\u2022We study how a number of information\nsources relate to the presence and the absence\nof propaganda in a piece of text.\n\u2022Based on this, we propose a general frame-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "work for interpretable propaganda detection.\n\u2022We demonstrate that our framework is comple-\nmentary to and can be combined with large-\nscale pre-trained transformers, yielding siz-\nable improvements over the state of the art.2 Task Setup\nGiven a document dthat consists of nsentences\nd=fdign\ni=1, each sentence should be classi\ufb01ed as\nbelonging to one of 18 propaganda techniques or"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "as being non-propaganda. The exact de\ufb01nition of\npropaganda can be subtly different depending on\nthe social environment and the individual\u2019s growth\nbackground, and thus it is not surprising that the\npropaganda techniques de\ufb01ned in the literature dif-\nfer (Miller, 1939; Jowett and O\u2019Donnell, 2012;\nHobbs and McGee, 2014; Torok, 2015; Weston,\n2018). The techniques we use in this paper are"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "shown in Table 1. Da San Martino et al. (2019b)\nderived the propaganda techniques from the liter-\nature: they selected 18 techniques and manually\nannotated 451 news articles with a total of 20,110\nsentences. This dataset1has fragment-level labels\nthat can span over multiple sentences and can over-\nlap with other labeled spans.\nThis granular labeling went beyond our scope"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "and we had to restructure the data. First, we di-\nvided the data into sentences. Second, in order to\nreduce the complexity of the task, we changed the\nmulti-label setup to a multi-class one by ignoring\nduplicate labels and only allowing one technique\nper sentence (the \ufb01rst one), breaking ties at ran-\ndom. As a result, we obtained 20,111 sentences\nlabeled with a non-propaganda class or with one of"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "18 propaganda techniques. Based on this data, we\nbuilt a system for predicting the use of propaganda\ntechniques at the sentence level, and we provided\nthe semantic and the structural information related\nto propaganda techniques as the basis of the results.\n3 Proposed Method\nOur method can detect the propaganda for each\nsentence in a document, and can explain what pro-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "paganda technique was used with interpretable se-\nmantic and syntactic features. We further propose\nnovel features conceived in the study of human\nbehavioral characteristics. More detail below.\n3.1 People Do Not Read Full Articles\nBehavior studies have shown that people read less\nthan 50% of the articles they \ufb01nd online, and often\nstop reading after the \ufb01rst few sentences, or even af-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "ter the title (Manjoo, 2013). Indeed, we found that\n77.5% of our articles use propaganda techniques in\nthe \ufb01rst \ufb01ve sentences, 65% do so in the \ufb01rst three\nsentences, and 31.07% do so in the title.\n1http://propaganda :math :unipd :it/1599Techniques De\ufb01nition\nName Calling give an object an insulting label\nRepetition inject the same message over and over\nSlogans use a brief and memorable phrase"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Appeal to Fear plant fear against other alternatives\nDoubt questioning the credibility\nExaggeration exaggerate or minimize something\nFlag-Waving appeal to patriotism\nLL appeal to emotions or stereotypes\nRtoH the disgusted group likes the idea\nBandwagon appeal to popularity\nCO assume a simple cause for the outcome\nOIC use obscure expressions to confuse\nAA use authority\u2019s support as evidence"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "AA use authority\u2019s support as evidence\nB&W Fallacy present only two options among many\nTC discourage meaningful discussion\nRed Herring introduce irrelevant material to distract\nStraw Men refute a nonexistent argument\nWhataboutism discredit an opponent\u2019s position\nTable 1: List of propaganda techniques and brief def-\ninitions. LL: Loaded Language, RtoH: Reduction to"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Hitlerum, CO: Casual Oversimpli\ufb01cation, OIC: Obfus-\ncation, Intentional vagueness, Confusion, AA: Appeal\nto Authority, TC: Thought-terminating Clich \u00b4es.\nWe used three types of features ( frp,fsim,fstn)\nto account for these observations, which we de-\nscribe below.\n3.1.1 Relative Position of the Sentence\nWe de\ufb01ne the relative position of a sentence as\nfrp"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "frp\ni=i=n, where iis the sequence number of the\nsentence, and nis the total number of sentences in\nthe article.\n3.1.2 Topic Similarity and Stance with\nRespect to the Title\nThe title of an article typically contains the topic\nand also the author\u2019s view of that topic. Thus, we\nhypothesize that propaganda should also focus on\nthe topic expressed in the title."}, {"source": "Propaganda Detection in News Articles.pdf", "text": "the topic expressed in the title.\nWe represent the relationship between the tar-\nget sentence and the title by measuring the se-\nmantic similarity fsim\nibetween them as the co-\nsine between the sentence-BERT representations\n(\u001e(x)) (Reimers and Gurevych, 2019) of the target\nsentence diand of the title d1.\nfsim\ni=\u001e(d1)\u0001\u001e(di)\nj\u001e(d1)jj\u001e(di)j(1)\nWe further model the stance of a target sentence"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "with respect to the title fstn\niusing a distribution\nover \ufb01ve classes: related ,unrelated ,agree ,dis-\nagree , and discuss . For this, we use a BERT model\n(Fang et al., 2019) \ufb01ne-tuned on the Fake News\nChallenge dataset (Hanselowski et al., 2018).Level Phrases\nClause S, SBAR, SBARQ, SINV , SQ\nPhrase ADJP, ADVP, CONJP, FRAG, INTJ,\nLST, NAC, NP, NX, PP, PRN, PRT,\nQP, RRC, UCP, VP, WHADJP,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "QP, RRC, UCP, VP, WHADJP,\nWHA VP, WHADVP, WHNP, WHPP, X\nTable 2: The syntactic labels we used as features.\nThe class unrelated indicates that the sentence is\nnot related to the claim made in the title, while\nagree anddisagree refer to the sentence agree-\ning/disagreeing with the title, and \ufb01nally discuss is\nassigned when the topic is the same as that in the"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "title, but there is no stance. We further introduce\ntherelated class as the union of agree ,disagree ,\nanddiscuss . We use as features the binary classi-\n\ufb01cation labels and also the probabilities for these\n\ufb01ve classes.\n3.2 Syntactic and Semantic Information\nSome propaganda techniques have speci\ufb01c struc-\ntural or semantic characteristics. For example,\nLoaded Language can be con\ufb01gured to elicit an"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "emotional response, usually using an emotional\nnoun phrase. To model this, we de\ufb01ne the follow-\ning three features: fdp,fsent, andfdoc.\n3.2.1 Syntactic Information\nWe used a syntactic parser to extract structural fea-\ntures about the target sentence fdp\ni. Our hypothesis\nis that such information could help to discover tech-\nniques that have speci\ufb01c structural characteristics"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "such as Doubt andBlack and White Fallacy . We\nconsidered a total of 27 clause-level classes and\nphrase-level labels, including the unknown class.\nThe set is shown in Table 2.\n3.2.2 Sentiment of the Sentence\nThe sentiment of the sentence fsent\ni is another im-\nportant feature for detecting propaganda. This is\nbecause many propagandistic articles try to con-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "vince the readers by appealing to their emotions\nand prejudices. Thus, we extract the sentiment us-\ning a sentiment analyzer trained on social media\ndata (Hutto and Gilbert, 2014), which gives a prob-\nability distribution over the following three classes:\npositive ,neutral , and negative . It further outputs\ncompound , which is a one-dimensional normalized,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "weighted composite score. We use all four scores\nas features.16003.2.3 Document-Level Prediction\nIf the document is likely to be propagandistic, then\neach of its sentences is more likely to contain propa-\nganda. To model this, we use as a feature fdocthe\nscore of the document-level propaganda classi\ufb01er\nProppy (Barr \u00b4on-Cedeno et al., 2019a). Note that"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Proppy is trained on articles labeled using media-\nlevel labels, i.e., using distant supervision. There-\nfore, all articles from a propagandistic source are\nconsidered to be propagandistic.\n4 Experimental Results\nIn this section, we present our experimental setup\nfor interpretable propaganda detection and the eval-\nuation results from our experiments. Speci\ufb01cally,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "we perform three sets of experiments: ( i) in Sec-\ntion 4.1, we quantitatively analyze the effectiveness\nof the features we proposed in Section 3; ( ii) in Sec-\ntions 4.2 and 4.3, we compare our feature-based\nmodel to the state-of-the-art model described in\n(Da San Martino et al., 2019b) using the experi-\nmental setup from that paper; ( iii) in Section 4.4,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "we analyze the performance of our model with re-\nspect to each of the 18 propaganda techniques.\n4.1 Quantitative Analysis of the Proposed\nFeatures\nFigure 2 shows the absolute value of the covari-\nance between each of our features fand each\nof the 18 propaganda techniques T. We calcu-\nlated the values of the features on the training and\non the development datasets, and we standardized"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "their values. Then, we formulated this as a prob-\nlem of calculating the covariance between contin-\nuous and Bernoulli random variables as follows:\ncov(f;T) =p\u0001(1\u0000p)\u0001(E[fjT= 1]\u0000E[fjT=\n0]).\nThe total number of sentences used is 16,137\n(for the training and for the development datasets,\ncombined), among which there are 4,584 propa-\ngandistic sentences. In Figure 2, the vertical axis"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "represents the proposed features, and the horizontal\naxis shows the individual propaganda techniques\nand the total number of instances thereof. Each\nsquare shows an absolute value of the covariance\nbetween some feature and some propaganda tech-\nnique. We show absolute values in order to ignore\nthe direction of the relationship, and we apply a\nthreshold of 0.001 in order to remove the negligible"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "relations from the \ufb01gure.Although the most frequent propaganda tech-\nniques appear in less than 10% of the examples,\nthey do show qualitatively meaningful associations.\nIndeed, we do not expect a feature to correlate with\nmultiple techniques, as they are fundamentally dif-\nferent. We believe that having features that strongly\ncorrelate with one technique might be an advance-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "ment towards detecting that technique.\nWe can see that the structural information ( fdp)\nand the sentiment of a sentence ( fsent) are closely\nassociated with certain propaganda techniques. For\nexample, Loaded Language has a strong correlation\nwith features identifying words bearing either a pos-\nitive or a negative sentiment. This makes sense as\nthe authors are more likely to use emotional words"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "rather than neutral ones, and Loaded Language\naims to elicit an emotional response. Similarly,\nDoubt has high correlation with certain syntactic\ncategories.\nThere are a number of interesting observations\nabout the other features. For example, the relative\nposition of sentences ( frp) is associated with more\nthan half of the propaganda techniques. Moreover,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "the similarity to the title ( fsim) and the stance with\nrespect to the title ( fstn) are strongly correlated\nwith the likelihood that the target sentence is pro-\npagandistic. The features that indicate whether a\nsentence is related to the subject of the title are\ncomplementary, and thus the covariances are the\nsame when absolute values are considered.\n4.2 Comparison to Existing Approaches"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "4.2 Comparison to Existing Approaches\nTable 3 shows a performance comparison for our\nmodel vs. existing models on the sentence-level\npropaganda detection dataset (Da San Martino\net al., 2019b). This dataset consists of 451 manu-\nally annotated articles, collected from various me-\ndia sources, and a total of 20,111 sentences. Unlike\nthe experimental setting in the previous sections,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "the task here is a binary classi\ufb01cation one: given a\nsentence, the goal is to predict whether it contains\nat least one of the 18 techniques or not. For the\nperformance comparison, we used BERT (Devlin\net al., 2019), which we \ufb01ne-tuned for sentence-level\nclassi\ufb01cation using the Multi-Granularity Network\n(MGN) (Da San Martino et al., 2019b) architecture"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "on top of the [CLS] tokens (trained end-to-end),\nas this model improves the performance for both\ntasks by controlling the word-level prediction using\ninformation from the sentence-level prediction and\nvice versa.1601\nFigure 2: Covariance matrix between the 18 propaganda techniques and the proposed features.1602Model P R F1\n\ufb01ne-tuned BERT163.20 53.16 57.74\nMGN160.41 61.58 60.98"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "MGN160.41 61.58 60.98\nProposed 40.97 73.27 52.55\nProposed w/ emb 49.41 80.87 61.34\nProposed w/ emb - fstn49.59 81.44 61.64\nTable 3: Comparison of our method to pre-existing\npropaganda detection models at the sentence level\nfor binary classi\ufb01cation ( propaganda vs. non-\npropaganda ). The models \ufb02agged with1are described\nin (Da San Martino et al., 2019b).\nAblations Precision Recall F1"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Ablations Precision Recall F1\nAll 40.97 73.27 52.55\n-frp40.87 73.17 52.45\n-fsim40.85 70.87 51.83\n-fstn40.07 69.62 50.86\n-fdp37.85 61.54 46.87\n-fsent30.53 77.69 43.83\nTable 4: Ablation study for our model on binary propa-\nganda detection at the sentence level.\nWe followed the original data split when training\nand testing the model, which is 14,137/2,006/3,967"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "for training/development/testing. We trained a\nSupport Vector Machine (SVM) model2using the\nabove-mentioned features and we optimized the\nvalues of the hyper-parameters on the development\ndataset using grid search. We used an RBF kernel\nwith gamma=f1e-3, 1e-4gand C=f10,100g.\nWe can see in Table 3 that our proposed model,\nwhich is based on interpretable features, performs"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "relatively well when compared to \ufb01ne-tuned BERT\nwithout direct semantic information about the tar-\nget sentence. While our model is not state-of-the-\nart by itself, we managed to outperform the existing\nmodels and to improve over the state of the art by\nsimply adding to it sentence embeddings as fea-\ntures (Reimers and Gurevych, 2019), which were\nnot \ufb01ne-tuned on propaganda data. However, when"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "the stance of the sentence and the embedding of the\nsentence are used together, performance decreases.\nThis may be due to the two techniques based on\nsemantic similarity being somewhat inconsistent.4.3 Ablation Study\nNext, we performed an ablation study of the binary\n(propaganda vs. non-propaganda) model discussed\nin Section 4.2. The results are presented in Table 4."}, {"source": "Propaganda Detection in News Articles.pdf", "text": "The values in the last row of the table, i.e., - fsent,\nare obtained by applying the document-level clas-\nsi\ufb01er, i.e., the feature fdoc, to all sentences. We\ncan see that the structural information about the\nsentence (fdp) is the best feature for this task. This\nis due to the nature of some propaganda techniques\nthat must have a speci\ufb01c sentence structure, such"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "asDoubt . In addition, as described above, since\nthere are many techniques related to inducing emo-\ntional responses in the readers, it can be understood\nthat the sentiment of a sentence may be a good fea-\nture, e.g., for Loaded Language . These results are\nconsistent with our \ufb01ndings in Section 4.1 above.\nMoreover, the novel features we devised based on"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "a human behavioral study for propaganda detec-\ntion (frp,fsim,fstn) improved the performance\nfurther. Overall, we can see in the table that all fea-\ntures contributed to the performance improvement.\n4.4 Detecting the 18 Propaganda Techniques\nFor the experiments described in the following, we\nrevert back to the task formulation in Section 2, but\nwe perform a more detailed analysis of the outcome"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "of the model: for a given article, the system must\npredict whether each sentence uses propaganda\ntechniques, and if so, which of the 18 techniques\nin Table 1 it uses.\nTable 5 shows the performance of our model\non this task. We can see in the rightmost column\nthat some techniques appear only in a very limited\nnumber of examples, which explains the very low"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "results for them, e.g., for Red Herring andStraw\nMan. In an attempt to counterbalance the lack of\ngold labels for some of the techniques, we used\nsentence embeddings with the proposed features to\ncapture more semantic information. Since this task\nis more challenging than the binary classi\ufb01cation\nproblem, we can intuitively expect a performance\nreduction, resulting in a weighted average F1 score"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "of 42.88. However, this formulation of the problem\nhas the advantage of providing more granular pre-\ndictions, thus enriching the propaganda detection\nresults.\n2Ran on Intel Xeon E5-1620 CPU @ 3.60GHz x 4; 16GiB\nDDR3 RAM @ 1600MHz.1603Techniques P R F1 #\nNon-propaganda 94.37 36.62 52.77 2,927\nName Calling 14.16 21.92 17.20 146\nRepetition 4.60 5.59 5.05 143\nSlogans 3.75 20.69 6.35 29"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Slogans 3.75 20.69 6.35 29\nAppeal to F. 12.99 38.37 19.41 86\nDoubt 5.97 34.85 10.20 66\nExaggeration 6.06 20.90 9.40 67\nFlag-Waving 10.98 44.62 17.63 65\nLoaded L. 32.80 20.13 24.95 303\nReduction 8.00 22.22 11.76 9\nBandwagon 0.00 0.00 0.00 3\nCasual O. 4.03 27.27 7.02 22\nO, I, C 0.00 0.00 0.00 5\nAppeal to A. 1.32 13.04 2.39 23\nB&W fallacy 0.89 4.55 1.49 22\nT. clich \u00b4es 3.67 44.44 6.78 18"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "T. clich \u00b4es 3.67 44.44 6.78 18\nRed Herring 0.00 0.00 0.00 11\nStraw Men 0.00 0.00 0.00 1\nWhataboutism 2.54 14.29 4.32 21\nweighted avg 73.59 32.80 42.88 3,967\nTable 5: Performance of our proposed method for the\ntask of detecting the 18 propaganda techniques, as eval-\nuated at the sentence level.\n5 Related Work\nResearch on propaganda detection has focused on"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "analyzing textual content (Barr \u00b4on-Cedeno et al.,\n2019b; Rashkin et al., 2017; Da San Martino\net al., 2019b,a; Yu et al., 2019; Da San Martino\net al., 2020b). Rashkin et al. (2017) developed the\nTSHP-17 corpus, which uses document-level an-\nnotation with four classes: trusted ,satire ,hoax ,\nandpropaganda . They trained a model using word\nn-gram representation and reported that the model"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "performed well only on articles from sources that\nthe system was trained on. Barr \u00b4on-Cedeno et al.\n(2019b) developed the QProp corpus with two la-\nbels: propaganda vs.non-propaganda . They also\nexperimented on TSHP-17 andQProp corpora,\nwhere for the TSHP-17 corpus, they binarized\nthe labels: propaganda vs. any of the other three\ncategories. Similarly, Habernal et al. (2017, 2018)"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "developed a corpus with 1.3k arguments annotated\nwith \ufb01ve fallacies, including ad hominem ,red her-\nring, and irrelevant authority , which directly relate\nto propaganda techniques. Moreover, Saleh et al.\n(2019) studied the connection between hyperparti-\nsanship and propaganda.A more \ufb01ne-grained propaganda analysis was\nproposed by Da San Martino et al. (2019b), who"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "developed a corpus of news articles annotated with\n18 propaganda techniques which was used in two\nshared tasks: at SemEval-2020 (Da San Martino\net al., 2020a) and at NLP4IF-2020 (Da San Mar-\ntino et al., 2019a). Subsequently, the Prta system\nwas released (Da San Martino et al., 2020c), and\nimproved models were proposed, addressing the\nlimitations of transformers (Chernyavskiy et al.,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "2021). The Prta system was used to perform a\nstudy of COVID-19 disinformation and associated\npropaganda techniques in Bulgaria (Nakov et al.,\n2021a) and Qatar (Nakov et al., 2021b). Finally,\nmultimodal content was explored in memes using\n22 \ufb01ne-grained propaganda techniques (Dimitrov\net al., 2021a), which was also used in a SemEval-\n2021 shared task (Dimitrov et al., 2021b)."}, {"source": "Propaganda Detection in News Articles.pdf", "text": "6 Conclusion and Future Work\nWe proposed a model for interpretable propaganda\ndetection, which can explain which sentence in an\ninput news article is propagandistic by pointing\nout the propaganda techniques used, and why the\nmodel has predicted it to be propagandistic. To\nthis end, we devised novel features motivated by\nhuman behavior studies, quantitatively deduced the"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "relationship between semantic or syntactic features\nand propaganda techniques, and selected the fea-\ntures that were important for detecting propaganda\ntechniques. Finally, we showed that our proposed\nmethod can be combined with a pre-trained lan-\nguage model to yield new state-of-the-art results.\nIn future work, we plan to expand the dataset\nby creating a platform to guide annotators. The"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "dataset will be updated continuously and released\nfor research purposes.3We also plan to release an\ninterpretable online system, with the aim to foster\na healthier and safer online news environment.\nAcknowledgements\nThis research is part of the Tanbih mega-project,4\nwhich aims to limit the impact of \u201cfake news\u201d, pro-\npaganda, and media bias by making users aware"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "of what they are reading, thus promoting media\nliteracy and critical thinking. It is developed in col-\nlaboration between the Qatar Computing Research\nInstitute, HBKU and the MIT Computer Science\nand Arti\ufb01cial Intelligence Laboratory.\n3http://propaganda :qcri :org/\n4http://tanbih :qcri :org/1604References\nRamy Baly, Giovanni Da San Martino, James Glass,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "and Preslav Nakov. 2020a. We can detect your\nbias: Predicting the political ideology of news ar-\nticles. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing ,\nEMNLP \u201920, pages 4982\u20134991.\nRamy Baly, Georgi Karadzhov, Jisun An, Haewoon\nKwak, Yoan Dinkov, Ahmed Ali, James Glass, and\nPreslav Nakov. 2020b. What was written vs. who"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "read it: News media pro\ufb01ling using text analysis and\nsocial media context. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics , ACL \u201920, pages 3364\u20133374.\nAlberto Barr \u00b4on-Cedeno, Giovanni Da San Martino, Is-\nraa Jaradat, and Preslav Nakov. 2019a. Proppy: A\nsystem to unmask propaganda in online news. In\nProceedings of the AAAI Conference on Arti\ufb01cial In-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "telligence , AAAI \u201919, pages 9847\u20139848.\nAlberto Barr \u00b4on-Cedeno, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019b. Proppy:\nOrganizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nAlexandre Bovet and Hern \u00b4an A Makse. 2019. In-\n\ufb02uence of fake news in Twitter during the 2016\nUS presidential election. Nature communications ,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "10(1):7.\nAnton Chernyavskiy, Dmitry Ilvovsky, and Preslav\nNakov. 2021. Transformers: \u201cThe end of history\u201d\nfor NLP? In Proceedings of the European Confer-\nence on Machine Learning and Principles and Prac-\ntice of Knowledge Discovery in Databases , ECML-\nPKDD\u201921.\nGiovanni Da San Martino, Alberto Barr \u00b4on-Cede \u02dcno,\nHenning Wachsmuth, Rostislav Petrov, and Preslav"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Nakov. 2020a. SemEval-2020 task 11: Detection\nof propaganda techniques in news articles. In Pro-\nceedings of the International Workshop on Semantic\nEvaluation , SemEval \u201920, Barcelona, Spain.\nGiovanni Da San Martino, Alberto Barron-Cedeno, and\nPreslav Nakov. 2019a. Findings of the NLP4IF-\n2019 shared task on \ufb01ne-grained propaganda detec-\ntion. In Proceedings of the 2nd Workshop on NLP"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "for Internet Freedom (NLP4IF): Censorship, Dis-\ninformation, and Propaganda , NLP4IF \u201919, pages\n162\u2013170, Hong Kong, China.\nGiovanni Da San Martino, Stefano Cresci, Alberto\nBarr\u00b4on-Cede \u02dcno, Seunghak Yu, Roberto Di Pietro,\nand Preslav Nakov. 2020b. A survey on compu-\ntational propaganda detection. In Proceedings of\nthe 29th International Joint Conference on Arti\ufb01-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "cial Intelligence and the 17th Paci\ufb01c Rim Interna-\ntional Conference on Arti\ufb01cial Intelligence , IJCAI-\nPRICAI \u201920, pages 4826\u20134832, Yokohama, Japan.Giovanni Da San Martino, Shaden Shaar, Yifan Zhang,\nSeunghak Yu, Alberto Barr \u00b4on-Cedeno, and Preslav\nNakov. 2020c. Prta: A system to support the anal-\nysis of propaganda techniques in the news. In Pro-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "ceedings of the Annual Meeting of Association for\nComputational Linguistics , ACL \u201920, pages 287\u2013\n293.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarr\u00b4on-Cede \u02dcno, Rostislav Petrov, and Preslav\nNakov. 2019b. Fine-grained analysis of propaganda\nin news articles. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "ence on Natural Language Processing , EMNLP-\nIJCNLP \u201919, pages 5636\u20135646, Hong Kong, China.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "nologies , NAACL-HLT \u201919, pages 4171\u20134186, Min-\nneapolis, Minnesota, USA.\nDimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021a. De-\ntecting propaganda techniques in memes. In Pro-\nceedings of the Joint Conference of the 59th Annual\nMeeting of the Association for Computational Lin-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "guistics and the 11th International Joint Conference\non Natural Language Processing , ACL-IJCNLP \u201921,\npages 6603\u20136617.\nDimiter Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021b. Task\n6 at SemEval-2021: Detection of persuasion tech-\nniques in texts and images. In Proceedings of the"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "15th International Workshop on Semantic Evalua-\ntion, SemEval \u201921, pages 70\u201398.\nWei Fang, Moin Nadeem, Mitra Mohtarami, and James\nGlass. 2019. Neural multi-task learning for stance\nprediction. In Proceedings of the Second Workshop\non Fact Extraction and VERi\ufb01cation , FEVER \u201919,\npages 13\u201319, Hong Kong, China.\nRobert Faris, Hal Roberts, Bruce Etling, Nikki"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Bourassa, Ethan Zuckerman, and Yochai Benkler.\n2017. Partisanship, propaganda, and disinformation:\nOnline media and the 2016 US presidential election.\nBerkman Klein Center Research Publication , 6.\nIvan Habernal, Raffael Hannemann, Christian Pol-\nlak, Christopher Klamm, Patrick Pauli, and Iryna\nGurevych. 2017. Argotario: Computational argu-\nmentation meets serious games. In Proceedings of"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "the 2017 Conference on Empirical Methods in Nat-\nural Language Processing: System Demonstrations ,\nEMNLP \u201917, pages 7\u201312, Copenhagen, Denmark.1605Ivan Habernal, Patrick Pauli, and Iryna Gurevych.\n2018. Adapting serious game for fallacious argu-\nmentation to German: Pitfalls, insights, and best\npractices. In Proceedings of the 11th International\nConference on Language Resources and Evaluation ,"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "LREC \u201918, pages 3329\u20133335, Miyazaki, Japan.\nAndreas Hanselowski, Avinesh PVS, Benjamin\nSchiller, Felix Caspelherr, Debanjan Chaudhuri,\nChristian M. Meyer, and Iryna Gurevych. 2018. A\nretrospective analysis of the fake news challenge\nstance-detection task. In Proceedings of the 27th\nInternational Conference on Computational Lin-\nguistics , COLING \u201918, pages 1859\u20131874, Santa Fe,\nNew Mexico, USA."}, {"source": "Propaganda Detection in News Articles.pdf", "text": "New Mexico, USA.\nRenee Hobbs and Sandra McGee. 2014. Teaching\nabout propaganda: An examination of the historical\nroots of media literacy. Journal of Media Literacy\nEducation , 6(2):5.\nPhilip N Howard and Bence Kollanyi. 2016. Bots,\n#StrongerIn, and #Brexit: Computational propa-\nganda during the UK-EU referendum. Available at\nSSRN 2798311 .\nClayton Hutto and Eric Gilbert. 2014. V ADER: A par-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "simonious rule-based model for sentiment analysis\nof social media text. Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media ,\n8(1):216\u2013225.\nGarth S Jowett and Victoria O\u2019Donnell. 2012. What is\npropaganda, and how does it differ from persuasion.\nPropaganda & Persuasion , pages 1\u201348.\nDavid M.J. Lazer, Matthew A. Baum, Yochai Ben-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "kler, Adam J. Berinsky, Kelly M. Greenhill, Filippo\nMenczer, Miriam J. Metzger, Brendan Nyhan, Gor-\ndon Pennycook, David Rothschild, Michael Schud-\nson, Steven A. Sloman, Cass R. Sunstein, Emily A.\nThorson, Duncan J. Watts, and Jonathan L. Zit-\ntrain. 2018. The science of fake news. Science ,\n359(6380):1094\u20131096.\nFarhad Manjoo. 2013. You won\u2019t \ufb01nish this article:"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Why people online don\u2019t read to the end.\nClyde R Miller. 1939. The techniques of propaganda.\nFrom \u201chow to detect and analyze propaganda,\u201d an\naddress given at town hall. The Center for learning .\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni\nDa San Martino, and Yifan Zhang. 2021a. COVID-\n19 in Bulgarian social media: Factuality, harmful-\nness, propaganda, and framing. In Proceedings of"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "the International Conference on Recent Advances in\nNatural Language Processing , RANLP \u201921.\nPreslav Nakov, Firoj Alam, Shaden Shaar, Giovanni\nDa San Martino, and Yifan Zhang. 2021b. A second\npandemic? Analysis of fake news about COVID-\n19 vaccines in Qatar. In Proceedings of the Inter-\nnational Conference on Recent Advances in Natural"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Language Processing , RANLP \u201921.Van-Hoang Nguyen, Kazunari Sugiyama, Preslav\nNakov, and Min-Yen Kan. 2020. FANG: Leveraging\nsocial context for fake news detection using graph\nrepresentation. In Proceedings of the 29th ACM In-\nternational Conference on Information and Knowl-\nedge Management , CIKM \u201920, pages 1165\u20131174.\nRaymond S Nickerson. 1998. Con\ufb01rmation bias: A"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "ubiquitous phenomenon in many guises. Review of\ngeneral psychology , 2(2):175\u2013220.\nNicholas J O\u2019Shaughnessy. 2004. Politics and propa-\nganda: Weapons of mass seduction . Manchester\nUniversity Press.\nMartin Potthast, Johannes Kiesel, Kevin Reinartz,\nJanek Bevendorff, and Benno Stein. 2018. A stylo-\nmetric inquiry into hyperpartisan and fake news. In"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "Proceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics , ACL \u201918,\npages 231\u2013240, Melbourne, Australia.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and politi-\ncal fact-checking. In Proceedings of the Conference\non Empirical Methods in Natural Language Process-"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "ing, EMNLP \u201917, pages 2931\u20132937, Copenhagen,\nDenmark.\nNils Reimers and Iryna Gurevych. 2019. Sentence-\nBERT: Sentence embeddings using Siamese BERT-\nnetworks. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Nat-\nural Language Processing , EMNLP-IJCNLP \u201919,\npages 3982\u20133992, Hong Kong, China."}, {"source": "Propaganda Detection in News Articles.pdf", "text": "pages 3982\u20133992, Hong Kong, China.\nAbdelrhman Saleh, Ramy Baly, Alberto Barr \u00b4on-\nCede \u02dcno, Giovanni Da San Martino, Mitra Mo-\nhtarami, Preslav Nakov, and James Glass. 2019.\nTeam QCRI-MIT at SemEval-2019 task 4: Propa-\nganda analysis meets hyperpartisan news detection.\nInProceedings of the 13th International Workshop\non Semantic Evaluation , SemEval \u201919, pages 1041\u2013"}, {"source": "Propaganda Detection in News Articles.pdf", "text": "1046, Minneapolis, Minnesota, USA.\nRobyn Torok. 2015. Symbiotic radicalisation strate-\ngies: Propaganda tools and neuro linguistic program-\nming. In Proceedings of the Australian Security and\nIntelligence Conference , pages 58\u201365, Perth, Aus-\ntralia.\nSoroush V osoughi, Deb Roy, and Sinan Aral. 2018.\nThe spread of true and false news online. Science ,\n359(6380):1146\u20131151."}, {"source": "Propaganda Detection in News Articles.pdf", "text": "359(6380):1146\u20131151.\nAnthony Weston. 2018. A rulebook for arguments .\nHackett Publishing.\nSeunghak Yu, Giovanni Da San Martino, and Preslav\nNakov. 2019. Experiments in detecting persua-\nsion techniques in the news. In Proceedings of\nthe NeurIPS 2019 Joint Workshop on AI for Social\nGood , NeurIPS \u201919, Vancouver, Canada."}, {"source": "2023.findings-eacl.35.pdf", "text": "Findings of the Association for Computational Linguistics: EACL 2023 , pages 472\u2013489\nMay 2-6, 2023 \u00a92023 Association for Computational Linguistics\nPaper Bullets: Modeling Propaganda with the Help of Metaphor\nDaniel Baleato Rodr\u00edguez\nILLC, University of Amsterdam\ndaniel@codealia.comVerna Dankers\nILCC, University of Edinburgh\nvernadankers@gmail.com\nPreslav Nakov\nMBZUAI"}, {"source": "2023.findings-eacl.35.pdf", "text": "Preslav Nakov\nMBZUAI\npreslav.nakov@mbzuai.ac.aeEkaterina Shutova\nILLC, University of Amsterdam\ne.shutova@uva.nl\nAbstract\nPropaganda aims to persuade an audience by\nappealing to emotions and using faulty reason-\ning, with the purpose of promoting a particular\npoint of view. Similarly, metaphor modifies the\nsemantic frame, thus eliciting a response that\ncan be used to tune up or down the emotional"}, {"source": "2023.findings-eacl.35.pdf", "text": "volume of the message. Given the close rela-\ntionship between them, we hypothesize that,\nwhen modeling them computationally, it can\nbe beneficial to do so jointly. In particular, we\nperform multi-task learning with propaganda\nidentification as the main task and metaphor de-\ntection as an auxiliary task. To the best of our\nknowledge, this is the first work that models"}, {"source": "2023.findings-eacl.35.pdf", "text": "metaphor and propaganda together. We exper-\niment with two datasets for identifying propa-\nganda techniques in news articles and in memes\nshared on social media. We find that leveraging\nmetaphor improves model performance, partic-\nularly for the two most common propaganda\ntechniques: loaded language and name-calling.\n1 Introduction\nPropaganda aims to influence an audience. It is a"}, {"source": "2023.findings-eacl.35.pdf", "text": "type of information that, whether true or false, tries\nto promote a particular agenda (Cantril, 1938) by\nappealing to emotions or by using faulty reason-\ning (Miller, 1939). Although this communication\nstrategy comes in many forms, it is conveyed us-\ning specific persuasion techniques that exploit our\npsychology to sell us an idea or a point of view"}, {"source": "2023.findings-eacl.35.pdf", "text": "(Da San Martino et al., 2019b). In Figure 1, we can\nsee an example of such techniques used in a meme\nshared on social media.\nAnother rhetorical device at the heart of many\nsuccessful communication strategies is metaphor .\nPostulated as a primordial mechanism to conceptu-\nalize what we think and experience (Lakoff, 1980),\nmetaphor works by mapping a concept in one do-"}, {"source": "2023.findings-eacl.35.pdf", "text": "main (often a physical domain) to another domain\n(usually an abstract one) by means of a systematic\nFigure 1: Meme containing propagandistic techniques\n(Dimitrov et al., 2021). These techniques are high-\nlighted with bounding boxes for illustration purposes.\nassociation. For instance, the term \u201c paper bullets \u201d1\nconnects the domains of information and war, illus-"}, {"source": "2023.findings-eacl.35.pdf", "text": "trating the weaponization of information.\nIn the same way that propaganda can exploit\nautomatic shortcuts our brain uses to process infor-\nmation ( e.g., stereotypes) (Tversky and Kahneman,\n1974), metaphors can affect how we reason about a\nparticular situation or issue by evoking a different\nsemantic frame (Fillmore et al., 2006). Research\nshows that characterizing crime as a beast deliv-"}, {"source": "2023.findings-eacl.35.pdf", "text": "ered more punishment-oriented strategies to fight\ncrime (Thibodeau and Boroditsky, 2011). Con-\n1The metaphor \u201c paper bullets \u201d was used during World\nWar II, where the Germans used tactical aircrafts to drop anti-\nSemitic leaflets over American troops (Margolin, 1946) as a\nway of psychological warfare.472versely, referring to crime as a virus gathered a"}, {"source": "2023.findings-eacl.35.pdf", "text": "more significant number of preventive measures\ntocure it. As a persuasive device, framing has\nsuccessfully been used in politics (Howe, 1988;\nAna, 1999; Lakoff, 2009) to shift the public opin-\nion about a particular topic. Moreover, the use of\nmetaphors by politicians in their posts on social\nmedia increases engagement with their electorate\n(Prabhakaran et al., 2021)."}, {"source": "2023.findings-eacl.35.pdf", "text": "(Prabhakaran et al., 2021).\nSome propagandist techniques and metaphors\ncan exhibit a similar intention by the author. For\ninstance, the most common technique is the use\nofloaded language to increase the emotional re-\nsponse of the audience (e.g., \u201c... disastrous [nuclear\ndeal]\u201d). Likewise, metaphor can also elicit an emo-\ntionally charged reaction (Mohammad et al., 2016)."}, {"source": "2023.findings-eacl.35.pdf", "text": "The following example combines both: \u201cthe ru-\ninous reforms\u201d. Similarly, name-calling connects\nthe object of the propaganda campaign with terms\nthe target audience sees positively or negatively\n(Miller, 1939). This technique seeks a love or hate\nemotional response, and it could also alter the se-\nmantic frame (e.g., \u201c Crooked Hillary\u201d or \u201c Deep\nState officials\u201d)."}, {"source": "2023.findings-eacl.35.pdf", "text": "State officials\u201d).\nOther salient examples where different pro-\npagandist techniques employ metaphor can be\nfound in the Propaganda Techniques Corpus (PTC)\n(Da San Martino et al., 2019b), including exagger-\nation (\u201catsunami of lies and smear\u201d), appeal to\nfear (\u201c[bubonic plague in Madagascar] could even\nspill over into neighboring countries and beyond\u201d),"}, {"source": "2023.findings-eacl.35.pdf", "text": "doubt (\u201cWhy is the U.S. singling out Iran ...\u201d) and\nflag-waving (\u201cit is time to take our government\nback ...\u201d), among others.\nWe explore how metaphor detection can aid pro-\npaganda technique classification under the multi-\ntask learning paradigm. Computational modeling\nfor propaganda detection was initially studied as\na document-level classification task in news arti-"}, {"source": "2023.findings-eacl.35.pdf", "text": "cles (Rashkin et al., 2017; Barr\u00f3n-Cede\u00f1o et al.,\n2019; Martino et al., 2020). More recently, anno-\ntation efforts produced datasets that identify the\ntext spans where particular forms of propaganda\nare used. Our work builds upon the most extensive\ncorpus of fragment-level propaganda techniques to\ndate (Da San Martino et al., 2019b) and on shared\ntask 6 from SemEval-2021 (Dimitrov et al., 2021)"}, {"source": "2023.findings-eacl.35.pdf", "text": "to identify persuasive techniques in both news arti-\ncles and internet memes, respectively. We analyze\nhow a multi-task learning approach that leverages\nmetaphor detection can improve results in propa-ganda identification.\nTo our knowledge, this is the first study of the\nrole of metaphor in computational propaganda iden-\ntification. We produce the first models that combine"}, {"source": "2023.findings-eacl.35.pdf", "text": "the two phenomena and analyze their predictive ca-\npability, both quantitatively and qualitatively.\nOur findings show that metaphor detection can\nincrease performance for certain types of propa-\nganda. We see improvements across multiple tasks\ncovering both datasets. The gains are more pro-\nnounced for name-calling , with significant results\nfor the news domain. Furthermore, our models\u2019"}, {"source": "2023.findings-eacl.35.pdf", "text": "predictions suggest that propagandist content uses\nfigurative language more extensively than non-\npropagandist text.\n2 Related work\n2.1 Metaphor detection\nNLP applications need to distinguish the partic-\nular intent that metaphor plays in context (Veale\net al., 2016). Metaphor detection research has stud-\nied various approaches: hand-crafted features and"}, {"source": "2023.findings-eacl.35.pdf", "text": "word classes (Beigman Klebanov et al., 2016), con-\ncreteness and imageability word ratings (Broad-\nwell et al., 2013; Turney et al., 2011), seman-\ntic classification making use of lexical databases\n(e.g., WordNet, VerbNet, ConceptNet) (Wilks et al.,\n2013; Neuman et al., 2013; Mohler et al., 2013;\nTsvetkov et al., 2013), distributional semantic mod-"}, {"source": "2023.findings-eacl.35.pdf", "text": "els (Gutierrez et al., 2016; Bulat et al., 2017; Hovy\net al., 2013), and even visual (Shutova et al., 2016)\nor sensorial features (Tekiroglu et al., 2015). More\nrecently, deep learning methods (Mao et al., 2019;\nDankers et al., 2020; Gao et al., 2018; Rei et al.,\n2017; Wu et al., 2018) have been used to detect\nmetaphors.\nCurrent state-of-the-art textual metaphor detec-"}, {"source": "2023.findings-eacl.35.pdf", "text": "tion is powered by large pre-trained neural network\nmodels (Su et al., 2020; Chen et al., 2020; Gong\net al., 2020; Choi et al., 2021) that have been trained\nusing datasets of billions of words. These mod-\nels can leverage word representations that carry\ncontext-sensitive semantic information. As the lat-\nest shared task on metaphor detection highlights"}, {"source": "2023.findings-eacl.35.pdf", "text": "(ACL 2020) (Leong et al., 2020), more than half of\nthe participants used BERT (Devlin et al., 2019) or\nits variants, widely successful pre-trained models\nthat perform well on downstream tasks.\nIn addition, metaphor detection has successfully\nbeen used as an auxiliary task in multi-task learning"}, {"source": "2023.findings-eacl.35.pdf", "text": "(MTL) (Caruana, 1993) for emotion classification473(Dankers et al., 2019), political perspective, affil-\niation, and framing (Huguet Cabot et al., 2020);\nand aspect-based sentiment analysis (Mao and Li,\n2021), among others. The MTL approach builds on\nthe idea that the same model can encode valuable\nfeatures for different tasks that would help each\nother\u2019s performance. As metaphor is extensively"}, {"source": "2023.findings-eacl.35.pdf", "text": "used in everyday language and dramatically influ-\nences the expressiveness of the message, it can help\nin a significant number of semantic tasks.\n2.2 Propaganda detection\nPropaganda is closely related to political bias and\nmisinformation (colloquially referred to as fake\nnews ) (Guess and Lyons, 2020). This area of re-\nsearch has gained popularity in the last decade due"}, {"source": "2023.findings-eacl.35.pdf", "text": "to concerns regarding the weaponization of social\nmedia and how it can negatively affect political\ndiscourse (Wardle and Derakhshan, 2017). Work\non political bias commonly uses lexicon-based ap-\nproaches to detect sentiment on political topics,\nwhile models to expose fake stories usually rely\non publishing patterns and knowledge graphs (Haq\net al., 2020)."}, {"source": "2023.findings-eacl.35.pdf", "text": "et al., 2020).\nHowever, propaganda does not necessarily have\nto be politically driven or rely on untrue or incor-\nrect information. While some instances of propa-\nganda usually do (e.g., clickbait) (Martino et al.,\n2020), propagandist content varies in accuracy and\nthe acknowledgment of its sources (Jowett et al.,\n2012). In essence, propaganda aims to influence an"}, {"source": "2023.findings-eacl.35.pdf", "text": "audience to exercise a particular agenda (Cantril,\n1938) by appealing to emotions or faulty reasoning\n(Miller, 1939).\nComputational approaches to propaganda detec-\ntion are relatively recent and were initially directed\nto the document classification of varying sizes,\nfrom news articles to tweets (Barr\u00f3n-Cede\u00f1o et al.,\n2019; Rashkin et al., 2017; V olkova et al., 2017)."}, {"source": "2023.findings-eacl.35.pdf", "text": "Proposed models used BERT, LSTM (Hochreiter\nand Schmidhuber, 1997), Convolutional Neural\nNetworks (CNN) (LeCun et al., 1995), and Naive\nBayes models powered by Glove (Pennington et al.,\n2014) embeddings. These works rely to different\ndegrees on the labeling of information sources by\ncrowd-sourced groups or non-profit organizations\n(e.g., MBFC2, PropOrNot3). Unfortunately, this"}, {"source": "2023.findings-eacl.35.pdf", "text": "categorization approach can introduce noise into\nthe system. Reliable news agencies might occasion-\n2https://mediabiasfactcheck.com\n3http://www.propornot.com/p/the-list.\nhtmlally include a propagandist article to fulfill their\ninterest. Conversely, highly propagandist media\ncould publish a non-propagandist piece to boost\ntheir credibility.\nThe latest propaganda detection approaches take"}, {"source": "2023.findings-eacl.35.pdf", "text": "advantage of the rhetorical devices that propaganda\nuses to influence reasoning. Although the litera-\nture compiles different accounts of propagandist or\npersuasive techniques (Miller, 1939; Shah, 2005;\nAbd Kadir and Abu Hasan, 2014), they are mainly\nsub-types of the general principles first proposed\nin Cantril (1938), which share the aim of connect-"}, {"source": "2023.findings-eacl.35.pdf", "text": "ing an idea or propagandist object to an attitude or\nemotion.\nThe PTC corpus (Da San Martino et al., 2019b)\nwas the first effort to classify propaganda at a\nmore granular level. It identifies 18 persuasive\ntechniques across 451 news articles, making it\nthe largest of its kind. It annotates the start and\nend of each propagandist fragment. This cor-"}, {"source": "2023.findings-eacl.35.pdf", "text": "pus, and a later variant, were used in shared tasks\non propaganda detection (Da San Martino et al.,\n2019a, 2020). The best systems used pre-trained\nTransformer-based models and ensembles (Yoosuf\nand Yang, 2019; Jurkiewicz et al., 2020; Morio\net al., 2020; Chernyavskiy et al., 2020).\nMore recently, SemEval 2021 Task 6 (Dim-\nitrov et al., 2021) has expanded fragment-level"}, {"source": "2023.findings-eacl.35.pdf", "text": "propaganda identification efforts outside the news\ncorpora. It identifies propaganda techniques in-\ngrained in the combination of textual and image\ndata. The task\u2019s dataset consists of 950 internet\nmemes posted on social media with topics related\nto politics, vaccines, COVID-19, and gender equal-\nity. Apart from identifying 20 textual propagan-"}, {"source": "2023.findings-eacl.35.pdf", "text": "dist techniques, it also identifies two that are only\npresent when in combination with the image. The\nmost common and best-performing models used\nfor textual tasks were the transformer-based mod-\nels BERT and RoBERTa (Kaczy \u00b4nski and Przyby\u0142a,\n2021; Gupta et al., 2021).\n3 Tasks and datasets\nIn this work, we examine six tasks for fragment-\nlevel propagandist technique identification. Half of"}, {"source": "2023.findings-eacl.35.pdf", "text": "them use labeled data from news articles, while the\nothers use textual information from memes shared\non social media. For each domain, we perform\na multi-label classification task \u2014 to identify all\npropagandist techniques in the dataset \u2014 and two\nsingle-label classification tasks to detect the two474most common persuasive techniques: loaded lan-\nguage andname-calling . The single-label tasks"}, {"source": "2023.findings-eacl.35.pdf", "text": "ignore the rest of the labels in the dataset while us-\ning the same textual input as the multi-label tasks.\nIn addition, MTL models include metaphor de-\ntection as an auxiliary task. This task aims to detect\nall content words used as metaphors in a given text.\n3.1 VUA Metaphor Corpus\nWe use the data from the ACL 2020 shared task on\nmetaphor detection (Leong et al., 2020). Specif-"}, {"source": "2023.findings-eacl.35.pdf", "text": "ically, the all-POS subtask that identifies which\ncontent words (i.e., nouns, verbs, adjectives, and\nadverbs) are used in their metaphorical sense. The\ndata for the task comes from the VU Amsterdam\nMetaphor Corpus, (Steen et al., 2010) which con-\ntains annotations for all words in 117 texts from the\nBritish National Corpus (Clear, 1993) and across"}, {"source": "2023.findings-eacl.35.pdf", "text": "four different registers: academic text, conversa-\ntion, fiction, and news. The dataset covers 190K\nlexical units over 16,189 sentences with a train/test\nsplit of 12,109 and 4,080 sentences. The preva-\nlence of metaphorical use for content words is 6.8%\nfor the training set and 7.7% for the test set. We\nrandomly sample 10% of the training split for vali-\ndation.\n3.2 Propaganda Techniques Corpus"}, {"source": "2023.findings-eacl.35.pdf", "text": "3.2 Propaganda Techniques Corpus\nThe PTC corpus (Da San Martino et al., 2019b)\nidentifies 18 propaganda techniques across 451 ar-\nticles (350K tokens) from 49 news outlets. The\nannotations were produced by separate teams of\nannotators and merged through a consolidation pro-\ncess where all disagreements were discussed before\nbecoming part of the final version. Each annota-"}, {"source": "2023.findings-eacl.35.pdf", "text": "tion identifies the technique used and its start and\nend within the news article. The dataset contains\n20,339 sentences split into training, validation, and\ntest sets with 14,263, 2,034, and 4,042 sentences,\nrespectively.\nThe number of instances per technique and its\nlength varies widely. The most common classes\nareloaded language with 2,547 occurrences and"}, {"source": "2023.findings-eacl.35.pdf", "text": "name-calling with 1,294. Those techniques have\nbeen used an average of 6.7 and 4.7 times per arti-\ncle, whereas all others appear a maximum of twice\nper article. We evaluated these two techniques sep-\narately as they provide a larger number of positive\nexamples and can relate to metaphor as described in\nSection 1. Details on the number of annotations per"}, {"source": "2023.findings-eacl.35.pdf", "text": "split and their average length are shown in Table 1.Dataset #Annotations Length\nProp. technique Total Train Val Test Avg. \u00b1 SD\nNews\nLoaded language 2,547 1,811 304 432 23.70 \u00b1 25.30\nName-calling 1,294 931 154 209 26.10 \u00b1 19.88\nAll combined 7,480 5,114 927 1,439 46.99 \u00b1 61.45\nMemes\nLoaded language 761 543 68 150 14.87 \u00b1 18.17\nName-calling 408 301 37 70 17.00 \u00b1 11.65"}, {"source": "2023.findings-eacl.35.pdf", "text": "All combined 2,083 1,498 182 403 40.43 \u00b1 48.91\nTable 1: Statistics on propaganda technique annotations\nand their average length in characters.\n3.3 Propaganda detection in memes\nSemEval-2021 Task 6 (Dimitrov et al., 2021) aims\nto identify the propagandist technique used in\nmemes shared on social media. The images were\ncollected from 26 public Facebook groups, which"}, {"source": "2023.findings-eacl.35.pdf", "text": "provided memes on the following topics: politics,\nCOVID-19, pro-vaccines, anti-vaccines, and gen-\nder equality. The annotation process involved a\nheterogeneous group of annotators and a consoli-\ndation step. The text of the images was retrieved\nautomatically using Google Vision API4and manu-\nally corrected afterward. We focus on subtask two,\nwhich only uses the textual data of the meme to"}, {"source": "2023.findings-eacl.35.pdf", "text": "predict where in the text a particular technique is\npresent.\nThe dataset contains 951 examples (16,840 to-\nkens) divided into 688, 63, and 200 samples for\ntrain, validation, and test splits. The average num-\nber of sentences per meme is 1.68, with a maxi-\nmum of 13 sentences in one image alone. Again,\nthe most common techniques are loaded language\nwith 761 annotations (36.5%) and name-calling"}, {"source": "2023.findings-eacl.35.pdf", "text": "408 occurrences (19.6%) from 2,083 propagandist\nfragments.\nWe provide a summary of the textual persua-\nsion techniques in the Appendix Section A.1 and\nexamples in the Appendix Table 12.\n4 Methods\n4.1 Models\nWe employ the pre-trained ROBERT A-BASE\nmodel (Liu et al., 2019). ROBERT Ashares its\narchitecture with its counterpart BERT (Devlin\net al., 2019), but it improves performance across"}, {"source": "2023.findings-eacl.35.pdf", "text": "many tasks due to its highly optimized training and\nthe use of ten times more data.\n4http://cloud.google.com/vision475ROBERT Atokenizes inputs using byte-pair en-\ncodings (Sennrich et al., 2016) and computes con-\ntextualised embeddings for these input tokens. We\nadd task-specific classifiers on top of ROBERT A,\nconsisting of a linear layer followed by the sigmoid"}, {"source": "2023.findings-eacl.35.pdf", "text": "activation function. During inference, tokens with\npredicted targets over 0.5 are assigned to the class\ncorresponding to the classifier. We fine-tune all\nof the model parameters in our respective tasks.\nSince the datasets provide labels at the word level,\nwe aggregate predictions for words consisting of\nmultiple tokens. If the model predicts any token to"}, {"source": "2023.findings-eacl.35.pdf", "text": "belong to a particular class, we assign the label to\nthe whole word.\n4.2 Single-task learning\nOur main task is to detect the text span of each pro-\npaganda technique from news articles and memes.\nWhen solely training the model on a propaganda\ntask, we refer to this as single-task learning (STL).\nThe standard propaganda task as introduced in Sec-"}, {"source": "2023.findings-eacl.35.pdf", "text": "tion 3 is multi label . Since propagandist fragments\ncan overlap, we perform multi-label classification\nby predicting the presence of each technique inde-\npendently at each token, using separate task classi-\nfiers per technique as described in Section 4.1.\nIn addition to the multi-label propaganda tech-\nnique identification, we generate two single-label"}, {"source": "2023.findings-eacl.35.pdf", "text": "tasks targeting the most frequent persuasion tech-\nniques (i.e., loaded language andname-calling ).\nBoth techniques share common aspects with\nmetaphor discussed in Section 1, making them par-\nticularly interesting for experimentation.\n4.3 Multi-task learning\nIn the MTL setup, we train the model jointly on two\ntasks: one of the propaganda identification tasks"}, {"source": "2023.findings-eacl.35.pdf", "text": "and the metaphor detection task. Similar to the STL\nsetup, we do this both for single-label and multi-\nlabel classification. As the model learns to iden-\ntify metaphors, we hypothesize that the metaphor-\nrelated features benefit the propaganda technique\nidentification.\nWe extend the STL models with an additional\nclassifier to predict metaphor as the auxiliary task."}, {"source": "2023.findings-eacl.35.pdf", "text": "All tasks share the pre-trained model ( ROBERT A)\nin a hard parameter sharing fashion. For fine-\ntuning, we reuse the best configuration from the\nsingle-task models to facilitate comparison be-\ntween the two strategies. We experiment with\ndifferent MTL regimes attending to the following\nhyper-parameters:\u2022Task sampling ratios (ra, rm): these ratios\nare used to select a task at each update step"}, {"source": "2023.findings-eacl.35.pdf", "text": "during training. With a probability of pm=\nrm/(ra+rm)the main task is selected, and\nwithpa=ra/(ra+rm)the auxiliary task is\nselected.\n\u2022Epoch sampling coefficients (ca, cm): these\ncoefficients are used to update the sampling\nratios at every epoch. At epoch n,rmn=\nrmn\u22121\u00d7cm, and , ran=ran\u22121\u00d7ca.\n\u2022Loss scaling factors (sa, sm): these hyper-\nparameters are used to scale the losses for"}, {"source": "2023.findings-eacl.35.pdf", "text": "the main task ( sm) and the auxiliary task ( sa).\nAlthough the MTL models have access to more\ndata, as they are trained on two datasets, we limit\ntheir computational budget to match the one avail-\nable for STL models. Every epoch, the model is\ntrained in iterations, where the number of iterations\nis the same as for the STL model. Each iteration"}, {"source": "2023.findings-eacl.35.pdf", "text": "randomly selects a task for training according to its\nsampling probability p. We shuffle all examples in\nthe training set at the start and after exhaustion of\nthe training split. We fill each batch with samples\nfrom the selected task at random without replace-\nment.\n5 Experiments and results\n5.1 Experimental Setup\nIn the implementation, we use the PyTorch frame-"}, {"source": "2023.findings-eacl.35.pdf", "text": "work and the pre-trained ROBERT A-BASE5model\nfrom the transformers library (Wolf et al., 2020).\nWe trained all models using a maximum sequence\nlength of 512 tokens, a weight decay of 0.01, and\nthe AdamW optimizer (Loshchilov and Hutter,\n2017) with a 10% warm-up period and a cosine-\nbased learning rate decay function. All hyper-\nparameter search trials and the selected configu-"}, {"source": "2023.findings-eacl.35.pdf", "text": "rations for each task are listed in Appendix Table\n11. We use the binary cross-entropy loss with mod-\nified class weights to account for class imbalances.\nHyper-parameter search trials are performed over\nfive different random seeds that dictate the order\nof data presentation and the initialisation of the\ntask-specific classifiers. For the final configuration,"}, {"source": "2023.findings-eacl.35.pdf", "text": "performance is computed over ten different random\nseeds.\nTo ensure that the MTL models do capture mean-\ningful features for metaphor identification \u2013 in spite\n5https://huggingface.co/roberta-base476of it being the auxiliary task \u2013 we discard hyper-\nparameter combinations with a median F1-score\nbelow 0.6 for metaphor identification, asserting the\nmodels exceed the baseline level set out by base-"}, {"source": "2023.findings-eacl.35.pdf", "text": "lines one and two of Leong et al. (2020).\nWe evaluate the performance of propaganda de-\ntection based on the micro-averaged F1 score us-\ning precision (P) and recall (R) metrics defined in\nDa San Martino et al. (2019b). These metrics give\npartial credit to imperfect matches to account for\noverlap between techniques and the significant vari-\nation in length between propagandistic fragments."}, {"source": "2023.findings-eacl.35.pdf", "text": "We provide details of these calculations in the Ap-\npendix A.2. We use statistical bootstrapping (Efron,\n1979) to test the significance of our results and de-\ntail the procedure in Appendix A.3. We detail the\nsystem and configurations used for this work in\nAppendix A.4 for reproducibility.\n5.2 Results\n5.2.1 Single-label propaganda technique\ndetection"}, {"source": "2023.findings-eacl.35.pdf", "text": "detection\nTable 2 shows the performance for single-label pro-\npaganda detection tasks. The MTL approach im-\nproves results for all single-label tasks. Adding\nmetaphor increases performance in news articles by\n1.02 points for name-calling , from 28.72 to 29.74.\nThis growth is statistically significant under the\npaired bootstrap test between learning strategies."}, {"source": "2023.findings-eacl.35.pdf", "text": "The improvement is milder for loaded language ,\nwith a gain of 0.22 points, although results were\nmore stable, almost halving the standard deviation\nfor the metric.\nWe observe similar results in the memes dataset.\nDetection of name-calling improves the F1 met-\nric by 1.24 points to 57.77 when training with\nmetaphor as an auxiliary task. This increase is"}, {"source": "2023.findings-eacl.35.pdf", "text": "also more stable, lowering the standard deviation\nfrom 2.44 to 1.26. Loaded language improvements\nare smaller, adding 0.34 points to a total of 65.5\nwith lower variability.\n5.2.2 Multi-label propaganda technique\ndetection\nTable 3 shows the results for the multi-label propa-\nganda identification task in the news dataset. We\ncompare our models to previous work (Da San Mar-"}, {"source": "2023.findings-eacl.35.pdf", "text": "tino et al., 2019b) and achieve better results using\na similar pre-trained model with the same number\nof parameters. The multi-task models obtained the\nbest overall performance with an F1 of 24.32andLoaded Language Name Calling\nModel P R F1 P R F1\nNews\nSTL 32.67 48.04 38.72 \u00b1 1.00 24.48 35.25 28.72 \u00b1 1.14\nMTL 33.60 46.88 38.94 \u00b1 0.51 26.30 35.35 29.74 \u00b1 1.64\nMemes"}, {"source": "2023.findings-eacl.35.pdf", "text": "Memes\nSTL 68.88 62.21 65.16 \u00b1 2.16 52.39 61.70 56.53 \u00b1 2.44\nMTL 66.29 64.90 65.50 \u00b1 1.62 59.03 57.13 57.77 \u00b1 1.26\nTable 2: Propaganda detection performance for single-\nlabel models. Statistically significant differences be-\ntween STL and MTL are underlined ( p <0.05).\nModel P R F1\nDa San Martino et al. (2019b) 24.42 21.05 22.58\nMulti-label STL 20.37 30.42 23.78 \u00b1 2.03"}, {"source": "2023.findings-eacl.35.pdf", "text": "Multi-label MTL 21.98 27.46 24.32 \u00b1 0.48\nTable 3: Propaganda technique identification results in\nnews articles. The highest performance per model type\nis shown in bold. Underlined values denote statistical\nsignificance ( p<0.05) via paired bootstrap test between\nsingle-task and multi-task models.\na standard deviation of 0.48. The single-task mod-\nels averaged 23.78F1 score with a much higher"}, {"source": "2023.findings-eacl.35.pdf", "text": "variation ( \u03c3= 2.03).\nResults for multi-label propaganda detection in\nmemes are shown in Table 4. State-of-the-art per-\nformance for the task reaches an F1 score of 47.6,\n(Gupta et al., 2021) but it uses a model with 340M\nparameters. This model is three times larger than\nthe ones we used (110M parameters). Comparing\nperformance across same-size models, we see that"}, {"source": "2023.findings-eacl.35.pdf", "text": "our STL model performs best with an average F1\nscore of 46.22 and a standard deviation of 1.82. In\ncontrast, the multi-task model achieves 44.81 \u00b11.31.\nBoth models outperform the value of 43.9 \u00b10.9 re-\nported in Gupta et al. (2021).\nIn the Appendix, Tables 8 and 9 show the perfor-\nmance of multi-label models for all techniques in\nthe news and memes datasets, respectively."}, {"source": "2023.findings-eacl.35.pdf", "text": "6 Analysis and discussion\nGiven the shared traits between the use of metaphor\nand specific propagandist techniques, we hypoth-\nesized that it can be beneficial to model them\njointly. We split the analysis into two subsections\ndiscussing quantitative and qualitative aspects.\n6.1 Quantitative analysis\nThe results show improvements across most pro-"}, {"source": "2023.findings-eacl.35.pdf", "text": "paganda detection tasks when trained in a multi-477Model P R F1\nV olta (RoBERTa-Large) - - 47.6 \u00b1 1.5\nV olta (RoBERTa-Base) - - 43.9 \u00b1 0.9\nMulti-label STL 46.02 46.51 46.22 \u00b1 1.82\nMulti-label MTL 42.62 47.82 44.81 \u00b1 1.31\nTable 4: Propaganda technique identification results in\nmemes. We include the winning team for the shared\ntask: Volta Gupta et al. (2021). The highest performance"}, {"source": "2023.findings-eacl.35.pdf", "text": "per model type is shown in bold. Underlined values de-\nnote statistical significance ( p<0.05) via paired boot-\nstrap test between single-task and multi-task models.\ntask setting with metaphor as the auxiliary task.\nWe hypothesised metaphor detection would benefit\nthe single-label tasks, due to the use of a different\nsemantic frame in name-calling and emotionally"}, {"source": "2023.findings-eacl.35.pdf", "text": "charged vocabulary in loaded language . Improve-\nments were more pronounced for name-calling in\nboth datasets, which suggests that, as anticipated,\nmetaphorical framing plays a role in this propa-\nganda technique. The fact that the gain in F1-score\nis the largest for name calling in both datasets fur-\nther strengths this conclusion.\nTo further consolidate the relationship between"}, {"source": "2023.findings-eacl.35.pdf", "text": "proganda and metaphor our models identify, we\ninvestigate the prevalence of metaphors\u2019 predic-\ntions in propagandistic text fragments. We use our\nMTL models to predict metaphors on the propa-\nganda corpora, and observe a higher percentage of\nmetaphors in propagandist fragments than for non-\npropagandist content, and even higher for loaded\nlanguage andname-calling . This is shown in the"}, {"source": "2023.findings-eacl.35.pdf", "text": "Appendix, in Figures 2 and 3. These model pre-\ndictions hint at the likelihood that propagandist\ncontent, and some techniques in particular, may re-\nsort to metaphor more often than non-propagandist\ntext does. Manual annotation of metaphors in pro-\npaganda datasets will allow asserting this with cer-\ntainty, yet, we leave this for future work.\nAlthough a slight improvement in task perfor-"}, {"source": "2023.findings-eacl.35.pdf", "text": "mance was observed for multi-label propaganda\nidentification in the news dataset, this was not the\ncase for the memes task. This task was the only one\nfor which the MTL strategy was not superior. The\nmemes dataset is 20 times smaller than the news\ndataset and includes two more labels. These chal-\nlenges of size and sparsity could play a role in the"}, {"source": "2023.findings-eacl.35.pdf", "text": "utility of the MTL architecture, particularly when\nimposing on it the best hyper-parameters from the\nsingle-task models. We did this to facilitate thecomparison between models, but we risk ending\nup with a configuration especially harmful to the\nMTL approach. Further experimentation is needed\nto investigate this drop in performance.\n6.2 Qualitative analysis"}, {"source": "2023.findings-eacl.35.pdf", "text": "6.2 Qualitative analysis\nTo validate the effect of metaphor for the tasks,\nwe pooled the predictions for all ten models of the\nsame type trained with different seeds. We use\nsimple majority voting to harmonize predictions\nacross the different runs. Next, we identify the\ndifference in the predicted spans between single-\ntask and multi-task models. We include gold labels"}, {"source": "2023.findings-eacl.35.pdf", "text": "and the predicted metaphors by multi-task models\nfor analysis. Examples of models\u2019 predictions for\nnews articles and memes are shown in Table 5.\nMTL models can detect figurative language,\nwhich contributes to detecting propaganda tech-\nniques that use this device. Idioms such as \u201c throw\nout the window \u201d (ref. LL.N.1) and \u201c kick the can\ndown the road \u201d (ref. LL.N.2) are correctly iden-"}, {"source": "2023.findings-eacl.35.pdf", "text": "tified, albeit partially, as loaded language in the\ncontext of the news article. This is also the case\nfor the metaphorical use of the word \u201c dinosaurs \u201d,\npresent in an example of name-calling , to convey\nthe point of view that current social media plat-\nforms will go extinct (ref. NC.N.1).\nOther instances of non-literal meaning deliver in-\ncorrect predictions. However, we believe that some"}, {"source": "2023.findings-eacl.35.pdf", "text": "of those instances could be considered correct. In\nthe case of name-calling , the models detect \u201c poor\nsport \u201d (ref. NC.N.2), which is alluding to a de-\nfeated candidate in an electoral race. Similarly, the\nphrase \u201c you can throw us in jail, but you will never\ndefeat us \u201d (ref. LL.N.3) signals defiance with a\nconsiderable degree of emotion which borderlines\ntheloaded language category."}, {"source": "2023.findings-eacl.35.pdf", "text": "theloaded language category.\nConversely, the label hardworking used in \u201chard-\nworking Georgians\u201d (ref. NC.N.3) cannot be at-\ntributed to name-calling as it does not refer to the\npropagandist target of the article: Georgia guber-\nnatorial candidate Stacy Abrams. This mislabeled\nexample highlights the task\u2019s difficulty and need\nfor a broader context. Our models received individ-"}, {"source": "2023.findings-eacl.35.pdf", "text": "ual sentences for training and inference, which is\ninsufficient in this instance to identify the object of\nthe propaganda campaign.\nLooking at predictions on the memes dataset, we\nobserve that the gains in name-calling for multi-\ntask models were driven primarily by minimizing"}, {"source": "2023.findings-eacl.35.pdf", "text": "incorrect predictions. The examples NC.M.1 and478PT Reference Text fragmentsName-callingNC.News.1 ... we will risefrom the ashes of the social\nMTLmedia dinosaurs to help build andcreate new platforms ...\nNC.News.2 Talk about a\nMTLpoor sport , but Democrats are often like that in these races.\nNC.News.3 \u201cThe election is over and\nMTLhardworking Georgians are ready tomove forward ,\u201d he said."}, {"source": "2023.findings-eacl.35.pdf", "text": "NC.Memes.1 HOLD UP!!!\nMTLSleepy Joe broke my record?!?!?!?\nNC.Memes.2 ...the most corrupt ,lying anddespised member\nMTLofCongress and the WORST Speaker of the house ...\nNC.Memes.3 So Don King and\nSTLBeetlejuice had a baby...\nNC.Memes.4 WARNING SIGNS OF A\nSTLCULT // ...\nNC.Memes.5 ATTENTION\nSTLPATRIOTS //MEET YOUR\nSTLCIVIL WAR OPPONENTSLoaded LanguageLL.News.1 Political correctness needs to be"}, {"source": "2023.findings-eacl.35.pdf", "text": "MTLthrown out thewindow when dealing with those who...\nLL.News.2 In other words, let\u2019s just\nMTLkick thecan down\nMTLtheroad and hope for a more reasonable Iranian regime ...\nLL.News.3 You can throw us in jail, but\nMTLyouwillnever defeat us.\nLL.Memes.1 WHEN TRUMP IS REELECTED THERE WILL BE\nMTLBLOOD !\nLL.Memes.2 WE ARE AT\nMTLWAR !\nLL.Memes.3\nMTLFAKE WINNER"}, {"source": "2023.findings-eacl.35.pdf", "text": "MTLWAR !\nLL.Memes.3\nMTLFAKE WINNER\nLL.Memes.4 ... UNDERCOVER FEDS DOCUMENTING THE FRAUD AND THEY\u2019VE STEPPED INTO A\nMTLTRAP\nTable 5: Example predictions of propaganda techniques. Gold labels in yellow, predictions in blue, and their\nintersection in green. The underline style identifies predictions only produced by one learning strategy. Predicted\nmetaphors from MTL models are shown in bold."}, {"source": "2023.findings-eacl.35.pdf", "text": "NC.M.2 were the only ones containing prediction\nspans singular to the multi-task models. Both in-\nstances correctly label parts of the text that do not\ninclude predicted metaphors, although they contain\nmetaphors in their vicinity. In contrast, the single-\ntask models produced more mislabels on nouns\nor noun phrases, see examples NC.M.3, NC.M.4\nand NC.M.5. With respect to loaded language , we"}, {"source": "2023.findings-eacl.35.pdf", "text": "observe metaphor predictions falling equally into\ncorrect and incorrect spans, see examples LL.M.1,\nLL.M.2, LL.M.3, LL.M.4.\n7 Conclusion and Future Work\nIn this work, we explored the influence of metaphor\ndetection on propaganda technique identification\nin a multi-task learning setup. Joint modelling of\nmetaphor and propaganda was performed using two"}, {"source": "2023.findings-eacl.35.pdf", "text": "propaganda datasets from different domains: news\narticles and internet memes. We experimented with\nsix different propaganda detection tasks, includ-\ning multi-label propaganda technique identification\nand single-label tasks for the two most common\npropagandist techniques: name-calling andloadedlanguage , for each dataset. Incorporating metaphor\ndetection yielded performance improvements in"}, {"source": "2023.findings-eacl.35.pdf", "text": "five of the six tasks considered, with the highest\nimprovements observed for the name-calling tech-\nnique. Moreover, the different datasets showed\nsimilar patterns in performance changes. We sup-\nplemented the task performance results with an\nanalysis of the prevalence of metaphor in the propa-\nganda corpora and qualitatively examined a range\nof examples of metaphorical language use in pro-"}, {"source": "2023.findings-eacl.35.pdf", "text": "pagandist fragments. We are the first to investigate\nthe interaction of these two phenomena and our\npromising results encourage further research in this\ndirection.\nIn future work, we plan to extend our analysis\nto other propaganda techniques. In view of the\nemergence of datasets for other languages, such as\nan the Arabic propaganda detection shared task at"}, {"source": "2023.findings-eacl.35.pdf", "text": "WANLP\u20192022 and the multilingual SemEval-2023\ntask 3 subtask 3 on propagada detection in English,\nFrench, German, Italian, Polish, and Russian, we\nplan future multi/cross-lingual experiments.479Limitations\nAlthough we established a positive influence of\nmetaphor detection on propaganda technique iden-\ntification, our work also has some limitations. (1)"}, {"source": "2023.findings-eacl.35.pdf", "text": "Considering that this work focused on the two most\ncommon propagandist techniques, future work\ncould extend this analysis to cover others, although\nwe should note that these analyses are limited by\na data scarcity issue (in particular in the memes\ndataset). (2) While we considered six tasks, these\ntasks used one MTL architecture. Previous work\nhas experimented with more advanced MTL meth-"}, {"source": "2023.findings-eacl.35.pdf", "text": "ods (e.g., soft parameter sharing) and in the future,\nthese methods could also benefit joint learning of\nmetaphor and propaganda. (3) Finally, it should\nbe emphasised that both types of propaganda em-\nployed and the types of figurative language used\nare very specific to cultures and languages. As\nsuch, the techniques applied in this study might not"}, {"source": "2023.findings-eacl.35.pdf", "text": "deliver the same effect when using data from differ-\nent geographical locations, or data from languages\nother than English. Moreover, the prevalence of\nmetaphor varies across different propagandist tech-\nniques, meaning that not every propaganda-related\ntask will benefit from joint learning with metaphor.\nEthics and Broader Impact\nIntended Use and Misuse Potential Our mod-"}, {"source": "2023.findings-eacl.35.pdf", "text": "els can be of interest to the general public, fact-\ncheckers, and journalists. However, they could also\nbe misused by malicious actors. We, therefore, ask\nresearchers to exercise caution.\nEnvironmental Impact We would like to warn\nthat the use of large language models requires a\nlot of computations and the use of GPUs/TPUs\nfor training, which contributes to global warming"}, {"source": "2023.findings-eacl.35.pdf", "text": "(Strubell et al., 2019). This is a bit less of an issue\nin our case, as we do not train such models from\nscratch, we just fine-tune them.\nReferences\nShamsiah Abd Kadir and Ahmad Sauffiyan Abu Hasan.\n2014. A content analysis of propaganda in harakah\nnewspaper. Journal of Media and Information War-\nfare (JMIW) , 5:73\u2013116.\nOtto Santa Ana. 1999. \u2018Like an Animal I was Treated\u2019:"}, {"source": "2023.findings-eacl.35.pdf", "text": "Anti-Immigrant Metaphor in US Public Discourse.\nDiscourse & Society , 10(2):191\u2013224.\nAlberto Barr\u00f3n-Cede\u00f1o, Israa Jaradat, Giovanni\nDa San Martino, and Preslav Nakov. 2019. Proppy:Organizing the news based on their propagandistic\ncontent. Information Processing & Management ,\n56(5):1849\u20131864.\nBeata Beigman Klebanov, Chee Wee Leong, E. Dario\nGutierrez, Ekaterina Shutova, and Michael Flor."}, {"source": "2023.findings-eacl.35.pdf", "text": "2016. Semantic classifications for detection of verb\nmetaphors. In Proceedings of the 54th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 2: Short Papers) , pages 101\u2013106, Berlin,\nGermany. Association for Computational Linguis-\ntics.\nGeorge Aaron Broadwell, Umit Boz, Ignacio Cases,\nTomek Strzalkowski, Laurie Feldman, Sarah Taylor,"}, {"source": "2023.findings-eacl.35.pdf", "text": "Samira Shaikh, Ting Liu, Kit Cho, and Nick Webb.\n2013. Using Imageability and Topic Chaining to\nLocate Metaphors in Linguistic Corpora. In Social\nComputing, Behavioral-Cultural Modeling and Pre-\ndiction , pages 102\u2013110, Berlin, Heidelberg. Springer\nBerlin Heidelberg.\nLuana Bulat, Stephen Clark, and Ekaterina Shutova.\n2017. Modelling metaphor with attribute-based se-"}, {"source": "2023.findings-eacl.35.pdf", "text": "mantics. In Proceedings of the 15th Conference of\nthe European Chapter of the Association for Compu-\ntational Linguistics: Volume 2, Short Papers , pages\n523\u2013528, Valencia, Spain. Association for Computa-\ntional Linguistics.\nHadley Cantril. 1938. Propaganda analysis. The En-\nglish Journal , 27(3):217\u2013221.\nRichard A. Caruana. 1993. Multitask Learning: A"}, {"source": "2023.findings-eacl.35.pdf", "text": "Knowledge-Based Source of Inductive Bias. In Ma-\nchine Learning Proceedings 1993 , pages 41\u201348. El-\nsevier.\nXianyang Chen, Chee Wee (Ben) Leong, Michael\nFlor, and Beata Beigman Klebanov. 2020. Go Fig-\nure! Multi-task transformer-based architecture for\nmetaphor detection using idioms: ETS team in 2020\nmetaphor shared task. In Proceedings of the Second"}, {"source": "2023.findings-eacl.35.pdf", "text": "Workshop on Figurative Language Processing , pages\n235\u2013243, Online. Association for Computational Lin-\nguistics.\nAnton Chernyavskiy, Dmitry Ilvovsky, and Preslav\nNakov. 2020. Aschern at SemEval-2020 task 11:\nIt takes three to tango: RoBERTa, CRF, and trans-\nfer learning. In Proceedings of the Fourteenth\nWorkshop on Semantic Evaluation , pages 1462\u2013"}, {"source": "2023.findings-eacl.35.pdf", "text": "1468, Barcelona (online). International Committee\nfor Computational Linguistics.\nMinjin Choi, Sunkyung Lee, Eunseong Choi, Heesoo\nPark, Junhyuk Lee, Dongwon Lee, and Jongwuk Lee.\n2021. MelBERT: Metaphor Detection via Contextu-\nalized Late Interaction using Metaphorical Identifica-\ntion Theories. In Proceedings of the 2021 Conference\nof the North American Chapter of the Association for"}, {"source": "2023.findings-eacl.35.pdf", "text": "Computational Linguistics: Human Language Tech-\nnologies , pages 1763\u20131773, Online. Association for\nComputational Linguistics.480Jeremy H. Clear. 1993. The British National Corpus ,\npage 163\u2013187. MIT Press, Cambridge, MA, USA.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o, and\nPreslav Nakov. 2019a. Findings of the NLP4IF-2019\nshared task on fine-grained propaganda detection. In"}, {"source": "2023.findings-eacl.35.pdf", "text": "Proceedings of the Second Workshop on Natural Lan-\nguage Processing for Internet Freedom: Censorship,\nDisinformation, and Propaganda , pages 162\u2013170,\nHong Kong, China. Association for Computational\nLinguistics.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\nNakov. 2020. SemEval-2020 Task 11: Detection of"}, {"source": "2023.findings-eacl.35.pdf", "text": "Propaganda Techniques in News Articles. In Pro-\nceedings of the Fourteenth Workshop on Semantic\nEvaluation , pages 1377\u20131414, Barcelona (online).\nInternational Committee for Computational Linguis-\ntics.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarr\u00f3n-Cede\u00f1o, Rostislav Petrov, and Preslav Nakov.\n2019b. Fine-Grained Analysis of Propaganda in\nNews Article. In Proceedings of the 2019 Confer-"}, {"source": "2023.findings-eacl.35.pdf", "text": "ence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP) ,\npages 5635\u20135645, Hong Kong, China. Association\nfor Computational Linguistics.\nVerna Dankers, Karan Malhotra, Gaurav Kudva,\nV olodymyr Medentsiy, and Ekaterina Shutova. 2020.\nBeing neighbourly: Neural metaphor identification"}, {"source": "2023.findings-eacl.35.pdf", "text": "in discourse. In Proceedings of the Second Workshop\non Figurative Language Processing , pages 227\u2013234,\nOnline. Association for Computational Linguistics.\nVerna Dankers, Marek Rei, Martha Lewis, and Eka-\nterina Shutova. 2019. Modelling the interplay of\nmetaphor and emotion through multitask learning. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the"}, {"source": "2023.findings-eacl.35.pdf", "text": "9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 2218\u2013\n2229, Hong Kong, China. Association for Computa-\ntional Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\nDeep Bidirectional Transformers for Language Un-\nderstanding. In Proceedings of the 2019 Conference"}, {"source": "2023.findings-eacl.35.pdf", "text": "of the North {A}merican Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171\u20134186, Minneapolis, Minnesota. Associa-\ntion for Computational Linguistics.\nDimitar Dimitrov, Bishr Bin Ali, Shaden Shaar, Firoj\nAlam, Fabrizio Silvestri, Hamed Firooz, Preslav\nNakov, and Giovanni Da San Martino. 2021."}, {"source": "2023.findings-eacl.35.pdf", "text": "SemEval-2021 Task 6: Detection of Persuasion Tech-\nniques in Texts and Images. In Proceedings of the\n15th International Workshop on Semantic Evaluation\n(SemEval-2021) , pages 70\u201398, Online. Association\nfor Computational Linguistics.Rotem Dror, Gili Baumer, Segev Shlomov, and Roi\nReichart. 2018. The hitchhiker\u2019s guide to testing\nstatistical significance in natural language processing."}, {"source": "2023.findings-eacl.35.pdf", "text": "InProceedings of the 56th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers) , pages 1383\u20131392. Association for\nComputational Linguistics.\nB. Efron. 1979. Bootstrap methods: Another look at the\njackknife. The Annals of Statistics , 7(1).\nCharles J Fillmore et al. 2006. Frame semantics. Cog-\nnitive linguistics: Basic readings , 34:373\u2013400."}, {"source": "2023.findings-eacl.35.pdf", "text": "Ge Gao, Eunsol Choi, Yejin Choi, and Luke Zettle-\nmoyer. 2018. Neural Metaphor Detection in Context.\nInProceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing , pages\n607\u2013613, Brussels, Belgium. Association for Com-\nputational Linguistics.\nHongyu Gong, Kshitij Gupta, Akriti Jain, and Suma\nBhat. 2020. IlliniMet: Illinois System for Metaphor"}, {"source": "2023.findings-eacl.35.pdf", "text": "Detection with Contextual and Linguistic Informa-\ntion. In Proceedings of the Second Workshop on Figu-\nrative Language Processing , pages 146\u2013153, Online.\nAssociation for Computational Linguistics.\nAndrew M. Guess and Benjamin A. Lyons. 2020. Misin-\nformation, Disinformation, and Online Propaganda ,\nSSRC Anxieties of Democracy, page 10\u201333. Cam-\nbridge University Press."}, {"source": "2023.findings-eacl.35.pdf", "text": "bridge University Press.\nKshitij Gupta, Devansh Gautam, and Radhika Mamidi.\n2021. V olta at SemEval-2021 Task 6: Towards De-\ntecting Persuasive Texts and Images using Textual\nand Multimodal Ensemble. In Proceedings of the\n15th International Workshop on Semantic Evaluation\n(SemEval-2021) , pages 1075\u20131081, Online. Associa-\ntion for Computational Linguistics."}, {"source": "2023.findings-eacl.35.pdf", "text": "tion for Computational Linguistics.\nE.Dario Gutierrez, Ekaterina Shutova, Tyler Marghetis,\nand Benjamin Bergen. 2016. Literal and Metaphori-\ncal Senses in Compositional Distributional Semantic\nModels. In Proceedings of the 54th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers) , pages 183\u2013193, Berlin,\nGermany. Association for Computational Linguis-\ntics."}, {"source": "2023.findings-eacl.35.pdf", "text": "tics.\nEhsan Ul Haq, Tristan Braud, Young D. Kwon, and\nPan Hui. 2020. A Survey on Computational Politics.\nIEEE Access , 8:197379\u2013197406. Conference Name:\nIEEE Access.\nSepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long\nshort-term memory. Neural computation , 9(8):1735\u2013\n1780.\nDirk Hovy, Shashank Shrivastava, Sujay Kumar Jauhar,\nMrinmaya Sachan, Kartik Goyal, Huying Li, Whit-"}, {"source": "2023.findings-eacl.35.pdf", "text": "ney Sanders, and Eduard Hovy. 2013. Identify-\ning Metaphorical Word Use with Tree Kernels. In\nProceedings of the First Workshop on Metaphor in\n{NLP} , pages 52\u201357, Atlanta, Georgia.481Nicholas Howe. 1988. Metaphor in Contemporary\nAmerican Political Discourse. Metaphor and Sym-\nbolic Activity , 3(2):87\u2013104.\nPere-Llu\u00eds Huguet Cabot, Verna Dankers, David Abadi,"}, {"source": "2023.findings-eacl.35.pdf", "text": "Agneta Fischer, and Ekaterina Shutova. 2020. The\nPragmatics behind Politics: Modelling Metaphor,\nFraming and Emotion in Political Discourse. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2020 , pages 4479\u20134488, Online. Association\nfor Computational Linguistics.\nGarth Jowett, Victoria O\u2019Donnell, and Garth Jowett.\n2012. Propaganda & persuasion , 5th edition. SAGE,"}, {"source": "2023.findings-eacl.35.pdf", "text": "Thousand Oaks, Calif. OCLC: ocn674939375.\nDawid Jurkiewicz, \u0141ukasz Borchmann, Izabela Kos-\nmala, and Filip Grali \u00b4nski. 2020. ApplicaAI at\nSemEval-2020 task 11: On RoBERTa-CRF, span\nCLS and whether self-training helps them. In Pro-\nceedings of the Fourteenth Workshop on Semantic\nEvaluation , pages 1415\u20131424, Barcelona (online).\nInternational Committee for Computational Linguis-\ntics."}, {"source": "2023.findings-eacl.35.pdf", "text": "tics.\nKonrad Kaczy \u00b4nski and Piotr Przyby\u0142a. 2021. HOMA-\nDOS at SemEval-2021 task 6: Multi-task learning\nfor propaganda detection. In Proceedings of the\n15th International Workshop on Semantic Evaluation\n(SemEval-2021) , pages 1027\u20131031, Online. Associa-\ntion for Computational Linguistics.\nGeorge Lakoff. 1980. Metaphors we live by . University\nof Chicago Press, Chicago [etc."}, {"source": "2023.findings-eacl.35.pdf", "text": "of Chicago Press, Chicago [etc.\nGeorge Lakoff. 2009. Metaphor and War: The\nMetaphor System Used to Justify War in the Gulf.\nCognitive Semiotics , 4(2).\nYann LeCun, Yoshua Bengio, et al. 1995. Convolu-\ntional networks for images, speech, and time series.\nThe handbook of brain theory and neural networks ,\n3361(10):1995.\nChee Wee (Ben) Leong, Beata Beigman Klebanov,"}, {"source": "2023.findings-eacl.35.pdf", "text": "Chris Hamill, Egon Stemle, Rutuja Ubale, and Xi-\nanyang Chen. 2020. A Report on the 2020 VUA\nand TOEFL Metaphor Detection Shared Task. In\nProceedings of the Second Workshop on Figurative\nLanguage Processing , pages 18\u201329, Online. Associa-\ntion for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,"}, {"source": "2023.findings-eacl.35.pdf", "text": "Luke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoBERTa: A Robustly Optimized BERT Pretrain-\ning Approach. arXiv:1907.11692 [cs] . ArXiv:\n1907.11692.\nIlya Loshchilov and Frank Hutter. 2017. Decoupled\nweight decay regularization.\nRui Mao and Xiao Li. 2021. Bridging towers of multi-\ntask learning with a gating mechanism for aspect-\nbased sentiment analysis and sequential metaphor"}, {"source": "2023.findings-eacl.35.pdf", "text": "identification. Proceedings of the AAAI Conference\non Artificial Intelligence , 35(15):13534\u201313542.Rui Mao, Chenghua Lin, and Frank Guerin. 2019. End-\nto-End Sequential Metaphor Identification Inspired\nby Linguistic Theories. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics , pages 3888\u20133898, Florence, Italy. Asso-\nciation for Computational Linguistics."}, {"source": "2023.findings-eacl.35.pdf", "text": "ciation for Computational Linguistics.\nLeo Jay Margolin. 1946. Paper Bullets: A Brief Story of\nPsychological Warfare in World War II. New York:\nFroben Press.\nGiovanni Da San Martino, Stefano Cresci, Alberto\nBarr\u00f3n-Cede\u00f1o, Seunghak Yu, Roberto Di Pietro,\nand Preslav Nakov. 2020. A Survey on Computa-\ntional Propaganda Detection. In Proceedings of the"}, {"source": "2023.findings-eacl.35.pdf", "text": "Twenty-Ninth International Joint Conference on Ar-\ntificial Intelligence , pages 4826\u20134832, Yokohama,\nJapan. International Joint Conferences on Artificial\nIntelligence Organization.\nClyde R Miller. 1939. The techniques of propaganda.\nfrom \u201chow to detect and analyze propaganda,\u201d an\naddress given at town hall. The Center for learning .\nSaif Mohammad, Ekaterina Shutova, and Peter Turney."}, {"source": "2023.findings-eacl.35.pdf", "text": "2016. Metaphor as a medium for emotion: An empir-\nical study. In Proceedings of the Fifth Joint Confer-\nence on Lexical and Computational Semantics , pages\n23\u201333.\nMichael Mohler, David Bracewell, Marc Tomlinson,\nand David Hinote. 2013. Semantic Signatures for\nExample-Based Linguistic Metaphor Detection. In\nProceedings of the First Workshop on Metaphor in"}, {"source": "2023.findings-eacl.35.pdf", "text": "{NLP} , pages 27\u201335, Atlanta, Georgia. Association\nfor Computational Linguistics.\nGaku Morio, Terufumi Morishita, Hiroaki Ozaki, and\nToshinori Miyoshi. 2020. Hitachi at SemEval-2020\ntask 11: An empirical study of pre-trained trans-\nformer family for propaganda detection. In Pro-\nceedings of the Fourteenth Workshop on Semantic\nEvaluation , pages 1739\u20131748, Barcelona (online)."}, {"source": "2023.findings-eacl.35.pdf", "text": "International Committee for Computational Linguis-\ntics.\nYair Neuman, Dan Assaf, Yohai Cohen, Mark Last,\nShlomo Argamon, Newton Howard, and Ophir\nFrieder. 2013. Metaphor Identification in Large Texts\nCorpora. PLoS ONE , 8(4):e62343.\nJeffrey Pennington, Richard Socher, and Christopher D\nManning. 2014. Glove: Global vectors for word rep-\nresentation. In Proceedings of the 2014 conference"}, {"source": "2023.findings-eacl.35.pdf", "text": "on empirical methods in natural language processing\n(EMNLP) , pages 1532\u20131543.\nVinodkumar Prabhakaran, Marek Rei, and Ekaterina\nShutova. 2021. How Metaphors Impact Political Dis-\ncourse: A Large-Scale Topic-Agnostic Study Using\nNeural Metaphor Detection. Proceedings of the Inter-\nnational AAAI Conference on Web and Social Media ,\n15:503\u2013512.482Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana"}, {"source": "2023.findings-eacl.35.pdf", "text": "V olkova, and Yejin Choi. 2017. Truth of Varying\nShades: Analyzing Language in Fake News and Po-\nlitical Fact-Checking. In Proceedings of the 2017\nConference on Empirical Methods in Natural Lan-\nguage Processing , pages 2931\u20132937, Copenhagen,\nDenmark. Association for Computational Linguis-\ntics.\nMarek Rei, Luana Bulat, Douwe Kiela, and Ekaterina\nShutova. 2017. Grasping the Finer Point: A Super-"}, {"source": "2023.findings-eacl.35.pdf", "text": "vised Similarity Network for Metaphor Detection.\nInProceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing , pages\n1537\u20131546, Copenhagen, Denmark. Association for\nComputational Linguistics.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Neural machine translation of rare words\nwith subword units. In 54th Annual Meeting of"}, {"source": "2023.findings-eacl.35.pdf", "text": "the Association for Computational Linguistics , pages\n1715\u20131725. Association for Computational Linguis-\ntics (ACL).\nAnup Shah. 2005. War, propaganda and the media.\nGlobal Issues , 31.\nEkaterina Shutova, Douwe Kiela, and Jean Maillard.\n2016. Black Holes and White Rabbits: Metaphor\nIdentification with Visual Features. In Proceedings of\nthe 2016 Conference of the North {A}merican Chap-"}, {"source": "2023.findings-eacl.35.pdf", "text": "ter of the Association for Computational Linguistics:\nHuman Language Technologies , pages 160\u2013170, San\nDiego, California. Association for Computational\nLinguistics.\nGerard J Steen, Aletta G Dorst, J Berenike Herrmann,\nAnna A Kaal, and Tina Krennmayr. 2010. VU ams-\nterdam metaphor corpus. Oxford Text Archive.\nEmma Strubell, Ananya Ganesh, and Andrew McCal-"}, {"source": "2023.findings-eacl.35.pdf", "text": "lum. 2019. Energy and policy considerations for\ndeep learning in NLP. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics . Association for Computational Linguis-\ntics.\nChuandong Su, Fumiyo Fukumoto, Xiaoxi Huang, Jiyi\nLi, Rongbo Wang, and Zhiqun Chen. 2020. DeepMet:\nA Reading Comprehension Paradigm for Token-level"}, {"source": "2023.findings-eacl.35.pdf", "text": "Metaphor Detection. In Proceedings of the Second\nWorkshop on Figurative Language Processing , pages\n30\u201339, Online. Association for Computational Lin-\nguistics.\nSerra Sinem Tekiroglu, G\u00f6zde \u00d6zbal, and Carlo Strap-\nparava. 2015. Exploring Sensorial Features for\nMetaphor Identification. In Proceedings of the Third\nWorkshop on Metaphor in NLP , pages 31\u201339, Denver,"}, {"source": "2023.findings-eacl.35.pdf", "text": "Colorado. Association for Computational Linguis-\ntics.\nPaul H. Thibodeau and Lera Boroditsky. 2011.\nMetaphors We Think With: The Role of Metaphor in\nReasoning. PLoS ONE , 6(2):e16782.Yulia Tsvetkov, Elena Mukomel, and Anatole Gersh-\nman. 2013. Cross-Lingual Metaphor Detection Us-\ning Common Semantic Features. In Proceedings of\nthe First Workshop on Metaphor in {NLP} , pages 45\u2013"}, {"source": "2023.findings-eacl.35.pdf", "text": "51, Atlanta, Georgia. Association for Computational\nLinguistics.\nPeter Turney, Yair Neuman, Dan Assaf, and Yohai Co-\nhen. 2011. Literal and Metaphorical Sense Identifi-\ncation through Concrete and Abstract Context. Pro-\nceedings of the 2011 Conference on Empirical Meth-\nods in Natural Language Processing , pages 680\u2013690.\nAmos Tversky and Daniel Kahneman. 1974. Judgment"}, {"source": "2023.findings-eacl.35.pdf", "text": "under uncertainty: Heuristics and biases. Science ,\n185(4157):1124\u20131131.\nTony Veale, Ekaterina Shutova, and Beata Beigman\nKlebanov. 2016. Metaphor : A Computational Per-\nspective. Number V ol. 31 in Synthesis Lectures on\nHuman Language Technologies. Morgan & Claypool\nPublishers.\nSvitlana V olkova, Kyle Shaffer, Jin Yea Jang, and\nNathan Hodas. 2017. Separating Facts from Fiction:"}, {"source": "2023.findings-eacl.35.pdf", "text": "Linguistic Models to Classify Suspicious and Trusted\nNews Posts on Twitter. In Proceedings of the 55th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pages 647\u2013653,\nVancouver, Canada. Association for Computational\nLinguistics.\nClaire Wardle and Hossein Derakhshan. 2017. Informa-\ntion disorder: Toward an interdisciplinary framework"}, {"source": "2023.findings-eacl.35.pdf", "text": "for research and policy making. Council of Europe\nreport , 27:1\u2013107.\nYorick Wilks, Adam Dalton, James Allen, and Lucian\nGalescu. 2013. Automatic Metaphor Detection us-\ning Large-Scale Lexical Resources and Conventional\nMetaphor Extraction. In Proceedings of the First\nWorkshop on Metaphor in {NLP} , pages 36\u201344. As-\nsociation for Computational Linguistics."}, {"source": "2023.findings-eacl.35.pdf", "text": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing."}, {"source": "2023.findings-eacl.35.pdf", "text": "InProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations , pages 38\u201345, Online. Association\nfor Computational Linguistics.\nChuhan Wu, Fangzhao Wu, Yubo Chen, Sixing Wu,\nZhigang Yuan, and Yongfeng Huang. 2018. THU\nNGN at NAACL-2018 Metaphor Shared Task: Neu-\nral Metaphor Detecting with CNN-LSTM Model. In"}, {"source": "2023.findings-eacl.35.pdf", "text": "Proceedings of the Workshop on Figurative Language\nProcessing , pages 110\u2013114, New Orleans, Louisiana.\nAssociation for Computational Linguistics.483Shehel Yoosuf and Yin Yang. 2019. Fine-grained propa-\nganda detection with fine-tuned BERT. In Proceed-\nings of the Second Workshop on Natural Language\nProcessing for Internet Freedom: Censorship, Dis-\ninformation, and Propaganda , pages 87\u201391, Hong"}, {"source": "2023.findings-eacl.35.pdf", "text": "Kong, China. Association for Computational Linguis-\ntics.\nA Appendix\nA.1 Persuasion techniques\nThe following list compiles the descriptions of\npropaganda techniques present in the PTC corpus\n(Da San Martino et al., 2019b) and the dataset used\nby SemEval-2021 task 6 (Dimitrov et al., 2021).\n1.Appeal to authority: stating the validity of\na claim because an expert or authority has"}, {"source": "2023.findings-eacl.35.pdf", "text": "issued it without providing any other evidence.\nThe datasets include Testimonials as part of\nthis technique, although they might not refer\nto an expert or authority.\n2.Appeal to fear/prejudice: building support for\nan idea by provoking anxiety/panic to the al-\nternative. In some instances, it leverages prej-\nudices to obtain the desired response.\n3.Bandwagon: invites the target audience to sup-"}, {"source": "2023.findings-eacl.35.pdf", "text": "port an idea or action with the pretext that\n\"everyone is doing the same \".\n4.Black-and-white Fallacy (Dictatorship): in-\ntroduces two alternatives as the only possible\noptions to weaken or strengthen one of them.\nIn the extreme, it morphs into dictatorship\nwhen the choice is made for the audience, and\nall other options are considered impossible.\n5.Causal Oversimplification: assuming a sin-"}, {"source": "2023.findings-eacl.35.pdf", "text": "gle cause for an issue when there might be\nmany factors at play in reality. The data also\nincludes scapegoating in this category - mov-\ning the blame to a person or group without\nconsidering the issue\u2019s complexities.\n6.Doubt: questioning the credibility of some-\nthing or someone.\n7.Exaggeration/Minimisation: representing\nsomething as more extreme/dramatic than it is"}, {"source": "2023.findings-eacl.35.pdf", "text": "or, conversely, downplaying its significance.\n8.Flag-waving: rally around a solid national\nsentiment to justify an action or idea.9.Glittering generalities (Virtue)6: words or\nsymbols that produce a positive image of the\npropagandist object by association with the\npreferences of the target audience.\n10.Loaded Language: the use of emotionally\ncharged words to influence an audience. It"}, {"source": "2023.findings-eacl.35.pdf", "text": "often exploits stereotypes and vagueness.\n11.Name-calling: referring to the object of the\npropagandist campaign with a label that con-\nnects the target audience with an emotion, ei-\nther positive (love, praise) or negative (fear,\nhate).\n12.Obfuscation, Intentional Vagueness, Confu-\nsion: deliberately use unclear statements forc-\ning the audience to produce their interpreta-\ntion."}, {"source": "2023.findings-eacl.35.pdf", "text": "tion.\n13.Red Herring: presenting irrelevant data to di-\nvert attention away from the discussed issue.\n14.Reductio ad Hitlerum: seek disapproval of a\nposition by suggesting that it is popular with\na group the target audience hates.\n15.Repetition: repeating the same message to\nsubdue the audience into acceptance.\n16.Slogans: brief and memorable motto or phrase\nto persuade the audience."}, {"source": "2023.findings-eacl.35.pdf", "text": "to persuade the audience.\n17.Smears6: effort to damage or question some-\none\u2019s reputation by propounding negative pro-\npaganda.\n18.Straw Man: misrepresentation of someone\u2019s\nposition to disprove it leaving the original ar-\ngument unaddressed.\n19.Thought-terminating clich\u00e9: using expres-\nsions to prevent critical thinking and mean-\ningful discussions.\n20.Whataboutism: replying with a counter-"}, {"source": "2023.findings-eacl.35.pdf", "text": "question or counter-accusation that suggests\nthe rival is hypocritical concerning their posi-\ntion without refuting their argument.\n6Only present for propaganda in memes, not for propa-\nganda in the news dataset484A.2 Evaluation metrics for propaganda\nTo evaluate the model\u2019s performance in identify-\ning propagandist instances, we follow the meth-\nods used by preceding works. The authors of the"}, {"source": "2023.findings-eacl.35.pdf", "text": "PTC corpus (Da San Martino et al., 2019b) propose\nprecision and recall metrics based on the overlaps\nbetween the target and predicted spans. These met-\nrics are then used to calculate the F1 score for each\ntechnique and all techniques combined.\nShould document dbe a sequence of charac-\nters, we can represent a propaganda technique span\nbyt= [ti, ..., t j]\u2286d. This ground truth will"}, {"source": "2023.findings-eacl.35.pdf", "text": "be compared against the predicted model outputs\ns= [si, ..., s j]. The labeling function l(x)will\nreturn the propaganda technique associated with\nthe fragment x. The function \u03b4(la, lb)will return\n1 when laequals lband 0 otherwise. The groups\nTandSdenote the group of propagandist frag-\nments for gold labels and predictions respectively.\nEquation 1 calculates the overlapping number of"}, {"source": "2023.findings-eacl.35.pdf", "text": "character between two spans and divides it by a\ngiven length h.\nC(s, t, h ) =|(s\u2229t)|\nh\u03b4(l(s), l(t)) (1)\nIn turn, Equation 2 reuses Cto calculate the pre-\ncision metric as the average proportion of correct\nprediction spans. Conversely, the Equation 3 de-\nfines recall as the average proportion of ground\ntruth fragments covered by the predicted spans."}, {"source": "2023.findings-eacl.35.pdf", "text": "Both metrics are similar, but while precision uses\nthe number and length of the predictions, recall\nuses the gold label spans instead.\nP(S, T) =1\n|S|/summationdisplay\ns\u2208S,t\u2208TC(s, t,|s|) (2)\nR(S, T) =1\n|T|/summationdisplay\ns\u2208S,t\u2208TC(s, t,|t|) (3)\nIn contrast, precision and recall metrics for\nmetaphor are calculated as a binary classification\ntask at the word level. Only content words are"}, {"source": "2023.findings-eacl.35.pdf", "text": "considered for this task.\nA.3 Significance testing\nTo check the statistical significance of our results,\nwe use statistical bootstrapping (Efron, 1979). This\npowerful non-parametric method is recommended\nfor evaluation metrics such as precision, recall, and\nF-score in NLP tasks (Dror et al., 2018). The main"}, {"source": "2023.findings-eacl.35.pdf", "text": "idea is to assess whether differences in performancebetween two models originate from variability in\nthe data rather than from the superiority of one\nmodel over the other.\nFirst, we create 100 different bootstrap samples\n(B1..100) from the test data (T) by sampling with\nreplacement (i.e., an example can appear multi-\nple times within the same sample while others"}, {"source": "2023.findings-eacl.35.pdf", "text": "might not be present at all). Our examples are\neither individual sentences from news articles or\nthe textual information of a meme, depending on\nthe dataset used for the task. Each bootstrap sample\nhas the same size as the test set ( |T|=|Bn|\u2200n\u2208\n{1,100}). The premise is that being the test set\na representative sample from all possible data for\nthe task; we can get a sense of the variability of"}, {"source": "2023.findings-eacl.35.pdf", "text": "the task\u2019s data by comparing performance across\nmultiple bootstrap samples.\nAfter randomly generating the samples, we per-\nformed a paired bootstrap test as suggested in Dror\net al. (2018). We calculate the p-value as the pro-\nportion of bootstrap samples where one type of\nmodel outperforms another. Since we use ten dif-\nferent seeds for each setup, comparing results be-"}, {"source": "2023.findings-eacl.35.pdf", "text": "tween single-task and multi-task learning strate-\ngies requires calculating the mean across multiple\nmodels\u2019 performances. We start by calculating the\nperformance of all models of a particular type by\naveraging their scores on each bootstrap sample.\nWe do this for single-task and multi-task models.\nThen, we count the number of times one strategy\nachieves higher performance than the other. Fi-"}, {"source": "2023.findings-eacl.35.pdf", "text": "nally, we calculate the p-value as the proportion of\nsamples where that strategy was superior. We use\nthe standard confidence level of 95% ( \u03b1= 0.05).\nA.4 Reproducibility\nWe adapted our source code7to achieve repro-\nducible results. First, we enabled the use of de-\nterministic algorithms in the PyTorch framework.\nNext, we manually set the seed for all packages"}, {"source": "2023.findings-eacl.35.pdf", "text": "involved in random number generation. We use\nnatural numbers for the seeds starting at one and\nup to the number of runs for each set of hyper-\nparameters tested. Finally, we pined the versions\nfor all dependencies.\nThe system we used had the following soft-\nware: Python/3.8.2, GCCcore/9.3.0, CUDA/11.2,\ncuDNN/8.2.1.32. Additionally, we assigned\nthe value \":4096:8\" to the environment vari-"}, {"source": "2023.findings-eacl.35.pdf", "text": "7https://github.com/baleato/\npaper-bullets485Duration\nTask STL MTL\nNews\nMulti-label 1:31:14 1:31:01\nName Calling 38:53 52:59\nLoaded Language 37:06 53:47\nMemes\nMulti-label 12:38 36:48\nName Calling 6:33 23:59\nLoaded Language 15:06 22:36\nTable 6: Average training runtime per task. This in-\ncludes models discarded in hyper-parameter search tri-\nals.\nable \"CUBLAS_WORKSPACE_CONFIG\" as sug-"}, {"source": "2023.findings-eacl.35.pdf", "text": "able \"CUBLAS_WORKSPACE_CONFIG\" as sug-\ngested by Nvidia documentation8to avoid non-\ndeterministic behavior. Our models used a single\nGeForce 1080Ti GPU for training. The average\ntraining runtime per task is shown in Appendix\nTable 6.\nA.5 Preprocessing\nThe PTC dataset used NLTK sentence splitter9to\nbreak news articles into individual sentences. We"}, {"source": "2023.findings-eacl.35.pdf", "text": "detected duplicates driven primarily by boilerplate\ncontent regarding site functionality (e.g., invitation\nto participate in an online poll or request to sub-\nscribe to their newsletter). Duplicates were mainly\nshort sentences that did not include any labels. We\nremoved these instances from the training set.\nWe observed that the text in 454 examples (47%"}, {"source": "2023.findings-eacl.35.pdf", "text": "of the data) for the memes dataset was upper-cased.\nSince our model is case-sensitive, we true-cased\nall instances to minimize the number of out-of-\nvocabulary words by the tokenizer.\n8https://docs.nvidia.com/cuda/cublas/\nindex.html\n9https://www.nltk.org/api/nltk.\ntokenize.html#module-nltk.tokenize.punkt\nNon-Propagandist Propagandist (all) Loaded language Name-calling0510152025"}, {"source": "2023.findings-eacl.35.pdf", "text": "Figure 2: Percentages of metaphorical open-class words\npredicted by multi-label MTL models in news articles\n(test set).\nNon-Propagandist Propagandist (all) Name-calling Loaded language01020304050607080\nFigure 3: Percentages of metaphorical open-class words\nas predicted by multi-label MTL models in social\nmemes (test set).\nModel F1 score\nMulti-label (news) 66.77 \u00b1 0.61"}, {"source": "2023.findings-eacl.35.pdf", "text": "Multi-label (news) 66.77 \u00b1 0.61\nName Calling (news) 62.95 \u00b1 2.05\nLoaded Language (news) 61.42 \u00b1 1.64\nMulti-label (memes) 64.09 \u00b1 4.63\nName Calling (memes) 56.23 \u00b1 4.68*\nLoaded Language (memes) 63.05 \u00b1 5.73\nTable 7: Metaphor F1 score performance for multi-task\nmodels. *The first five runs had a median of 60.79;\nhowever, adding five extra seeds brought it down to"}, {"source": "2023.findings-eacl.35.pdf", "text": "56.23.486Model / Propagandist Technique P R F1\nSingle-task learning\n- Appeal to Authority 7.58 1.14 1.67 \u00b1 0.80\n- Appeal to fear-prejudice 23.66 26.87 24.02 \u00b1 2.67\n- Bandwagon 0.00 0.00 0.00 \u00b1 0.00\n- Black-and-White Fallacy 8.16 14.97 10.20 \u00b1 2.48\n- Causal Oversimplification 4.11 8.02 5.14 \u00b1 1.91\n- Doubt 7.02 20.89 10.01 \u00b1 1.42\n- Exaggeration, Minimisation 18.16 24.25 20.16 \u00b1 2.12"}, {"source": "2023.findings-eacl.35.pdf", "text": "- Flag-Waving 31.66 49.44 37.83 \u00b1 3.44\n- Loaded Language 28.26 47.64 34.79 \u00b1 3.16\n- Name Calling 23.74 37.70 28.58 \u00b1 1.63\n- Obfuscation, Vagueness, Confusion 0.00 0.00 0.00 \u00b1 0.00\n- Red Herring 2.26 1.33 1.65 \u00b1 3.32\n- Reductio ad hitlerum 16.81 17.73 15.88 \u00b1 4.26\n- Repetition 9.82 6.75 7.23 \u00b1 1.76\n- Slogans 31.20 32.68 31.42 \u00b1 1.95\n- Straw Men 0.00 0.00 0.00 \u00b1 0.00"}, {"source": "2023.findings-eacl.35.pdf", "text": "- Straw Men 0.00 0.00 0.00 \u00b1 0.00\n- Thought-terminating Cliches 3.82 11.07 5.36 \u00b1 2.69\n- Whataboutism 13.42 4.73 5.56 \u00b1 3.67\nMulti-task learning\n- Appeal to Authority 5.57 0.95 1.50 \u00b1 1.02\n- Appeal to fear-prejudice 24.58 24.71 24.44 \u00b1 2.13\n- Bandwagon 0.00 0.00 0.00 \u00b1 0.00\n- Black-and-White Fallacy 9.05 11.47 9.72 \u00b1 3.44\n- Causal Oversimplification 5.39 8.42 6.35 \u00b1 1.88"}, {"source": "2023.findings-eacl.35.pdf", "text": "- Doubt 7.88 15.46 10.31 \u00b1 1.16\n- Exaggeration, Minimisation 19.82 21.13 20.29 \u00b1 1.06\n- Flag-Waving 34.16 46.40 39.16 \u00b1 1.76\n- Loaded Language 29.51 43.40 34.96 \u00b1 0.95\n- Name Calling 25.73 34.44 29.36 \u00b1 1.52\n- Obfuscation, Vagueness, Confusion 0.00 0.00 0.00 \u00b1 0.00\n- Red Herring 1.61 2.00 1.59 \u00b1 2.77\n- Reductio ad hitlerum 11.78 16.85 13.59 \u00b1 3.71\n- Repetition 10.03 4.54 6.12 \u00b1 1.98"}, {"source": "2023.findings-eacl.35.pdf", "text": "- Repetition 10.03 4.54 6.12 \u00b1 1.98\n- Slogans 35.35 31.94 32.74 \u00b1 5.45\n- Straw Men 0.00 0.00 0.00 \u00b1 0.00\n- Thought-terminating Cliches 6.18 13.57 8.32 \u00b1 3.72\n- Whataboutism 12.12 3.99 5.89 \u00b1 3.62\nTable 8: Performance on propaganda technique identifi-\ncation in news articles by multi-label models on every\ntechnique. The highest performance for each metric is"}, {"source": "2023.findings-eacl.35.pdf", "text": "in bold.Model / Propagandist Technique P R F1\nSingle-task learning\n- Appeal to authority 61.76 45.29 49.67 \u00b1 9.13\n- Appeal to fear/prejudice 16.17 6.82 9.05 \u00b1 7.45\n- Bandwagon 0.00 0.00 0.00 \u00b1 0.00\n- Black-and-white Fallacy 67.70 30.70 41.55 \u00b1 4.01\n- Causal Oversimplification 12.20 8.70 8.61 \u00b1 7.63\n- Doubt 45.90 13.95 20.98 \u00b1 6.92\n- Exaggeration/Minimisation 44.71 35.90 39.44 \u00b1 3.43"}, {"source": "2023.findings-eacl.35.pdf", "text": "- Flag-waving 52.13 35.18 40.88 \u00b1 8.91\n- Glittering generalities (Virtue) 33.83 6.74 9.92 \u00b1 7.09\n- Loaded Language 60.48 68.93 64.39 \u00b1 1.95\n- Name calling 52.90 55.88 54.21 \u00b1 3.23\n- Obfuscation, Vagueness, Confusion 0.00 0.00 0.00 \u00b1 0.00\n- Red Herring 0.00 0.00 0.00 \u00b1 0.00\n- Reductio ad hitlerum 0.00 0.00 0.00 \u00b1 0.00\n- Repetition 0.00 0.00 0.00 \u00b1 0.00\n- Slogans 32.74 25.58 27.75 \u00b1 6.00"}, {"source": "2023.findings-eacl.35.pdf", "text": "- Slogans 32.74 25.58 27.75 \u00b1 6.00\n- Smears 30.57 37.19 33.13 \u00b1 2.43\n- Straw Man 0.00 0.00 0.00 \u00b1 0.00\n- Thought-terminating clich\u00e9 23.33 10.16 13.43 \u00b1 10.76\n- Whataboutism 21.69 26.25 22.98 \u00b1 6.57\nMulti-task learning\n- Appeal to authority 51.53 50.93 49.52 \u00b1 6.90\n- Appeal to fear/prejudice 11.81 6.80 7.96 \u00b1 5.79\n- Bandwagon 0.00 0.00 0.00 \u00b1 0.00\n- Black-and-white Fallacy 42.31 28.17 33.23 \u00b1 5.65"}, {"source": "2023.findings-eacl.35.pdf", "text": "- Causal Oversimplification 13.55 19.10 12.74 \u00b1 7.71\n- Doubt 43.46 22.48 28.60 \u00b1 6.31\n- Exaggeration/Minimisation 37.45 39.07 37.40 \u00b1 5.86\n- Flag-waving 45.99 52.85 48.17 \u00b1 6.56\n- Glittering generalities (Virtue) 32.43 11.59 16.07 \u00b1 6.80\n- Loaded Language 56.68 68.82 61.51 \u00b1 2.90\n- Name calling 52.49 57.49 54.50 \u00b1 1.87\n- Obfuscation, Vagueness, Confusion 0.00 0.00 0.00 \u00b1 0.00"}, {"source": "2023.findings-eacl.35.pdf", "text": "- Red Herring 0.00 0.00 0.00 \u00b1 0.00\n- Reductio ad hitlerum 0.00 0.00 0.00 \u00b1 0.00\n- Repetition 10.42 12.50 11.25 \u00b1 19.65\n- Slogans 32.49 27.27 28.87 \u00b1 5.63\n- Smears 31.49 34.70 32.28 \u00b1 3.52\n- Straw Man 0.00 0.00 0.00 \u00b1 0.00\n- Thought-terminating clich\u00e9 12.87 5.42 6.72 \u00b1 6.86\n- Whataboutism 23.49 25.89 22.49 \u00b1 6.66\nTable 9: Performance on propaganda technique identifi-"}, {"source": "2023.findings-eacl.35.pdf", "text": "cation in memes by multi-label models on every tech-\nnique. The highest performance for each metric is in\nbold.\nDataset / Model P R F1\nNews\n- STL Multi-label 24.92 29.26 26.18 \u00b1 1.87\n- MTL Multi-label 26.41 26.59 26.39 \u00b1 0.78\n- STL Loaded Language 39.03 50.23 43.80 \u00b1 0.77\n- MTL Loaded Language 40.20 48.40 43.70 \u00b1 0.99\n- STL Name-Calling 30.32 38.29 33.67 \u00b1 0.88"}, {"source": "2023.findings-eacl.35.pdf", "text": "- MTL Name-Calling 30.96 38.68 34.08 \u00b1 0.62\nMemes\n- STL Multi-label 57.84 54.83 56.23 \u00b1 0.79\n- MTL Multi-label 54.75 56.68 55.59 \u00b1 1.20\n- STL Loaded Language 77.13 73.07 74.84 \u00b1 1.67\n- MTL Loaded Language 71.89 75.62 73.64 \u00b1 1.77\n- STL Name-Calling 71.71 69.33 70.32 \u00b1 1.91\n- MTL Name-Calling 74.56 71.66 72.88 \u00b1 1.65\nTable 10: Performance on the validation set for propa-"}, {"source": "2023.findings-eacl.35.pdf", "text": "ganda technique identification.487Task Parameter Values\nAlldropout 0.0\nLR scheduler cosine\nwarmup 10%\nweight decay 0.01\nNews - Multi labelbatch size 8, 16, 32\nlearning rate 1e-5, 3e-5, 4e-5, 5e-5\nmax epochs 35\npatience 7\ntask sampling ratio \u2217(1/6, 5/6), (1/5, 4/5) , (1/4, 3/4),\n(1/3, 2/3), (1/2, 1/2), (2/3, 1/3)\nepoch factor \u2217 (0.95, 1.0), (0.96, 1.0), (0.97, 1.0),"}, {"source": "2023.findings-eacl.35.pdf", "text": "(0.98, 1.0), (0.99, 1.0), (1.0, 1.0)\nNews - Name callingbatch size 16, 32\nlearning rate 5e-6, 1e-5, 3e-5, 5e-5\ntask sampling ratio \u2217(1/4, 3/4), (1/3, 2/3), (1/2, 1/2)\nepoch factor \u2217 (0.99, 1.0), (1.0, 1.0)\nNews - Loaded languagebatch size 16, 32\nlearning rate 5e-6, 1e-5, 3e-5, 5e-5\ntask sampling ratio \u2217(1/4, 3/4), (1/3, 2/3) , (1/2, 1/2)\nepoch factor \u2217 (0.99, 1.0), (1.0, 1.0)"}, {"source": "2023.findings-eacl.35.pdf", "text": "epoch factor \u2217 (0.99, 1.0), (1.0, 1.0)\nMemes - Multi labelbatch size 8, 16, 32\nlearning rate 1e-5, 3e-5, 4e-5, 5e-5\nmax epochs 150\npatience 50\nepoch factor \u2217 (0.98, 1.0), (0.99, 1.0) , (0.995, 1.0)\n(1.0, 1.0)\ntask sampling ratio \u2217(1/4, 3/4), (1/3, 2/3), (1/2, 1/2) ,\n(6/10, 4/10), (7/10, 3/10)\nloss scaling \u2217 (3/4, 1), (1, 1)\nMemes - Name callingbatch size 8, 16, 32"}, {"source": "2023.findings-eacl.35.pdf", "text": "learning rate 1e-5, 3e-5, 4e-5, 5e-5\ntask sampling ratio \u2217(1/5, 4/5), (1/4, 3/4) , (1/3, 2/3),\n(1/2, 1/2), (6/10, 4/10)\nepoch factor \u2217 (0.98, 1), (0.99, 1.0), (0.995, 1)\n(1.0, 1.0)\nloss scaling \u2217 (3/4, 1), (1, 1) , (5/4, 1)\n(1, 5/4), (1, 3/2)\nMemes - Loaded languagebatch size 8, 16, 32\nlearning rate 1e-5, 2e-5, 3e-5, 4e-5, 5e-5\ntask sampling ratio \u2217(1/5, 4/5), (1/4, 3/4), (1/3, 2/3)"}, {"source": "2023.findings-eacl.35.pdf", "text": "(1/2, 1/2), (6/10, 4/10), (7/10, 3/10)\n(4/5, 1/5)\nepoch factor \u2217 (0.98, 1.0), (0.99, 1.0) , (0.995, 1.0)\n(1.0, 1.0)\nloss scaling \u2217 (3/4, 1), (1, 1)\nTable 11: Best performance parameters after five runs are in bold. Multi-task parameters are identified with an\nasterisk, and their values belong to the auxiliary and main tasks.488Technique Example"}, {"source": "2023.findings-eacl.35.pdf", "text": "Appeal to authority \"... information released by investigative reporter Laura Loomer proves that\nauthorities have directly lied to the American people about the case at least\nonce ...\nAppeal to fear \"... students told her daughter that she was going to hell .\nBandwagon \"... the likelihood that this disease will move to other more densely populated"}, {"source": "2023.findings-eacl.35.pdf", "text": "regions of the planet has become a huge concern for many.\nBlack-and-white Fallacy Either you stand with BDS, Hamas, blood libels and those who want to\ndestroy Israel or with Jews.\nCausal Oversimplification On the other hand, it knows that by seeking continued secrecy, it\u2019s essentially\nan implicit acknowledgment of guilt."}, {"source": "2023.findings-eacl.35.pdf", "text": "an implicit acknowledgment of guilt.\nDoubt What happened during the 6 minutes between Campos being shot and Paddock\nopening fire, and why weren\u2019t the police rushing to the scene immediately?\nExaggeration/Minimisation Whatever definition that one might put on that nebulous term, no reasonable\nperson can honestly believe that the release of 50-year-old records are going to"}, {"source": "2023.findings-eacl.35.pdf", "text": "result in the United States falling into the ocean or even that the communists\nare going to take over the federal government.\nFlag-waving \"I want to get our soldiers out. I want to bring our soldiers back home,\" Trump\nsaid.\nGlittering generalities \"... to show the enormous, enthusiastic crowd in front of him ."}, {"source": "2023.findings-eacl.35.pdf", "text": "Loaded Language On both of their blogs the pair called their bans from entering the UK \" a striking\nblow against freedom \" and said the \" the nation that gave the world the Magna\nCarta is dead \".\nStraw Man His opinion is: \"Take it seriously, but with a large grain of salt.\" Which is just\nAllen\u2019s more nuanced way of saying: \"Don\u2019t believe it.\""}, {"source": "2023.findings-eacl.35.pdf", "text": "Name-calling \"It\u2019s embarrassing for this so-called land of democracy and freedom of\nspeech, \" he said.\nObfuscation Accordingly, he rushed to the defense of Bergoglio and his corrupt regime against\n\"a radicalization of religious conservatism in the neo-traditionalism sense ...\nRed Herring \"The jury of six men and six women, including three immigrants , found the\nMexican national not guilty ..."}, {"source": "2023.findings-eacl.35.pdf", "text": "Mexican national not guilty ...\nReductio ad Hitlerum Exactly what this \"special need\" is that can constitute a Gestapo like police\nstate surveilling its own citizens is a moving target that has already been proven\nto be abused over and over again.\nRepetition Take notice , Dutch Prime Minister Rutte. Take notice , Mrs. Merkel or President\nMacron. Take notice : the future is ours and not yours"}, {"source": "2023.findings-eacl.35.pdf", "text": "Slogans Christianity is Europe\u2019s last hope .\nSmears No honor, no integrity, no principles, no morals , ...\nThought-terminating clich\u00e9 This whole idea of a two-state solution, it doesn\u2019t work .\nWhataboutism \"They interpreted the law in my case to say it was criminal,\" Saucier told Fox\nNews, referring to prosecuting authorities in his case, \" but they didn\u2019t prosecute\nHillary Clinton ."}, {"source": "2023.findings-eacl.35.pdf", "text": "Hillary Clinton .\nTable 12: Examples of persuasion techniques are in bold.489"}, {"source": "2020.codi-1.8.pdf", "text": "Proceedings of the First Workshop on Computational Approaches to Discourse , pages 76\u201385\nOnline, November 20, 2020. c\r2020 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P1776DSNDM: Deep Siamese Neural Discourse Model with Attention for Text\nPairs Categorization and Ranking\nAlexander Chernyavskiy and Dmitry Ilvovsky\nNational Research University Higher School of Economics"}, {"source": "2020.codi-1.8.pdf", "text": "Moscow, Russia\nalschernyavskiy@gmail.com ;dilvovsky@hse.ru\nAbstract\nIn this paper, the utility and advantages of the\ndiscourse analysis for text pairs categorization\nand ranking are investigated. We consider two\ntasks in which discourse structure seems use-\nful and important: automatic veri\ufb01cation of po-\nlitical statements, and ranking in question an-\nswering systems. We propose a neural network"}, {"source": "2020.codi-1.8.pdf", "text": "based approach to learn the match between\npairs of discourse tree structures. To this end,\nthe neural TreeLSTM model is modi\ufb01ed to ef-\nfectively encode discourse trees and DSNDM\nmodel based on it is suggested to analyze pairs\nof texts. In addition, the integration of the at-\ntention mechanism in the model is proposed.\nMoreover, different ranking approaches are in-"}, {"source": "2020.codi-1.8.pdf", "text": "vestigated for the second task. In the paper,\nthe comparison with state-of-the-art methods\nis given. Experiments illustrate that combina-\ntion of neural networks and discourse structure\nin DSNDM is effective since it reaches top re-\nsults in the assigned tasks. The evaluation also\ndemonstrates that discourse analysis improves\nquality for the processing of longer texts.\n1 Introduction"}, {"source": "2020.codi-1.8.pdf", "text": "1 Introduction\nThe growing popularity of social networks and the\nwidespread use of social media contributed to the\nemergence of many NLP tasks associated with the\nprocessing of statements. It can be analyzed from\nan emotional point of view (sentiment analysis),\nopinion and argumentation mining, text summa-\nrization and so forth.\nDespite the success of the transformer-based neu-"}, {"source": "2020.codi-1.8.pdf", "text": "ral networks, such as BERT (Devlin et al., 2018)\nand its modi\ufb01cations, in various NLP tasks, they\nalso have disadvantages since they frequently ana-\nlyze only the plain text that can be quite long and\ncomplex. At the same time, discourse structure con-\ntains important knowledge for solving these tasks,\nand several researchers demonstrated its signi\ufb01-"}, {"source": "2020.codi-1.8.pdf", "text": "cance (Galitsky et al., 2015; Bhatia et al., 2015; Jiand Smith, 2017). However, the value of discourse\nhave been already investigated only for some single\ntext categorization tasks.\nIn this study, we demonstrate the utility and ad-\nvantages of the matching of discourse tree struc-\ntures of text pairs. Discourse analysis seems effec-\ntive in textual entailment, text simpli\ufb01cation and"}, {"source": "2020.codi-1.8.pdf", "text": "paraphrase detection tasks. However, it is neces-\nsary to analyze texts on the sentence level in most\ncases. We consider typical NLP tasks in which\ninput texts are quite long and paragraphs are given\ninitially.\nOne of such tasks is automatic veri\ufb01cation of fac-\ntual texts. Politicians may utilize unreliable state-\nments for their own purposes. Due to the fact that"}, {"source": "2020.codi-1.8.pdf", "text": "there are plenty of such statements, it should be\nautomatically evaluated for reliability and the pos-\nsibility of manipulation of public opinion. In most\ncases, it is possible to extract some con\ufb01rmation or\nrefutation for a given factual text. In this way, we\ninvestigate the utility of discourse analysis in the\nclassi\ufb01cation of pairs of texts: statements and their"}, {"source": "2020.codi-1.8.pdf", "text": "justi\ufb01cations. Discourse structure may contain cru-\ncial knowledge even for the classi\ufb01cation of the\nstatements alone but can be even more effective in\nthe case of analyzing additionally the con\ufb01rmations\nand refutations.\nApart from that, one of the most appropriate\ntasks is the ranking in question answering sys-\ntems. It was shown that discourse structure of ques-"}, {"source": "2020.codi-1.8.pdf", "text": "tions and correct answers should correlate (Galitsky\net al., 2015). Companies are interested in QA sys-\ntems development in order to maximize the ease of\ninteraction with customers. All questions can be\ndivided into two groups: factoid and non-factoid. It\nis important to answer factoid questions to provide\nsome speci\ufb01c information and non-factoid ones to"}, {"source": "2020.codi-1.8.pdf", "text": "maintain a dialogue. It is worth to emphasize that\nthe second task is more challenging because there\nis no single correct answer for each question. We77consider the non-factoid questions asked on Inter-\nnet forums since the discourse analysis seems to be\nmore helpful in this case.\nThe main technical idea of this paper is to com-\nbine discourse analysis and recursive neural net-"}, {"source": "2020.codi-1.8.pdf", "text": "work TreeLSTM (Tai et al., 2015), which previ-\nously obtained the state-of-the-art results in some\nsingle text classi\ufb01cation tasks.\nOur contributions can be formulated as the fol-\nlowing:\n\u000fWe propose a neural network approach to\nlearn the match between pairs of the discourse\ntree structures. To this end, we modify the\nbasic TreeLSTM model to effectively encode"}, {"source": "2020.codi-1.8.pdf", "text": "the discourse structure and propose DSNDM\n(Deep Siamese Neural Discourse Model) to\nanalyze pairs of texts.\n\u000fWe suggest the way of integration of the atten-\ntion mechanism in the DSNDM model.\n\u000fWe investigate the value of the proposed ap-\nproach considering two tasks and experimen-\ntally con\ufb01rm the utility and importance of dis-\ncourse analysis for the text pairs processing."}, {"source": "2020.codi-1.8.pdf", "text": "Our paper is organized as follows. Firstly, we\nsummarize related work and introduce some base\nconcepts. We continue with the description of the\nbase model and its modi\ufb01cations. Then, we discuss\nthe obtained results, error analysis and propose\ndirections for further research.\n2 Related Work\nThere are several approaches to solve the fact-\nchecking problem. The best models presented in"}, {"source": "2020.codi-1.8.pdf", "text": "the FEVER competition (Thorne et al., 2018) allo-\ncate a stage of extracting supporting or refuting in-\nformation and a classi\ufb01cation stage. Justi\ufb01cations\nhave already been extracted in our case. Therefore,\nthere is no need to use the \ufb01rst stage. The BERT\nmodel (Devlin et al., 2018) is frequently used as\nthe main model of the approach (Nie et al., 2019;"}, {"source": "2020.codi-1.8.pdf", "text": "Alonso-Reina et al., 2019). It is worth to emphasize\nthat BERT cannot process long texts (the sequence\nis limited to 512 tokens). Therefore, it is neces-\nsary to extract the key information from the given\njusti\ufb01cation paragraph. Besides, BERT can not\nef\ufb01ciently store and process discourse features.\nAnother approach uses knowledge graphs.\nClancy et al. (2019) proposed the use of relations"}, {"source": "2020.codi-1.8.pdf", "text": "between the entities of the graph in order to con\ufb01rmsome \u201cdistill\u201d information extracted from the state-\nment. Ciampaglia et al. (2015) suggested Knowl-\nedge Linker, the main idea of which is that if the\npath between entities in the knowledge graph is\nshort, then the factual text containing them is re-\nliable. It should be mentioned that this approach"}, {"source": "2020.codi-1.8.pdf", "text": "is generally applicable only to factoid statements\nsince the entities must exist within knowledge\ngraphs.\nFinally, we distinguish the third approach which\nconsiders structural information extracted from\ntexts (Wu et al., 2017; Galitsky and Ilvovsky, 2016).\nGalitsky et al. (2015) proposed to match discourse\ntrees and solved the categorization task using Tree"}, {"source": "2020.codi-1.8.pdf", "text": "Kernel-based SVM. However, this approach does\nnot utilize any modern neural networks. At the\nsame time, recursive neural networks are gaining\npopularity (Ji and Smith, 2017; Bhatia et al., 2015;\nTai et al., 2015). The main goal of them is to encode\ntree-like structures, such as syntax and discourse\ntrees. These models achieved superior results in the"}, {"source": "2020.codi-1.8.pdf", "text": "single text categorization tasks, but researchers did\nnot investigate the value of discourse analysis for\nprocessing pairs of texts. However, this approach is\npromising for the assigned task since frequently not\nonly unreliable texts have a similar discourse struc-\nture, but the discourse structure of texts refuting\nthem is also similar.\nThe main baselines for the question-answering"}, {"source": "2020.codi-1.8.pdf", "text": "problem are models that utilize keywords for rank-\ning: using TF-iDF, BM25 and its modi\ufb01cations\n(Okapi BM25, BM25F). Frequently, their results\nare bad enough and need to be re-ranked using\nmore complex methods. Neural network models,\nsuch as BERT, allow obtaining state-of-the-art re-\nsults (Hashemi et al., 2020). It should be mentioned\nhere that different training techniques of ranking"}, {"source": "2020.codi-1.8.pdf", "text": "are often not investigated.\nIn addition, some fact-checking approaches can\nbe applied in question answering systems. For\ninstance, Cui et al. (2017) and Liu et al. (2019) con-\nsidered the possibility of using knowledge graphs.\nGalitsky (2019) investigated the value of discourse\nanalysis in QA systems, but did not utilize any\nneural network approaches.\n3 Methods\n3.1 Discourse Tree Structure"}, {"source": "2020.codi-1.8.pdf", "text": "3 Methods\n3.1 Discourse Tree Structure\nAny text can be represented as a tree using the\nRhetorical Structure Theory (RST) proposed by\nMann and Thompson (1987). The tree is con-78\nElaboration\nElaboration\nElaboration\nContrast Condition\nWould ... wings again or they don't. Either ... (evolve)Wow, ... your mind.\nif they ... again?"}, {"source": "2020.codi-1.8.pdf", "text": "if they ... again?\nT ext: \"Wow, make up your mind. Either populations change over time (evolve) or they don't.\u00a0 Would your wingless beetles be\nable to produce wings again if they were somehow bene\ufb01cial again? Y ou are starting to sound like Darwin and his \ufb01nches.\"Yoy are ... \ufb01nches.Figure 1: Discourse tree for text from an Internet forum.\nstructed step by step from the leaves to the root."}, {"source": "2020.codi-1.8.pdf", "text": "Initially, the text is divided into several intervals,\ncalled elementary discourse units (EDUs). Each\nof them contains a single thought, which cannot\nbe broken more. Further, these intervals are con-\nnected by discourse relations such as \u201cElaboration\u201d,\n\u201cJoint\u201d and \u201cCondition\u201d. After the uni\ufb01cation of the\nelementary units, there are formed larger intervals"}, {"source": "2020.codi-1.8.pdf", "text": "of the text, which can be also connected by the cor-\nresponding discourse relations. This process can\nbe continued until the only one node will remain\n(the root of the tree).\nRST identi\ufb01es two types of vertices: \u201cNucleus\u201d\nand \u201cSatellite\u201d. Vertices of the \ufb01rst type contain\nthe crucial parts of the text, whereas, vertices of the\nsecond type provide some additional information."}, {"source": "2020.codi-1.8.pdf", "text": "Figure 1 demonstrates an example of a discourse\ntree for a text from an Internet forum.\n3.2 EDU Embeddings\nThe pretrained Deep Averaging Network was cho-\nsen to construct embeddings of elementary dis-\ncourse units (text spans). This model is a variation\nof the Universal Sentence Encoder, proposed by\nCer et al. (2018). DAN averages word embeddings"}, {"source": "2020.codi-1.8.pdf", "text": "and applies a stack of fully-connected layers to get\nthe \ufb01nal vector representation of the text.\nWe also consider parts-of-speech tags as addi-\ntional information about the text. We embed POS-\ntags as vectors using one-hot encoding.\nThe \ufb01nal vector representation of an EDU is the\nconcatenation of a semantic embedding from DAN\nand syntactic embedding constructed due to the\nPOS-tags."}, {"source": "2020.codi-1.8.pdf", "text": "POS-tags.\n3.2.1 Recursive Neural Network\nA recursive neural network encodes a tree as a\nvector of a \ufb01xed dimension. Similar to the tree con-\nstruction in RST, the encoding occurs recursively\nalong subtrees from leaves to root. The process ofobtaining an embedding of a subtree with the root\nin the nodeican be described as follows.\nLetxidenote the text embedding corresponding\nto the nodei.\nxi=("}, {"source": "2020.codi-1.8.pdf", "text": "to the nodei.\nxi=(\nEDU embedding, if iis the leaf\nEmbedding of the empty text, else\nText Encoder applies a fully-connected layer to\nthis pre-trained vector:\nText Enc(i) =FC(xi) (1)\nLet nodes denoted as jandkbe children indices\nfor the node i, andrbe the name of the discourse\nrelation that characterizes the link between them.\nDummy child vertices containing empty text are"}, {"source": "2020.codi-1.8.pdf", "text": "added for the leaves. The vector representation\nof the input associated with iconcatenates four\nvectors as follows:\nti=Concat [I[jis Nucleus ];I[kis Nucleus ];\nOneHot (r);Text Enc(i)](2)\nIn (2) Iis the indicator function.\nAn embedding of the tree which has root in the\nnodeiis computed based on embeddings of its\nleft and right subtrees due to the binary TreeLSTM\nmodel (Tai et al., 2015)."}, {"source": "2020.codi-1.8.pdf", "text": "model (Tai et al., 2015).\nhi=TreeLSTM (ti;hj;hk) (3)\nWe use TreeLSTM with dropout regularization\nof recurrent networks suggested by Semeniuta et al.\n(2016). Formally, the model is expressed with equa-\ntions (4), (5) and (6).\n0\nBBBB@ii\nfi0\nfi1\noi\nui1\nCCCCA=0\nBBBB@\u001b(Wi[ti;hj;hk] +bi)\n\u001b(Wf0[ti;hj;hk] +bf0)\n\u001b(Wf1[ti;hj;hk] +bf1)\n\u001b(Wo[ti;hj;hk] +bo)\nD(tanh(Wu[ti;hj;hk] +bu);\u000b)1\nCCCCA\n(4)79"}, {"source": "2020.codi-1.8.pdf", "text": "CCCCA\n(4)79\nLSTM LSTM LSTM LSTMLSTM LSTMLSTM\nLSTM LSTMLSTM LSTMLSTM\nFirst text (statement) Second text (justi\ufb01cation)ConcatenationFCFCPredicition\nDiscourse\ntree based\nstructureStatement embedding Justi\ufb01cation embedding\nDiscourse\ntree based\nstructureLSTM\nLSTMLSTM\nLSTM\nLSTM LSTM\nRST RST0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0\n0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a00\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7"}, {"source": "2020.codi-1.8.pdf", "text": "0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a00\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0 0\u20d7\u00a0\n0\u20d7\u00a0 0\u20d7\u00a00\u20d7\u00a0 0\u20d7\u00a0Figure 2: DSNDM model. Here, \u201cLSTM\u201d applies the TreeLSTM cell. Cells with the same color use the same\nweights. Each cell applied to EDUs receives zero vectors as embeddings of its children.\nci=cj\u0003fi0+ck\u0003fi1+ii\u0003ui (5)\nhi=oi\u0003ci (6)\nHere,\u001bis the sigmoid function, Dis the Dropout\nfunction,\u000bis the dropout rate and \u0003is the element-"}, {"source": "2020.codi-1.8.pdf", "text": "wise multiplication. The memory cell is denoted as\nc. There are two forget outputs since the trees are\nbinary.\nThe embedding received at the root of the tree is\nthe vector representation of the entire text.\n3.3 DSNDM\nWe propose DSNDM - siamese model based on the\nrecursive neural network. There are two stages of\nthe \ufb01nal model.\nFirstly, the embeddings of the discourse trees for"}, {"source": "2020.codi-1.8.pdf", "text": "each of the input texts are calculated. The trainable\nparameters for both texts are the same. At the next\nstage, the resulting embeddings are aggregated for\nsolving the categorization task. Here, the model\nconcatenates the calculated trees embeddings and\napplies a sequence of two fully-connected layers to\nit. The last layer utilizes the Softmax function to"}, {"source": "2020.codi-1.8.pdf", "text": "map input features to the class probability space.\nThe main advantage of the proposed model is\nthat it is capable of end-to-end learning. Figure 2\nshows the architecture of the model. In this case, it\nsolves the fact-checking problem. At the same time,\nit is almost the same for question-answer systems,\nexcept its inputs: the \ufb01rst text is a question, and the"}, {"source": "2020.codi-1.8.pdf", "text": "second is an answer.3.4 Integration of the Attention Mechanism\nWe suggest a way of the integration of the at-\ntention mechanism (Vaswani et al., 2017), which\nhas gained popularity in many NLP tasks. The\nmain idea is that a constructed embedding of a\nquestion/statement can be used to \ufb01lter informa-\ntion while constructing an embedding of an an-\nswer/justi\ufb01cation. Thus, at each step, the model"}, {"source": "2020.codi-1.8.pdf", "text": "decides information from which subtree is more\nuseful. The attention module can be integrated into\nthe equations of the TreeLSTM model as follows.\nLet us consider the Attention module, in which\nthe key is the vector kand the values are repre-\nsented by the matrix Q. In our case, the key is the\nembedding of the \ufb01rst text. The matrix Qis com-\nposed of vectors q1=cj\u0003fi0andq2=ck\u0003fi1"}, {"source": "2020.codi-1.8.pdf", "text": "posed of vectors q1=cj\u0003fi0andq2=ck\u0003fi1\nand has the dimension 2\u0002d, wheredis the di-\nmension of the memory vector. Then, instead of\nequation (5), the memory cell vector is recalculated\nusing attention matrices:\nci= 2\u0001Att(k;Q) +ii\u0003ui (7)\nAtt(k;Q) =SM0\n@jQjX\nj=1hWKk;W Q;qjiWVqj1\nA\n(8)\nHere, SM is the Softmax layer which is used\nfor normalization. In (7), multiplication by 2 is"}, {"source": "2020.codi-1.8.pdf", "text": "necessary to maintain a balance with equation (5).\nIn (8), matrices WK;WQandWVare trainable\nmatrices of parameters of the Attention module.80Equation (7) is utilized instead of (5) only to\nconstruct the embedding of the second text.\n3.5 Training Techniques for Ranking\nDSNDM can be used both in the text classi\ufb01cation\ntask and in the ranking task. In this paper, we"}, {"source": "2020.codi-1.8.pdf", "text": "investigate three ranking techniques.\n1) Classi\ufb01cation-based\nAll pairs in the dataset can be divided into two\ngroups based on relevance. The suggested model\ncan be applied to solve the binary classi\ufb01cation of\ntext pairs with these groups. The ranking of the\nanswers for each question is carried out using the\nclass probabilities predicted by the model. The ar-"}, {"source": "2020.codi-1.8.pdf", "text": "chitecture of the model completely coincides with\nthe base one in this case, and cross-entropy loss is\nused to train it.\n2) Pointwise ranking\nIn this case, the main task is the regression prob-\nlem. Letf(qi;ai)i=1::Ngis the set of the given\npairs, andfrigare the corresponding relevance\nscores. Let the proposed model is denoted as\nDSNDM (q;a;w ), whereware model parameters."}, {"source": "2020.codi-1.8.pdf", "text": "Then, the model minimizes the following loss:\nNX\ni=1(DSNDM (qi;ai;w)\u0000ri)2!min\nw(9)\n3) Pairwise ranking\nHere, the input are triplets f(qi;a+\ni;a\u0000\ni)i=1::Mg,\nwhere the relevant and irrelevant answer are se-\nlected for each question. These triplets can be\ngenerated from pairs using relevance scores. The\nranking model solves the regression problem and\nminimizes the loss from (11).\nPN(w) =DSNDM (qi;a+"}, {"source": "2020.codi-1.8.pdf", "text": "PN(w) =DSNDM (qi;a+\ni;w)\u0000DSNDM (qi;a\u0000\ni;w)\n(10)\nMX\ni=11\n1 + exp( PN(w) )!min\nw(11)\n4 Results\n4.1 Automatic Fact Veri\ufb01cation\n4.1.1 LIAR-PLUS dataset\nThis dataset (Alhindi et al., 2018) contains the state-\nments of politicians collected from politifact.com\nand labeled by experts, depending on the veracity\non a 6-point scale. Binary classi\ufb01cation is also pos-"}, {"source": "2020.codi-1.8.pdf", "text": "sible when all labels less than four indicate lie and\nthe rest indicate truth. The LIAR-PLUS dataset isan extension of the LIAR dataset. It contains auto-\nmatically extracted justi\ufb01cation for each statement.\nThe dataset also contains metadata with infor-\nmation about the politician and the global context\nof the statement. The LIAR-PLUS dataset can be"}, {"source": "2020.codi-1.8.pdf", "text": "used in four scenarios, depending on the restriction\non the available data: S (only statement is used), S\n+ M (statement and metadata), SJ (pairs: statement\nand justi\ufb01cation), and S + JM (all available data).\nThe model proposed in this paper is applied to pairs\nin the SJ scenario. At the same time, the model\ncan be also used in the S scenario utilizing only the\nrecursive neural network."}, {"source": "2020.codi-1.8.pdf", "text": "recursive neural network.\nThe dataset contains 12,782 statements which\nwere split into the train, validation and test samples\nin the ratio of 10:1:1. This dataset is balanced, and\nthe accuracy metric can be used to compare results.\n4.1.2 Implementation Details\nFirstly, text preprocessing was applied. We con-\nverted texts to lower case, removed extra characters"}, {"source": "2020.codi-1.8.pdf", "text": "and stop words. The open-source discourse parser\nALT (Joty et al., 2012) was applied to the prepos-\nsessed texts to obtain discourse trees. Finally, the\nconstructed trees were converted to the format de-\nscribed in section 3.1.\nWe used the DyNet python library to implement\nour model. The size of the hidden layer in LSTM\ncells was established at 100, the dropout rate"}, {"source": "2020.codi-1.8.pdf", "text": "at 0.1, the learning rate at 0.004 and the number\nof units in the fully-connected layer in the Text\nEncoder at the dimension of xi. We chose the Ada-\ngrad optimizer which is less prone to over\ufb01tting for\nthe assigned task. The optimal number of epochs\nis 4-9. The model was trained by mini-batches of\n150 pairs of texts.\n4.1.3 Experiments\nThe parser identi\ufb01ed 18 unique discourse rela-"}, {"source": "2020.codi-1.8.pdf", "text": "tions. The most popular relations are \u201cElaboration\u201d\n(is chosen by default), \u201cAttribution\u201d, \u201cJoint\u201d and\n\u201cSame-Unit\u201d. Usually, the trivial relations are pop-\nular in texts, and the ALT parser tends to use it in\nuncertain cases.\nWe investigated the difference between relation\ndistributions for the instances in \u201ctrue\u201d and \u201cpants-\n\ufb01re\u201d classes. The \u201cJoint\u201d relation is less common"}, {"source": "2020.codi-1.8.pdf", "text": "for truthful statements than for misleading state-\nments (relative frequencies are 0.064 and 0.073).\nThus, politicians tend to construct longer, complex\nsentences in the case of the deceptive statements.\nBesides, the \u201cAttribution\u201d relation is used more81Model Binary Six-way\nvalid test valid test\nLR 0.68 0.67 0.37 0.37\nSVM 0.65 0.66 0.34 0.34\nBiLSTM 0.70 0.68 0.34 0.31\nP-BiLSTM 0.69 0.67 0.36 0.35"}, {"source": "2020.codi-1.8.pdf", "text": "P-BiLSTM 0.69 0.67 0.36 0.35\nDSNDM 0.71 0.69 0.40 0.40\nDSNDM + Att. 0.70 0.71 0.40 0.41\nTable 1: Model performance (macro-avg. F1-score) on\nthe LIAR-PLUS dataset.\noften for truthful statements (frequencies are 0.17\nand 0.15). In the biggest part of cases, it indicates a\nlink to the source. Thus, the relations contain some\nimportant information by themselves."}, {"source": "2020.codi-1.8.pdf", "text": "important information by themselves.\nWe compared the model with the methods pro-\nposed in (Alhindi et al., 2018). In addition to\nwell-known baselines (such as linear regression\nand SVM), BiLSTM and P-BiLSTM are consid-\nered. The last one is the siamese model based on\nthe BiLSTM architecture. Table 1 demonstrates\nthe results for the 6-class and binary categorization\ntasks."}, {"source": "2020.codi-1.8.pdf", "text": "tasks.\nThe table shows that the DSNDM model signi\ufb01-\ncantly improves the results of baselines, especially\nin the case of the multiclass classi\ufb01cation.\nThe fully-connected layer in the Text Encoder\nis crucial since it adds up to 0.02 to accuracy. The\nusage of the POS-tags embeddings also improves\nthe overall quality approximately by 0.003-0.01.\nThe DSNDM model with the integrated attention"}, {"source": "2020.codi-1.8.pdf", "text": "module (denoted as DSNDM + Att.) reached the\nbest results for the test set. This improvement is not\nsigni\ufb01cant because of the binary structure of trees\n(the attention module re-weights only two vectors\nat each node).\n4.1.4 Error Analysis\nIt is worth emphasizing that in some case trees\nfor statements contain only one node. Therefore,\ndiscourse analysis does not suf\ufb01ce to categorize"}, {"source": "2020.codi-1.8.pdf", "text": "it. For the deepest trees which contain more than\n45 nodes in the statement and justi\ufb01cation in total\n(there are 89 such instances in the dataset), the\nF1-score metric is higher than 0.46.\nThe confusion matrix is shown in Figure 3. It\ndemonstrates that DSNDM mainly intermingles\nclose labels. However, at the same time, it confuses\nthe classes \u201cfalse\u201d and \u201ctrue\u201d in some cases."}, {"source": "2020.codi-1.8.pdf", "text": "We distinguish several types of such instances\nwhich are demonstrated in Table 3 (see Appendix\npants-firefalse\nmostly falsehalf-true\nmostly-truetrue\nPredicted labelpants-fire\nfalse\nmostly false\nhalf-true\nmostly-true\ntrueTrue label29 31 18 6 2 6\n20 114 31 34 11 40\n13 43 78 41 24 15\n5 52 31 93 51 35\n2 42 9 52 95 49\n10 29 11 13 30 118Figure 3: Confusion matrix for DSNDM + Att. model"}, {"source": "2020.codi-1.8.pdf", "text": "for the LIAR-PLUS dataset.\nA). Firstly, there are some cases when refutation\npartly repeats the statement. Then, the model with\nattention focuses mainly on the repeated part and\nmarks the misleading statement as \u201ctrue\u201d. Sec-\nondly, the justi\ufb01cation text can be extracted inaccu-\nrately and be not suf\ufb01cient to estimate the veracity\nof the statement. Apart from that, the justi\ufb01cation"}, {"source": "2020.codi-1.8.pdf", "text": "can be complex and contain only one useful sen-\ntence like in the third example. Finally, in the last\npair, justi\ufb01cation indicates that the statement can\nbe labeled as \u201cfalse\u201d in some general cases, but has\nthe label \u201ctrue\u201d in the considered case. Therefore,\nthis justi\ufb01cation contains useless thoughts and can\nbe provided more accurately.\nThus, the quality of the proposed model is lim-"}, {"source": "2020.codi-1.8.pdf", "text": "ited by several factors: the size of the discourse\ntrees, the quality of the discourse parser, and the\nquality of the provided justi\ufb01cations.\n4.2 Question Answering Systems\n4.2.1 ANTIQUE Dataset\nThis dataset (Hashemi et al., 2020) contains non-\nfactoid questions with a set of possible answers for\neach of them. The authors selected questions from\nthe Yahoo! Webscope L6 (nfL6) database. The"}, {"source": "2020.codi-1.8.pdf", "text": "questions were preliminary \ufb01ltered: short ques-\ntions, duplicates, and some complex cases were\nremoved.\nThe corpus contains 2,426 questions in the train-\ning sample and 200 in the test sample. Answers\nfor each question were selected both from the ques-\ntion forum thread and from other threads using"}, {"source": "2020.codi-1.8.pdf", "text": "the BM25 algorithm. In this way, 27,422 answers82were allocated for training, and 6,589 instances for\ntesting.\nThe resulting QA pairs were labeled on a 4-point\nscale depending on the relevance of answers using\nthe crowdsourcing procedure. The authors also pro-\nposed a binary classi\ufb01cation task where instances\nwith labels 1 and 2 can be considered as irrelevant,"}, {"source": "2020.codi-1.8.pdf", "text": "and instances with labels 3 and 4 can be considered\nas as relevant. Thus, the most common ranking\nmetrics such as MAP and MRR can be used in\nthe second task. At the same time, the multiclass\nmetric nDCG can be also considered. The number\nof the best answers for questions differs, but on\naverage it is approximately equal to 8.\nThe dataset is not balanced: the number of rele-"}, {"source": "2020.codi-1.8.pdf", "text": "vant answers is almost twice bigger than irrelevant\nones. The authors used a negative sampling proce-\ndure to train baseline models, increasing the size of\nthe dataset several times. However, it is important\nto emphasize that these additional QA pairs were\nnot included in the publicly available dataset.\nQuestions are not very long and contain about 11"}, {"source": "2020.codi-1.8.pdf", "text": "words on average. At the same time, the answers\nare much longer and contain more than 47 words\non average. Therefore, it can be problematic to use\nthe standard BERT model, but it is an advantage\nfor the discourse analysis.\n4.2.2 Implementation Details\nThe implementation details are almost the same\nas described in Sect. 4.1.2 except for some hy-\nperparameters. It is better to choose the smaller"}, {"source": "2020.codi-1.8.pdf", "text": "dimension of the hidden vectors. The dimension\nof vectors in TreeLSTM was set to 100, and in\nthe TextEncoder layer was set to 64. It takes 1-3\nepochs to achieve optimal quality. A tenth of the\ntraining set was used as a validation sample during\ntraining.\n4.2.3 Experiments\nThe discourse parser identi\ufb01ed 18 different dis-\ncourse relations like in the \ufb01rst task. However, in"}, {"source": "2020.codi-1.8.pdf", "text": "this case, the frequency statistics of relations are\nvery similar for different classes. It is due to the\nfact that in this task the second text (answer) is not\nauxiliary.\nWe compared the suggested model with the base-\nlines presented in (Hashemi et al., 2020). It should\nbe highlighted that these baselines were trained\non the extended dataset. The authors additionally"}, {"source": "2020.codi-1.8.pdf", "text": "performed the negative sampling procedure. There-\nfore, it is not correct to compare the results ob-Model MRR P@1\n1 BM25 0.4885 0.3333\nDRMM-TKS (2016) 0.5774 0.4337\naNMM (2016) 0.6250 0.4847\nBERT (2018) 0.7968 0.7092\n2 ConvKNRM [pairwise] 0.4920 0.3650\nBERT [pointwise] 0.6694 0.5550\nBERT [pairwise] 0.6999 0.5850\nTuned BM25 0.5802 0.4550\nTuned SDM 0.5377 0.4400\n3 Base [classif.] 0.6792 0.5350"}, {"source": "2020.codi-1.8.pdf", "text": "3 Base [classif.] 0.6792 0.5350\n+ Att. [classif.] 0.6830 0.5350\nBase [pointwise] 0.6864 0.5300\n+ Att. [pointwise] 0.7098 0.5650\nBase [pairwise] 0.7120 0.5800\n+ Att. [pairwise] 0.7267 0.6000\nTable 2: Model performance on the ANTIQUE test set.\n1: Models presented in (Hashemi et al., 2020), 2: Mod-\nels presented in (MacAvaney et al., 2020), 3: DSNDM"}, {"source": "2020.codi-1.8.pdf", "text": "tained on the available base dataset with the results\nobtained on the extended dataset.\nApart from that, we considered several models\ndiscussed in (MacAvaney et al., 2020). In this\npaper, several negative examples were also added\nfor each question. However, they were most likely\nselected only from the training corpus, since the\nauthors were unable to reproduce the BERT results"}, {"source": "2020.codi-1.8.pdf", "text": "from the original paper.\nMacAvaney et al. (2020) proposed various mod-\ni\ufb01cations of the training loss by adding a weight\nfor each pair. We do not compare with the results\nobtained with a modi\ufb01ed curriculum since we con-\nsider only the basic pointwise and pairwise losses.\nThe comparison results are presented in Table\n2. It shows that DSNDM + Att. model trained"}, {"source": "2020.codi-1.8.pdf", "text": "using pairwise loss achieves high MRR and P@1\nmetrics. Its results are superior to the results of\nthe best BERT model presented in (MacAvaney\net al., 2020). We also trained BERT ourselves and\nobtained results close to it, and we could not repro-\nduce the results from the original paper too. Also,\nthe pointwise ranking performed better than the\nclassi\ufb01cation-based method."}, {"source": "2020.codi-1.8.pdf", "text": "classi\ufb01cation-based method.\nThe attention mechanism improved quality in\nall cases, especially for the pointwise and pairwise\ntechniques.\n4.2.4 Error Analysis\nWe investigated the mistakes of DSNDM trained\nfor the classi\ufb01cation problem. Figure 4 shows the83\n0.70 0.75 0.80 0.85 0.90 0.95\nLower bound of the predicted probability1.721.741.761.78Number of nodes in question trees\nCorrect predictions"}, {"source": "2020.codi-1.8.pdf", "text": "Correct predictions\nWrong predictions\n0.70 0.75 0.80 0.85 0.90 0.95\nLower bound of the predicted probability14151617181920Number of nodes in answer trees\nCorrect predictions\nWrong predictionsFigure 4: Dependence of the number of nodes in the\ndiscourse trees of questions (on the top) and answers\n(on the bottom) on the con\ufb01dence of DSNDM in cases\nof correct and wrong predictions."}, {"source": "2020.codi-1.8.pdf", "text": "of correct and wrong predictions.\ndependence of the average number of nodes in\nquestions/answers on the con\ufb01dence of the model.\nThresholds are moved along the horizontal axis.\nStatistics are calculated only for pairs for which\nthe model predicts a probability that exceeds the\nselected threshold. One can see that for both ques-\ntions and answers, the number of nodes in dis-"}, {"source": "2020.codi-1.8.pdf", "text": "course trees for correctly classi\ufb01ed pairs is greater\nthan for incorrectly classi\ufb01ed ones. Thus, DSNDM\nmakes wrong predictions mostly for small trees.\nAlso, the plot for questions demonstrates that the\nmodel\u2019s greater con\ufb01dence in the wrong answer is\nfrequently triggered by the smaller size of the ques-\ntion tree. Therefore, the quality of the proposed"}, {"source": "2020.codi-1.8.pdf", "text": "model is closely related to the size of the discourse\ntrees for this task too.\nIn this case, we distinguish several typical mis-\ntakes which are demonstrated in Table 4 (see Ap-\npendix A). In the \ufb01rst pair, the question contains\nonly a few signi\ufb01cant keywords, and the model\nfocuses mainly on them. Despite the fact that the\nanswer is irrelevant and unrelated to the question"}, {"source": "2020.codi-1.8.pdf", "text": "area, it often uses the same keywords. Thus, similar\nEDU embeddings do not contribute to the correctclassi\ufb01cation. In the second example, the meaning\nof the answer and the question is the opposite. That\nis, despite the correctness of the answer, its text\nrefutes the information in the question. If the ques-\ntion contains only one node, then such instance is"}, {"source": "2020.codi-1.8.pdf", "text": "one of the most dif\ufb01cult for analysis. Finally, the\nlast example demonstrates that in some cases the\ncorrect answers may be formulated in the way not\nexpected by the authors of the questions. Thus, the\nquality of the model is also limited by the variabil-\nity of possible answers.\n5 Conclusion and Future Work\nIn this paper, we investigated the utility and impor-"}, {"source": "2020.codi-1.8.pdf", "text": "tance of the discourse analysis for text pairs cate-\ngorization and ranking. We considered two typical\ntasks in which discourse analysis seems promising:\nautomatic veri\ufb01cation of political statements and\nranking in question answering systems.\nWe modi\ufb01ed TreeLSTM to effectively encode\ndiscourse trees and proposed DSNDM which is ca-\npable of processing pairs of texts. In addition, the"}, {"source": "2020.codi-1.8.pdf", "text": "integration of the attention mechanism in the pro-\nposed model was suggested to obtain more useful\nembeddings of subtrees. Moreover, we investigated\nthree training techniques for the ranking task.\nThe experiments were performed on the LIAR-\nPLUS and ANTIQUE datasets. DSNDM ef\ufb01ciently\nlearned the match between discourse tree structures\nand achieved high quality in both tasks. Besides,"}, {"source": "2020.codi-1.8.pdf", "text": "the attention module improved the metrics of the\nbase model in all cases. The error analysis showed\nthat the model processes deeper trees more success-\nfully.\nThere are possible directions for future work:\nthe use of trees not only of a binary structure, the\nmodi\ufb01cation of vector representations of EDUs,\nas well as the investigation of the performance of"}, {"source": "2020.codi-1.8.pdf", "text": "DSNDM in other various tasks where discourse\nanalysis may be helpful, e.g. machine translation,\nchat-bots and other QA systems. Apart from that,\nwe will experiment with other hierarchical struc-\ntures (e.g. syntactic) for deeper analysis of the\nimportance of the RST-based structure in the pro-\nposed model.\nAcknowledgments\nThe article was prepared within the framework"}, {"source": "2020.codi-1.8.pdf", "text": "of the HSE University Basic Research Program\nand funded by the Russian Academic Excellence\nProject \u20195-100\u2019.84References\nTariq Alhindi, Savvas Petridis, and Smaranda Mure-\nsan. 2018. Where is your evidence: Improving fact-\nchecking by justi\ufb01cation modeling. pages 85\u201390.\nAim\u00b4ee Alonso-Reina, Robiert Sep \u00b4ulveda-Torres, Es-\ntela Saquete, and Manuel Palomar. 2019. Team"}, {"source": "2020.codi-1.8.pdf", "text": "GPLSI. approach for automated fact checking. In\nProceedings of the Second Workshop on Fact Ex-\ntraction and VERi\ufb01cation (FEVER) , pages 110\u2013114,\nHong Kong, China. Association for Computational\nLinguistics.\nParminder Bhatia, Yangfeng Ji, and Jacob Eisen-\nstein. 2015. Better document-level sentiment\nanalysis from RST discourse parsing. CoRR ,\nabs/1509.01599."}, {"source": "2020.codi-1.8.pdf", "text": "abs/1509.01599.\nDaniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua,\nNicole Limtiaco, Rhomni St. John, Noah Con-\nstant, Mario Guajardo-Cespedes, Steve Yuan, Chris\nTar, Yun-Hsuan Sung, Brian Strope, and Ray\nKurzweil. 2018. Universal sentence encoder. CoRR ,\nabs/1803.11175.\nGiovanni Luca Ciampaglia, Prashant Shiralkar,\nLuis Mateus Rocha, Johan Bollen, Filippo Menczer,"}, {"source": "2020.codi-1.8.pdf", "text": "and Alessandro Flammini. 2015. Computational\nfact checking from knowledge networks. PLoS\nONE , 10.\nRyan Clancy, Ihab F. Ilyas, and Jimmy Lin. 2019. Scal-\nable knowledge graph construction from text collec-\ntions. In Proceedings of the Second Workshop on\nFact Extraction and VERi\ufb01cation (FEVER) , pages\n39\u201346, Hong Kong, China. Association for Compu-\ntational Linguistics."}, {"source": "2020.codi-1.8.pdf", "text": "tational Linguistics.\nWanyun Cui, Yanghua Xiao, Haixun Wang, Yangqiu\nSong, Seung-won Hwang, and Wei Wang. 2017.\nKbqa: Learning question answering over qa corpora\nand knowledge bases. Proceedings of the VLDB En-\ndowment , 10:565\u2013576.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. BERT: pre-training of\ndeep bidirectional transformers for language under-"}, {"source": "2020.codi-1.8.pdf", "text": "standing. CoRR , abs/1810.04805.\nBoris Galitsky. 2019. Learning Discourse-Level Struc-\ntures for Question Answering , pages 177\u2013219.\nBoris Galitsky and Dmitry Ilvovsky. 2016. Discover-\ning disinformation: discourse level approach. In\n15th National Conference on Arti\ufb01cial Intelligence\nwith International Participation (CAI) , pages 23\u201332.\nBoris Galitsky, Dmitry Ilvovsky, and Sergei O."}, {"source": "2020.codi-1.8.pdf", "text": "Kuznetsov. 2015. Text classi\ufb01cation into abstract\nclasses based on discourse structure. In RANLP ,\npages 200\u2013207.\nJiafeng Guo, Yixing Fan, Qingyao Ai, and W. Croft.\n2016. A deep relevance matching model for ad-hoc\nretrieval. pages 55\u201364.Helia Hashemi, Mohammad Aliannejadi, Hamed Za-\nmani, and W. Bruce Croft. 2020. Antique: A non-\nfactoid question answering benchmark. In Advances"}, {"source": "2020.codi-1.8.pdf", "text": "in Information Retrieval , pages 166\u2013173, Cham.\nSpringer International Publishing.\nYangfeng Ji and Noah A. Smith. 2017. Neural dis-\ncourse structure for text categorization. CoRR ,\nabs/1702.01829.\nSha\ufb01q Joty, Giuseppe Carenini, and Raymond Ng.\n2012. A novel discriminative framework for\nsentence-level discourse analysis. In Proceedings\nof the 2012 Joint Conference on Empirical Methods"}, {"source": "2020.codi-1.8.pdf", "text": "in Natural Language Processing and Computational\nNatural Language Learning , pages 904\u2013915, Jeju Is-\nland, Korea. Association for Computational Linguis-\ntics.\nAiting Liu, Ziqi Huang, Hengtong Lu, Xiaojie Wang,\nand Caixia Yuan. 2019. BB-KBQA: BERT-Based\nKnowledge Base Question Answering , pages 81\u201392.\nSean MacAvaney, Franco Maria Nardini, Raffaele\nPerego, Nicola Tonellotto, Nazli Goharian, and"}, {"source": "2020.codi-1.8.pdf", "text": "Ophir Frieder. 2020. Training curricula for open do-\nmain answer re-ranking. pages 529\u2013538.\nWilliam Mann and Sandra Thompson. 1987. Rhetori-\ncal structure theory: A theory of text organization.\nYixin Nie, Haonan Chen, and Mohit Bansal. 2019.\nCombining fact extraction and veri\ufb01cation with neu-\nral semantic matching networks. In AAAI .\nStanislau Semeniuta, Aliaksei Severyn, and Erhardt"}, {"source": "2020.codi-1.8.pdf", "text": "Barth. 2016. Recurrent dropout without memory\nloss. CoRR , abs/1603.05118.\nKai Sheng Tai, Richard Socher, and Christopher D.\nManning. 2015. Improved semantic representations\nfrom tree-structured long short-term memory net-\nworks. CoRR , abs/1503.00075.\nJames Thorne, Andreas Vlachos, Oana Cocarascu,\nChristos Christodoulopoulos, and Arpit Mittal. 2018.\nThe fact extraction and VERi\ufb01cation (FEVER)"}, {"source": "2020.codi-1.8.pdf", "text": "shared task. In Proceedings of the First Workshop on\nFact Extraction and VERi\ufb01cation (FEVER) , pages\n1\u20139, Brussels, Belgium. Association for Computa-\ntional Linguistics.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need.\nYou Wu, Pankaj K. Agarwal, Chengkai Li, Jun Yang,"}, {"source": "2020.codi-1.8.pdf", "text": "and Cong Yu. 2017. Computational fact checking\nthrough query perturbations. ACM Transactions on\nDatabase Systems (TODS) , 42:1 \u2013 41.\nLiu Yang, Qingyao Ai, Jiafeng Guo, and W. Croft.\n2016. anmm: Ranking short answer texts with\nattention-based neural matching model. pages 287\u2013\n296.85A Appendix\nAppendix contains typical examples of pairs for which DSNDM got wrong predictions."}, {"source": "2020.codi-1.8.pdf", "text": "Statement Justi\ufb01cation Label\nIn rural Virginia, Sen.\nWarner ran 8 - 10 points\nahead of a traditional\nDemocrat \u2013 ahead of\nSenator Kaine, ahead of\nGovernor McAuliffe.Hallock said Warner, in this fall\u2019s Senate election, ran 8 - 10 points\nahead of past performances by fellow Democrats McAuliffe and\nKaine in rural Virginia. McAuliffe\u2019s portion of the rural vote, in"}, {"source": "2020.codi-1.8.pdf", "text": "his 2013 gubernatorial victory, was 3.6 percentage points below\nWarner\u2019s. Kaine\u2019s slice of the rural vote, in his 2012 Senate win,\nwas 2.4 percentage points above Warner\u2019s.false\nIn the U. S. Constitu-\ntion, theres a little sec-\ntion in there that talks\nabout life, liberty and\nthe pursuit of happiness.No court makes a legal decision based on the Declaration of In-"}, {"source": "2020.codi-1.8.pdf", "text": "dependence, Wilkes said. With his \ufb01rst speech as a bona \ufb01de\ncandidate, Cain joins a long, bipartisan line of presidential hope-\nfuls who have succumbed to foot - in - mouth disease. They include\nCain\u2019s foe, President Barack Obama, who accidentally said there\nwere 57 states during the 2008 campaign and U. S. Sen. John\nMcCain, who said in an interview he was unsure how many houses"}, {"source": "2020.codi-1.8.pdf", "text": "he owned. Welcome to the 2012 presidential election season, folks.false\nIn the Illinois Legis-\nlature, Barack Obama\nvoted present, instead\nof yes or no on seven\nvotes involving abortion\nrights.Two other large groups, NARAL Prochoice America and Planned\nParenthood, are not endorsing. Planned Parenthood, however,\nhas given both candidates 100 percent ratings for their records on"}, {"source": "2020.codi-1.8.pdf", "text": "abortion. We stipulate that there are clearly different interpretations\nof the signi\ufb01cance of Obama s present votes. But there s no doubt\nhe made them.true\nAs a result of climate\nchange, ice \ufb01shermen\nin Wisconsin are already\nnoticing fewer days they\ncan be out on our ice\ncovered lakes.Not what is going to happen this year. Our rating It\u2019s been a longer"}, {"source": "2020.codi-1.8.pdf", "text": "and colder winter than in recent years. But that doesn\u2019t erase a\ntrend that\u2019s been well - established. The number of days that the\nlakes have ice on them \u2013 making them safe for ice \ufb01shing \u2013 has\ndeclined.true\nTable 3: Typical mistakes of DSNDM on the LIAR test set where the model confuses \u201ctrue\u201d and \u201cfalse\u201d instances.\nQuestion Answer Label\nhow does dis-\nneyland make"}, {"source": "2020.codi-1.8.pdf", "text": "how does dis-\nneyland make\nit snow?Well if you are using snow, just lay on you back in it and move your arms\nfrom your sides to the top of you head and open and close you legs a few\ntimes... to make snow angels!!!!Out of\ncontext\nWhy cant\nteenagers\nvote?Teens can vote. When theyre 18 and 19... Teens still have ALOT to learn.\nThere is nothing wrong or demeaning about this. Even most ADULTS"}, {"source": "2020.codi-1.8.pdf", "text": "have alot to learn about politics. They go into a voting booth having no\nidea what party stands for what, or what candidate believes in what, and\nvote Democrat when their beliefs are Republican, or vote Republican\nwhen their beliefs are Democrat.Correct\nanswer\nWhy is Gor-\ndon Ramsey so\npopular?Is he that popular? what little I have seen of him every second word is"}, {"source": "2020.codi-1.8.pdf", "text": "a swear word, if that makes him popular then it says a lot about what is\nwrong in this country... the man is a cretin.Correct\nanswer\nTable 4: Typical mistakes of DSNDM on the ANTIQUE test set where the model confuses \u201cCorrect answer\u201d and\n\u201cOut of context\u201d instances. ."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Published as a conference paper at ICLR 2021\nDEBERT A: D ECODING -ENHANCED BERT WITH DIS-\nENTANGLED ATTENTION\nPengcheng He1, Xiaodong Liu2, Jianfeng Gao2, Weizhu Chen1\n1Microsoft Dynamics 365 AI2Microsoft Research\n{penhe,xiaodl,jfgao,wzchen}@microsoft.com\nABSTRACT\nRecent progress in pre-trained neural language models has signi\ufb01cantly improved"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "the performance of many natural language processing (NLP) tasks. In this pa-\nper we propose a new model architecture DeBERTa (Decoding- enhanced BERT\nwith disentangled attention) that improves the BERT and RoBERTa models using\ntwo novel techniques. The \ufb01rst is the disentangled attention mechanism, where\neach word is represented using two vectors that encode its content and position,"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "respectively, and the attention weights among words are computed using disen-\ntangled matrices on their contents and relative positions, respectively. Second,\nan enhanced mask decoder is used to incorporate absolute positions in the de-\ncoding layer to predict the masked tokens in model pre-training. In addition, a\nnew virtual adversarial training method is used for \ufb01ne-tuning to improve models\u2019"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "generalization. We show that these techniques signi\ufb01cantly improve the ef\ufb01ciency\nof model pre-training and the performance of both natural language understand\n(NLU) and natural langauge generation (NLG) downstream tasks. Compared\nto RoBERTa-Large, a DeBERTa model trained on half of the training data per-\nforms consistently better on a wide range of NLP tasks, achieving improvements"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "on MNLI by +0.9% (90.2% vs. 91.1%), on SQuAD v2.0 by +2.3% (88.4% vs.\n90.7%) and RACE by +3.6% (83.2% vs. 86.8%). Notably, we scale up DeBERTa\nby training a larger version that consists of 48 Transform layers with 1.5 bil-\nlion parameters. The signi\ufb01cant performance boost makes the single DeBERTa\nmodel surpass the human performance on the SuperGLUE benchmark (Wang et al.,"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "2019a) for the \ufb01rst time in terms of macro-average score (89.9 versus 89.8), and\nthe ensemble DeBERTa model sits atop the SuperGLUE leaderboard as of Jan-\nuary 6, 2021, outperforming the human baseline by a decent margin (90.3 versus\n89.8). The pre-trained DeBERTa models and the source code were released at:\nhttps://github.com/microsoft/DeBERTa1.\n1 I NTRODUCTION"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "1 I NTRODUCTION\nThe Transformer has become the most effective neural network architecture for neural language\nmodeling. Unlike recurrent neural networks (RNNs) that process text in sequence, Transformers\napply self-attention to compute in parallel every word from the input text an attention weight that\ngauges the in\ufb02uence each word has on another, thus allowing for much more parallelization than"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "RNNs for large-scale model training (Vaswani et al., 2017). Since 2018, we have seen the rise of a\nset of large-scale Transformer-based Pre-trained Language Models (PLMs), such as GPT (Radford\net al., 2019; Brown et al., 2020), BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019c), XLNet\n(Yang et al., 2019), UniLM (Dong et al., 2019), ELECTRA (Clark et al., 2020), T5 (Raffel et al.,"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "2020), ALUM (Liu et al., 2020), StructBERT (Wang et al., 2019c) and ERINE (Sun et al., 2019) .\nThese PLMs have been \ufb01ne-tuned using task-speci\ufb01c labels and created new state of the art in many\ndownstream natural language processing (NLP) tasks (Liu et al., 2019b; Minaee et al., 2020; Jiang\net al., 2020; He et al., 2019a;b; Shen et al., 2020)."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "1Our code and models are also available at HuggingFace Transformers: https://github.com/\nhuggingface/transformers ,https://huggingface.co/models?filter=deberta\n1Published as a conference paper at ICLR 2021\nIn this paper, we propose a new Transformer-based neural language model DeBERTa (Decoding-\nenhanced BERT with disentangled attention), which improves previous state-of-the-art PLMs using"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "two novel techniques: a disentangled attention mechanism, and an enhanced mask decoder.\nDisentangled attention. Unlike BERT where each word in the input layer is represented using\na vector which is the sum of its word (content) embedding and position embedding, each word in\nDeBERTa is represented using two vectors that encode its content and position, respectively, and the"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "attention weights among words are computed using disentangled matrices based on their contents\nand relative positions, respectively. This is motivated by the observation that the attention weight of a\nword pair depends on not only their contents but their relative positions. For example, the dependency"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "between the words \u201cdeep\u201d and \u201clearning\u201d is much stronger when they occur next to each other than\nwhen they occur in different sentences.\nEnhanced mask decoder. Like BERT, DeBERTa is pre-trained using masked language modeling\n(MLM). MLM is a \ufb01ll-in-the-blank task, where a model is taught to use the words surrounding a"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "mask token to predict what the masked word should be. DeBERTa uses the content and position\ninformation of the context words for MLM. The disentangled attention mechanism already considers\nthe contents and relative positions of the context words, but not the absolute positions of these words,\nwhich in many cases are crucial for the prediction. Consider the sentence \u201ca new store opened beside"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "the new mall\u201d with the italicized words \u201cstore\u201d and \u201cmall\u201d masked for prediction. Although the local\ncontexts of the two words are similar, they play different syntactic roles in the sentence. (Here, the\nsubject of the sentence is \u201cstore\u201d not \u201cmall,\u201d for example.) These syntactical nuances depend, to a"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "large degree, upon the words\u2019 absolute positions in the sentence, and so it is important to account\nfor a word\u2019s absolute position in the language modeling process. DeBERTa incorporates absolute\nword position embeddings right before the softmax layer where the model decodes the masked words\nbased on the aggregated contextual embeddings of word contents and positions."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "In addition, we propose a new virtual adversarial training method for \ufb01ne-tuning PLMs to downstream\nNLP tasks. The method is effective in improving models\u2019 generalization.\nWe show through a comprehensive empirical study that these techniques substantially improve the\nef\ufb01ciency of pre-training and the performance of downstream tasks. In the NLU tasks, compared to"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "RoBERTa-Large, a DeBERTa model trained on half the training data performs consistently better\non a wide range of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%), on\nSQuAD v2.0 by +2.3%(88.4% vs. 90.7%), and RACE by +3.6% (83.2% vs. 86.8%). In the NLG\ntasks, DeBERTa reduces the perplexity from 21.6 to 19.5 on the Wikitext-103 dataset. We further"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "scale up DeBERTa by pre-training a larger model that consists of 48 Transformer layers with 1.5\nbillion parameters. The single 1.5B-parameter DeBERTa model substantially outperforms T5 with 11\nbillion parameters on the SuperGLUE benchmark (Wang et al., 2019a) by 0.6%(89.3% vs. 89.9%),\nand surpasses the human baseline (89.9 vs. 89.8) for the \ufb01rst time. The ensemble DeBERTa model"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "sits atop the SuperGLUE leaderboard as of January 6, 2021, outperforming the human baseline by a\ndecent margin (90.3 versus 89.8).\n2 B ACKGROUND\n2.1 T RANSFORMER\nA Transformer-based language model is composed of stacked Transformer blocks (Vaswani et al.,\n2017). Each block contains a multi-head self-attention layer followed by a fully connected positional"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "feed-forward network. The standard self-attention mechanism lacks a natural way to encode word\nposition information. Thus, existing approaches add a positional bias to each input word embedding\nso that each input word is represented by a vector whose value depends on its content and position.\nThe positional bias can be implemented using absolute position embedding (Vaswani et al., 2017;"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Radford et al., 2019; Devlin et al., 2019) or relative position embedding (Huang et al., 2018; Yang\net al., 2019). It has been shown that relative position representations are more effective for natural\nlanguage understanding and generation tasks (Dai et al., 2019; Shaw et al., 2018). The proposed\ndisentangled attention mechanism differs from all existing approaches in that we represent each"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "input word using two separate vectors that encode a word\u2019s content and position, respectively, and\n2Published as a conference paper at ICLR 2021\nattention weights among words are computed using disentangled matrices on their contents and\nrelative positions, respectively.\n2.2 M ASKED LANGUAGE MODEL\nLarge-scale Transformer-based PLMs are typically pre-trained on large amounts of text to learn"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "contextual word representations using a self-supervision objective, known as Masked Language\nModel (MLM) (Devlin et al., 2019). Speci\ufb01cally, given a sequence X\u0010txiu, we corrupt it into\n~Xby masking 15% of its tokens at random and then train a language model parameterized by \u0012to\nreconstructXby predicting the masked tokens ~xconditioned on ~X:\nmax\n\u0012logp\u0012pX|~Xq\u0010max\n\u0012\u00b8\niPClogp\u0012p~xi\u0010xi|~Xq(1)"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "\u0012\u00b8\niPClogp\u0012p~xi\u0010xi|~Xq(1)\nwhereCis the index set of the masked tokens in the sequence. The authors of BERT propose to keep\n10% of the masked tokens unchanged, another 10% replaced with randomly picked tokens and the\nrest replaced with the [MASK] token.\n3 T HEDEBERT AARCHITECTURE\n3.1 D ISENTANGLED ATTENTION : A T WO-VECTOR APPROACH TO CONTENT AND POSITION\nEMBEDDING"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "EMBEDDING\nFor a token at position iin a sequence, we represent it using two vectors, tHiuandtPi|ju, which\nrepresent its content and relative position with the token at position j, respectively. The calculation of\nthe cross attention score between tokens iandjcan be decomposed into four components as\nAi;j\u0010tHi;Pi|ju\u0002tHj;Pj|iu|\n\u0010HiH|\nj\u0000HiP|\nj|i\u0000Pi|jH|\nj\u0000Pi|jP|\nj|i(2)"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "\u0010HiH|\nj\u0000HiP|\nj|i\u0000Pi|jH|\nj\u0000Pi|jP|\nj|i(2)\nThat is, the attention weight of a word pair can be computed as a sum of four attention scores\nusing disentangled matrices on their contents and positions as content-to-content ,content-to-position ,\nposition-to-content , and position-to-position2.\nExisting approaches to relative position encoding use a separate embedding matrix to compute the"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "relative position bias in computing attention weights (Shaw et al., 2018; Huang et al., 2018). This\nis equivalent to computing the attention weights using only the content-to-content and content-to-\nposition terms in equation 2. We argue that the position-to-content term is also important since the\nattention weight of a word pair depends not only on their contents but on their relative positions,"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "which can only be fully modeled using both the content-to-position and position-to-content terms.\nSince we use relative position embedding, the position-to-position term does not provide much\nadditional information and is removed from equation 2 in our implementation.\nTaking single-head attention as an example, the standard self-attention operation (Vaswani et al.,\n2017) can be formulated as:"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "2017) can be formulated as:\nQ\u0010HWq;K\u0010HWk;V\u0010HWv;A\u0010QK|\n?\nd\nHo\u0010softmaxpAqV\nwhereHPRN\u0002drepresents the input hidden vectors, HoPRN\u0002dthe output of self-attention,\nWq;Wk;WvPRd\u0002dthe projection matrices, APRN\u0002Nthe attention matrix, Nthe length of the\ninput sequence, and dthe dimension of hidden states.\nDenotekas the maximum relative distance, \u000epi;jqPr0;2kqas the relative distance from token ito"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "tokenj, which is de\ufb01ned as:\n\u000epi;jq\u0010#0 fori\u0001j\u00a4\u0001k\n2k\u00011 fori\u0001j\u00a5k\ni\u0001j\u0000kothers:(3)\n2In this sense, our model shares some similarity to Tensor Product Representation (Smolensky, 1990; Schlag\net al., 2019; Chen et al., 2019) where a word is represented using a tensor product of its \ufb01ller (content) vector\nand its role (position) vector.\n3Published as a conference paper at ICLR 2021"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "We can represent the disentangled self-attention with relative position bias as equation 4,\nwhereQc;KcandVcare the projected content vectors generated using projection matrices\nWq;c;Wk;c;Wv;cPRd\u0002drespectively,PPR2k\u0002drepresents the relative position embedding\nvectors shared across all layers (i.e., staying \ufb01xed during forward propagation), and QrandKr"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "are projected relative position vectors generated using projection matrices Wq;r;Wk;rPRd\u0002d,\nrespectively.\nQc\u0010HWq;c;Kc\u0010HWk;c;Vc\u0010HWv;c;Qr\u0010PWq;r;Kr\u0010PWk;r\n~Ai;j\u0010Qc\niKc\nj|\nlooomooon\n(a) content-to-content\u0000Qc\niKr\n\u000epi;jq|\nlooooomooooon\n(b) content-to-position\u0000Kc\njQr\n\u000epj;iq|\nlooooomooooon\n(c) position-to-content\nHo\u0010softmaxp~A?\n3dqVc(4)"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Ho\u0010softmaxp~A?\n3dqVc(4)\n~Ai;jis the element of attention matrix ~A, representing the attention score from token ito token\nj.Qc\niis thei-th row ofQc.Kc\njis thej-th row ofKc.Kr\n\u000epi;jqis the\u000epi;jq-th row ofKrwith\nregarding to relative distance \u000epi;jq.Qr\n\u000epj;iqis the\u000epj;iq-th row ofQrwith regarding to relative"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "distance\u000epj;iq. Note that we use \u000epj;iqrather than\u000epi;jqhere. This is because for a given position\ni, position-to-content computes the attention weight of the key content at jwith respect to the\nquery position at i, thus the relative distance is \u000epj;iq. The position-to-content term is calculated as\nKc\njQr\n\u000epj;iq|. The content-to-position term is calculated in a similar way."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Finally, we apply a scaling factor of1?\n3don~A. The factor is important for stabilizing model\ntraining (Vaswani et al., 2017), especially for large-scale PLMs.\nAlgorithm 1 Disentangled Attention\nInput: Hidden stateH, relative distance embedding P, relative distance matrix \u000e. Content projec-\ntion matrixWk;c,Wq;c,Wv;c, position projection matrix Wk;r,Wq;r."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "1:Kc\u0010HWk;c,Qc\u0010HWq;c,Vc\u0010HWv;c,Kr\u0010PWk;r,Qr\u0010PWq;r\n2:Ac\u00d1c\u0010QcK|\nc\n3:fori\u00100;:::;N\u00011do\n4: ~Ac\u00d1pri;:s\u0010Qcri;:sK|\nr\n5:end for\n6:fori\u00100;:::;N\u00011do\n7: forj\u00100;:::;N\u00011do\n8:Ac\u00d1pri;js\u0010~Ac\u00d1pri;\u000eri;jss\n9: end for\n10:end for\n11:forj\u00100;:::;N\u00011do\n12: ~Ap\u00d1cr:;js\u0010Kcrj;:sQ|\nr\n13:end for\n14:forj\u00100;:::;N\u00011do\n15: fori\u00100;:::;N\u00011do\n16:Ap\u00d1cri;js\u0010~Ap\u00d1cr\u000erj;is;js\n17: end for\n18:end for\n19:~A\u0010Ac\u00d1c\u0000Ac\u00d1p\u0000Ap\u00d1c\n20:Ho\u0010softmaxp~A?"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "19:~A\u0010Ac\u00d1c\u0000Ac\u00d1p\u0000Ap\u00d1c\n20:Ho\u0010softmaxp~A?\n3dqVc\nOutput:Ho\n3.1.1 E FFICIENT IMPLEMENTATION\nFor an input sequence of length N, it requires a space complexity of OpN2dq(Shaw et al., 2018;\nHuang et al., 2018; Dai et al., 2019) to store the relative position embedding for each token. However,\ntaking content-to-position as an example, we note that since \u000epi;jqPr0;2kqand the embeddings"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "4Published as a conference paper at ICLR 2021\nof all possible relative positions are always a subset of KrPR2k\u0002d, then we can reuse Krin the\nattention calculation for all the queries.\nIn our experiments, we set the maximum relative distance kto 512 for pre-training. The disentangled\nattention weights can be computed ef\ufb01ciently using Algorithm 1. Let \u000ebe the relative position matrix"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "according to equation 3, i.e., \u000eri;js \u0010\u000epi;jq. Instead of allocating a different relative position\nembedding matrix for each query, we multiply each query vectorQcri;:sbyK|\nrPRd\u00022k, as in line\n3\u00015. Then, we extract the attention weight using the relative position matrix \u000eas the index, as in\nline6\u000110. To compute the position-to-content attention score, we calculate ~Ap\u00d1cr:;js, i.e., the"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "column vector of the attention matrix ~Ap\u00d1c, by multiplying each keyvectorKcrj;:sbyQ|\nr, as in\nline11\u000113. Finally, we extract the corresponding attention score via the relative position matrix \u000e\nas the index, as in line 14\u000118. In this way, we do not need to allocate memory to store a relative\nposition embedding for each query and thus reduce the space complexity to Opkdq(for storingKr\nandQr)."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "andQr).\n3.2 E NHANCED MASK DECODER ACCOUNTS FOR ABSOLUTE WORD POSITIONS\nDeBERTa is pretrained using MLM, where a model is trained to use the words surrounding a mask\ntoken to predict what the masked word should be. DeBERTa uses the content and position information\nof the context words for MLM. The disentangled attention mechanism already considers the contents"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "and relative positions of the context words, but not the absolute positions of these words, which in\nmany cases are crucial for the prediction.\nGiven a sentence \u201ca new store opened beside the new mall\u201d with the words \u201cstore\u201d and \u201cmall\u201d\nmasked for prediction. Using only the local context (e.g., relative positions and surrounding words)"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "is insuf\ufb01cient for the model to distinguish store andmall in this sentence, since both follow the word\nnewwith the same relative positions. To address this limitation, the model needs to take into account\nabsolute positions, as complement information to the relative positions. For example, the subject of"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "the sentence is \u201cstore\u201d not \u201cmall\u201d. These syntactical nuances depend, to a large degree, upon the\nwords\u2019 absolute positions in the sentence.\nThere are two methods of incorporating absolute positions. The BERT model incorporates absolute\npositions in the input layer. In DeBERTa, we incorporate them right after all the Transformer layers"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "but before the softmax layer for masked token prediction, as shown in Figure 2. In this way, DeBERTa\ncaptures the relative positions in all the Transformer layers and only uses absolute positions as\ncomplementary information when decoding the masked words. Thus, we call DeBERTa\u2019s decoding\ncomponent an Enhanced Mask Decoder (EMD). In the empirical study, we compare these two"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "methods of incorporating absolute positions and observe that EMD works much better. We conjecture\nthat the early incorporation of absolute positions used by BERT might undesirably hamper the model\nfrom learning suf\ufb01cient information of relative positions. In addition, EMD also enables us to\nintroduce other useful information, in addition to positions, for pre-training. We leave it to future\nwork."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "work.\n4 S CALE INVARIANT FINE-TUNING\nThis section presents a new virtual adversarial training algorithm, Scale-invariant-Fine-Tuning (SiFT),\na variant to the algorithm described in Miyato et al. (2018); Jiang et al. (2020), for \ufb01ne-tuning.\nVirtual adversarial training is a regularization method for improving models\u2019 generalization. It does"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "so by improving a model\u2019s robustness to adversarial examples, which are created by making small\nperturbations to the input. The model is regularized so that when given a task-speci\ufb01c example, the\nmodel produces the same output distribution as it produces on an adversarial perturbation of that\nexample.\nFor NLP tasks, the perturbation is applied to the word embedding instead of the original word"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "sequence. However, the value ranges (norms) of the embedding vectors vary among different words\nand models. The variance gets larger for bigger models with billions of parameters, leading to some\ninstability of adversarial training.\n5Published as a conference paper at ICLR 2021\nInspired by layer normalization (Ba et al., 2016), we propose the SiFT algorithm that improves the"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "training stability by applying the perturbations to the normalized word embeddings. Speci\ufb01cally,\nwhen \ufb01ne-tuning DeBERTa to a downstream NLP task in our experiments, SiFT \ufb01rst normalizes the\nword embedding vectors into stochastic vectors, and then applies the perturbation to the normalized\nembedding vectors. We \ufb01nd that the normalization substantially improves the performance of the"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "\ufb01ne-tuned models. The improvement is more prominent for larger DeBERTa models. Note that we\nonly apply SiFT to DeBERTa 1:5Bon SuperGLUE tasks in our experiments and we will provide a\nmore comprehensive study of SiFT in our future work.\n5 E XPERIMENT\nThis section reports DeBERTa results on various NLU tasks.\n5.1 M AINRESULTS ON NLU TASKS"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "5.1 M AINRESULTS ON NLU TASKS\nFollowing previous studies of PLMs, we report results using large and base models.\n5.1.1 P ERFORMANCE ON LARGE MODELS\nModelCoLA QQP MNLI-m/mm SST-2 STS-B QNLI RTE MRPC Avg.\nMcc Acc Acc Acc Corr Acc Acc Acc\nBERTlarge 60.6 91.3 86.6/- 93.2 90.0 92.3 70.4 88.0 84.05\nRoBERTa large 68.0 92.2 90.2/90.2 96.4 92.4 93.9 86.6 90.9 88.82"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "XLNetlarge 69.0 92.3 90.8/90.8 97.0 92.5 94.9 85.9 90.8 89.15\nELECTRA large 69.1 92.4 90.9/- 96.9 92.6 95.0 88.0 90.8 89.46\nDeBERTa large 70.5 92.3 91.1/91.1 96.8 92.8 95.3 88.3 91.9 90.00\nTable 1: Comparison results on the GLUE development set.\nWe pre-train our large models following the setting of BERT (Devlin et al., 2019), except that we use"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "the BPE vocabulary of Radford et al. (2019); Liu et al. (2019c). For training data, we use Wikipedia\n(English Wikipedia dump3; 12GB), BookCorpus (Zhu et al., 2015) (6GB), OPENWEBTEXT (public\nReddit content (Gokaslan & Cohen, 2019); 38GB), and STORIES (a subset of CommonCrawl (Trinh\n& Le, 2018); 31GB). The total data size after data deduplication (Shoeybi et al., 2019) is about 78G."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Refer to Appendix A.2 for a detailed description of the pre-training dataset.\nWe use 6 DGX-2 machines (96 V100 GPUs) to train the models. A single model trained with 2K\nbatch size and 1M steps takes about 20 days. Refer to Appendix A for the detailed hyperparamters.\nWe summarize the results on eight NLU tasks of GLUE (Wang et al., 2019b) in Table 1, where"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "DeBERTa is compared DeBERTa with previous Transform-based PLMs of similar structures (i.e. 24\nlayers with hidden size of 1024) including BERT, RoBERTa, XLNet, ALBERT and ELECTRA. Note\nthat RoBERTa, XLNet and ELECTRA are pre-trained on 160G training data while DeBERTa is pre-\ntrained on 78G training data. RoBERTa and XLNet are pre-trained for 500K steps with 8K samples"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "in a step, which amounts to four billion training samples. DeBERTa is pre-trained for one million\nsteps with 2K samples in each step. This amounts to two billion training samples, approximately\nhalf of either RoBERTa or XLNet. Table 1 shows that compared to BERT and RoBERTa, DeBERTa\nperforms consistently better across all the tasks. Meanwhile, DeBERTa outperforms XLNet in six out"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "of eight tasks. Particularly, the improvements on MRPC (1.1% over XLNet and 1.0% over RoBERTa),\nRTE (2.4% over XLNet and 1.7% over RoBERTa) and CoLA (1.5% over XLNet and 2.5% over\nRoBERTa) are signi\ufb01cant. DeBERTa also outperforms other SOTA PLMs, i.e., ELECTRA largeand\nXLNet large, in terms of average GLUE score."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Among all GLUE tasks, MNLI is most often used as an indicative task to monitor the research\nprogress of PLMs. DeBERTa signi\ufb01cantly outperforms all existing PLMs of similar size on MNLI\nand creates a new state of the art.\n3https://dumps.wikimedia.org/enwiki/\n6Published as a conference paper at ICLR 2021\nModelMNLI-m/mm SQuAD v1.1 SQuAD v2.0 RACE ReCoRD SWAG NER\nAcc F1/EM F1/EM Acc F1/EM Acc F1"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Acc F1/EM F1/EM Acc F1/EM Acc F1\nBERTlarge 86.6/- 90.9/84.1 81.8/79.0 72.0 - 86.6 92.8\nALBERTlarge 86.5/- 91.8/85.2 84.9/81.8 75.2 - - -\nRoBERTa large 90.2/90.2 94.6/88.9 89.4/86.5 83.2 90.6/90.0 89.9 93.4\nXLNetlarge 90.8/90.8 95.1/89.7 90.6/87.9 85.4 - - -\nMegatron 336M 89.7/90.0 94.2/88.0 88.1/84.8 83.0 - - -\nDeBERTa large 91.1/91.1 95.5/90.1 90.7/88.0 86.8 91.4/91.0 90.8 93.8"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "ALBERTxxlarge 90.8/- 94.8/89.3 90.2/87.4 86.5 - - -\nMegatron 1.3B 90.9/91.0 94.9/89.1 90.2/87.1 87.3 - - -\nMegatron 3.9B 91.4/91.4 95.5/90.0 91.2/88.5 89.5 - - -\nTable 2: Results on MNLI in/out-domain, SQuAD v1.1, SQuAD v2.0, RACE, ReCoRD, SWAG,\nCoNLL 2003 NER development set. Note that missing results in literature are signi\ufb01ed by \u201c-\u201d."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "In addition to GLUE, DeBERTa is evaluated on three categories of NLU benchmarks: (1) Question\nAnswering: SQuAD v1.1 (Rajpurkar et al., 2016), SQuAD v2.0 (Rajpurkar et al., 2018), RACE (Lai\net al., 2017), ReCoRD (Zhang et al., 2018) and SWAG (Zellers et al., 2018); (2) Natural Language\nInference: MNLI (Williams et al., 2018); and (3) NER: CoNLL-2003. For comparison, we include"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "ALBERT xxlarge (Lan et al., 2019)4and Megatron (Shoeybi et al., 2019) with three different model\nsizes, denoted as Megatron 336M, Megatron 1.3Band Megatron 3.9B, respectively, which are trained using\nthe same dataset as RoBERTa. Note that Megatron 336M has a similar model size as other models\nmentioned above5."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "mentioned above5.\nWe summarize the results in Table 2. Compared to the previous SOTA PLMs with a similar model\nsize (i.e., BERT, RoBERTa, XLNet, ALBERT large, and Megatron 336M), DeBERTa shows superior\nperformance in all seven tasks. Taking the RACE benchmark as an example, DeBERTa signi\ufb01cantly\noutperforms XLNet by +1.4% (86.8% vs. 85.4%). Although Megatron 1.3Bis three times larger than"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "DeBERTa, DeBERTa outperforms it in three of the four benchmarks. We further report DeBERTa on\ntext generation tasks in Appendix A.4.\n5.1.2 P ERFORMANCE ON BASE MODELS\nOur setting for base model pre-training is similar to that for large models. The base model structure\nfollows that of the BERT base model, i.e., L\u001012;H\u0010768;A\u001012. We use 4 DGX-2 with 64"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "V100 GPUs to train the base model. It takes 10 days to \ufb01nish a single pre-training of 1M training steps\nwith batch size 2048. We train DeBERTa using the same 78G dataset, and compare it to RoBERTa\nand XLNet trained on 160G text data.\nWe summarize the base model results in Table 3. Across all three tasks, DeBERTa consistently"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "outperforms RoBERTa and XLNet by a larger margin than that in large models. For example, on\nMNLI-m, DeBERTa baseobtains +1.2% (88.8% vs. 87.6%) over RoBERTa base, and +2% (88.8% vs.\n86.8%) over XLNet base.\nModel MNLI-m/mm (Acc) SQuAD v1.1 (F1/EM) SQuAD v2.0 (F1/EM)\nRoBERTa base 87.6/- 91.5/84.6 83.7/80.5\nXLNetbase 86.8/- -/- -/80.2\nDeBERTa base 88.8/88.5 93.1/87.2 86.2/83.1"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Table 3: Results on MNLI in/out-domain (m/mm), SQuAD v1.1 and v2.0 development set.\n4The hidden dimension of ALBERT xxlarge is 4 times of DeBERTa and the computation cost is about 4 times\nof DeBERTa.\n5T5 (Raffel et al., 2020) has more parameters (11B). Raffel et al. (2020) only report the test results of T5\nwhich are not comparable with other models.\n7Published as a conference paper at ICLR 2021"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "5.2 M ODEL ANALYSIS\nIn this section, we \ufb01rst present an ablation study to quantify the relative contributions of different\ncomponents introduced in DeBERTa. Then, we study the convergence property to characterize the\nmodel training ef\ufb01ciency. We run experiments for analysis using the base model setting: a model is"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "pre-trained using the Wikipedia + Bookcorpus dataset for 1M steps with batch size 256 in 7 days\non a DGX-2 machine with 16 V-100 GPUs. Due to space limit, we visualize the different attention\npatterns of DeBERTa and RoBERTa in Appendix A.7.\n5.2.1 A BLATION STUDY\nTo verify our experimental setting, we pre-train the RoBERTa base model from scratch. The re-pre-"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "trained RoBERTa model is denoted as RoBERTa-ReImp base. To investigate the relative contributions\nof different components in DeBERTa, we develop three variations:\n\u000f-EMD is the DeBERTa base model without EMD.\n\u000f-C2P is the DeBERTa base model without the content-to-position term ((c) in Eq. 4).\n\u000f-P2C is the DeBERTa base model without the position-to-content term ((b) in Eq. 4). As"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "XLNet also uses the relative position bias, this model is close to XLNet plus EMD.\nModelMNLI-m/mm SQuAD v1.1 SQuAD v2.0 RACE\nAcc F1/EM F1/EM Acc\nBERTbaseDevlin et al. (2019) 84.3/84.7 88.5/81.0 76.3/73.7 65.0\nRoBERTa baseLiu et al. (2019c) 84.7/- 90.6/- 79.7/- 65.6\nXLNetbaseYang et al. (2019) 85.8/85.4 -/- 81.3/78.5 66.7\nRoBERTa-ReImp base 84.9/85.1 91.1/84.8 79.5/76.0 66.8"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "DeBERTa base 86.3/86.2 92.1/86.1 82.5/79.3 71.7\n-EMD 86.1/86.1 91.8/85.8 81.3/78.0 70.3\n-C2P 85.9/85.7 91.6/85.8 81.3/78.3 69.3\n-P2C 86.0/85.8 91.7/85.7 80.8/77.6 69.6\n-(EMD+C2P) 85.8/85.9 91.5/85.3 80.3/77.2 68.1\n-(EMD+P2C) 85.8/85.8 91.3/85.1 80.2/77.1 68.5\nTable 4: Ablation study of the DeBERTa base model.\nTable 4 summarizes the results on four benchmark datasets. First, RoBERTa-ReImp performs"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "similarly to RoBERTa across all benchmark datasets, ver\ufb01ying that our setting is reasonable. Second,\nwe see that removing any one component in DeBERTa results in a sheer performance drop. For\ninstance, removing EMD (-EMD) results in a loss of 1.4% (71.7% vs. 70.3%) on RACE, 0.3%\n(92.1% vs. 91.8%) on SQuAD v1.1, 1.2% (82.5% vs. 81.3%) on SQuAD v2.0, 0.2% (86.3% vs."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "86.1%) and 0.1% (86.2% vs. 86.1%) on MNLI-m/mm, respectively. Similarly, removing either\ncontent-to-position orposition-to-content leads to inferior performance in all the benchmarks. As\nexpected, removing two components results in even more substantial loss in performance.\n5.3 S CALE UP TO 1.5 BILLION PARAMETERS"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "5.3 S CALE UP TO 1.5 BILLION PARAMETERS\nLarger pre-trained models have shown better generalization results (Raffel et al., 2020; Brown et al.,\n2020; Shoeybi et al., 2019). Thus, we have built a larger version of DeBERTa with 1.5 billion\nparameters, denoted as DeBERTa 1:5B. The model consists of 48 layers with a hidden size of 1,536"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "and 24 attention heads6. DeBERTa 1:5Bis trained on a pre-training dataset amounting to 160G,\nsimilar to that in Liu et al. (2019c), with a new vocabulary of size 128K constructed using the dataset.\nTo train DeBERTa 1:5B, we optimize the model architecture as follows. First, we share the projection\nmatrices of relative position embedding Wk;r;Wq;rwithWk;c;Wq;c, respectively, in all attention"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "layers to reduce the number of model parameters. Our ablation study in Table 13 on base models\nshows that the projection matrix sharing reduces the model size while retaining the model performance.\n6See Table 8 in Appendix for the model hyperparameters.\n8Published as a conference paper at ICLR 2021\nSecond, a convolution layer is added aside the \ufb01rst Transformer layer to induce n-gram knowledge of"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "sub-word encodings and their outputs are summed up before feeding to the next Transformer layer7.\nTable 5 reports the test results of SuperGLUE (Wang et al., 2019a) which is one of the most popular\nNLU benchmarks. SuperGLUE consists of a wide of NLU tasks, including Question Answering\n(Clark et al., 2019; Khashabi et al., 2018; Zhang et al., 2018), Natural Language Inference (Dagan"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "et al., 2006; Bar-Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009), Word Sense\nDisambiguation (Pilehvar & Camacho-Collados, 2019), and Reasoning (Levesque et al., 2011;\nRoemmele et al., 2011). Since its release in 2019, top research teams around the world have been\ndeveloping large-scale PLMs that have driven striking performance improvement on SuperGLUE."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "The signi\ufb01cant performance boost due to scaling DeBERTa to a larger model makes the single\nDeBERTa 1:5Bsurpass the human performance on SuperGLUE for the \ufb01rst time in terms of macro-\naverage score (89.9 versus 89.8) as of December 29, 2020, and the ensemble DeBERTa model\n(DeBERTa Ensemble ) sits atop the SuperGLUE benchmark rankings as of January 6, 2021, outper-"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "forming the human baseline by a decent margin (90.3 versus 89.8). Compared to T5, which consists\nof 11 billion parameters, the 1.5-billion-parameter DeBERTa is much more energy ef\ufb01cient to train\nand maintain, and it is easier to compress and deploy to apps of various settings.\nModelBoolQ CB COPA MultiRC ReCoRD RTE WiC WSC Average\nAcc F1/Acc Acc F1a/EM F1/EM Acc Acc Acc Score"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "RoBERTa large 87.1 90.5/95.2 90.6 84.4/52.5 90.6/90.0 88.2 69.9 89.0 84.6\nNEXHA-Plus 87.8 94.4/96.0 93.6 84.6/55.1 90.1/89.6 89.1 74.6 93.2 86.7\nT511B 91.2 93.9/96.8 94.8 88.1/63.3 94.1/93.4 92.5 76.9 93.8 89.3\nT511B+Meena 91.3 95.8/97.6 97.4 88.3/63.0 94.2/93.5 92.7 77.9 95.9 90.2\nHuman 89.0 95.8/98.9 100.0 81.8/51.9 91.7/91.3 93.6 80.0 100.0 89.8"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "DeBERTa 1:5B+SiFT 90.4 94.9/97.2 96.8 88.2/63.7 94.5/94.1 93.2 76.4 95.9 89.9\nDeBERTa Ensemble 90.4 95.7/97.6 98.4 88.2/63.7 94.5/94.1 93.2 77.5 95.9 90.3\nTable 5: SuperGLUE test set results scored using the SuperGLUE evaluation server. All the results\nare obtained from https://super.gluebenchmark.com on January 6, 2021.\n6 C ONCLUSIONS"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "6 C ONCLUSIONS\nThis paper presents a new model architecture DeBERTa (Decoding-enhanced BERT with disentangled\nattention) that improves the BERT and RoBERTa models using two novel techniques. The \ufb01rst is the\ndisentangled attention mechanism, where each word is represented using two vectors that encode\nits content and position, respectively, and the attention weights among words are computed using"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "disentangled matrices on their contents and relative positions, respectively. The second is an enhanced\nmask decoder which incorporates absolute positions in the decoding layer to predict the masked\ntokens in model pre-training. In addition, a new virtual adversarial training method is used for\n\ufb01ne-tuning to improve model\u2019s generalization on downstream tasks."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "We show through a comprehensive empirical study that these techniques signi\ufb01cantly improve the\nef\ufb01ciency of model pre-training and the performance of downstream tasks. The DeBERTa model\nwith 1.5 billion parameters surpasses the human performance on the SuperGLUE benchmark for the\n\ufb01rst time in terms of macro-average score."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "DeBERTa surpassing human performance on SuperGLUE marks an important milestone toward\ngeneral AI. Despite its promising results on SuperGLUE, the model is by no means reaching the\nhuman-level intelligence of NLU. Humans are extremely good at leveraging the knowledge learned\nfrom different tasks to solve a new task with no or little task-speci\ufb01c demonstration. This is referred"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "to as compositional generalization , the ability to generalize to novel compositions (new tasks) of\nfamiliar constituents (subtasks or basic problem-solving skills). Moving forward, it is worth exploring\nhow to make DeBERTa incorporate compositional structures in a more explicit manner, which could\nallow combining neural and symbolic computation of natural language similar to what humans do."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "7Please refer to Table 12 in Appendix A.6 for the ablation study of different model sizes, and Table 13 in\nAppendix A.6 for the ablation study of new modi\ufb01cations.\n9Published as a conference paper at ICLR 2021\n7 A CKNOWLEDGMENTS\nWe thank Jade Huang and Nikos Karampatziakis for proofreading the paper and providing insightful"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "comments. We thank Yoyo Liang, Saksham Singhal, Xia Song, and Saurabh Tiwary for their help\nwith large-scale model training. We also thank the anonymous reviewers for valuable discussions.\nREFERENCES\nJimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\narXiv:1607.06450 , 2016."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "arXiv:1607.06450 , 2016.\nRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, and Danilo Giampiccolo. The second PASCAL\nrecognising textual entailment challenge. In Proceedings of the Second PASCAL Challenges\nWorkshop on Recognising Textual Entailment , 01 2006.\nIz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: The long-document transformer.\narXiv preprint arXiv:2004.05150 , 2020."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "arXiv preprint arXiv:2004.05150 , 2020.\nLuisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, and Bernardo Magnini. The\n\ufb01fth pascal recognizing textual entailment challenge. In In Proc Text Analysis Conference (TAC\u201909 ,\n2009.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\nfew-shot learners. arXiv preprint arXiv:2005.14165 , 2020.\nDaniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia. Semeval-2017 task\n1: Semantic textual similarity-multilingual and cross-lingual focused evaluation. arXiv preprint\narXiv:1708.00055 , 2017."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "arXiv:1708.00055 , 2017.\nKezhen Chen, Qiuyuan Huang, Hamid Palangi, Paul Smolensky, Kenneth D Forbus, and Jianfeng\nGao. Natural-to formal-language generation using tensor product representations. arXiv preprint\narXiv:1910.02339 , 2019.\nRewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with sparse\ntransformers. arXiv preprint arXiv:1904.10509 , 2019."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina\nToutanova. BoolQ: Exploring the surprising dif\ufb01culty of natural yes/no questions. In Proceedings\nof NAACL-HLT 2019 , 2019.\nKevin Clark, Minh-Thang Luong, Quoc V . Le, and Christopher D. Manning. ELECTRA: Pre-training\ntext encoders as discriminators rather than generators. In ICLR , 2020."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Ido Dagan, Oren Glickman, and Bernardo Magnini. The pascal recognising textual entailment\nchallenge. In Proceedings of the First International Conference on Machine Learning Chal-\nlenges: Evaluating Predictive Uncertainty Visual Object Classi\ufb01cation, and Recognizing Textual\nEntailment , MLCW\u201905, Berlin, Heidelberg, 2006."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G Carbonell, Quoc Le, and Ruslan Salakhutdinov.\nTransformer-xl: Attentive language models beyond a \ufb01xed-length context. In Proceedings of the\n57th Annual Meeting of the Association for Computational Linguistics , pp. 2978\u20132988, 2019.\nMarie-Catherine De Marneffe, Mandy Simons, and Judith Tonhauser. The commitmentbank: In-"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "vestigating projection in naturally occurring discourse. In proceedings of Sinn und Bedeutung ,\nvolume 23, pp. 107\u2013124, 2019.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep\nbidirectional transformers for language understanding. In Proceedings of the 2019 Conference of"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "the North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) , pp. 4171\u20134186, 2019.\n10Published as a conference paper at ICLR 2021\nWilliam B Dolan and Chris Brockett. Automatically constructing a corpus of sentential paraphrases.\nInProceedings of the Third International Workshop on Paraphrasing (IWP2005) , 2005."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou,\nand Hsiao-Wuen Hon. Uni\ufb01ed language model pre-training for natural language understanding\nand generation. In Advances in Neural Information Processing Systems , pp. 13042\u201313054, 2019.\nDanilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. The third PASCAL recognizing"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment\nand Paraphrasing , pp. 1\u20139, Prague, June 2007. Association for Computational Linguistics. URL\nhttps://www.aclweb.org/anthology/W07-1401 .\nAaron Gokaslan and Vanya Cohen. Openwebtext corpus. http://Skylion007.github.io, 2019."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Pengcheng He, Xiaodong Liu, Weizhu Chen, and Jianfeng Gao. A hybrid neural network model for\ncommonsense reasoning. arXiv preprint arXiv:1907.11983 , 2019a.\nPengcheng He, Yi Mao, Kaushik Chakrabarti, and Weizhu Chen. X-sql: reinforce schema representa-\ntion with context. arXiv preprint arXiv:1908.08113 , 2019b."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Ian Simon, Curtis Hawthorne, Noam\nShazeer, Andrew M Dai, Matthew D Hoffman, Monica Dinculescu, and Douglas Eck. Music\ntransformer: Generating music with long-term structure. 2018.\nHaoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Tuo Zhao. SMART:"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Robust and ef\ufb01cient \ufb01ne-tuning for pre-trained natural language models through principled regu-\nlarized optimization. In ACL, July 2020. doi: 10.18653/v1/2020.acl-main.197.\nMandar Joshi, Danqi Chen, Yinhan Liu, Daniel S Weld, Luke Zettlemoyer, and Omer Levy. Spanbert:\nImproving pre-training by representing and predicting spans. Transactions of the Association for"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Computational Linguistics , 8:64\u201377, 2020.\nDaniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan Roth. Looking\nbeyond the surface: A challenge set for reading comprehension over multiple sentences. In\nProceedings of the 2018 Conference of the North American Chapter of the Association for Com-"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "putational Linguistics: Human Language Technologies, Volume 1 (Long Papers) , pp. 252\u2013262,\n2018.\nDiederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint\narXiv:1412.6980 , 2014.\nNikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. Reformer: The ef\ufb01cient transformer. In\nInternational Conference on Learning Representations , 2019."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. Race: Large-scale reading\ncomprehension dataset from examinations. In Proceedings of the 2017 Conference on Empirical\nMethods in Natural Language Processing , pp. 785\u2013794, 2017.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Albert: A lite bert for self-supervised learning of language representations. In International\nConference on Learning Representations , 2019.\nHector Levesque, Ernest Davis, and Leora Morgenstern. The winograd schema challenge. In\nThirteenth International Conference on the Principles of Knowledge Representation and Reasoning ,\n2012."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "2012.\nHector J Levesque, Ernest Davis, and Leora Morgenstern. The Winograd schema challenge. In AAAI\nSpring Symposium: Logical Formalizations of Commonsense Reasoning , volume 46, pp. 47, 2011.\nLiyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Jiawei\nHan. On the variance of the adaptive learning rate and beyond. In International Conference on"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Learning Representations , 2019a.\n11Published as a conference paper at ICLR 2021\nXiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. Multi-task deep neural networks\nfor natural language understanding. In Proceedings of the 57th Annual Meeting of the Associa-\ntion for Computational Linguistics , pp. 4487\u20134496, Florence, Italy, July 2019b. Association for"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Computational Linguistics. URL https://www.aclweb.org/anthology/P19-1441 .\nXiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon, and Jianfeng Gao.\nAdversarial training for large neural language models. arXiv preprint arXiv:2004.08994 , 2020.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining\napproach. arXiv preprint arXiv:1907.11692 , 2019c.\nIlya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. 2018.\nStephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture\nmodels. arXiv , pp. arXiv\u20131609, 2016."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "models. arXiv , pp. arXiv\u20131609, 2016.\nShervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, and Jian-\nfeng Gao. Deep learning based text classi\ufb01cation: A comprehensive review. arXiv preprint\narXiv:2004.03705 , 2020.\nTakeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "regularization method for supervised and semi-supervised learning. IEEE transactions on pattern\nanalysis and machine intelligence , 41(8):1979\u20131993, 2018.\nMohammad Taher Pilehvar and Jose Camacho-Collados. Wic: the word-in-context dataset for\nevaluating context-sensitive meaning representations. In Proceedings of the 2019 Conference of"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "the North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) , pp. 1267\u20131273, 2019.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language\nmodels are unsupervised multitask learners. OpenAI Blog , 1(8), 2019."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena,\nYanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a uni\ufb01ed\ntext-to-text transformer. Journal of Machine Learning Research , 21(140):1\u201367, 2020. URL\nhttp://jmlr.org/papers/v21/20-074.html ."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+ questions\nfor machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods\nin Natural Language Processing , November 2016.\nPranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don\u2019t know: Unanswerable questions"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "for squad. In Proceedings of the 56th Annual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pp. 784\u2013789, 2018.\nMelissa Roemmele, Cosmin Adrian Bejan, and Andrew S. Gordon. Choice of plausible alternatives:\nAn evaluation of commonsense causal reasoning. In 2011 AAAI Spring Symposium Series , 2011."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Imanol Schlag, Paul Smolensky, Roland Fernandez, Nebojsa Jojic, J\u00fcrgen Schmidhuber, and Jianfeng\nGao. Enhancing the transformer with explicit relational encoding for math problem solving. arXiv\npreprint arXiv:1910.06611 , 2019.\nPeter Shaw, Jakob Uszkoreit, and Ashish Vaswani. Self-attention with relative position representations."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "InProceedings of the 2018 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, Volume 2 (Short Papers) , pp. 464\u2013468,\n2018.\nTao Shen, Yi Mao, Pengcheng He, Guodong Long, Adam Trischler, and Weizhu Chen. Ex-\nploiting structured knowledge in text via graph-guided representation learning. arXiv preprint\narXiv:2004.14224 , 2020."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "arXiv:2004.14224 , 2020.\n12Published as a conference paper at ICLR 2021\nMohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan\nCatanzaro. Megatron-lm: Training multi-billion parameter language models using gpu model\nparallelism. arXiv preprint arXiv:1909.08053 , 2019.\nPaul Smolensky. Tensor product variable binding and the representation of symbolic structures in"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "connectionist systems. Arti\ufb01cial intelligence , 46(1-2):159\u2013216, 1990.\nRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, and\nChristopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank.\nInProceedings of the 2013 conference on empirical methods in natural language processing , pp.\n1631\u20131642, 2013."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "1631\u20131642, 2013.\nYu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu,\nHao Tian, and Hua Wu. Ernie: Enhanced representation through knowledge integration. arXiv\npreprint arXiv:1904.09223 , 2019.\nTrieu H Trinh and Quoc V Le. A simple method for commonsense reasoning. arXiv preprint\narXiv:1806.02847 , 2018."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "arXiv:1806.02847 , 2018.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz\nKaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information\nprocessing systems , pp. 5998\u20136008, 2017.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Levy, and Samuel Bowman. Superglue: A stickier benchmark for general-purpose language\nunderstanding systems. In Advances in neural information processing systems , pp. 3266\u20133280,\n2019a.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. Glue:\nA multi-task benchmark and analysis platform for natural language understanding. In 7th Interna-"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "tional Conference on Learning Representations, ICLR 2019 , 2019b.\nWei Wang, Bin Bi, Ming Yan, Chen Wu, Zuyi Bao, Liwei Peng, and Luo Si. Structbert: Incor-\nporating language structures into pre-training for deep language understanding. arXiv preprint\narXiv:1908.04577 , 2019c.\nAlex Warstadt, Amanpreet Singh, and Samuel R Bowman. Neural network acceptability judgments."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "arXiv preprint arXiv:1805.12471 , 2018.\nAdina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for\nsentence understanding through inference. In Proceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technolo-"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "gies, Volume 1 (Long Papers) , pp. 1112\u20131122. Association for Computational Linguistics, 2018.\nURLhttp://aclweb.org/anthology/N18-1101 .\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le.\nXlnet: Generalized autoregressive pretraining for language understanding. In Advances in neural\ninformation processing systems , pp. 5754\u20135764, 2019."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Rowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin Choi. Swag: A large-scale adversarial\ndataset for grounded commonsense inference. In Proceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing , pp. 93\u2013104, 2018.\nSheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, and Benjamin Van Durme."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "ReCoRD: Bridging the gap between human and machine commonsense reading comprehension.\narXiv preprint 1810.12885 , 2018.\nYukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and\nSanja Fidler. Aligning books and movies: Towards story-like visual explanations by watching\nmovies and reading books. In Proceedings of the IEEE international conference on computer"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "vision , pp. 19\u201327, 2015.\n13Published as a conference paper at ICLR 2021\nA A PPENDIX\nA.1 D ATASET\nCorpus Task #Train #Dev #Test #Label Metrics\nGeneral Language Understanding Evaluation (GLUE )\nCoLA Acceptability 8.5k 1k 1k 2 Matthews corr\nSST Sentiment 67k 872 1.8k 2 Accuracy\nMNLI NLI 393k 20k 20k 3 Accuracy\nRTE NLI 2.5k 276 3k 2 Accuracy\nWNLI NLI 634 71 146 2 Accuracy"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "WNLI NLI 634 71 146 2 Accuracy\nQQP Paraphrase 364k 40k 391k 2 Accuracy/F1\nMRPC Paraphrase 3.7k 408 1.7k 2 Accuracy/F1\nQNLI QA/NLI 108k 5.7k 5.7k 2 Accuracy\nSTS-B Similarity 7k 1.5k 1.4k 1 Pearson/Spearman corr\nSuperGLUE\nWSC Coreference 554k 104 146 2 Accuracy\nBoolQ QA 9,427 3,270 3,245 2 Accuracy\nCOPA QA 400k 100 500 2 Accuracy\nCB NLI 250 57 250 3 Accuracy/F1\nRTE NLI 2.5k 276 3k 2 Accuracy"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "RTE NLI 2.5k 276 3k 2 Accuracy\nWiC WSD 2.5k 276 3k 2 Accuracy\nReCoRD MRC 101k 10k 10k - Exact Match (EM)/F1\nMultiRC Multiple choice 5,100 953 1,800 - Exact Match (EM)/F1\nQuestion Answering\nSQuAD v1.1 MRC 87.6k 10.5k 9.5k - Exact Match (EM)/F1\nSQuAD v2.0 MRC 130.3k 11.9k 8.9k - Exact Match (EM)/F1\nRACE MRC 87,866 4,887 4,934 4 Accuracy\nSWAG Multiple choice 73.5k 20k 20k 4 Accuracy"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Token Classi\ufb01cation\nCoNLL 2003 NER 14,987 3,466 3,684 8 F1\nTable 6: Summary information of the NLP application benchmarks.\n\rGLUE . The General Language Understanding Evaluation (GLUE) benchmark is a collection of\nnine natural language understanding (NLU) tasks. As shown in Table 6, it includes question answer-"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "ing (Rajpurkar et al., 2016), linguistic acceptability (Warstadt et al., 2018), sentiment analysis (Socher\net al., 2013), text similarity (Cer et al., 2017), paraphrase detection (Dolan & Brockett, 2005), and\nnatural language inference (NLI) (Dagan et al., 2006; Bar-Haim et al., 2006; Giampiccolo et al.,"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "2007; Bentivogli et al., 2009; Levesque et al., 2012; Williams et al., 2018). The diversity of the tasks\nmakes GLUE very suitable for evaluating the generalization and robustness of NLU models.\n\rSuperGLUE . SuperGLUE is an extension of the GLUE benchmark, but more dif\ufb01cult, which is\na collection of eight NLU tasks. It covers a various of tasks including question answering (Zhang"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "et al., 2018; Clark et al., 2019; Khashabi et al., 2018), natural language inference (Dagan et al.,\n2006; Bar-Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009; De Marneffe et al.,\n2019), coreference resolution (Levesque et al., 2012) and word sense disambiguation (Pilehvar &\nCamacho-Collados, 2019)."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Camacho-Collados, 2019).\n\rRACE is a large-scale machine reading comprehension dataset, collected from English examinations\nin China, which are designed for middle school and high school students (Lai et al., 2017).\n\rSQuAD v1.1/v2.0 is the Stanford Question Answering Dataset (SQuAD) v1.1 and v2.0 (Rajpurkar"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "et al., 2016; 2018) are popular machine reading comprehension benchmarks. Their passages come\nfrom approximately 500 Wikipedia articles and the questions and answers are obtained by crowd-\nsourcing. The SQuAD v2.0 dataset includes unanswerable questions about the same paragraphs.\n14Published as a conference paper at ICLR 2021"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "SWAG is a large-scale adversarial dataset for the task of grounded commonsense inference, which\nuni\ufb01es natural language inference and physically grounded reasoning (Zellers et al., 2018). SWAG\nconsists of 113k multiple choice questions about grounded situations.\n\rCoNLL 2003 is an English dataset consisting of text from a wide variety of sources. It has 4 types\nof named entity."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "of named entity.\nA.2 P RE-TRAINING DATASET\nFor DeBERTa pre-training, we use Wikipedia (English Wikipedia dump8; 12GB), BookCorpus (Zhu\net al., 2015)9(6GB), OPENWEBTEXT (public Reddit content (Gokaslan & Cohen, 2019); 38GB)\nand STORIES10(a subset of CommonCrawl (Trinh & Le, 2018); 31GB). The total data size after"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "data deduplication(Shoeybi et al., 2019) is about 78GB. For pre-training, we also sample 5% training\ndata as the validation set to monitor the training process. Table 7 compares datasets used in different\npre-trained models.\nModel Wiki+Book OpenWebText Stories CC-News Giga5 ClueWeb Common Crawl\n16GB 38GB 31GB 76GB 16GB 19GB 110GB\nBERT X\nXLNet X X X X\nRoBERTa X X X X\nDeBERTa X X X"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "RoBERTa X X X X\nDeBERTa X X X\nDeBERTa 1:5B X X X X\nTable 7: Comparison of the pre-training data.\nA.3 I MPLEMENTATION DETAILS\nFollowing RoBERTa (Liu et al., 2019c), we adopt dynamic data batching. We also include span\nmasking (Joshi et al., 2020) as an additional masking strategy with the span size up to three. We list"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "the detailed hyperparameters of pre-training in Table 8. For pre-training, we use Adam (Kingma &\nBa, 2014) as the optimizer with weight decay (Loshchilov & Hutter, 2018). For \ufb01ne-tuning, even\nthough we can get better and robust results with RAdam(Liu et al., 2019a) on some tasks, e.g. CoLA,\nRTE and RACE, we use Adam(Kingma & Ba, 2014) as the optimizer for a fair comparison. For"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "\ufb01ne-tuning, we train each task with a hyper-parameter search procedure, each run takes about 1-2\nhours on a DGX-2 node. All the hyper-parameters are presented in Table 9. The model selection is\nbased on the performance on the task-speci\ufb01c development sets.\nOur code is implemented based on Huggingface Transformers11, FairSeq12and Megatron (Shoeybi\net al., 2019)13.\nA.3.1 P RE-TRAINING EFFICIENCY"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "A.3.1 P RE-TRAINING EFFICIENCY\nTo investigate the ef\ufb01ciency of model pre-training, we plot the performance of the \ufb01ne-tuned model\non downstream tasks as a function of the number of pre-training steps. As shown in Figure 1, for\nRoBERTa-ReImp baseand DeBERTa base, we dump a checkpoint every 150K pre-training steps, and"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "then \ufb01ne-tune the checkpoint on two representative downstream tasks, MNLI and SQuAD v2.0, and\nthen report the accuracy and F1 score, respectively. As a reference, we also report the \ufb01nal model\nperformance of both the original RoBERTa base(Liu et al., 2019c) and XLNet base(Yang et al., 2019).\nThe results show that DeBERTa baseconsistently outperforms RoBERTa-ReImp baseduring the course"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "of pre-training.\n8https://dumps.wikimedia.org/enwiki/\n9https://github.com/butsugiri/homemade_bookcorpus\n10https://github.com/tensor\ufb02ow/models/tree/master/research/lm_commonsense\n11https://github.com/huggingface/transformers\n12https://github.com/pytorch/fairseq\n13https://github.com/NVIDIA/Megatron-LM\n15Published as a conference paper at ICLR 2021"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Hyper-parameter DeBERTa 1:5BDeBERTa large DeBERTa base DeBERTa base\u0001ablation\nNumber of Layers 48 24 12 12\nHidden size 1536 1024 768 768\nFNN inner hidden size 6144 4096 3072 3072\nAttention Heads 24 16 12 12\nAttention Head size 64 64 64 64\nDropout 0.1 0.1 0.1 0.1\nWarmup Steps 10k 10k 10k 10k\nLearning Rates 1.5e-4 2e-4 2e-4 1e-4\nBatch Size 2k 2k 2k 256\nWeight Decay 0.01 0.01 0.01 0.01"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Weight Decay 0.01 0.01 0.01 0.01\nMax Steps 1M 1M 1M 1M\nLearning Rate Decay Linear Linear Linear Linear\nAdam\u000f 1e-6 1e-6 1e-6 1e-6\nAdam\f1 0.9 0.9 0.9 0.9\nAdam\f2 0.999 0.999 0.999 0.999\nGradient Clipping 1.0 1.0 1.0 1.0\nNumber of DGX-2 nodes 16 6 4 1\nTraining Time 30 days 20 days 10 days 7 days\nTable 8: Hyper-parameters for pre-training DeBERTa."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Hyper-parameter DeBERTa 1:5B DeBERTa large DeBERTa base\nDropout of task layer {0,0.15,0.3} {0,0.1,0.15} {0,0.1,0.15}\nWarmup Steps {50,100,500,1000} {50,100,500,1000} {50,100,500,1000}\nLearning Rates {1e-6, 3e-6, 5e-6} {5e-6, 8e-6, 9e-6, 1e-5} {1.5e-5,2e-5, 3e-5, 4e-5}\nBatch Size {16,32,64} {16,32,48,64} {16,32,48,64}\nWeight Decay 0.01 0.01\nMaximun Training Epochs 10 10 10"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Maximun Training Epochs 10 10 10\nLearning Rate Decay Linear Linear Linear\nAdam\u000f 1e-6 1e-6 1e-6\nAdam\f1 0.9 0.9 0.9\nAdam\f2 0.999 0.999 0.999\nGradient Clipping 1.0 1.0 1.0\nTable 9: Hyper-parameters for \ufb01ne-tuning DeBERTa on down-streaming tasks.\n(a) Results on MNLI development\n (b) Results on SQuAD v2.0 development"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "(b) Results on SQuAD v2.0 development\nFigure 1: Pre-training performance curve between DeBERTa and its counterparts on the MNLI and\nSQuAD v2.0 development set.\n16Published as a conference paper at ICLR 2021\nA.4 M AINRESULTS ON GENERATION TASKS\nIn addition to NLU tasks, DeBERTa can also be extended to handle NLG tasks. To allow DeBERTa"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "operating like an auto-regressive model for text generation, we use a triangular matrix for self-\nattention and set the upper triangular part of the self-attention mask to \u00018, following Dong et al.\n(2019).\nWe evaluate DeBERTa on the task of auto-regressive language model (ARLM) using Wikitext-\n103 (Merity et al., 2016). To do so, we train a new version of DeBERTa, denoted as DeBERTa-MT."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "It is jointly pre-trained using the MLM and ARLM tasks as in UniLM (Dong et al., 2019). The\npre-training hyper-parameters follows that of DeBERTa baseexcept that we use fewer training steps\n(200k). For comparison, we use RoBERTa as baseline, and include GPT-2 and Transformer-XL as\nadditional references. DeBERTa-AP is a variant of DeBERTa where absolute position embeddings"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "are incorporated in the input layer as RoBERTa. For a fair comparison, all these models are base\nmodels pre-trained in a similar setting.\nModel RoBERTa DeBERTa-AP DeBERTa DeBERTa-MT GPT-2 Transformer-XL\nDev PPL 21.6 20.7 20.5 19.5 - 23.1\nTest PPL 21.6 20.0 19.9 19.5 37.50 24\nTable 10: Language model results in perplexity (lower is better) on Wikitext-103 ."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Table 10 summarizes the results on Wikitext-103. We see that DeBERTa baseobtains lower perplexities\non both dev and test data, and joint training using MLM and ARLM reduces perplexity further.\nThat DeBERTa-AP is inferior to DeBERTa indicates that it is more effective to incorporate absolute\nposition embeddings of words in the decoding layer as the EMD in DeBERTa than in the input layer"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "as RoBERTa.\nA.5 H ANDLING LONG SEQUENCE INPUT\nWith relative position bias, we choose to truncate the maximum relative distance to kas in equation 3.\nThus in each layer, each token can attend directly to at most 2pk\u00011qtokens and itself. By stacking\nTransformer layers, each token in the l\u0001th layer can attend to at most p2k\u00011qltokens implicitly."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Taking DeBERTa large as an example, where k\u0010512;L\u001024, in theory, the maximum sequence\nlength that can be handled is 24,528. This is a byproduct bene\ufb01t of our design choice and we \ufb01nd it\nbene\ufb01cial for the RACE task. A comparison of long sequence effect on the RACE task is shown in\nTable 11.\nSequence length Middle High Accuracy\n512 88.8 85.0 86.3\n768 88.7 86.3 86.8"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "512 88.8 85.0 86.3\n768 88.7 86.3 86.8\nTable 11: The effect of handling long sequence input for RACE task with DeBERTa\nLong sequence handling is an active research area. There have been a lot of studies where the\nTransformer architecture is extended for long sequence handling(Beltagy et al., 2020; Kitaev et al.,"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "2019; Child et al., 2019; Dai et al., 2019). One of our future research directions is to extend DeBERTa\nto deal with extremely long sequences.\nA.6 P ERFORMANCE IMPROVEMENTS OF DIFFERENT MODEL SCALES\nIn this subsection, we study the effect of different model sizes applied to large models on GLUE.\nTable 12 summarizes the results, showing that larger models can obtain a better result and SiFT also"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "improves the model performance consistently.\n17Published as a conference paper at ICLR 2021\nModelCoLA QQP MNLI-m/mm SST-2 STS-B QNLI RTE MRPC Avg.\nMcc Acc Acc Acc Corr Acc Acc Acc\nDeBERTa large 70.5 92.3 91.1/91.1 96.8 92.8 95.3 88.3 91.9 90.00\nDeBERTa 900M 71.1 92.3 91.7/91.6 97.5 92.0 95.8 93.5 93.1 90.86\nDeBERTa 1:5B 72.0 92.7 91.7/91.9 97.2 92.9 96.0 93.9 92.0 91.17"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "DeBERTa 1:5B+SiFT 73.5 93.0 92.0/92.1 97.5 93.2 96.5 96.5 93.2 91.93\nTable 12: Comparison results of DeBERTa models with different sizes on the GLUE development set.\nModel Parameters MNLI-m/mm SQuAD v1.1 SQuAD v2.0\nAcc F1/EM F1/EM\nRoBERTa-ReImp base 120M 84.9/85.1 91.1/84.8 79.5/76.0\nDeBERTa base 134M 86.3/86.2 92.1/86.1 82.5/79.3\n+ ShareProjection 120M 86.3/86.3 92.2/86.2 82.3/79.5"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "+ Conv 122M 86.3/86.5 92.5/86.4 82.5/79.7\n+ 128k V ocab 190M 86.7/86.9 93.1/86.8 83.0/80.1\nTable 13: Ablation study of the additional modi\ufb01cations in DeBERTa 1:5Band DeBERTa 900Mmodels.\nNote that we progressively add each component on the top of DeBERTa base.\nA.7 M ODEL COMPLEXITY\nWith the disentangled attention mechanism, we introduce three additional sets of parameters"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Wq;r;Wk;rPRd\u0002dandPPR2k\u0002d. The total increase in model parameters is 2L\u0002d2\u00002k\u0002d.\nFor the large model pd\u00101024;L\u001024;k\u0010512q, this amounts to about 49Madditional parameters,\nan increase of 13%. For the base model pd\u0010768;L\u001012;k\u0010512q, this amounts to 14Madditional\nparameters, an increase of 12%. However, by sharing the projection matrix between content and"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "position embedding, i.e. Wq;r\u0010Wq;c;Wk;r\u0010Wk;c, the number of parameters of DeBERTa is\nthe same as RoBERTa. Our experiment on base model shows that the results are almost the same, as\nin Table 13.\nThe additional computational complexity is OpNkdqdue to the calculation of the additional position-\nto-content andcontent-to-position attention scores. Compared with BERT or RoBERTa, this increases"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "the computational cost by 30%. Compared with XLNet which also uses relative position embedding,\nthe increase of computational cost is about 15%. A further optimization by fusing the attention\ncomputation kernel can signi\ufb01cantly reduce this additional cost. For EMD , since the decoder in\npre-training only reconstructs the masked tokens, it does not introduce additional computational cost"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "for unmasked tokens. In the situation where 15% tokens are masked and we use only two decoder\nlayers, the additional cost is 0:15\u00022{Lwhich results in an additional computational cost of only 3%\nfor base model( L\u001012) and 2%for large model( L\u001024) in EMD.\nA.8 A DDITIONAL DETAILS OF ENHANCED MASK DECODER\nThe structure of EMD is shown in Figure 2b. There are two inputs for EMD, (i.e., I;H ).Hdenotes"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "the hidden states from the previous Transformer layer, and Ican be any necessary information for\ndecoding, e.g., H, absolute position embedding or output from previous EMD layer. ndenotesn\nstacked layers of EMD where the output of each EMD layer will be the input Ifor next EMD layer\nand the output of last EMD layer will be fed to the language model head directly. The nlayers can"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "share the same weight. In our experiment we share the same weight for n\u00102layers to reduce the\nnumber of parameters and use absolute position embedding as Iof the \ufb01rst EMD layer. When I\u0010H\nandn\u00101, EMD is the same as the BERT decoder layer. However, EMD is more general and \ufb02exible\nas it can take various types of input information for decoding.\nA.9 A TTENTION PATTERNS"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "A.9 A TTENTION PATTERNS\nTo visualize how DeBERTa operates differently from RoBERTa, we present in Figure 3 the attention\npatterns (taken in the last self-attention layers) of RoBERTa, DeBERTa and three DeBERTa variants.\n18Published as a conference paper at ICLR 2021\nLanguage Model Head\nK V Q\nHTransformer Layer\n(a) BERT decoding layer\nLanguage Model Head\nX n\nK V Q"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Language Model Head\nX n\nK V Q\nHITransformer Layer (b) Enhanced Mask Decoder\nFigure 2: Comparison of the decoding layer.\nFigure 3: Comparison of attention patterns of the last layer among DeBERTa, RoBERTa and DeBERTa\nvariants (i.e., DeBERTa without EMD, C2P and P2C respectively).\nWe observe two differences. First, RoBERTa has a clear diagonal line effect for a token attending to"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "itself. But this effect is not very visible in DeBERTa. This can be attributed to the use of EMD, in\nwhich the absolute position embedding is added to the hidden state of content as the query vector,\nas veri\ufb01ed by the attention pattern of DeBERTa-EMD where the diagonal line effect is more visible\nthan that of the original DeBERTa. Second, we observe vertical strips in the attention patterns of"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "RoBERTa, which are mainly caused by high-frequent functional words or tokens (e.g., \u201ca\u201d, \u201cthe\u201d, and\npunctuation). For DeBERTa, the strip only appears in the \ufb01rst column, which represents the [CLS]\ntoken. We conjecture that a dominant emphasis on [CLS] is desirable since the feature vector of\n[CLS] is often used as a contextual representation of the entire input sequence in downstream tasks."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "We also observe that the vertical strip effect is quite obvious in the patterns of the three DeBERTa\nvariants.\nWe present three additional examples to illustrate the different attention patterns of DeBERTa and\nRoBERTa in Figures 4 and 5.\n19Published as a conference paper at ICLR 2021\n(a)\n(b)\n(c)\nFigure 4: Comparison on attention patterns of the last layer between DeBERTa and RoBERTa."}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "20Published as a conference paper at ICLR 2021\n(a)\n(b)\n(c)\nFigure 5: Comparison on attention patterns of last layer between DeBERTa and its variants (i.e.\nDeBERTa without EMD, C2P and P2C respectively).\nA.10 A CCOUNT FOR THE VARIANCE IN FINE-TUNING\nAccounting for the variance of different runs of \ufb01ne-tuning, in our experiments, we always follow"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "Liu et al. (2019c) to report the results on downstream tasks by averaging over \ufb01ve runs with different\nrandom initialization seeds, and perform signi\ufb01cance test when comparing results. As the examples\nshown in Table 14, DeBERTa basesigni\ufb01cantly outperforms RoBERTa base(p-value < 0.05).\nModel MNLI-matched (Min/Max/Avg) SQuAD v1.1 (Min/Max/Avg) p-value"}, {"source": "3690_deberta_decoding_enhanced_bert.pdf", "text": "RoBERTa base 84.7/85.0/84.9 90.8/91.3/91.1 0.02\nDeBERTa base 86.1/86.5/86.3 91.8/92.2/92.1 0.01\nTable 14: Comparison of DeBERTa and RoBERTa on MNLI-matched and SQuAD v1.1.\n21"}]